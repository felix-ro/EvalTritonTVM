Using cache found in /home/fjr38/.cache/torch/hub/pytorch_vision_v0.10.0
/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[2023-12-28 21:22:49,533] [0/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:284
[2023-12-28 21:22:49,537] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:284
[2023-12-28 21:22:49,537] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:49,558] [0/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (64, 3, 224, 224) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]
[2023-12-28 21:22:49,559] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:285
[2023-12-28 21:22:49,559] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return self._forward_impl(x)
[2023-12-28 21:22:49,559] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,559] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_impl [NNModuleVariable()]
[2023-12-28 21:22:49,560] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserMethodVariable(<function ResNet._forward_impl at 0x7fa091c60af0>, NNModuleVariable())]
[2023-12-28 21:22:49,560] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserMethodVariable(<function ResNet._forward_impl at 0x7fa091c60af0>, NNModuleVariable()), TensorVariable()]
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _forward_impl at 0x7fa091c39df0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 266>
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 268           0 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               4 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 269          10 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              14 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 270          20 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              24 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 271          30 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 LOAD_METHOD              3 (maxpool)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              34 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 273          40 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 LOAD_METHOD              4 (layer1)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              44 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 274          50 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 LOAD_METHOD              5 (layer2)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              54 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 275          60 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 LOAD_METHOD              6 (layer3)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              64 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 276          70 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 LOAD_METHOD              7 (layer4)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              74 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 278          80 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 LOAD_METHOD              8 (avgpool)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              84 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 279          90 LOAD_GLOBAL              9 (torch)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 LOAD_METHOD             10 (flatten)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              94 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_CONST               1 (1)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 CALL_METHOD              2
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 280         102 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             104 LOAD_METHOD             11 (fc)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 CALL_METHOD              1
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 282         112 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 RETURN_VALUE
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:266 (inline depth: 1)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _forward_impl(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:268 (inline depth: 1)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:49,562] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,562] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,566] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:49,566] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:269 (inline depth: 1)
[2023-12-28 21:22:49,566] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)
[2023-12-28 21:22:49,566] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,567] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:49,567] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,567] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,583] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:49,583] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:270 (inline depth: 1)
[2023-12-28 21:22:49,583] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.relu(x)
[2023-12-28 21:22:49,583] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,584] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,584] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,584] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,585] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:49,585] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:271 (inline depth: 1)
[2023-12-28 21:22:49,585] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.maxpool(x)
[2023-12-28 21:22:49,586] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,586] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR maxpool [NNModuleVariable()]
[2023-12-28 21:22:49,586] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,586] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,587] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:49,588] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:273 (inline depth: 1)
[2023-12-28 21:22:49,588] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.layer1(x)
[2023-12-28 21:22:49,588] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,588] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer1 [NNModuleVariable()]
[2023-12-28 21:22:49,589] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,589] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:49,592] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,594] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:49,594] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:49,594] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:49,594] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:49,594] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:49,594] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:49,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:49,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:49,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:49,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,596] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,596] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,597] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,597] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,597] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,597] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,597] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:49,600] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:49,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,604] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,604] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:49,604] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:49,604] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,604] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:49,605] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,605] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,618] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,618] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:49,618] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,618] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,618] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,618] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,619] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,620] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:49,620] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:49,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:49,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,623] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,623] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:49,623] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:49,623] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,623] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:49,624] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,624] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,636] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,636] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:49,636] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,637] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,637] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,637] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,637] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,638] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,638] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:49,638] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:49,638] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,638] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:49,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,641] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:49,641] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:49,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,642] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:49,642] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,642] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,655] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,655] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:49,655] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:49,655] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,655] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:49,656] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [NNModuleVariable()]
[2023-12-28 21:22:49,656] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [NNModuleVariable(), ConstantVariable(NoneType)]
[2023-12-28 21:22:49,656] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:49,656] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158 (inline depth: 3)
[2023-12-28 21:22:49,656] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 identity = self.downsample(x)
[2023-12-28 21:22:49,656] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,656] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:49,657] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,657] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,672] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,672] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:49,672] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:49,672] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,672] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,672] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:49,673] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,673] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:49,673] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,673] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,673] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,674] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,674] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,675] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,675] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:49,675] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:49,675] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,675] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,675] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,675] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,675] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:49,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,680] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:49,680] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:49,680] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:49,680] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:49,680] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:49,681] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:49,681] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:49,681] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:49,681] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,681] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,682] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:49,682] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,682] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,682] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,682] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,682] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,682] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,684] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:49,685] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:49,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:49,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,688] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,690] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,690] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:49,690] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:49,690] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,690] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:49,691] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,691] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,704] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,704] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:49,704] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,704] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,704] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,704] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,704] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,705] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,706] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:49,706] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:49,706] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,706] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:49,706] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,706] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,709] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,709] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:49,709] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:49,709] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,709] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:49,709] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,709] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,722] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,722] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:49,722] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,722] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,722] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,723] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,723] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,724] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,724] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:49,724] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:49,724] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,724] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:49,724] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,724] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,727] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,727] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:49,727] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:49,727] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,727] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:49,728] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,728] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,740] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,741] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,742] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:49,742] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,742] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:49,742] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,742] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,743] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,743] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,743] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,744] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,744] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:49,744] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:49,744] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,744] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,744] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,745] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,745] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:49,747] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,749] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:49,749] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:49,750] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:49,750] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:49,750] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:49,750] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:49,750] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:49,750] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:49,751] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,751] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,751] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:49,751] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,751] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,751] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,751] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,751] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,753] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,753] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,753] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,753] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:49,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:49,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,759] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,759] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:49,759] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:49,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:49,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,773] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,773] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:49,773] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,773] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,773] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,774] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,774] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,775] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,775] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:49,775] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:49,775] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,775] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:49,775] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,775] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,778] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,778] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:49,778] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:49,778] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,778] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:49,779] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,779] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,791] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,791] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:49,791] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,791] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,793] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,793] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:49,793] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:49,793] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,793] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:49,794] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,794] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,796] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,796] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:49,796] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:49,797] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,797] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:49,797] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,797] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,810] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:49,810] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:49,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:49,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,811] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:49,811] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:49,811] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:49,811] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:49,811] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,811] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,811] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:49,812] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,812] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:49,812] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,812] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,812] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,812] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,812] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:274 (inline depth: 1)
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.layer2(x)
[2023-12-28 21:22:49,814] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,815] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer2 [NNModuleVariable()]
[2023-12-28 21:22:49,815] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,815] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:49,818] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,820] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:49,820] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:49,820] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:49,820] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:49,820] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:49,821] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:49,821] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:49,821] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:49,821] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,821] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,822] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:49,822] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,822] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,822] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,822] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,822] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,822] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,823] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,823] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,823] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,823] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,823] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,824] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,824] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,824] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,824] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,825] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:49,826] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:49,827] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,828] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:49,828] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:49,828] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,828] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:49,828] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,828] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,831] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,831] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:49,831] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:49,831] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,831] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:49,831] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,831] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,844] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,844] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:49,844] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,844] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,844] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,845] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,845] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,846] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,846] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:49,846] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:49,846] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,846] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:49,847] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,847] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,850] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,850] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:49,850] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:49,850] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,850] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:49,850] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,850] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,863] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,863] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:49,863] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,863] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,863] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,864] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,864] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,865] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,865] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:49,865] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:49,865] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,865] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:49,866] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,866] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,868] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,868] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:49,868] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:49,868] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,868] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:49,869] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,869] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,882] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,882] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:49,882] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:49,882] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,882] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:49,882] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [NNModuleVariable()]
[2023-12-28 21:22:49,882] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [NNModuleVariable(), ConstantVariable(NoneType)]
[2023-12-28 21:22:49,883] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:49,883] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158 (inline depth: 3)
[2023-12-28 21:22:49,883] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 identity = self.downsample(x)
[2023-12-28 21:22:49,883] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,883] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:49,883] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,883] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,899] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,899] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:49,899] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:49,899] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,899] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,899] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:49,900] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,900] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:49,900] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,900] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,900] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,900] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,901] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,902] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,902] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:49,902] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:49,902] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,902] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,902] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,902] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,902] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:49,905] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,907] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:49,907] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:49,907] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:49,907] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:49,907] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:49,908] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:49,908] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:49,908] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:49,908] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,908] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,909] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:49,909] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,909] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,909] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,909] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,909] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,910] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,910] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,910] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,910] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,910] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,910] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,911] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,911] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,911] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,912] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:49,913] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:49,914] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:49,915] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,915] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:49,915] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:49,915] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,915] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:49,915] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,915] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,918] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,918] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:49,918] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:49,918] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,918] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:49,918] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,919] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,931] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,931] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:49,931] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,932] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,932] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,932] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,932] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,933] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,933] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:49,933] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:49,934] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,934] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:49,934] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,934] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,937] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,937] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:49,937] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:49,937] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,937] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:49,937] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,937] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,950] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,950] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:49,950] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,950] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,950] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,951] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,951] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,952] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,952] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:49,952] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:49,952] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,952] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:49,953] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,953] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,955] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,955] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:49,955] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:49,955] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,956] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:49,956] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,956] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,969] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,969] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:49,969] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:49,969] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,969] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:49,969] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,970] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:49,970] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:49,970] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:49,970] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:49,970] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,970] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,970] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:49,971] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,971] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:49,971] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:49,971] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,971] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:49,972] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,972] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,973] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,973] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:49,973] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:49,973] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:49,973] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,973] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,973] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:49,973] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:49,976] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,978] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:49,978] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:49,978] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:49,978] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:49,979] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:49,979] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:49,979] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:49,979] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:49,980] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:49,980] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,980] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:49,980] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,980] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,980] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,980] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,980] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,981] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,981] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,981] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,981] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,981] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,982] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,982] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,982] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,982] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,983] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:49,984] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:49,985] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:49,986] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:49,989] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:49,989] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:49,989] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:49,989] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:49,989] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:49,990] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:49,990] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,002] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,003] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,003] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,003] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,003] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,003] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,003] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,004] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,005] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,005] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,005] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,005] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,005] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,005] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,008] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,008] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,008] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,008] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,008] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,008] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,009] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,021] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,021] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,021] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,021] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,022] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,022] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,022] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,023] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,023] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,023] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,023] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,023] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,024] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,024] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,026] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,027] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,027] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,027] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,027] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,027] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,027] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,040] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,040] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,040] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,040] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,040] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,041] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,041] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,041] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,041] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,041] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,041] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,041] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,041] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,042] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,042] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,042] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,043] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,043] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,043] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,043] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,044] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,044] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,044] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,044] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,045] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,045] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,045] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,045] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,048] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,050] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,050] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,050] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,050] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,050] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,050] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,051] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,051] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,051] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,051] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,051] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,052] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,052] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,052] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,052] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,052] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,052] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,052] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,052] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,053] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,053] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,053] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,053] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,054] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,054] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,054] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,054] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,054] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,054] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,055] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,056] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,056] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,056] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,056] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,056] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,056] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,056] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,057] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,058] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,058] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,058] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,061] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,061] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,061] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,061] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,061] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,061] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,061] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,075] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,075] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,075] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,075] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,075] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,076] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,076] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,077] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,077] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,077] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,077] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,077] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,078] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,078] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,080] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,080] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,080] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,081] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,081] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,081] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,081] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,094] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,094] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,094] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,094] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,094] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,094] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,095] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,096] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,096] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,096] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,096] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,096] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,096] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,097] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,099] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,099] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,099] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,099] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,099] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,100] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,100] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,113] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,113] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,113] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,113] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,113] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,113] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,113] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,113] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,114] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,114] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,114] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,114] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,114] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,115] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,115] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,115] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,115] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,115] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,115] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,116] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,117] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,117] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,117] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,117] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,117] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,117] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,117] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,117] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,118] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:50,118] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:275 (inline depth: 1)
[2023-12-28 21:22:50,118] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.layer3(x)
[2023-12-28 21:22:50,118] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,118] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer3 [NNModuleVariable()]
[2023-12-28 21:22:50,119] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,119] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,122] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,124] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,124] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,124] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,124] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,124] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,124] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,125] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,125] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,125] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,125] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,125] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,126] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,126] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,126] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,126] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,126] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,126] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,126] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,127] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,127] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,127] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,127] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,128] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,128] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,128] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,129] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,130] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,131] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,132] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,135] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,135] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,135] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,135] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,135] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,136] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,136] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,149] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,149] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,149] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,149] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,149] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,149] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,149] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,151] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,151] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,151] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,151] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,151] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,151] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,152] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,154] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,154] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,154] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,154] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,154] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,155] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,155] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,168] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,168] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,168] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,168] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,168] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,168] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,168] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,170] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,170] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,170] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,170] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,170] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,170] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,170] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,173] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,173] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,173] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,173] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,173] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,174] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,174] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,187] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,187] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,187] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,187] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,187] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,187] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [NNModuleVariable()]
[2023-12-28 21:22:50,188] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [NNModuleVariable(), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,188] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,188] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158 (inline depth: 3)
[2023-12-28 21:22:50,188] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 identity = self.downsample(x)
[2023-12-28 21:22:50,188] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,188] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,189] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,189] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,204] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,204] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,204] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,204] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,204] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,204] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,205] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,205] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,205] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,206] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,206] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,206] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,206] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,207] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,207] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,207] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,207] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,208] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,208] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,208] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,208] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,211] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,213] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,213] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,213] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,213] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,213] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,213] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,214] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,214] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,214] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,214] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,214] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,215] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,215] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,215] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,215] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,215] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,215] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,216] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,216] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,216] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,216] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,216] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,217] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,217] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,217] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,218] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,219] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,220] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,221] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,222] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,222] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,224] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,225] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,225] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,225] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,225] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,225] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,225] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,238] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,238] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,238] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,238] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,238] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,239] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,239] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,240] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,240] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,240] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,240] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,240] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,241] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,241] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,244] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,244] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,244] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,244] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,244] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,244] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,244] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,257] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,257] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,257] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,257] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,257] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,258] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,258] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,259] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,259] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,259] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,259] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,260] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,260] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,260] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,263] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,263] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,263] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,263] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,263] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,263] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,263] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,276] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,276] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,276] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,277] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,277] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,277] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,277] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,277] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,278] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,278] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,278] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,278] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,278] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,279] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,279] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,279] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,279] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,279] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,279] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,279] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,281] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,281] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,281] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,281] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,281] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,281] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,281] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,281] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,284] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,287] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,287] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,287] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,287] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,287] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,287] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,287] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,287] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,288] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,288] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,288] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,288] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,288] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,288] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,288] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,288] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,289] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,289] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,289] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,290] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,290] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,290] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,290] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,291] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,291] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,291] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,292] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,293] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,294] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,295] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,298] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,298] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,298] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,298] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,298] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,299] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,299] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,312] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,312] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,312] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,312] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,312] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,312] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,313] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,314] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,314] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,314] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,314] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,314] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,315] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,315] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,317] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,317] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,317] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,318] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,318] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,318] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,318] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,331] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,331] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,331] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,331] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,331] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,331] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,332] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,333] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,333] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,333] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,333] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,333] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,334] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,334] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,336] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,336] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,336] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,336] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,337] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,337] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,337] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,350] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,350] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,350] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,350] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,350] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,351] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,351] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,351] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,351] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,351] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,351] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,351] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,351] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,352] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,352] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,352] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,353] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,353] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,353] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,353] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,354] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,354] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,354] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,355] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,355] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,355] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,355] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,355] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,358] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,360] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,360] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,360] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,360] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,360] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,361] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,361] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,361] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,361] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,361] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,361] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,362] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,362] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,362] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,362] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,362] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,362] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,363] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,363] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,363] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,364] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,364] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,364] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,364] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,364] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,365] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,366] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,367] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,367] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,368] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,369] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,369] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,372] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,372] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,372] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,372] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,372] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,372] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,372] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,385] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,386] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,386] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,386] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,386] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,386] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,386] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,388] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,388] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,388] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,388] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,388] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,388] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,388] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,391] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,391] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,391] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,391] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,391] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,392] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,392] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,405] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,405] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,405] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,405] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,405] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,405] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,405] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,407] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,407] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,407] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,407] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,407] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,407] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,407] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,410] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,410] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,410] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,410] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,410] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,411] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,411] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,424] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,424] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,424] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,424] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,424] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,425] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,425] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,425] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,425] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,425] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,425] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,425] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,425] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,426] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,427] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,427] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,427] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,427] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,427] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,427] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,429] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,429] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,429] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,429] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,429] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,429] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,429] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,429] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,432] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,434] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,434] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,434] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,434] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,435] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,435] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,435] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,435] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,436] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,436] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,436] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,436] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,436] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,436] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,436] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,436] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,437] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,437] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,437] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,437] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,438] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,438] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,438] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,439] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,439] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,439] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,439] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,439] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,439] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,440] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,441] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,441] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,441] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,441] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,441] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,441] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,442] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,443] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,443] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,443] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,443] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,443] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,443] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,443] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,443] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,446] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,446] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,446] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,446] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,446] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,447] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,447] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,460] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,460] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,460] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,460] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,460] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,460] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,460] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,462] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,462] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,462] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,462] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,462] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,462] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,463] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,465] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,465] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,465] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,465] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,465] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,466] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,466] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,479] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,479] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,479] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,479] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,479] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,479] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,479] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,481] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,481] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,481] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,481] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,481] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,481] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,482] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,484] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,484] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,484] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,484] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,485] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,485] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,485] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,498] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,498] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,498] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,498] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,498] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,499] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,499] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,499] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,499] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,499] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,499] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,499] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,499] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,500] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,500] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,500] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,501] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,501] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,501] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,501] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,502] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,503] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,503] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,503] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,503] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,503] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,503] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,503] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,506] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,508] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,508] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,508] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,508] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,509] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,509] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,509] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,509] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,510] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,510] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,510] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,510] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,510] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,510] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,510] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,510] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,511] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,511] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,511] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,511] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,512] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,512] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,512] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,512] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,513] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,513] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,514] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,515] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,516] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,517] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,520] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,528] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,528] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,528] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,528] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,529] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,529] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,542] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,542] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,542] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,542] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,542] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,542] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,543] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,544] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,544] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,544] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,544] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,544] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,545] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,545] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,548] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,548] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,548] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,548] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,548] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,548] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,548] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,561] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,561] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,561] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,562] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,562] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,562] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,563] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,564] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,564] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,564] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,564] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,564] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,564] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,567] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,567] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,567] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,567] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,567] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,568] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,568] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,581] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,581] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,581] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,581] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,581] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,581] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,581] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,581] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,582] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,582] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,582] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,582] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,582] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,583] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,583] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,583] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,583] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,583] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,584] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,584] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,585] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,585] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,585] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,585] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,585] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,585] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,586] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,586] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,586] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:50,586] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:276 (inline depth: 1)
[2023-12-28 21:22:50,586] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.layer4(x)
[2023-12-28 21:22:50,587] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,587] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer4 [NNModuleVariable()]
[2023-12-28 21:22:50,587] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,587] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,590] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,592] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,592] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,593] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,593] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,593] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,593] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,593] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,593] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,594] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,594] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,594] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,594] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,594] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,594] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,594] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,594] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,595] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,596] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,597] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,597] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,597] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,598] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,599] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,601] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,602] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,605] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,605] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,605] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,605] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,605] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,606] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,606] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,619] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,619] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,619] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,619] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,619] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,619] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,620] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,621] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,621] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,621] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,621] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,621] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,622] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,622] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,625] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,625] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,625] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,625] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,625] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,625] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,626] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,639] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,639] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,639] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,641] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,641] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,641] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,644] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,644] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,644] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,644] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,645] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,645] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,645] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,658] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,658] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,658] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,658] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,658] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,659] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [NNModuleVariable()]
[2023-12-28 21:22:50,659] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [NNModuleVariable(), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,659] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,659] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158 (inline depth: 3)
[2023-12-28 21:22:50,659] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 identity = self.downsample(x)
[2023-12-28 21:22:50,659] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,660] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,660] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,660] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,676] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,676] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,676] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,676] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,676] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,676] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,677] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,677] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,677] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,677] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,678] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,680] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,680] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,680] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,680] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,680] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,680] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,680] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,680] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,683] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,686] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,686] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,686] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,686] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,686] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,687] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,687] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,687] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,688] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,688] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,688] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,689] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,689] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,689] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,689] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,690] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,690] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,690] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,691] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,691] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,691] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,691] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,691] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,691] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,692] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,693] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,693] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,693] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,693] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,694] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,695] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,698] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,698] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,698] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,698] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,699] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,699] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,699] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,712] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,712] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,712] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,712] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,712] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,713] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,713] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,714] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,714] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,714] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,714] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,715] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,715] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,715] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,718] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,718] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,718] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,718] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,718] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,719] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,719] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,732] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,732] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,732] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,732] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,732] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,732] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,733] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,734] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,734] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,734] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,734] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,734] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,735] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,735] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,738] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,738] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,738] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,738] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,738] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,738] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,738] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,751] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,751] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,751] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,752] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,753] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,753] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,753] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,753] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,753] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,754] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,754] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,755] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,756] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,756] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,756] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,757] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1521           0 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                2 LOAD_ATTR                1 (_C)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                4 LOAD_METHOD              2 (_get_tracing_state)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                6 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]                8 POP_JUMP_IF_FALSE       16
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               10 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               12 LOAD_ATTR                3 (_slow_forward)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               14 JUMP_FORWARD             4 (to 20)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   16 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               18 LOAD_ATTR                4 (forward)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>   20 STORE_FAST               3 (forward_call)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          22 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               24 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               26 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               28 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               30 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               32 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               36 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               38 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               40 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               42 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               44 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          46 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          48 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1525          50 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          52 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          54 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          56 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1526          58 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1524          60 POP_JUMP_IF_TRUE        72
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1527          62 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               64 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               66 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               68 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               70 RETURN_VALUE
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1529     >>   72 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               74 SETUP_FINALLY          598 (to 674)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1530          76 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               78 STORE_FAST               4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1531          80 LOAD_GLOBAL             13 (set)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               82 CALL_FUNCTION            0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               84 STORE_FAST               5 (called_always_called_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1533          86 BUILD_LIST               0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               88 BUILD_LIST               0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               90 ROT_TWO
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               92 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               94 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1534          96 BUILD_LIST               0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               98 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1535         100 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              102 LOAD_ATTR                6 (_backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              104 POP_JUMP_IF_TRUE       110
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              106 LOAD_GLOBAL              9 (_global_backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              108 POP_JUMP_IF_FALSE      118
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1536     >>  110 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              112 LOAD_METHOD             14 (_get_backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              114 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              116 STORE_FAST               8 (backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1538     >>  118 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              120 LOAD_ATTR                5 (_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              122 POP_JUMP_IF_TRUE       128
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              124 LOAD_GLOBAL             10 (_global_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              126 POP_JUMP_IF_FALSE      140
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1539     >>  128 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              130 LOAD_METHOD             15 (_get_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              132 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              134 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              136 STORE_FAST               6 (full_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              138 STORE_FAST               7 (non_full_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1541     >>  140 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              142 POP_JUMP_IF_TRUE       152
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              144 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              146 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              148 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              150 POP_JUMP_IF_FALSE      304
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1543     >>  152 LOAD_GLOBAL             12 (_global_forward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              154 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              156 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1544         158 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              160 LOAD_ATTR                8 (_forward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              162 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              164 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1542         166 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              168 GET_ITER
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  170 FOR_ITER               132 (to 304)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              172 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              174 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              176 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1546         178 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              180 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              182 LOAD_ATTR               17 (_forward_pre_hooks_with_kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              184 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              186 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              188 POP_JUMP_IF_FALSE      262
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1547         190 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              192 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              194 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              196 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              198 CALL_FUNCTION            3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              200 STORE_FAST              11 (args_kwargs_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1548         202 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              204 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              206 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              208 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              210 POP_JUMP_IF_FALSE      302
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1549         212 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              214 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              216 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              218 CALL_FUNCTION            2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              220 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              222 LOAD_GLOBAL             20 (len)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              224 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              226 CALL_FUNCTION            1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              228 LOAD_CONST               1 (2)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              230 COMPARE_OP               2 (==)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              232 POP_JUMP_IF_FALSE      244
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1550         234 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              236 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              238 STORE_FAST               1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              240 STORE_FAST               2 (kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              242 JUMP_FORWARD            16 (to 260)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552     >>  244 LOAD_GLOBAL             21 (RuntimeError)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1553         246 LOAD_CONST               2 ('forward pre-hook must return None or a tuple of (new_args, new_kwargs), but got ')
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              248 LOAD_FAST               11 (args_kwargs_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              250 FORMAT_VALUE             0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              252 LOAD_CONST               3 ('.')
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              254 BUILD_STRING             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1552         256 CALL_FUNCTION            1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              258 RAISE_VARARGS            1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  260 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1557     >>  262 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              264 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              266 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              268 CALL_FUNCTION            2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              270 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1558         272 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              274 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              276 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              278 POP_JUMP_IF_FALSE      170
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1559         280 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              282 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              284 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              286 CALL_FUNCTION            2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              288 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              290 POP_JUMP_IF_TRUE       298
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1560         292 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              294 BUILD_TUPLE              1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              296 STORE_FAST              12 (args_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1561     >>  298 LOAD_FAST               12 (args_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              300 STORE_FAST               1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  302 JUMP_ABSOLUTE          170
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1563     >>  304 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              306 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1564         308 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              310 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              312 POP_JUMP_IF_TRUE       320
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              314 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              316 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              318 POP_JUMP_IF_FALSE      344
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1565     >>  320 LOAD_GLOBAL             22 (hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              322 LOAD_METHOD             23 (BackwardHook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              324 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              326 LOAD_FAST                6 (full_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              328 LOAD_FAST                8 (backward_pre_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              330 CALL_METHOD              3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              332 STORE_FAST              13 (bw_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1566         334 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              336 LOAD_METHOD             24 (setup_input_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              338 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              340 CALL_METHOD              1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              342 STORE_FAST               1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1568     >>  344 LOAD_FAST                3 (forward_call)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              346 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              348 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              350 CALL_FUNCTION_EX         1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              352 STORE_FAST               4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1569         354 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              356 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              358 POP_JUMP_IF_TRUE       368
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              360 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              362 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              364 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              366 POP_JUMP_IF_FALSE      484
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1571     >>  368 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              370 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              372 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1572         374 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              376 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              378 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              380 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1570         382 BUILD_TUPLE_UNPACK       2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              384 GET_ITER
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  386 FOR_ITER                96 (to 484)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              388 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              390 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              392 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1575         394 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              396 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              398 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              400 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              402 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              404 POP_JUMP_IF_TRUE       416
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              406 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              408 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              410 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              412 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              414 POP_JUMP_IF_FALSE      426
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1576     >>  416 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              418 LOAD_METHOD             27 (add)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              420 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              422 CALL_METHOD              1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              424 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1578     >>  426 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              428 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              430 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              432 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              434 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              436 POP_JUMP_IF_FALSE      454
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1579         438 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              440 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              442 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              444 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              446 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              448 CALL_FUNCTION            4
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              450 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              452 JUMP_FORWARD            12 (to 466)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1581     >>  454 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              456 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              458 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              460 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              462 CALL_FUNCTION            3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              464 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1583     >>  466 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              468 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              470 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              472 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              474 POP_JUMP_IF_FALSE      386
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1584         476 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              478 STORE_FAST               4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              480 EXTENDED_ARG             1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              482 JUMP_ABSOLUTE          386
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1586     >>  484 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              486 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              488 POP_JUMP_IF_FALSE      538
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1587         490 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              492 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              494 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              496 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              498 LOAD_GLOBAL             19 (tuple)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              500 BUILD_TUPLE              2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              502 CALL_FUNCTION            2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              504 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              506 POP_JUMP_IF_TRUE       528
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1588         508 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              510 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              512 LOAD_CONST               4 ('For backward hooks to be called, module output should be a Tensor or a tuple of Tensors but received ')
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              514 LOAD_GLOBAL             32 (type)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              516 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              518 CALL_FUNCTION            1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              520 FORMAT_VALUE             0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              522 BUILD_STRING             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              524 CALL_METHOD              1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              526 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1591     >>  528 LOAD_FAST               13 (bw_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              530 LOAD_METHOD             33 (setup_output_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              532 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              534 CALL_METHOD              1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              536 STORE_FAST               4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1594     >>  538 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              540 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              542 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1595         544 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              546 STORE_FAST              15 (var)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1596     >>  548 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              550 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              552 LOAD_GLOBAL              0 (torch)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              554 LOAD_ATTR               29 (Tensor)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              556 CALL_FUNCTION            2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              558 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              560 POP_JUMP_IF_TRUE       610
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1597         562 LOAD_GLOBAL             18 (isinstance)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              564 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              566 LOAD_GLOBAL             34 (dict)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              568 CALL_FUNCTION            2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              570 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              572 POP_JUMP_IF_FALSE      598
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1598         574 LOAD_GLOBAL             35 (next)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              576 LOAD_CONST               5 (<code object <genexpr> at 0x7fa096bb12f0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1598>)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              578 LOAD_CONST               6 ('Module._call_impl.<locals>.<genexpr>')
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              580 MAKE_FUNCTION            0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              582 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              584 LOAD_METHOD             36 (values)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              586 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              588 GET_ITER
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              590 CALL_FUNCTION            1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              592 CALL_FUNCTION            1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              594 STORE_FAST              15 (var)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              596 JUMP_FORWARD             8 (to 606)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1600     >>  598 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              600 LOAD_CONST               7 (0)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              602 BINARY_SUBSCR
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              604 STORE_FAST              15 (var)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  606 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              608 JUMP_ABSOLUTE          548
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1601     >>  610 LOAD_FAST               15 (var)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              612 LOAD_ATTR               37 (grad_fn)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              614 STORE_FAST              16 (grad_fn)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1602         616 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              618 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              620 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              622 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              624 POP_JUMP_IF_FALSE      668
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1603         626 LOAD_FAST                7 (non_full_backward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              628 GET_ITER
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  630 FOR_ITER                22 (to 654)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              632 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1604         634 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              636 LOAD_METHOD             38 (register_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              638 LOAD_GLOBAL             39 (_WrappedHook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              640 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              642 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              644 CALL_FUNCTION            2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              646 CALL_METHOD              1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              648 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              650 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              652 JUMP_ABSOLUTE          630
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1605     >>  654 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              656 LOAD_METHOD             40 (_maybe_warn_non_full_backward_hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              658 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              660 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              662 LOAD_FAST               16 (grad_fn)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              664 CALL_METHOD              3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              666 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1607     >>  668 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              670 POP_BLOCK
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              672 RETURN_VALUE
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1609     >>  674 DUP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              676 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              678 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              680 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              682 POP_JUMP_IF_FALSE     1004
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              684 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              686 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              688 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1613         690 LOAD_GLOBAL             11 (_global_forward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              692 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              694 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              696 GET_ITER
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  698 FOR_ITER               128 (to 828)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              700 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              702 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              704 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1614         706 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              708 LOAD_GLOBAL             26 (_global_forward_hooks_always_called)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              710 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              712 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              714 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              716 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              718 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              720 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              722 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              724 POP_JUMP_IF_FALSE      698
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1615         726 SETUP_FINALLY           30 (to 758)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1616         728 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              730 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              732 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              734 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              736 CALL_FUNCTION            3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              738 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1617         740 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              742 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              744 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              746 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              748 POP_JUMP_IF_FALSE      754
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1618         750 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              752 STORE_FAST               4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  754 POP_BLOCK
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              756 JUMP_FORWARD            66 (to 824)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1619     >>  758 DUP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              760 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              762 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              764 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              766 POP_JUMP_IF_FALSE      822
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              768 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              770 STORE_FAST              17 (e)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              772 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              774 SETUP_FINALLY           34 (to 810)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1620         776 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              778 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              780 LOAD_CONST               8 ('global module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              782 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              784 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              786 CALL_FUNCTION            1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              788 FORMAT_VALUE             0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              790 BUILD_STRING             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              792 CALL_METHOD              1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              794 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1622         796 POP_BLOCK
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              798 POP_EXCEPT
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              800 CALL_FINALLY             8 (to 810)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              802 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              804 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              806 POP_BLOCK
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              808 BEGIN_FINALLY
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  810 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              812 STORE_FAST              17 (e)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              814 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              816 END_FINALLY
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              818 POP_EXCEPT
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              820 JUMP_FORWARD             2 (to 824)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  822 END_FINALLY
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  824 EXTENDED_ARG             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              826 JUMP_ABSOLUTE          698
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1624     >>  828 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              830 LOAD_ATTR                7 (_forward_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              832 LOAD_METHOD             16 (items)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              834 CALL_METHOD              0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              836 GET_ITER
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  838 FOR_ITER               158 (to 998)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              840 UNPACK_SEQUENCE          2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              842 STORE_FAST               9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              844 STORE_FAST              10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1625         846 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              848 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              850 LOAD_ATTR               25 (_forward_hooks_always_called)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              852 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              854 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              856 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              858 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              860 LOAD_FAST                5 (called_always_called_hooks)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              862 COMPARE_OP               7 (not in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              864 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              866 POP_JUMP_IF_FALSE      838
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1626         868 SETUP_FINALLY           58 (to 928)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1627         870 LOAD_FAST                9 (hook_id)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              872 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              874 LOAD_ATTR               28 (_forward_hooks_with_kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              876 COMPARE_OP               6 (in)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              878 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              880 POP_JUMP_IF_FALSE      898
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1628         882 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              884 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              886 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              888 LOAD_FAST                2 (kwargs)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              890 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              892 CALL_FUNCTION            4
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              894 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              896 JUMP_FORWARD            12 (to 910)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1630     >>  898 LOAD_FAST               10 (hook)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              900 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              902 LOAD_FAST                1 (args)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              904 LOAD_FAST                4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              906 CALL_FUNCTION            3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              908 STORE_FAST              14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1631     >>  910 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              912 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              914 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              916 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              918 POP_JUMP_IF_FALSE      924
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1632         920 LOAD_FAST               14 (hook_result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              922 STORE_FAST               4 (result)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  924 POP_BLOCK
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              926 JUMP_FORWARD            66 (to 994)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1633     >>  928 DUP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              930 LOAD_GLOBAL             41 (Exception)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              932 COMPARE_OP              10 (exception match)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              934 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              936 POP_JUMP_IF_FALSE      992
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              938 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              940 STORE_FAST              17 (e)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              942 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              944 SETUP_FINALLY           34 (to 980)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1634         946 LOAD_GLOBAL             30 (warnings)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              948 LOAD_METHOD             31 (warn)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              950 LOAD_CONST               9 ('module forward hook with ``always_call=True`` raised an exception that was silenced as another error was raised in forward: ')
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              952 LOAD_GLOBAL             42 (str)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              954 LOAD_FAST               17 (e)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              956 CALL_FUNCTION            1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              958 FORMAT_VALUE             0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              960 BUILD_STRING             2
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              962 CALL_METHOD              1
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              964 POP_TOP
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1636         966 POP_BLOCK
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              968 POP_EXCEPT
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              970 CALL_FINALLY             8 (to 980)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              972 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              974 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              976 POP_BLOCK
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              978 BEGIN_FINALLY
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  980 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              982 STORE_FAST              17 (e)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              984 DELETE_FAST             17 (e)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              986 END_FINALLY
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              988 POP_EXCEPT
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              990 JUMP_FORWARD             2 (to 994)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  992 END_FINALLY
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >>  994 EXTENDED_ARG             3
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              996 JUMP_ABSOLUTE          838
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 1638     >>  998 RAISE_VARARGS            0
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1000 POP_EXCEPT
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1002 JUMP_FORWARD             2 (to 1006)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1004 END_FINALLY
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]          >> 1006 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             1008 RETURN_VALUE
[2023-12-28 21:22:50,760] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,763] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1520 (inline depth: 2)
[2023-12-28 21:22:50,763] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):
[2023-12-28 21:22:50,763] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1521 (inline depth: 2)
[2023-12-28 21:22:50,763] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
[2023-12-28 21:22:50,763] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,763] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,763] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]
[2023-12-28 21:22:50,764] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7fa096f79090>)]
[2023-12-28 21:22:50,764] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,764] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,764] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]
[2023-12-28 21:22:50,764] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,764] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,764] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,764] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,765] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,765] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,765] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,766] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,766] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,766] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,766] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,767] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,767] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,767] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]
[2023-12-28 21:22:50,768] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,768] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,768] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,768] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []
[2023-12-28 21:22:50,768] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,768] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1525 (inline depth: 2)
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1526 (inline depth: 2)
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1524 (inline depth: 2)
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
[2023-12-28 21:22:50,769] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]
[2023-12-28 21:22:50,770] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py:1527 (inline depth: 2)
[2023-12-28 21:22:50,770] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)
[2023-12-28 21:22:50,770] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []
[2023-12-28 21:22:50,770] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable())]
[2023-12-28 21:22:50,770] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable()]
[2023-12-28 21:22:50,770] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function Bottleneck.forward at 0x7fa091c60940>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 144           0 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               2 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 146           4 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               6 LOAD_METHOD              0 (conv1)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]               8 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              10 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              12 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 147          14 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              16 LOAD_METHOD              1 (bn1)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              18 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              20 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              22 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 148          24 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              26 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              28 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              30 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              32 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 150          34 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              36 LOAD_METHOD              3 (conv2)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              38 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              40 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              42 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 151          44 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              46 LOAD_METHOD              4 (bn2)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              48 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              50 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              52 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 152          54 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              56 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              58 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              60 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              62 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 154          64 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              66 LOAD_METHOD              5 (conv3)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              68 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              70 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              72 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 155          74 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              76 LOAD_METHOD              6 (bn3)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              78 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              80 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              82 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 157          84 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              86 LOAD_ATTR                7 (downsample)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              88 LOAD_CONST               0 (None)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              90 COMPARE_OP               9 (is not)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              92 POP_JUMP_IF_FALSE      104
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 158          94 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              96 LOAD_METHOD              7 (downsample)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]              98 LOAD_FAST                1 (x)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             100 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             102 STORE_FAST               2 (identity)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 160     >>  104 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             106 LOAD_FAST                2 (identity)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             108 INPLACE_ADD
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             110 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 161         112 LOAD_FAST                0 (self)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             114 LOAD_METHOD              2 (relu)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             116 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             118 CALL_METHOD              1
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             120 STORE_FAST               3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 163         122 LOAD_FAST                3 (out)
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG]             124 RETURN_VALUE
[2023-12-28 21:22:50,771] [0/0] torch._dynamo.symbolic_convert: [DEBUG] 
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:143 (inline depth: 3)
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x: Tensor) -> Tensor:
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:144 (inline depth: 3)
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             identity = x
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146 (inline depth: 3)
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv1(x)
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,772] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,775] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,775] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147 (inline depth: 3)
[2023-12-28 21:22:50,775] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn1(out)
[2023-12-28 21:22:50,776] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,776] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]
[2023-12-28 21:22:50,776] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,776] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,789] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,789] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148 (inline depth: 3)
[2023-12-28 21:22:50,789] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,789] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,789] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,790] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,790] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,792] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150 (inline depth: 3)
[2023-12-28 21:22:50,792] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv2(out)
[2023-12-28 21:22:50,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]
[2023-12-28 21:22:50,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,792] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,796] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,796] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151 (inline depth: 3)
[2023-12-28 21:22:50,796] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn2(out)
[2023-12-28 21:22:50,796] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,796] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]
[2023-12-28 21:22:50,797] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,797] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,810] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152 (inline depth: 3)
[2023-12-28 21:22:50,810] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,810] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,812] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,812] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154 (inline depth: 3)
[2023-12-28 21:22:50,812] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.conv3(out)
[2023-12-28 21:22:50,812] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,812] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv3 [NNModuleVariable()]
[2023-12-28 21:22:50,813] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,813] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,816] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,816] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155 (inline depth: 3)
[2023-12-28 21:22:50,816] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.bn3(out)
[2023-12-28 21:22:50,816] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,816] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn3 [NNModuleVariable()]
[2023-12-28 21:22:50,816] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,816] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,829] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,829] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:157 (inline depth: 3)
[2023-12-28 21:22:50,829] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:
[2023-12-28 21:22:50,830] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,830] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]
[2023-12-28 21:22:50,830] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]
[2023-12-28 21:22:50,830] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]
[2023-12-28 21:22:50,830] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 104 [ConstantVariable(bool)]
[2023-12-28 21:22:50,831] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160 (inline depth: 3)
[2023-12-28 21:22:50,831] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out += identity
[2023-12-28 21:22:50,831] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,831] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST identity [TensorVariable()]
[2023-12-28 21:22:50,831] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]
[2023-12-28 21:22:50,832] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,832] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161 (inline depth: 3)
[2023-12-28 21:22:50,832] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             out = self.relu(out)
[2023-12-28 21:22:50,832] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,832] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR relu [NNModuleVariable()]
[2023-12-28 21:22:50,833] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out [NNModuleVariable()]
[2023-12-28 21:22:50,833] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,834] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST out [TensorVariable()]
[2023-12-28 21:22:50,834] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:163 (inline depth: 3)
[2023-12-28 21:22:50,834] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return out
[2023-12-28 21:22:50,834] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST out []
[2023-12-28 21:22:50,835] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,835] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7fa091c39b30, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 143>
[2023-12-28 21:22:50,835] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,835] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7fa096bb1450, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520>
[2023-12-28 21:22:50,836] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:50,836] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:278 (inline depth: 1)
[2023-12-28 21:22:50,836] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.avgpool(x)
[2023-12-28 21:22:50,836] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,836] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR avgpool [NNModuleVariable()]
[2023-12-28 21:22:50,836] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,837] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,839] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:50,839] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:279 (inline depth: 1)
[2023-12-28 21:22:50,839] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = torch.flatten(x, 1)
[2023-12-28 21:22:50,839] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []
[2023-12-28 21:22:50,839] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flatten [TorchVariable(<module 'torch' from '/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/__init__.py'>)]
[2023-12-28 21:22:50,839] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TorchVariable(<built-in method flatten of type object at 0x7fa111c1fd00>)]
[2023-12-28 21:22:50,839] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TorchVariable(<built-in method flatten of type object at 0x7fa111c1fd00>), TensorVariable()]
[2023-12-28 21:22:50,839] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TorchVariable(<built-in method flatten of type object at 0x7fa111c1fd00>), TensorVariable(), ConstantVariable(int)]
[2023-12-28 21:22:50,861] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:50,861] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:280 (inline depth: 1)
[2023-12-28 21:22:50,861] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.fc(x)
[2023-12-28 21:22:50,861] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []
[2023-12-28 21:22:50,861] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR fc [NNModuleVariable()]
[2023-12-28 21:22:50,861] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]
[2023-12-28 21:22:50,862] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]
[2023-12-28 21:22:50,868] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]
[2023-12-28 21:22:50,868] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _forward_impl /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:282 (inline depth: 1)
[2023-12-28 21:22:50,868] [0/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x
[2023-12-28 21:22:50,868] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []
[2023-12-28 21:22:50,868] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,868] [0/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _forward_impl at 0x7fa091c39df0, file "/home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py", line 266>
[2023-12-28 21:22:50,869] [0/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]
[2023-12-28 21:22:50,869] [0/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)
[2023-12-28 21:22:50,869] [0/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile
[2023-12-28 21:22:50,869] [0/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py, line 285 in forward>], graph_break=False)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_0 =====
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.0 class GraphModule(torch.nn.Module):
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor):
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:268, code: x = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___conv1 = self.L__self___conv1(l_x_);  l_x_ = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:269, code: x = self.bn1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___bn1 = self.L__self___bn1(l__self___conv1);  l__self___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:270, code: x = self.relu(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___relu = self.L__self___relu(l__self___bn1);  l__self___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:271, code: x = self.maxpool(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___maxpool = self.L__self___maxpool(l__self___relu);  l__self___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___conv1 = self.getattr_L__self___layer1___0___conv1(l__self___maxpool)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn1 = self.getattr_L__self___layer1___0___bn1(getattr_l__self___layer1___0___conv1);  getattr_l__self___layer1___0___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___relu = self.getattr_L__self___layer1___0___relu(getattr_l__self___layer1___0___bn1);  getattr_l__self___layer1___0___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___conv2 = self.getattr_L__self___layer1___0___conv2(getattr_l__self___layer1___0___relu);  getattr_l__self___layer1___0___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn2 = self.getattr_L__self___layer1___0___bn2(getattr_l__self___layer1___0___conv2);  getattr_l__self___layer1___0___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___relu_1 = self.getattr_L__self___layer1___0___relu(getattr_l__self___layer1___0___bn2);  getattr_l__self___layer1___0___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___conv3 = self.getattr_L__self___layer1___0___conv3(getattr_l__self___layer1___0___relu_1);  getattr_l__self___layer1___0___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn3 = self.getattr_L__self___layer1___0___bn3(getattr_l__self___layer1___0___conv3);  getattr_l__self___layer1___0___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___downsample_0 = self.getattr_L__self___layer1___0___downsample_0(l__self___maxpool);  l__self___maxpool = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___downsample_1 = self.getattr_L__self___layer1___0___downsample_1(getattr_l__self___layer1___0___downsample_0);  getattr_l__self___layer1___0___downsample_0 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn3 += getattr_l__self___layer1___0___downsample_1;  iadd = getattr_l__self___layer1___0___bn3;  getattr_l__self___layer1___0___bn3 = getattr_l__self___layer1___0___downsample_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___relu_2 = self.getattr_L__self___layer1___0___relu(iadd);  iadd = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___conv1 = self.getattr_L__self___layer1___1___conv1(getattr_l__self___layer1___0___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn1 = self.getattr_L__self___layer1___1___bn1(getattr_l__self___layer1___1___conv1);  getattr_l__self___layer1___1___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___relu = self.getattr_L__self___layer1___1___relu(getattr_l__self___layer1___1___bn1);  getattr_l__self___layer1___1___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___conv2 = self.getattr_L__self___layer1___1___conv2(getattr_l__self___layer1___1___relu);  getattr_l__self___layer1___1___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn2 = self.getattr_L__self___layer1___1___bn2(getattr_l__self___layer1___1___conv2);  getattr_l__self___layer1___1___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___relu_1 = self.getattr_L__self___layer1___1___relu(getattr_l__self___layer1___1___bn2);  getattr_l__self___layer1___1___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___conv3 = self.getattr_L__self___layer1___1___conv3(getattr_l__self___layer1___1___relu_1);  getattr_l__self___layer1___1___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn3 = self.getattr_L__self___layer1___1___bn3(getattr_l__self___layer1___1___conv3);  getattr_l__self___layer1___1___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn3 += getattr_l__self___layer1___0___relu_2;  iadd_1 = getattr_l__self___layer1___1___bn3;  getattr_l__self___layer1___1___bn3 = getattr_l__self___layer1___0___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___relu_2 = self.getattr_L__self___layer1___1___relu(iadd_1);  iadd_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___conv1 = self.getattr_L__self___layer1___2___conv1(getattr_l__self___layer1___1___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___bn1 = self.getattr_L__self___layer1___2___bn1(getattr_l__self___layer1___2___conv1);  getattr_l__self___layer1___2___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___relu = self.getattr_L__self___layer1___2___relu(getattr_l__self___layer1___2___bn1);  getattr_l__self___layer1___2___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___conv2 = self.getattr_L__self___layer1___2___conv2(getattr_l__self___layer1___2___relu);  getattr_l__self___layer1___2___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___bn2 = self.getattr_L__self___layer1___2___bn2(getattr_l__self___layer1___2___conv2);  getattr_l__self___layer1___2___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___relu_1 = self.getattr_L__self___layer1___2___relu(getattr_l__self___layer1___2___bn2);  getattr_l__self___layer1___2___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___conv3 = self.getattr_L__self___layer1___2___conv3(getattr_l__self___layer1___2___relu_1);  getattr_l__self___layer1___2___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___bn3 = self.getattr_L__self___layer1___2___bn3(getattr_l__self___layer1___2___conv3);  getattr_l__self___layer1___2___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___bn3 += getattr_l__self___layer1___1___relu_2;  iadd_2 = getattr_l__self___layer1___2___bn3;  getattr_l__self___layer1___2___bn3 = getattr_l__self___layer1___1___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___2___relu_2 = self.getattr_L__self___layer1___2___relu(iadd_2);  iadd_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___conv1 = self.getattr_L__self___layer2___0___conv1(getattr_l__self___layer1___2___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn1 = self.getattr_L__self___layer2___0___bn1(getattr_l__self___layer2___0___conv1);  getattr_l__self___layer2___0___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___relu = self.getattr_L__self___layer2___0___relu(getattr_l__self___layer2___0___bn1);  getattr_l__self___layer2___0___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___conv2 = self.getattr_L__self___layer2___0___conv2(getattr_l__self___layer2___0___relu);  getattr_l__self___layer2___0___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn2 = self.getattr_L__self___layer2___0___bn2(getattr_l__self___layer2___0___conv2);  getattr_l__self___layer2___0___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___relu_1 = self.getattr_L__self___layer2___0___relu(getattr_l__self___layer2___0___bn2);  getattr_l__self___layer2___0___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___conv3 = self.getattr_L__self___layer2___0___conv3(getattr_l__self___layer2___0___relu_1);  getattr_l__self___layer2___0___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn3 = self.getattr_L__self___layer2___0___bn3(getattr_l__self___layer2___0___conv3);  getattr_l__self___layer2___0___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___downsample_0 = self.getattr_L__self___layer2___0___downsample_0(getattr_l__self___layer1___2___relu_2);  getattr_l__self___layer1___2___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___downsample_1 = self.getattr_L__self___layer2___0___downsample_1(getattr_l__self___layer2___0___downsample_0);  getattr_l__self___layer2___0___downsample_0 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn3 += getattr_l__self___layer2___0___downsample_1;  iadd_3 = getattr_l__self___layer2___0___bn3;  getattr_l__self___layer2___0___bn3 = getattr_l__self___layer2___0___downsample_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___relu_2 = self.getattr_L__self___layer2___0___relu(iadd_3);  iadd_3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___conv1 = self.getattr_L__self___layer2___1___conv1(getattr_l__self___layer2___0___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn1 = self.getattr_L__self___layer2___1___bn1(getattr_l__self___layer2___1___conv1);  getattr_l__self___layer2___1___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___relu = self.getattr_L__self___layer2___1___relu(getattr_l__self___layer2___1___bn1);  getattr_l__self___layer2___1___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___conv2 = self.getattr_L__self___layer2___1___conv2(getattr_l__self___layer2___1___relu);  getattr_l__self___layer2___1___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn2 = self.getattr_L__self___layer2___1___bn2(getattr_l__self___layer2___1___conv2);  getattr_l__self___layer2___1___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___relu_1 = self.getattr_L__self___layer2___1___relu(getattr_l__self___layer2___1___bn2);  getattr_l__self___layer2___1___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___conv3 = self.getattr_L__self___layer2___1___conv3(getattr_l__self___layer2___1___relu_1);  getattr_l__self___layer2___1___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn3 = self.getattr_L__self___layer2___1___bn3(getattr_l__self___layer2___1___conv3);  getattr_l__self___layer2___1___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn3 += getattr_l__self___layer2___0___relu_2;  iadd_4 = getattr_l__self___layer2___1___bn3;  getattr_l__self___layer2___1___bn3 = getattr_l__self___layer2___0___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___relu_2 = self.getattr_L__self___layer2___1___relu(iadd_4);  iadd_4 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___conv1 = self.getattr_L__self___layer2___2___conv1(getattr_l__self___layer2___1___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___bn1 = self.getattr_L__self___layer2___2___bn1(getattr_l__self___layer2___2___conv1);  getattr_l__self___layer2___2___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___relu = self.getattr_L__self___layer2___2___relu(getattr_l__self___layer2___2___bn1);  getattr_l__self___layer2___2___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___conv2 = self.getattr_L__self___layer2___2___conv2(getattr_l__self___layer2___2___relu);  getattr_l__self___layer2___2___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___bn2 = self.getattr_L__self___layer2___2___bn2(getattr_l__self___layer2___2___conv2);  getattr_l__self___layer2___2___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___relu_1 = self.getattr_L__self___layer2___2___relu(getattr_l__self___layer2___2___bn2);  getattr_l__self___layer2___2___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___conv3 = self.getattr_L__self___layer2___2___conv3(getattr_l__self___layer2___2___relu_1);  getattr_l__self___layer2___2___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___bn3 = self.getattr_L__self___layer2___2___bn3(getattr_l__self___layer2___2___conv3);  getattr_l__self___layer2___2___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___bn3 += getattr_l__self___layer2___1___relu_2;  iadd_5 = getattr_l__self___layer2___2___bn3;  getattr_l__self___layer2___2___bn3 = getattr_l__self___layer2___1___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___2___relu_2 = self.getattr_L__self___layer2___2___relu(iadd_5);  iadd_5 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___conv1 = self.getattr_L__self___layer2___3___conv1(getattr_l__self___layer2___2___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___bn1 = self.getattr_L__self___layer2___3___bn1(getattr_l__self___layer2___3___conv1);  getattr_l__self___layer2___3___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___relu = self.getattr_L__self___layer2___3___relu(getattr_l__self___layer2___3___bn1);  getattr_l__self___layer2___3___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___conv2 = self.getattr_L__self___layer2___3___conv2(getattr_l__self___layer2___3___relu);  getattr_l__self___layer2___3___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___bn2 = self.getattr_L__self___layer2___3___bn2(getattr_l__self___layer2___3___conv2);  getattr_l__self___layer2___3___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___relu_1 = self.getattr_L__self___layer2___3___relu(getattr_l__self___layer2___3___bn2);  getattr_l__self___layer2___3___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___conv3 = self.getattr_L__self___layer2___3___conv3(getattr_l__self___layer2___3___relu_1);  getattr_l__self___layer2___3___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___bn3 = self.getattr_L__self___layer2___3___bn3(getattr_l__self___layer2___3___conv3);  getattr_l__self___layer2___3___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___bn3 += getattr_l__self___layer2___2___relu_2;  iadd_6 = getattr_l__self___layer2___3___bn3;  getattr_l__self___layer2___3___bn3 = getattr_l__self___layer2___2___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___3___relu_2 = self.getattr_L__self___layer2___3___relu(iadd_6);  iadd_6 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___conv1 = self.getattr_L__self___layer3___0___conv1(getattr_l__self___layer2___3___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn1 = self.getattr_L__self___layer3___0___bn1(getattr_l__self___layer3___0___conv1);  getattr_l__self___layer3___0___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___relu = self.getattr_L__self___layer3___0___relu(getattr_l__self___layer3___0___bn1);  getattr_l__self___layer3___0___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___conv2 = self.getattr_L__self___layer3___0___conv2(getattr_l__self___layer3___0___relu);  getattr_l__self___layer3___0___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn2 = self.getattr_L__self___layer3___0___bn2(getattr_l__self___layer3___0___conv2);  getattr_l__self___layer3___0___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___relu_1 = self.getattr_L__self___layer3___0___relu(getattr_l__self___layer3___0___bn2);  getattr_l__self___layer3___0___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___conv3 = self.getattr_L__self___layer3___0___conv3(getattr_l__self___layer3___0___relu_1);  getattr_l__self___layer3___0___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn3 = self.getattr_L__self___layer3___0___bn3(getattr_l__self___layer3___0___conv3);  getattr_l__self___layer3___0___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___downsample_0 = self.getattr_L__self___layer3___0___downsample_0(getattr_l__self___layer2___3___relu_2);  getattr_l__self___layer2___3___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___downsample_1 = self.getattr_L__self___layer3___0___downsample_1(getattr_l__self___layer3___0___downsample_0);  getattr_l__self___layer3___0___downsample_0 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn3 += getattr_l__self___layer3___0___downsample_1;  iadd_7 = getattr_l__self___layer3___0___bn3;  getattr_l__self___layer3___0___bn3 = getattr_l__self___layer3___0___downsample_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___relu_2 = self.getattr_L__self___layer3___0___relu(iadd_7);  iadd_7 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___conv1 = self.getattr_L__self___layer3___1___conv1(getattr_l__self___layer3___0___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn1 = self.getattr_L__self___layer3___1___bn1(getattr_l__self___layer3___1___conv1);  getattr_l__self___layer3___1___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___relu = self.getattr_L__self___layer3___1___relu(getattr_l__self___layer3___1___bn1);  getattr_l__self___layer3___1___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___conv2 = self.getattr_L__self___layer3___1___conv2(getattr_l__self___layer3___1___relu);  getattr_l__self___layer3___1___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn2 = self.getattr_L__self___layer3___1___bn2(getattr_l__self___layer3___1___conv2);  getattr_l__self___layer3___1___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___relu_1 = self.getattr_L__self___layer3___1___relu(getattr_l__self___layer3___1___bn2);  getattr_l__self___layer3___1___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___conv3 = self.getattr_L__self___layer3___1___conv3(getattr_l__self___layer3___1___relu_1);  getattr_l__self___layer3___1___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn3 = self.getattr_L__self___layer3___1___bn3(getattr_l__self___layer3___1___conv3);  getattr_l__self___layer3___1___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn3 += getattr_l__self___layer3___0___relu_2;  iadd_8 = getattr_l__self___layer3___1___bn3;  getattr_l__self___layer3___1___bn3 = getattr_l__self___layer3___0___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___relu_2 = self.getattr_L__self___layer3___1___relu(iadd_8);  iadd_8 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___conv1 = self.getattr_L__self___layer3___2___conv1(getattr_l__self___layer3___1___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___bn1 = self.getattr_L__self___layer3___2___bn1(getattr_l__self___layer3___2___conv1);  getattr_l__self___layer3___2___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___relu = self.getattr_L__self___layer3___2___relu(getattr_l__self___layer3___2___bn1);  getattr_l__self___layer3___2___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___conv2 = self.getattr_L__self___layer3___2___conv2(getattr_l__self___layer3___2___relu);  getattr_l__self___layer3___2___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___bn2 = self.getattr_L__self___layer3___2___bn2(getattr_l__self___layer3___2___conv2);  getattr_l__self___layer3___2___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___relu_1 = self.getattr_L__self___layer3___2___relu(getattr_l__self___layer3___2___bn2);  getattr_l__self___layer3___2___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___conv3 = self.getattr_L__self___layer3___2___conv3(getattr_l__self___layer3___2___relu_1);  getattr_l__self___layer3___2___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___bn3 = self.getattr_L__self___layer3___2___bn3(getattr_l__self___layer3___2___conv3);  getattr_l__self___layer3___2___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___bn3 += getattr_l__self___layer3___1___relu_2;  iadd_9 = getattr_l__self___layer3___2___bn3;  getattr_l__self___layer3___2___bn3 = getattr_l__self___layer3___1___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___2___relu_2 = self.getattr_L__self___layer3___2___relu(iadd_9);  iadd_9 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___conv1 = self.getattr_L__self___layer3___3___conv1(getattr_l__self___layer3___2___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___bn1 = self.getattr_L__self___layer3___3___bn1(getattr_l__self___layer3___3___conv1);  getattr_l__self___layer3___3___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___relu = self.getattr_L__self___layer3___3___relu(getattr_l__self___layer3___3___bn1);  getattr_l__self___layer3___3___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___conv2 = self.getattr_L__self___layer3___3___conv2(getattr_l__self___layer3___3___relu);  getattr_l__self___layer3___3___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___bn2 = self.getattr_L__self___layer3___3___bn2(getattr_l__self___layer3___3___conv2);  getattr_l__self___layer3___3___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___relu_1 = self.getattr_L__self___layer3___3___relu(getattr_l__self___layer3___3___bn2);  getattr_l__self___layer3___3___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___conv3 = self.getattr_L__self___layer3___3___conv3(getattr_l__self___layer3___3___relu_1);  getattr_l__self___layer3___3___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___bn3 = self.getattr_L__self___layer3___3___bn3(getattr_l__self___layer3___3___conv3);  getattr_l__self___layer3___3___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___bn3 += getattr_l__self___layer3___2___relu_2;  iadd_10 = getattr_l__self___layer3___3___bn3;  getattr_l__self___layer3___3___bn3 = getattr_l__self___layer3___2___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___3___relu_2 = self.getattr_L__self___layer3___3___relu(iadd_10);  iadd_10 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___conv1 = self.getattr_L__self___layer3___4___conv1(getattr_l__self___layer3___3___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___bn1 = self.getattr_L__self___layer3___4___bn1(getattr_l__self___layer3___4___conv1);  getattr_l__self___layer3___4___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___relu = self.getattr_L__self___layer3___4___relu(getattr_l__self___layer3___4___bn1);  getattr_l__self___layer3___4___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___conv2 = self.getattr_L__self___layer3___4___conv2(getattr_l__self___layer3___4___relu);  getattr_l__self___layer3___4___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___bn2 = self.getattr_L__self___layer3___4___bn2(getattr_l__self___layer3___4___conv2);  getattr_l__self___layer3___4___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___relu_1 = self.getattr_L__self___layer3___4___relu(getattr_l__self___layer3___4___bn2);  getattr_l__self___layer3___4___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___conv3 = self.getattr_L__self___layer3___4___conv3(getattr_l__self___layer3___4___relu_1);  getattr_l__self___layer3___4___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___bn3 = self.getattr_L__self___layer3___4___bn3(getattr_l__self___layer3___4___conv3);  getattr_l__self___layer3___4___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___bn3 += getattr_l__self___layer3___3___relu_2;  iadd_11 = getattr_l__self___layer3___4___bn3;  getattr_l__self___layer3___4___bn3 = getattr_l__self___layer3___3___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___4___relu_2 = self.getattr_L__self___layer3___4___relu(iadd_11);  iadd_11 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___conv1 = self.getattr_L__self___layer3___5___conv1(getattr_l__self___layer3___4___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___bn1 = self.getattr_L__self___layer3___5___bn1(getattr_l__self___layer3___5___conv1);  getattr_l__self___layer3___5___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___relu = self.getattr_L__self___layer3___5___relu(getattr_l__self___layer3___5___bn1);  getattr_l__self___layer3___5___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___conv2 = self.getattr_L__self___layer3___5___conv2(getattr_l__self___layer3___5___relu);  getattr_l__self___layer3___5___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___bn2 = self.getattr_L__self___layer3___5___bn2(getattr_l__self___layer3___5___conv2);  getattr_l__self___layer3___5___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___relu_1 = self.getattr_L__self___layer3___5___relu(getattr_l__self___layer3___5___bn2);  getattr_l__self___layer3___5___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___conv3 = self.getattr_L__self___layer3___5___conv3(getattr_l__self___layer3___5___relu_1);  getattr_l__self___layer3___5___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___bn3 = self.getattr_L__self___layer3___5___bn3(getattr_l__self___layer3___5___conv3);  getattr_l__self___layer3___5___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___bn3 += getattr_l__self___layer3___4___relu_2;  iadd_12 = getattr_l__self___layer3___5___bn3;  getattr_l__self___layer3___5___bn3 = getattr_l__self___layer3___4___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___5___relu_2 = self.getattr_L__self___layer3___5___relu(iadd_12);  iadd_12 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___conv1 = self.getattr_L__self___layer4___0___conv1(getattr_l__self___layer3___5___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn1 = self.getattr_L__self___layer4___0___bn1(getattr_l__self___layer4___0___conv1);  getattr_l__self___layer4___0___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___relu = self.getattr_L__self___layer4___0___relu(getattr_l__self___layer4___0___bn1);  getattr_l__self___layer4___0___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___conv2 = self.getattr_L__self___layer4___0___conv2(getattr_l__self___layer4___0___relu);  getattr_l__self___layer4___0___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn2 = self.getattr_L__self___layer4___0___bn2(getattr_l__self___layer4___0___conv2);  getattr_l__self___layer4___0___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___relu_1 = self.getattr_L__self___layer4___0___relu(getattr_l__self___layer4___0___bn2);  getattr_l__self___layer4___0___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___conv3 = self.getattr_L__self___layer4___0___conv3(getattr_l__self___layer4___0___relu_1);  getattr_l__self___layer4___0___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn3 = self.getattr_L__self___layer4___0___bn3(getattr_l__self___layer4___0___conv3);  getattr_l__self___layer4___0___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___downsample_0 = self.getattr_L__self___layer4___0___downsample_0(getattr_l__self___layer3___5___relu_2);  getattr_l__self___layer3___5___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___downsample_1 = self.getattr_L__self___layer4___0___downsample_1(getattr_l__self___layer4___0___downsample_0);  getattr_l__self___layer4___0___downsample_0 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn3 += getattr_l__self___layer4___0___downsample_1;  iadd_13 = getattr_l__self___layer4___0___bn3;  getattr_l__self___layer4___0___bn3 = getattr_l__self___layer4___0___downsample_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___relu_2 = self.getattr_L__self___layer4___0___relu(iadd_13);  iadd_13 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___conv1 = self.getattr_L__self___layer4___1___conv1(getattr_l__self___layer4___0___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn1 = self.getattr_L__self___layer4___1___bn1(getattr_l__self___layer4___1___conv1);  getattr_l__self___layer4___1___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___relu = self.getattr_L__self___layer4___1___relu(getattr_l__self___layer4___1___bn1);  getattr_l__self___layer4___1___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___conv2 = self.getattr_L__self___layer4___1___conv2(getattr_l__self___layer4___1___relu);  getattr_l__self___layer4___1___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn2 = self.getattr_L__self___layer4___1___bn2(getattr_l__self___layer4___1___conv2);  getattr_l__self___layer4___1___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___relu_1 = self.getattr_L__self___layer4___1___relu(getattr_l__self___layer4___1___bn2);  getattr_l__self___layer4___1___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___conv3 = self.getattr_L__self___layer4___1___conv3(getattr_l__self___layer4___1___relu_1);  getattr_l__self___layer4___1___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn3 = self.getattr_L__self___layer4___1___bn3(getattr_l__self___layer4___1___conv3);  getattr_l__self___layer4___1___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn3 += getattr_l__self___layer4___0___relu_2;  iadd_14 = getattr_l__self___layer4___1___bn3;  getattr_l__self___layer4___1___bn3 = getattr_l__self___layer4___0___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___relu_2 = self.getattr_L__self___layer4___1___relu(iadd_14);  iadd_14 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___conv1 = self.getattr_L__self___layer4___2___conv1(getattr_l__self___layer4___1___relu_2)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___bn1 = self.getattr_L__self___layer4___2___bn1(getattr_l__self___layer4___2___conv1);  getattr_l__self___layer4___2___conv1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___relu = self.getattr_L__self___layer4___2___relu(getattr_l__self___layer4___2___bn1);  getattr_l__self___layer4___2___bn1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___conv2 = self.getattr_L__self___layer4___2___conv2(getattr_l__self___layer4___2___relu);  getattr_l__self___layer4___2___relu = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___bn2 = self.getattr_L__self___layer4___2___bn2(getattr_l__self___layer4___2___conv2);  getattr_l__self___layer4___2___conv2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___relu_1 = self.getattr_L__self___layer4___2___relu(getattr_l__self___layer4___2___bn2);  getattr_l__self___layer4___2___bn2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___conv3 = self.getattr_L__self___layer4___2___conv3(getattr_l__self___layer4___2___relu_1);  getattr_l__self___layer4___2___relu_1 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___bn3 = self.getattr_L__self___layer4___2___bn3(getattr_l__self___layer4___2___conv3);  getattr_l__self___layer4___2___conv3 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___bn3 += getattr_l__self___layer4___1___relu_2;  iadd_15 = getattr_l__self___layer4___2___bn3;  getattr_l__self___layer4___2___bn3 = getattr_l__self___layer4___1___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___2___relu_2 = self.getattr_L__self___layer4___2___relu(iadd_15);  iadd_15 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:278, code: x = self.avgpool(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___avgpool = self.L__self___avgpool(getattr_l__self___layer4___2___relu_2);  getattr_l__self___layer4___2___relu_2 = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:279, code: x = torch.flatten(x, 1)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         flatten = torch.flatten(l__self___avgpool, 1);  l__self___avgpool = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:280, code: x = self.fc(x)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___fc = self.L__self___fc(flatten);  flatten = None
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___fc,)
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         
[2023-12-28 21:22:50,878] [0/0] torch._dynamo.output_graph.__graph_code: [DEBUG] 
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] Tabulate module missing, please install tabulate to log the graph in tabular format, logging code instead:
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]  ===== __compiled_fn_0 =====
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]  <eval_with_key>.0 class GraphModule(torch.nn.Module):
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]     def forward(self, L_x_ : torch.Tensor):
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         l_x_ = L_x_
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:268, code: x = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         l__self___conv1 = self.L__self___conv1(l_x_);  l_x_ = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:269, code: x = self.bn1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         l__self___bn1 = self.L__self___bn1(l__self___conv1);  l__self___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:270, code: x = self.relu(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         l__self___relu = self.L__self___relu(l__self___bn1);  l__self___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:271, code: x = self.maxpool(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         l__self___maxpool = self.L__self___maxpool(l__self___relu);  l__self___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___conv1 = self.getattr_L__self___layer1___0___conv1(l__self___maxpool)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___bn1 = self.getattr_L__self___layer1___0___bn1(getattr_l__self___layer1___0___conv1);  getattr_l__self___layer1___0___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___relu = self.getattr_L__self___layer1___0___relu(getattr_l__self___layer1___0___bn1);  getattr_l__self___layer1___0___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___conv2 = self.getattr_L__self___layer1___0___conv2(getattr_l__self___layer1___0___relu);  getattr_l__self___layer1___0___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___bn2 = self.getattr_L__self___layer1___0___bn2(getattr_l__self___layer1___0___conv2);  getattr_l__self___layer1___0___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___relu_1 = self.getattr_L__self___layer1___0___relu(getattr_l__self___layer1___0___bn2);  getattr_l__self___layer1___0___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___conv3 = self.getattr_L__self___layer1___0___conv3(getattr_l__self___layer1___0___relu_1);  getattr_l__self___layer1___0___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___bn3 = self.getattr_L__self___layer1___0___bn3(getattr_l__self___layer1___0___conv3);  getattr_l__self___layer1___0___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___downsample_0 = self.getattr_L__self___layer1___0___downsample_0(l__self___maxpool);  l__self___maxpool = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___downsample_1 = self.getattr_L__self___layer1___0___downsample_1(getattr_l__self___layer1___0___downsample_0);  getattr_l__self___layer1___0___downsample_0 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___bn3 += getattr_l__self___layer1___0___downsample_1;  iadd = getattr_l__self___layer1___0___bn3;  getattr_l__self___layer1___0___bn3 = getattr_l__self___layer1___0___downsample_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___0___relu_2 = self.getattr_L__self___layer1___0___relu(iadd);  iadd = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___conv1 = self.getattr_L__self___layer1___1___conv1(getattr_l__self___layer1___0___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___bn1 = self.getattr_L__self___layer1___1___bn1(getattr_l__self___layer1___1___conv1);  getattr_l__self___layer1___1___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___relu = self.getattr_L__self___layer1___1___relu(getattr_l__self___layer1___1___bn1);  getattr_l__self___layer1___1___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___conv2 = self.getattr_L__self___layer1___1___conv2(getattr_l__self___layer1___1___relu);  getattr_l__self___layer1___1___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___bn2 = self.getattr_L__self___layer1___1___bn2(getattr_l__self___layer1___1___conv2);  getattr_l__self___layer1___1___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___relu_1 = self.getattr_L__self___layer1___1___relu(getattr_l__self___layer1___1___bn2);  getattr_l__self___layer1___1___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___conv3 = self.getattr_L__self___layer1___1___conv3(getattr_l__self___layer1___1___relu_1);  getattr_l__self___layer1___1___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___bn3 = self.getattr_L__self___layer1___1___bn3(getattr_l__self___layer1___1___conv3);  getattr_l__self___layer1___1___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___bn3 += getattr_l__self___layer1___0___relu_2;  iadd_1 = getattr_l__self___layer1___1___bn3;  getattr_l__self___layer1___1___bn3 = getattr_l__self___layer1___0___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___1___relu_2 = self.getattr_L__self___layer1___1___relu(iadd_1);  iadd_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___conv1 = self.getattr_L__self___layer1___2___conv1(getattr_l__self___layer1___1___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___bn1 = self.getattr_L__self___layer1___2___bn1(getattr_l__self___layer1___2___conv1);  getattr_l__self___layer1___2___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___relu = self.getattr_L__self___layer1___2___relu(getattr_l__self___layer1___2___bn1);  getattr_l__self___layer1___2___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___conv2 = self.getattr_L__self___layer1___2___conv2(getattr_l__self___layer1___2___relu);  getattr_l__self___layer1___2___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___bn2 = self.getattr_L__self___layer1___2___bn2(getattr_l__self___layer1___2___conv2);  getattr_l__self___layer1___2___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___relu_1 = self.getattr_L__self___layer1___2___relu(getattr_l__self___layer1___2___bn2);  getattr_l__self___layer1___2___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___conv3 = self.getattr_L__self___layer1___2___conv3(getattr_l__self___layer1___2___relu_1);  getattr_l__self___layer1___2___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___bn3 = self.getattr_L__self___layer1___2___bn3(getattr_l__self___layer1___2___conv3);  getattr_l__self___layer1___2___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___bn3 += getattr_l__self___layer1___1___relu_2;  iadd_2 = getattr_l__self___layer1___2___bn3;  getattr_l__self___layer1___2___bn3 = getattr_l__self___layer1___1___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer1___2___relu_2 = self.getattr_L__self___layer1___2___relu(iadd_2);  iadd_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___conv1 = self.getattr_L__self___layer2___0___conv1(getattr_l__self___layer1___2___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___bn1 = self.getattr_L__self___layer2___0___bn1(getattr_l__self___layer2___0___conv1);  getattr_l__self___layer2___0___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___relu = self.getattr_L__self___layer2___0___relu(getattr_l__self___layer2___0___bn1);  getattr_l__self___layer2___0___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___conv2 = self.getattr_L__self___layer2___0___conv2(getattr_l__self___layer2___0___relu);  getattr_l__self___layer2___0___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___bn2 = self.getattr_L__self___layer2___0___bn2(getattr_l__self___layer2___0___conv2);  getattr_l__self___layer2___0___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___relu_1 = self.getattr_L__self___layer2___0___relu(getattr_l__self___layer2___0___bn2);  getattr_l__self___layer2___0___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___conv3 = self.getattr_L__self___layer2___0___conv3(getattr_l__self___layer2___0___relu_1);  getattr_l__self___layer2___0___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___bn3 = self.getattr_L__self___layer2___0___bn3(getattr_l__self___layer2___0___conv3);  getattr_l__self___layer2___0___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___downsample_0 = self.getattr_L__self___layer2___0___downsample_0(getattr_l__self___layer1___2___relu_2);  getattr_l__self___layer1___2___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___downsample_1 = self.getattr_L__self___layer2___0___downsample_1(getattr_l__self___layer2___0___downsample_0);  getattr_l__self___layer2___0___downsample_0 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___bn3 += getattr_l__self___layer2___0___downsample_1;  iadd_3 = getattr_l__self___layer2___0___bn3;  getattr_l__self___layer2___0___bn3 = getattr_l__self___layer2___0___downsample_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___0___relu_2 = self.getattr_L__self___layer2___0___relu(iadd_3);  iadd_3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___conv1 = self.getattr_L__self___layer2___1___conv1(getattr_l__self___layer2___0___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___bn1 = self.getattr_L__self___layer2___1___bn1(getattr_l__self___layer2___1___conv1);  getattr_l__self___layer2___1___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___relu = self.getattr_L__self___layer2___1___relu(getattr_l__self___layer2___1___bn1);  getattr_l__self___layer2___1___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___conv2 = self.getattr_L__self___layer2___1___conv2(getattr_l__self___layer2___1___relu);  getattr_l__self___layer2___1___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___bn2 = self.getattr_L__self___layer2___1___bn2(getattr_l__self___layer2___1___conv2);  getattr_l__self___layer2___1___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___relu_1 = self.getattr_L__self___layer2___1___relu(getattr_l__self___layer2___1___bn2);  getattr_l__self___layer2___1___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___conv3 = self.getattr_L__self___layer2___1___conv3(getattr_l__self___layer2___1___relu_1);  getattr_l__self___layer2___1___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___bn3 = self.getattr_L__self___layer2___1___bn3(getattr_l__self___layer2___1___conv3);  getattr_l__self___layer2___1___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___bn3 += getattr_l__self___layer2___0___relu_2;  iadd_4 = getattr_l__self___layer2___1___bn3;  getattr_l__self___layer2___1___bn3 = getattr_l__self___layer2___0___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___1___relu_2 = self.getattr_L__self___layer2___1___relu(iadd_4);  iadd_4 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___conv1 = self.getattr_L__self___layer2___2___conv1(getattr_l__self___layer2___1___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___bn1 = self.getattr_L__self___layer2___2___bn1(getattr_l__self___layer2___2___conv1);  getattr_l__self___layer2___2___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___relu = self.getattr_L__self___layer2___2___relu(getattr_l__self___layer2___2___bn1);  getattr_l__self___layer2___2___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___conv2 = self.getattr_L__self___layer2___2___conv2(getattr_l__self___layer2___2___relu);  getattr_l__self___layer2___2___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___bn2 = self.getattr_L__self___layer2___2___bn2(getattr_l__self___layer2___2___conv2);  getattr_l__self___layer2___2___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___relu_1 = self.getattr_L__self___layer2___2___relu(getattr_l__self___layer2___2___bn2);  getattr_l__self___layer2___2___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___conv3 = self.getattr_L__self___layer2___2___conv3(getattr_l__self___layer2___2___relu_1);  getattr_l__self___layer2___2___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___bn3 = self.getattr_L__self___layer2___2___bn3(getattr_l__self___layer2___2___conv3);  getattr_l__self___layer2___2___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___bn3 += getattr_l__self___layer2___1___relu_2;  iadd_5 = getattr_l__self___layer2___2___bn3;  getattr_l__self___layer2___2___bn3 = getattr_l__self___layer2___1___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___2___relu_2 = self.getattr_L__self___layer2___2___relu(iadd_5);  iadd_5 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___conv1 = self.getattr_L__self___layer2___3___conv1(getattr_l__self___layer2___2___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___bn1 = self.getattr_L__self___layer2___3___bn1(getattr_l__self___layer2___3___conv1);  getattr_l__self___layer2___3___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___relu = self.getattr_L__self___layer2___3___relu(getattr_l__self___layer2___3___bn1);  getattr_l__self___layer2___3___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___conv2 = self.getattr_L__self___layer2___3___conv2(getattr_l__self___layer2___3___relu);  getattr_l__self___layer2___3___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___bn2 = self.getattr_L__self___layer2___3___bn2(getattr_l__self___layer2___3___conv2);  getattr_l__self___layer2___3___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___relu_1 = self.getattr_L__self___layer2___3___relu(getattr_l__self___layer2___3___bn2);  getattr_l__self___layer2___3___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___conv3 = self.getattr_L__self___layer2___3___conv3(getattr_l__self___layer2___3___relu_1);  getattr_l__self___layer2___3___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___bn3 = self.getattr_L__self___layer2___3___bn3(getattr_l__self___layer2___3___conv3);  getattr_l__self___layer2___3___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___bn3 += getattr_l__self___layer2___2___relu_2;  iadd_6 = getattr_l__self___layer2___3___bn3;  getattr_l__self___layer2___3___bn3 = getattr_l__self___layer2___2___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer2___3___relu_2 = self.getattr_L__self___layer2___3___relu(iadd_6);  iadd_6 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___conv1 = self.getattr_L__self___layer3___0___conv1(getattr_l__self___layer2___3___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___bn1 = self.getattr_L__self___layer3___0___bn1(getattr_l__self___layer3___0___conv1);  getattr_l__self___layer3___0___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___relu = self.getattr_L__self___layer3___0___relu(getattr_l__self___layer3___0___bn1);  getattr_l__self___layer3___0___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___conv2 = self.getattr_L__self___layer3___0___conv2(getattr_l__self___layer3___0___relu);  getattr_l__self___layer3___0___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___bn2 = self.getattr_L__self___layer3___0___bn2(getattr_l__self___layer3___0___conv2);  getattr_l__self___layer3___0___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___relu_1 = self.getattr_L__self___layer3___0___relu(getattr_l__self___layer3___0___bn2);  getattr_l__self___layer3___0___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___conv3 = self.getattr_L__self___layer3___0___conv3(getattr_l__self___layer3___0___relu_1);  getattr_l__self___layer3___0___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___bn3 = self.getattr_L__self___layer3___0___bn3(getattr_l__self___layer3___0___conv3);  getattr_l__self___layer3___0___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___downsample_0 = self.getattr_L__self___layer3___0___downsample_0(getattr_l__self___layer2___3___relu_2);  getattr_l__self___layer2___3___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___downsample_1 = self.getattr_L__self___layer3___0___downsample_1(getattr_l__self___layer3___0___downsample_0);  getattr_l__self___layer3___0___downsample_0 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___bn3 += getattr_l__self___layer3___0___downsample_1;  iadd_7 = getattr_l__self___layer3___0___bn3;  getattr_l__self___layer3___0___bn3 = getattr_l__self___layer3___0___downsample_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___0___relu_2 = self.getattr_L__self___layer3___0___relu(iadd_7);  iadd_7 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___conv1 = self.getattr_L__self___layer3___1___conv1(getattr_l__self___layer3___0___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___bn1 = self.getattr_L__self___layer3___1___bn1(getattr_l__self___layer3___1___conv1);  getattr_l__self___layer3___1___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___relu = self.getattr_L__self___layer3___1___relu(getattr_l__self___layer3___1___bn1);  getattr_l__self___layer3___1___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___conv2 = self.getattr_L__self___layer3___1___conv2(getattr_l__self___layer3___1___relu);  getattr_l__self___layer3___1___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___bn2 = self.getattr_L__self___layer3___1___bn2(getattr_l__self___layer3___1___conv2);  getattr_l__self___layer3___1___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___relu_1 = self.getattr_L__self___layer3___1___relu(getattr_l__self___layer3___1___bn2);  getattr_l__self___layer3___1___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___conv3 = self.getattr_L__self___layer3___1___conv3(getattr_l__self___layer3___1___relu_1);  getattr_l__self___layer3___1___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___bn3 = self.getattr_L__self___layer3___1___bn3(getattr_l__self___layer3___1___conv3);  getattr_l__self___layer3___1___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___bn3 += getattr_l__self___layer3___0___relu_2;  iadd_8 = getattr_l__self___layer3___1___bn3;  getattr_l__self___layer3___1___bn3 = getattr_l__self___layer3___0___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___1___relu_2 = self.getattr_L__self___layer3___1___relu(iadd_8);  iadd_8 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___conv1 = self.getattr_L__self___layer3___2___conv1(getattr_l__self___layer3___1___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___bn1 = self.getattr_L__self___layer3___2___bn1(getattr_l__self___layer3___2___conv1);  getattr_l__self___layer3___2___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___relu = self.getattr_L__self___layer3___2___relu(getattr_l__self___layer3___2___bn1);  getattr_l__self___layer3___2___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___conv2 = self.getattr_L__self___layer3___2___conv2(getattr_l__self___layer3___2___relu);  getattr_l__self___layer3___2___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___bn2 = self.getattr_L__self___layer3___2___bn2(getattr_l__self___layer3___2___conv2);  getattr_l__self___layer3___2___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___relu_1 = self.getattr_L__self___layer3___2___relu(getattr_l__self___layer3___2___bn2);  getattr_l__self___layer3___2___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___conv3 = self.getattr_L__self___layer3___2___conv3(getattr_l__self___layer3___2___relu_1);  getattr_l__self___layer3___2___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___bn3 = self.getattr_L__self___layer3___2___bn3(getattr_l__self___layer3___2___conv3);  getattr_l__self___layer3___2___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___bn3 += getattr_l__self___layer3___1___relu_2;  iadd_9 = getattr_l__self___layer3___2___bn3;  getattr_l__self___layer3___2___bn3 = getattr_l__self___layer3___1___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___2___relu_2 = self.getattr_L__self___layer3___2___relu(iadd_9);  iadd_9 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___conv1 = self.getattr_L__self___layer3___3___conv1(getattr_l__self___layer3___2___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___bn1 = self.getattr_L__self___layer3___3___bn1(getattr_l__self___layer3___3___conv1);  getattr_l__self___layer3___3___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___relu = self.getattr_L__self___layer3___3___relu(getattr_l__self___layer3___3___bn1);  getattr_l__self___layer3___3___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___conv2 = self.getattr_L__self___layer3___3___conv2(getattr_l__self___layer3___3___relu);  getattr_l__self___layer3___3___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___bn2 = self.getattr_L__self___layer3___3___bn2(getattr_l__self___layer3___3___conv2);  getattr_l__self___layer3___3___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___relu_1 = self.getattr_L__self___layer3___3___relu(getattr_l__self___layer3___3___bn2);  getattr_l__self___layer3___3___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___conv3 = self.getattr_L__self___layer3___3___conv3(getattr_l__self___layer3___3___relu_1);  getattr_l__self___layer3___3___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___bn3 = self.getattr_L__self___layer3___3___bn3(getattr_l__self___layer3___3___conv3);  getattr_l__self___layer3___3___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___bn3 += getattr_l__self___layer3___2___relu_2;  iadd_10 = getattr_l__self___layer3___3___bn3;  getattr_l__self___layer3___3___bn3 = getattr_l__self___layer3___2___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___3___relu_2 = self.getattr_L__self___layer3___3___relu(iadd_10);  iadd_10 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___conv1 = self.getattr_L__self___layer3___4___conv1(getattr_l__self___layer3___3___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___bn1 = self.getattr_L__self___layer3___4___bn1(getattr_l__self___layer3___4___conv1);  getattr_l__self___layer3___4___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___relu = self.getattr_L__self___layer3___4___relu(getattr_l__self___layer3___4___bn1);  getattr_l__self___layer3___4___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___conv2 = self.getattr_L__self___layer3___4___conv2(getattr_l__self___layer3___4___relu);  getattr_l__self___layer3___4___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___bn2 = self.getattr_L__self___layer3___4___bn2(getattr_l__self___layer3___4___conv2);  getattr_l__self___layer3___4___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___relu_1 = self.getattr_L__self___layer3___4___relu(getattr_l__self___layer3___4___bn2);  getattr_l__self___layer3___4___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___conv3 = self.getattr_L__self___layer3___4___conv3(getattr_l__self___layer3___4___relu_1);  getattr_l__self___layer3___4___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___bn3 = self.getattr_L__self___layer3___4___bn3(getattr_l__self___layer3___4___conv3);  getattr_l__self___layer3___4___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___bn3 += getattr_l__self___layer3___3___relu_2;  iadd_11 = getattr_l__self___layer3___4___bn3;  getattr_l__self___layer3___4___bn3 = getattr_l__self___layer3___3___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___4___relu_2 = self.getattr_L__self___layer3___4___relu(iadd_11);  iadd_11 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___conv1 = self.getattr_L__self___layer3___5___conv1(getattr_l__self___layer3___4___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___bn1 = self.getattr_L__self___layer3___5___bn1(getattr_l__self___layer3___5___conv1);  getattr_l__self___layer3___5___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___relu = self.getattr_L__self___layer3___5___relu(getattr_l__self___layer3___5___bn1);  getattr_l__self___layer3___5___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___conv2 = self.getattr_L__self___layer3___5___conv2(getattr_l__self___layer3___5___relu);  getattr_l__self___layer3___5___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___bn2 = self.getattr_L__self___layer3___5___bn2(getattr_l__self___layer3___5___conv2);  getattr_l__self___layer3___5___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___relu_1 = self.getattr_L__self___layer3___5___relu(getattr_l__self___layer3___5___bn2);  getattr_l__self___layer3___5___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___conv3 = self.getattr_L__self___layer3___5___conv3(getattr_l__self___layer3___5___relu_1);  getattr_l__self___layer3___5___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___bn3 = self.getattr_L__self___layer3___5___bn3(getattr_l__self___layer3___5___conv3);  getattr_l__self___layer3___5___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___bn3 += getattr_l__self___layer3___4___relu_2;  iadd_12 = getattr_l__self___layer3___5___bn3;  getattr_l__self___layer3___5___bn3 = getattr_l__self___layer3___4___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer3___5___relu_2 = self.getattr_L__self___layer3___5___relu(iadd_12);  iadd_12 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___conv1 = self.getattr_L__self___layer4___0___conv1(getattr_l__self___layer3___5___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___bn1 = self.getattr_L__self___layer4___0___bn1(getattr_l__self___layer4___0___conv1);  getattr_l__self___layer4___0___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___relu = self.getattr_L__self___layer4___0___relu(getattr_l__self___layer4___0___bn1);  getattr_l__self___layer4___0___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___conv2 = self.getattr_L__self___layer4___0___conv2(getattr_l__self___layer4___0___relu);  getattr_l__self___layer4___0___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___bn2 = self.getattr_L__self___layer4___0___bn2(getattr_l__self___layer4___0___conv2);  getattr_l__self___layer4___0___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___relu_1 = self.getattr_L__self___layer4___0___relu(getattr_l__self___layer4___0___bn2);  getattr_l__self___layer4___0___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___conv3 = self.getattr_L__self___layer4___0___conv3(getattr_l__self___layer4___0___relu_1);  getattr_l__self___layer4___0___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___bn3 = self.getattr_L__self___layer4___0___bn3(getattr_l__self___layer4___0___conv3);  getattr_l__self___layer4___0___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___downsample_0 = self.getattr_L__self___layer4___0___downsample_0(getattr_l__self___layer3___5___relu_2);  getattr_l__self___layer3___5___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___downsample_1 = self.getattr_L__self___layer4___0___downsample_1(getattr_l__self___layer4___0___downsample_0);  getattr_l__self___layer4___0___downsample_0 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___bn3 += getattr_l__self___layer4___0___downsample_1;  iadd_13 = getattr_l__self___layer4___0___bn3;  getattr_l__self___layer4___0___bn3 = getattr_l__self___layer4___0___downsample_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___0___relu_2 = self.getattr_L__self___layer4___0___relu(iadd_13);  iadd_13 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___conv1 = self.getattr_L__self___layer4___1___conv1(getattr_l__self___layer4___0___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___bn1 = self.getattr_L__self___layer4___1___bn1(getattr_l__self___layer4___1___conv1);  getattr_l__self___layer4___1___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___relu = self.getattr_L__self___layer4___1___relu(getattr_l__self___layer4___1___bn1);  getattr_l__self___layer4___1___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___conv2 = self.getattr_L__self___layer4___1___conv2(getattr_l__self___layer4___1___relu);  getattr_l__self___layer4___1___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___bn2 = self.getattr_L__self___layer4___1___bn2(getattr_l__self___layer4___1___conv2);  getattr_l__self___layer4___1___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___relu_1 = self.getattr_L__self___layer4___1___relu(getattr_l__self___layer4___1___bn2);  getattr_l__self___layer4___1___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___conv3 = self.getattr_L__self___layer4___1___conv3(getattr_l__self___layer4___1___relu_1);  getattr_l__self___layer4___1___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___bn3 = self.getattr_L__self___layer4___1___bn3(getattr_l__self___layer4___1___conv3);  getattr_l__self___layer4___1___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___bn3 += getattr_l__self___layer4___0___relu_2;  iadd_14 = getattr_l__self___layer4___1___bn3;  getattr_l__self___layer4___1___bn3 = getattr_l__self___layer4___0___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___1___relu_2 = self.getattr_L__self___layer4___1___relu(iadd_14);  iadd_14 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___conv1 = self.getattr_L__self___layer4___2___conv1(getattr_l__self___layer4___1___relu_2)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___bn1 = self.getattr_L__self___layer4___2___bn1(getattr_l__self___layer4___2___conv1);  getattr_l__self___layer4___2___conv1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___relu = self.getattr_L__self___layer4___2___relu(getattr_l__self___layer4___2___bn1);  getattr_l__self___layer4___2___bn1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___conv2 = self.getattr_L__self___layer4___2___conv2(getattr_l__self___layer4___2___relu);  getattr_l__self___layer4___2___relu = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___bn2 = self.getattr_L__self___layer4___2___bn2(getattr_l__self___layer4___2___conv2);  getattr_l__self___layer4___2___conv2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___relu_1 = self.getattr_L__self___layer4___2___relu(getattr_l__self___layer4___2___bn2);  getattr_l__self___layer4___2___bn2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___conv3 = self.getattr_L__self___layer4___2___conv3(getattr_l__self___layer4___2___relu_1);  getattr_l__self___layer4___2___relu_1 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___bn3 = self.getattr_L__self___layer4___2___bn3(getattr_l__self___layer4___2___conv3);  getattr_l__self___layer4___2___conv3 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___bn3 += getattr_l__self___layer4___1___relu_2;  iadd_15 = getattr_l__self___layer4___2___bn3;  getattr_l__self___layer4___2___bn3 = getattr_l__self___layer4___1___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         getattr_l__self___layer4___2___relu_2 = self.getattr_L__self___layer4___2___relu(iadd_15);  iadd_15 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:278, code: x = self.avgpool(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         l__self___avgpool = self.L__self___avgpool(getattr_l__self___layer4___2___relu_2);  getattr_l__self___layer4___2___relu_2 = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:279, code: x = torch.flatten(x, 1)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         flatten = torch.flatten(l__self___avgpool, 1);  l__self___avgpool = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:280, code: x = self.fc(x)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         l__self___fc = self.L__self___fc(flatten);  flatten = None
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         return (l__self___fc,)
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG]         
[2023-12-28 21:22:50,886] [0/0] torch._dynamo.output_graph.__graph: [DEBUG] 
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_0 =====
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (64, 3, 224, 224)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___conv1: (64, 64, 112, 112)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___bn1: (64, 64, 112, 112)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___relu: (64, 64, 112, 112)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___maxpool: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___conv1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___bn1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___relu: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___conv2: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___bn2: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___relu_1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___conv3: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___bn3: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___downsample_0: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___downsample_1: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___relu_2: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___conv1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___bn1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___relu: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___conv2: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___bn2: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___relu_1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___conv3: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___bn3: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_1: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___relu_2: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___conv1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___bn1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___relu: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___conv2: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___bn2: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___relu_1: (64, 64, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___conv3: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___bn3: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_2: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___2___relu_2: (64, 256, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___conv1: (64, 128, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___bn1: (64, 128, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___relu: (64, 128, 56, 56)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___conv2: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___bn2: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___relu_1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___conv3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___bn3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___downsample_0: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___downsample_1: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___relu_2: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___conv1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___bn1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___relu: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___conv2: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___bn2: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___relu_1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___conv3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___bn3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_4: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___relu_2: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___conv1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___bn1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___relu: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___conv2: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___bn2: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___relu_1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___conv3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___bn3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_5: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___2___relu_2: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___conv1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___bn1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___relu: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___conv2: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___bn2: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___relu_1: (64, 128, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___conv3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___bn3: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_6: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___3___relu_2: (64, 512, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___conv1: (64, 256, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___bn1: (64, 256, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___relu: (64, 256, 28, 28)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___conv2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___bn2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___relu_1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___conv3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___bn3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___downsample_0: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___downsample_1: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_7: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___relu_2: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___conv1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___bn1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___relu: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___conv2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___bn2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___relu_1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___conv3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___bn3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_8: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___relu_2: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___conv1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___bn1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___relu: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___conv2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___bn2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___relu_1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___conv3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___bn3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_9: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___2___relu_2: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___conv1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___bn1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___relu: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___conv2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___bn2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___relu_1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___conv3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___bn3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_10: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___3___relu_2: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___conv1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___bn1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___relu: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___conv2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___bn2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___relu_1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___conv3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___bn3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_11: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___4___relu_2: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___conv1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___bn1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___relu: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___conv2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___bn2: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___relu_1: (64, 256, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___conv3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___bn3: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_12: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___5___relu_2: (64, 1024, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___conv1: (64, 512, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___bn1: (64, 512, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___relu: (64, 512, 14, 14)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___conv2: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___bn2: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___relu_1: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___conv3: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___bn3: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___downsample_0: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___downsample_1: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_13: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___relu_2: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___conv1: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___bn1: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___relu: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___conv2: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___bn2: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___relu_1: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___conv3: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___bn3: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_14: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___relu_2: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___conv1: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___bn1: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___relu: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___conv2: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___bn2: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___relu_1: (64, 512, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___conv3: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___bn3: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_15: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___2___relu_2: (64, 2048, 7, 7)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___avgpool: (64, 2048, 1, 1)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] flatten: (64, 2048)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___fc: (64, 1000)
[2023-12-28 21:22:50,894] [0/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] 
[2023-12-28 21:22:50,895] [0/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO] TRACED GRAPH
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]  ===== Joint graph 0 =====
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]  <eval_with_key>.4 from /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py:477 in wrapped class joint_helper(torch.nn.Module):
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]     def forward(self, primals, tangents):
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         primals_1: f32[64, 3, 7, 7], primals_2: f32[64], primals_3: f32[64], primals_4: f32[64, 64, 1, 1], primals_5: f32[64], primals_6: f32[64], primals_7: f32[64, 64, 3, 3], primals_8: f32[64], primals_9: f32[64], primals_10: f32[256, 64, 1, 1], primals_11: f32[256], primals_12: f32[256], primals_13: f32[256, 64, 1, 1], primals_14: f32[256], primals_15: f32[256], primals_16: f32[64, 256, 1, 1], primals_17: f32[64], primals_18: f32[64], primals_19: f32[64, 64, 3, 3], primals_20: f32[64], primals_21: f32[64], primals_22: f32[256, 64, 1, 1], primals_23: f32[256], primals_24: f32[256], primals_25: f32[64, 256, 1, 1], primals_26: f32[64], primals_27: f32[64], primals_28: f32[64, 64, 3, 3], primals_29: f32[64], primals_30: f32[64], primals_31: f32[256, 64, 1, 1], primals_32: f32[256], primals_33: f32[256], primals_34: f32[128, 256, 1, 1], primals_35: f32[128], primals_36: f32[128], primals_37: f32[128, 128, 3, 3], primals_38: f32[128], primals_39: f32[128], primals_40: f32[512, 128, 1, 1], primals_41: f32[512], primals_42: f32[512], primals_43: f32[512, 256, 1, 1], primals_44: f32[512], primals_45: f32[512], primals_46: f32[128, 512, 1, 1], primals_47: f32[128], primals_48: f32[128], primals_49: f32[128, 128, 3, 3], primals_50: f32[128], primals_51: f32[128], primals_52: f32[512, 128, 1, 1], primals_53: f32[512], primals_54: f32[512], primals_55: f32[128, 512, 1, 1], primals_56: f32[128], primals_57: f32[128], primals_58: f32[128, 128, 3, 3], primals_59: f32[128], primals_60: f32[128], primals_61: f32[512, 128, 1, 1], primals_62: f32[512], primals_63: f32[512], primals_64: f32[128, 512, 1, 1], primals_65: f32[128], primals_66: f32[128], primals_67: f32[128, 128, 3, 3], primals_68: f32[128], primals_69: f32[128], primals_70: f32[512, 128, 1, 1], primals_71: f32[512], primals_72: f32[512], primals_73: f32[256, 512, 1, 1], primals_74: f32[256], primals_75: f32[256], primals_76: f32[256, 256, 3, 3], primals_77: f32[256], primals_78: f32[256], primals_79: f32[1024, 256, 1, 1], primals_80: f32[1024], primals_81: f32[1024], primals_82: f32[1024, 512, 1, 1], primals_83: f32[1024], primals_84: f32[1024], primals_85: f32[256, 1024, 1, 1], primals_86: f32[256], primals_87: f32[256], primals_88: f32[256, 256, 3, 3], primals_89: f32[256], primals_90: f32[256], primals_91: f32[1024, 256, 1, 1], primals_92: f32[1024], primals_93: f32[1024], primals_94: f32[256, 1024, 1, 1], primals_95: f32[256], primals_96: f32[256], primals_97: f32[256, 256, 3, 3], primals_98: f32[256], primals_99: f32[256], primals_100: f32[1024, 256, 1, 1], primals_101: f32[1024], primals_102: f32[1024], primals_103: f32[256, 1024, 1, 1], primals_104: f32[256], primals_105: f32[256], primals_106: f32[256, 256, 3, 3], primals_107: f32[256], primals_108: f32[256], primals_109: f32[1024, 256, 1, 1], primals_110: f32[1024], primals_111: f32[1024], primals_112: f32[256, 1024, 1, 1], primals_113: f32[256], primals_114: f32[256], primals_115: f32[256, 256, 3, 3], primals_116: f32[256], primals_117: f32[256], primals_118: f32[1024, 256, 1, 1], primals_119: f32[1024], primals_120: f32[1024], primals_121: f32[256, 1024, 1, 1], primals_122: f32[256], primals_123: f32[256], primals_124: f32[256, 256, 3, 3], primals_125: f32[256], primals_126: f32[256], primals_127: f32[1024, 256, 1, 1], primals_128: f32[1024], primals_129: f32[1024], primals_130: f32[512, 1024, 1, 1], primals_131: f32[512], primals_132: f32[512], primals_133: f32[512, 512, 3, 3], primals_134: f32[512], primals_135: f32[512], primals_136: f32[2048, 512, 1, 1], primals_137: f32[2048], primals_138: f32[2048], primals_139: f32[2048, 1024, 1, 1], primals_140: f32[2048], primals_141: f32[2048], primals_142: f32[512, 2048, 1, 1], primals_143: f32[512], primals_144: f32[512], primals_145: f32[512, 512, 3, 3], primals_146: f32[512], primals_147: f32[512], primals_148: f32[2048, 512, 1, 1], primals_149: f32[2048], primals_150: f32[2048], primals_151: f32[512, 2048, 1, 1], primals_152: f32[512], primals_153: f32[512], primals_154: f32[512, 512, 3, 3], primals_155: f32[512], primals_156: f32[512], primals_157: f32[2048, 512, 1, 1], primals_158: f32[2048], primals_159: f32[2048], primals_160: f32[1000, 2048], primals_161: f32[1000], primals_162: f32[64], primals_163: f32[64], primals_164: i64[], primals_165: f32[64], primals_166: f32[64], primals_167: i64[], primals_168: f32[64], primals_169: f32[64], primals_170: i64[], primals_171: f32[256], primals_172: f32[256], primals_173: i64[], primals_174: f32[256], primals_175: f32[256], primals_176: i64[], primals_177: f32[64], primals_178: f32[64], primals_179: i64[], primals_180: f32[64], primals_181: f32[64], primals_182: i64[], primals_183: f32[256], primals_184: f32[256], primals_185: i64[], primals_186: f32[64], primals_187: f32[64], primals_188: i64[], primals_189: f32[64], primals_190: f32[64], primals_191: i64[], primals_192: f32[256], primals_193: f32[256], primals_194: i64[], primals_195: f32[128], primals_196: f32[128], primals_197: i64[], primals_198: f32[128], primals_199: f32[128], primals_200: i64[], primals_201: f32[512], primals_202: f32[512], primals_203: i64[], primals_204: f32[512], primals_205: f32[512], primals_206: i64[], primals_207: f32[128], primals_208: f32[128], primals_209: i64[], primals_210: f32[128], primals_211: f32[128], primals_212: i64[], primals_213: f32[512], primals_214: f32[512], primals_215: i64[], primals_216: f32[128], primals_217: f32[128], primals_218: i64[], primals_219: f32[128], primals_220: f32[128], primals_221: i64[], primals_222: f32[512], primals_223: f32[512], primals_224: i64[], primals_225: f32[128], primals_226: f32[128], primals_227: i64[], primals_228: f32[128], primals_229: f32[128], primals_230: i64[], primals_231: f32[512], primals_232: f32[512], primals_233: i64[], primals_234: f32[256], primals_235: f32[256], primals_236: i64[], primals_237: f32[256], primals_238: f32[256], primals_239: i64[], primals_240: f32[1024], primals_241: f32[1024], primals_242: i64[], primals_243: f32[1024], primals_244: f32[1024], primals_245: i64[], primals_246: f32[256], primals_247: f32[256], primals_248: i64[], primals_249: f32[256], primals_250: f32[256], primals_251: i64[], primals_252: f32[1024], primals_253: f32[1024], primals_254: i64[], primals_255: f32[256], primals_256: f32[256], primals_257: i64[], primals_258: f32[256], primals_259: f32[256], primals_260: i64[], primals_261: f32[1024], primals_262: f32[1024], primals_263: i64[], primals_264: f32[256], primals_265: f32[256], primals_266: i64[], primals_267: f32[256], primals_268: f32[256], primals_269: i64[], primals_270: f32[1024], primals_271: f32[1024], primals_272: i64[], primals_273: f32[256], primals_274: f32[256], primals_275: i64[], primals_276: f32[256], primals_277: f32[256], primals_278: i64[], primals_279: f32[1024], primals_280: f32[1024], primals_281: i64[], primals_282: f32[256], primals_283: f32[256], primals_284: i64[], primals_285: f32[256], primals_286: f32[256], primals_287: i64[], primals_288: f32[1024], primals_289: f32[1024], primals_290: i64[], primals_291: f32[512], primals_292: f32[512], primals_293: i64[], primals_294: f32[512], primals_295: f32[512], primals_296: i64[], primals_297: f32[2048], primals_298: f32[2048], primals_299: i64[], primals_300: f32[2048], primals_301: f32[2048], primals_302: i64[], primals_303: f32[512], primals_304: f32[512], primals_305: i64[], primals_306: f32[512], primals_307: f32[512], primals_308: i64[], primals_309: f32[2048], primals_310: f32[2048], primals_311: i64[], primals_312: f32[512], primals_313: f32[512], primals_314: i64[], primals_315: f32[512], primals_316: f32[512], primals_317: i64[], primals_318: f32[2048], primals_319: f32[2048], primals_320: i64[], primals_321: f32[64, 3, 224, 224], tangents_1: f32[64], tangents_2: f32[64], tangents_3: i64[], tangents_4: f32[64], tangents_5: f32[64], tangents_6: i64[], tangents_7: f32[64], tangents_8: f32[64], tangents_9: i64[], tangents_10: f32[256], tangents_11: f32[256], tangents_12: i64[], tangents_13: f32[256], tangents_14: f32[256], tangents_15: i64[], tangents_16: f32[64], tangents_17: f32[64], tangents_18: i64[], tangents_19: f32[64], tangents_20: f32[64], tangents_21: i64[], tangents_22: f32[256], tangents_23: f32[256], tangents_24: i64[], tangents_25: f32[64], tangents_26: f32[64], tangents_27: i64[], tangents_28: f32[64], tangents_29: f32[64], tangents_30: i64[], tangents_31: f32[256], tangents_32: f32[256], tangents_33: i64[], tangents_34: f32[128], tangents_35: f32[128], tangents_36: i64[], tangents_37: f32[128], tangents_38: f32[128], tangents_39: i64[], tangents_40: f32[512], tangents_41: f32[512], tangents_42: i64[], tangents_43: f32[512], tangents_44: f32[512], tangents_45: i64[], tangents_46: f32[128], tangents_47: f32[128], tangents_48: i64[], tangents_49: f32[128], tangents_50: f32[128], tangents_51: i64[], tangents_52: f32[512], tangents_53: f32[512], tangents_54: i64[], tangents_55: f32[128], tangents_56: f32[128], tangents_57: i64[], tangents_58: f32[128], tangents_59: f32[128], tangents_60: i64[], tangents_61: f32[512], tangents_62: f32[512], tangents_63: i64[], tangents_64: f32[128], tangents_65: f32[128], tangents_66: i64[], tangents_67: f32[128], tangents_68: f32[128], tangents_69: i64[], tangents_70: f32[512], tangents_71: f32[512], tangents_72: i64[], tangents_73: f32[256], tangents_74: f32[256], tangents_75: i64[], tangents_76: f32[256], tangents_77: f32[256], tangents_78: i64[], tangents_79: f32[1024], tangents_80: f32[1024], tangents_81: i64[], tangents_82: f32[1024], tangents_83: f32[1024], tangents_84: i64[], tangents_85: f32[256], tangents_86: f32[256], tangents_87: i64[], tangents_88: f32[256], tangents_89: f32[256], tangents_90: i64[], tangents_91: f32[1024], tangents_92: f32[1024], tangents_93: i64[], tangents_94: f32[256], tangents_95: f32[256], tangents_96: i64[], tangents_97: f32[256], tangents_98: f32[256], tangents_99: i64[], tangents_100: f32[1024], tangents_101: f32[1024], tangents_102: i64[], tangents_103: f32[256], tangents_104: f32[256], tangents_105: i64[], tangents_106: f32[256], tangents_107: f32[256], tangents_108: i64[], tangents_109: f32[1024], tangents_110: f32[1024], tangents_111: i64[], tangents_112: f32[256], tangents_113: f32[256], tangents_114: i64[], tangents_115: f32[256], tangents_116: f32[256], tangents_117: i64[], tangents_118: f32[1024], tangents_119: f32[1024], tangents_120: i64[], tangents_121: f32[256], tangents_122: f32[256], tangents_123: i64[], tangents_124: f32[256], tangents_125: f32[256], tangents_126: i64[], tangents_127: f32[1024], tangents_128: f32[1024], tangents_129: i64[], tangents_130: f32[512], tangents_131: f32[512], tangents_132: i64[], tangents_133: f32[512], tangents_134: f32[512], tangents_135: i64[], tangents_136: f32[2048], tangents_137: f32[2048], tangents_138: i64[], tangents_139: f32[2048], tangents_140: f32[2048], tangents_141: i64[], tangents_142: f32[512], tangents_143: f32[512], tangents_144: i64[], tangents_145: f32[512], tangents_146: f32[512], tangents_147: i64[], tangents_148: f32[2048], tangents_149: f32[2048], tangents_150: i64[], tangents_151: f32[512], tangents_152: f32[512], tangents_153: i64[], tangents_154: f32[512], tangents_155: f32[512], tangents_156: i64[], tangents_157: f32[2048], tangents_158: f32[2048], tangents_159: i64[], tangents_160: f32[64, 1000], = fx_pytree.tree_flatten_spec([primals, tangents], self._in_spec)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:268, code: x = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution: f32[64, 64, 112, 112] = torch.ops.aten.convolution.default(primals_321, primals_1, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:269, code: x = self.bn1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add: i64[] = torch.ops.aten.add.Tensor(primals_164, 1);  primals_164 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean = torch.ops.aten.var_mean.correction(convolution, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem: f32[1, 64, 1, 1] = var_mean[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_1: f32[1, 64, 1, 1] = var_mean[1];  var_mean = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_1: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(convolution, getitem_1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze: f32[64] = torch.ops.aten.squeeze.dims(getitem_1, [0, 2, 3]);  getitem_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_1: f32[64] = torch.ops.aten.squeeze.dims(rsqrt, [0, 2, 3]);  rsqrt = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_1: f32[64] = torch.ops.aten.mul.Tensor(squeeze, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_2: f32[64] = torch.ops.aten.mul.Tensor(primals_162, 0.9);  primals_162 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_2: f32[64] = torch.ops.aten.add.Tensor(mul_1, mul_2);  mul_1 = mul_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_2: f32[64] = torch.ops.aten.squeeze.dims(getitem, [0, 2, 3]);  getitem = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_3: f32[64] = torch.ops.aten.mul.Tensor(squeeze_2, 1.0000012456169853);  squeeze_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_4: f32[64] = torch.ops.aten.mul.Tensor(mul_3, 0.1);  mul_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_5: f32[64] = torch.ops.aten.mul.Tensor(primals_163, 0.9);  primals_163 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_3: f32[64] = torch.ops.aten.add.Tensor(mul_4, mul_5);  mul_4 = mul_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_2, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_1: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze, -1);  unsqueeze = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_6: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(mul, unsqueeze_1);  mul = unsqueeze_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_2: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_3, -1);  primals_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_3: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_2, -1);  unsqueeze_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_4: f32[64, 64, 112, 112] = torch.ops.aten.add.Tensor(mul_6, unsqueeze_3);  mul_6 = unsqueeze_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:270, code: x = self.relu(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu: f32[64, 64, 112, 112] = torch.ops.aten.relu.default(add_4);  add_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:271, code: x = self.maxpool(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         max_pool2d_with_indices = torch.ops.aten.max_pool2d_with_indices.default(relu, [3, 3], [2, 2], [1, 1])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_2: f32[64, 64, 56, 56] = max_pool2d_with_indices[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_3: i64[64, 64, 56, 56] = max_pool2d_with_indices[1];  max_pool2d_with_indices = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_1: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(getitem_2, primals_4, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_5: i64[] = torch.ops.aten.add.Tensor(primals_167, 1);  primals_167 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_1 = torch.ops.aten.var_mean.correction(convolution_1, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_4: f32[1, 64, 1, 1] = var_mean_1[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_5: f32[1, 64, 1, 1] = var_mean_1[1];  var_mean_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_6: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_4, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_1: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_6);  add_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_1: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_1, getitem_5)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_7: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_1, rsqrt_1);  sub_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_3: f32[64] = torch.ops.aten.squeeze.dims(getitem_5, [0, 2, 3]);  getitem_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_4: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_1, [0, 2, 3]);  rsqrt_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_8: f32[64] = torch.ops.aten.mul.Tensor(squeeze_3, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_9: f32[64] = torch.ops.aten.mul.Tensor(primals_165, 0.9);  primals_165 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_7: f32[64] = torch.ops.aten.add.Tensor(mul_8, mul_9);  mul_8 = mul_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_5: f32[64] = torch.ops.aten.squeeze.dims(getitem_4, [0, 2, 3]);  getitem_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_10: f32[64] = torch.ops.aten.mul.Tensor(squeeze_5, 1.0000049824865598);  squeeze_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_11: f32[64] = torch.ops.aten.mul.Tensor(mul_10, 0.1);  mul_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_12: f32[64] = torch.ops.aten.mul.Tensor(primals_166, 0.9);  primals_166 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_8: f32[64] = torch.ops.aten.add.Tensor(mul_11, mul_12);  mul_11 = mul_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_4: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_5, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_5: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_4, -1);  unsqueeze_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_13: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_7, unsqueeze_5);  mul_7 = unsqueeze_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_6: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_6, -1);  primals_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_7: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_6, -1);  unsqueeze_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_9: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_13, unsqueeze_7);  mul_13 = unsqueeze_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_1: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_9);  add_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_2: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_1, primals_7, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_10: i64[] = torch.ops.aten.add.Tensor(primals_170, 1);  primals_170 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_2 = torch.ops.aten.var_mean.correction(convolution_2, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_6: f32[1, 64, 1, 1] = var_mean_2[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_7: f32[1, 64, 1, 1] = var_mean_2[1];  var_mean_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_11: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_6, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_2: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_11);  add_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_2: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_2, getitem_7)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_14: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_2, rsqrt_2);  sub_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_6: f32[64] = torch.ops.aten.squeeze.dims(getitem_7, [0, 2, 3]);  getitem_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_7: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_2, [0, 2, 3]);  rsqrt_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_15: f32[64] = torch.ops.aten.mul.Tensor(squeeze_6, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_16: f32[64] = torch.ops.aten.mul.Tensor(primals_168, 0.9);  primals_168 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_12: f32[64] = torch.ops.aten.add.Tensor(mul_15, mul_16);  mul_15 = mul_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_8: f32[64] = torch.ops.aten.squeeze.dims(getitem_6, [0, 2, 3]);  getitem_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_17: f32[64] = torch.ops.aten.mul.Tensor(squeeze_8, 1.0000049824865598);  squeeze_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_18: f32[64] = torch.ops.aten.mul.Tensor(mul_17, 0.1);  mul_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_19: f32[64] = torch.ops.aten.mul.Tensor(primals_169, 0.9);  primals_169 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_13: f32[64] = torch.ops.aten.add.Tensor(mul_18, mul_19);  mul_18 = mul_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_8: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_8, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_9: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_8, -1);  unsqueeze_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_20: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_14, unsqueeze_9);  mul_14 = unsqueeze_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_10: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_9, -1);  primals_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_11: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_10, -1);  unsqueeze_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_14: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_20, unsqueeze_11);  mul_20 = unsqueeze_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_2: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_14);  add_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_3: f32[64, 256, 56, 56] = torch.ops.aten.convolution.default(relu_2, primals_10, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_15: i64[] = torch.ops.aten.add.Tensor(primals_173, 1);  primals_173 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_3 = torch.ops.aten.var_mean.correction(convolution_3, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_8: f32[1, 256, 1, 1] = var_mean_3[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_9: f32[1, 256, 1, 1] = var_mean_3[1];  var_mean_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_16: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_8, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_3: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_3: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_3, getitem_9)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_21: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_3, rsqrt_3);  sub_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_9: f32[256] = torch.ops.aten.squeeze.dims(getitem_9, [0, 2, 3]);  getitem_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_10: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_3, [0, 2, 3]);  rsqrt_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_22: f32[256] = torch.ops.aten.mul.Tensor(squeeze_9, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_23: f32[256] = torch.ops.aten.mul.Tensor(primals_171, 0.9);  primals_171 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_17: f32[256] = torch.ops.aten.add.Tensor(mul_22, mul_23);  mul_22 = mul_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_11: f32[256] = torch.ops.aten.squeeze.dims(getitem_8, [0, 2, 3]);  getitem_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_24: f32[256] = torch.ops.aten.mul.Tensor(squeeze_11, 1.0000049824865598);  squeeze_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_25: f32[256] = torch.ops.aten.mul.Tensor(mul_24, 0.1);  mul_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_26: f32[256] = torch.ops.aten.mul.Tensor(primals_172, 0.9);  primals_172 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_18: f32[256] = torch.ops.aten.add.Tensor(mul_25, mul_26);  mul_25 = mul_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_12: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_11, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_13: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_12, -1);  unsqueeze_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_27: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(mul_21, unsqueeze_13);  mul_21 = unsqueeze_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_14: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_12, -1);  primals_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_15: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_14, -1);  unsqueeze_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_19: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(mul_27, unsqueeze_15);  mul_27 = unsqueeze_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_4: f32[64, 256, 56, 56] = torch.ops.aten.convolution.default(getitem_2, primals_13, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_20: i64[] = torch.ops.aten.add.Tensor(primals_176, 1);  primals_176 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_4 = torch.ops.aten.var_mean.correction(convolution_4, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_10: f32[1, 256, 1, 1] = var_mean_4[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_11: f32[1, 256, 1, 1] = var_mean_4[1];  var_mean_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_21: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_10, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_4: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_21);  add_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_4: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_4, getitem_11)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_28: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_4, rsqrt_4);  sub_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_12: f32[256] = torch.ops.aten.squeeze.dims(getitem_11, [0, 2, 3]);  getitem_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_13: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_4, [0, 2, 3]);  rsqrt_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_29: f32[256] = torch.ops.aten.mul.Tensor(squeeze_12, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_30: f32[256] = torch.ops.aten.mul.Tensor(primals_174, 0.9);  primals_174 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_22: f32[256] = torch.ops.aten.add.Tensor(mul_29, mul_30);  mul_29 = mul_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_14: f32[256] = torch.ops.aten.squeeze.dims(getitem_10, [0, 2, 3]);  getitem_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_31: f32[256] = torch.ops.aten.mul.Tensor(squeeze_14, 1.0000049824865598);  squeeze_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_32: f32[256] = torch.ops.aten.mul.Tensor(mul_31, 0.1);  mul_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_33: f32[256] = torch.ops.aten.mul.Tensor(primals_175, 0.9);  primals_175 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_23: f32[256] = torch.ops.aten.add.Tensor(mul_32, mul_33);  mul_32 = mul_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_16: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_14, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_17: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_16, -1);  unsqueeze_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_34: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(mul_28, unsqueeze_17);  mul_28 = unsqueeze_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_18: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_15, -1);  primals_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_19: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_18, -1);  unsqueeze_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_24: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(mul_34, unsqueeze_19);  mul_34 = unsqueeze_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_25: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(add_19, add_24);  add_19 = add_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_3: f32[64, 256, 56, 56] = torch.ops.aten.relu.default(add_25);  add_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_5: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_3, primals_16, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_26: i64[] = torch.ops.aten.add.Tensor(primals_179, 1);  primals_179 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_5 = torch.ops.aten.var_mean.correction(convolution_5, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_12: f32[1, 64, 1, 1] = var_mean_5[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_13: f32[1, 64, 1, 1] = var_mean_5[1];  var_mean_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_27: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_12, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_5: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_27);  add_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_5: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_5, getitem_13)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_35: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_5, rsqrt_5);  sub_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_15: f32[64] = torch.ops.aten.squeeze.dims(getitem_13, [0, 2, 3]);  getitem_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_16: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_5, [0, 2, 3]);  rsqrt_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_36: f32[64] = torch.ops.aten.mul.Tensor(squeeze_15, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_37: f32[64] = torch.ops.aten.mul.Tensor(primals_177, 0.9);  primals_177 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_28: f32[64] = torch.ops.aten.add.Tensor(mul_36, mul_37);  mul_36 = mul_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_17: f32[64] = torch.ops.aten.squeeze.dims(getitem_12, [0, 2, 3]);  getitem_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_38: f32[64] = torch.ops.aten.mul.Tensor(squeeze_17, 1.0000049824865598);  squeeze_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_39: f32[64] = torch.ops.aten.mul.Tensor(mul_38, 0.1);  mul_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_40: f32[64] = torch.ops.aten.mul.Tensor(primals_178, 0.9);  primals_178 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_29: f32[64] = torch.ops.aten.add.Tensor(mul_39, mul_40);  mul_39 = mul_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_20: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_17, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_21: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_20, -1);  unsqueeze_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_41: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_35, unsqueeze_21);  mul_35 = unsqueeze_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_22: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_18, -1);  primals_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_23: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_22, -1);  unsqueeze_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_30: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_41, unsqueeze_23);  mul_41 = unsqueeze_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_4: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_30);  add_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_6: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_4, primals_19, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_31: i64[] = torch.ops.aten.add.Tensor(primals_182, 1);  primals_182 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_6 = torch.ops.aten.var_mean.correction(convolution_6, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_14: f32[1, 64, 1, 1] = var_mean_6[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_15: f32[1, 64, 1, 1] = var_mean_6[1];  var_mean_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_32: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_14, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_6: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_32);  add_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_6: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_6, getitem_15)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_42: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_6, rsqrt_6);  sub_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_18: f32[64] = torch.ops.aten.squeeze.dims(getitem_15, [0, 2, 3]);  getitem_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_19: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_6, [0, 2, 3]);  rsqrt_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_43: f32[64] = torch.ops.aten.mul.Tensor(squeeze_18, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_44: f32[64] = torch.ops.aten.mul.Tensor(primals_180, 0.9);  primals_180 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_33: f32[64] = torch.ops.aten.add.Tensor(mul_43, mul_44);  mul_43 = mul_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_20: f32[64] = torch.ops.aten.squeeze.dims(getitem_14, [0, 2, 3]);  getitem_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_45: f32[64] = torch.ops.aten.mul.Tensor(squeeze_20, 1.0000049824865598);  squeeze_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_46: f32[64] = torch.ops.aten.mul.Tensor(mul_45, 0.1);  mul_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_47: f32[64] = torch.ops.aten.mul.Tensor(primals_181, 0.9);  primals_181 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_34: f32[64] = torch.ops.aten.add.Tensor(mul_46, mul_47);  mul_46 = mul_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_24: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_20, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_25: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_24, -1);  unsqueeze_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_48: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_42, unsqueeze_25);  mul_42 = unsqueeze_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_26: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_21, -1);  primals_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_27: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_26, -1);  unsqueeze_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_35: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_48, unsqueeze_27);  mul_48 = unsqueeze_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_5: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_35);  add_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_7: f32[64, 256, 56, 56] = torch.ops.aten.convolution.default(relu_5, primals_22, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_36: i64[] = torch.ops.aten.add.Tensor(primals_185, 1);  primals_185 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_7 = torch.ops.aten.var_mean.correction(convolution_7, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_16: f32[1, 256, 1, 1] = var_mean_7[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_17: f32[1, 256, 1, 1] = var_mean_7[1];  var_mean_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_37: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_16, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_7: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_37);  add_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_7: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_7, getitem_17)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_49: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_7, rsqrt_7);  sub_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_21: f32[256] = torch.ops.aten.squeeze.dims(getitem_17, [0, 2, 3]);  getitem_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_22: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_7, [0, 2, 3]);  rsqrt_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_50: f32[256] = torch.ops.aten.mul.Tensor(squeeze_21, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_51: f32[256] = torch.ops.aten.mul.Tensor(primals_183, 0.9);  primals_183 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_38: f32[256] = torch.ops.aten.add.Tensor(mul_50, mul_51);  mul_50 = mul_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_23: f32[256] = torch.ops.aten.squeeze.dims(getitem_16, [0, 2, 3]);  getitem_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_52: f32[256] = torch.ops.aten.mul.Tensor(squeeze_23, 1.0000049824865598);  squeeze_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_53: f32[256] = torch.ops.aten.mul.Tensor(mul_52, 0.1);  mul_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_54: f32[256] = torch.ops.aten.mul.Tensor(primals_184, 0.9);  primals_184 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_39: f32[256] = torch.ops.aten.add.Tensor(mul_53, mul_54);  mul_53 = mul_54 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_28: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_23, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_29: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_28, -1);  unsqueeze_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_55: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(mul_49, unsqueeze_29);  mul_49 = unsqueeze_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_30: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_24, -1);  primals_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_31: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_30, -1);  unsqueeze_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_40: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(mul_55, unsqueeze_31);  mul_55 = unsqueeze_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_41: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(add_40, relu_3);  add_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_6: f32[64, 256, 56, 56] = torch.ops.aten.relu.default(add_41);  add_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_8: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_6, primals_25, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_42: i64[] = torch.ops.aten.add.Tensor(primals_188, 1);  primals_188 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_8 = torch.ops.aten.var_mean.correction(convolution_8, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_18: f32[1, 64, 1, 1] = var_mean_8[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_19: f32[1, 64, 1, 1] = var_mean_8[1];  var_mean_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_43: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_18, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_8: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_43);  add_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_8: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_8, getitem_19)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_56: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_8, rsqrt_8);  sub_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_24: f32[64] = torch.ops.aten.squeeze.dims(getitem_19, [0, 2, 3]);  getitem_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_25: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_8, [0, 2, 3]);  rsqrt_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_57: f32[64] = torch.ops.aten.mul.Tensor(squeeze_24, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_58: f32[64] = torch.ops.aten.mul.Tensor(primals_186, 0.9);  primals_186 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_44: f32[64] = torch.ops.aten.add.Tensor(mul_57, mul_58);  mul_57 = mul_58 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_26: f32[64] = torch.ops.aten.squeeze.dims(getitem_18, [0, 2, 3]);  getitem_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_59: f32[64] = torch.ops.aten.mul.Tensor(squeeze_26, 1.0000049824865598);  squeeze_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_60: f32[64] = torch.ops.aten.mul.Tensor(mul_59, 0.1);  mul_59 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_61: f32[64] = torch.ops.aten.mul.Tensor(primals_187, 0.9);  primals_187 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_45: f32[64] = torch.ops.aten.add.Tensor(mul_60, mul_61);  mul_60 = mul_61 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_32: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_26, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_33: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_32, -1);  unsqueeze_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_62: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_56, unsqueeze_33);  mul_56 = unsqueeze_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_34: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_27, -1);  primals_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_35: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_34, -1);  unsqueeze_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_46: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_62, unsqueeze_35);  mul_62 = unsqueeze_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_7: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_46);  add_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_9: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_7, primals_28, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_47: i64[] = torch.ops.aten.add.Tensor(primals_191, 1);  primals_191 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_9 = torch.ops.aten.var_mean.correction(convolution_9, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_20: f32[1, 64, 1, 1] = var_mean_9[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_21: f32[1, 64, 1, 1] = var_mean_9[1];  var_mean_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_48: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_20, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_9: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_48);  add_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_9: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_9, getitem_21)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_63: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_9, rsqrt_9);  sub_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_27: f32[64] = torch.ops.aten.squeeze.dims(getitem_21, [0, 2, 3]);  getitem_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_28: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_9, [0, 2, 3]);  rsqrt_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_64: f32[64] = torch.ops.aten.mul.Tensor(squeeze_27, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_65: f32[64] = torch.ops.aten.mul.Tensor(primals_189, 0.9);  primals_189 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_49: f32[64] = torch.ops.aten.add.Tensor(mul_64, mul_65);  mul_64 = mul_65 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_29: f32[64] = torch.ops.aten.squeeze.dims(getitem_20, [0, 2, 3]);  getitem_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_66: f32[64] = torch.ops.aten.mul.Tensor(squeeze_29, 1.0000049824865598);  squeeze_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_67: f32[64] = torch.ops.aten.mul.Tensor(mul_66, 0.1);  mul_66 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_68: f32[64] = torch.ops.aten.mul.Tensor(primals_190, 0.9);  primals_190 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_50: f32[64] = torch.ops.aten.add.Tensor(mul_67, mul_68);  mul_67 = mul_68 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_36: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_29, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_37: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_36, -1);  unsqueeze_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_69: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_63, unsqueeze_37);  mul_63 = unsqueeze_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_38: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_30, -1);  primals_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_39: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_38, -1);  unsqueeze_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_51: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_69, unsqueeze_39);  mul_69 = unsqueeze_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_8: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_51);  add_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_10: f32[64, 256, 56, 56] = torch.ops.aten.convolution.default(relu_8, primals_31, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_52: i64[] = torch.ops.aten.add.Tensor(primals_194, 1);  primals_194 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_10 = torch.ops.aten.var_mean.correction(convolution_10, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_22: f32[1, 256, 1, 1] = var_mean_10[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_23: f32[1, 256, 1, 1] = var_mean_10[1];  var_mean_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_53: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_22, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_10: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_53);  add_53 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_10: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_10, getitem_23)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_70: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_10, rsqrt_10);  sub_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_30: f32[256] = torch.ops.aten.squeeze.dims(getitem_23, [0, 2, 3]);  getitem_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_31: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_10, [0, 2, 3]);  rsqrt_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_71: f32[256] = torch.ops.aten.mul.Tensor(squeeze_30, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_72: f32[256] = torch.ops.aten.mul.Tensor(primals_192, 0.9);  primals_192 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_54: f32[256] = torch.ops.aten.add.Tensor(mul_71, mul_72);  mul_71 = mul_72 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_32: f32[256] = torch.ops.aten.squeeze.dims(getitem_22, [0, 2, 3]);  getitem_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_73: f32[256] = torch.ops.aten.mul.Tensor(squeeze_32, 1.0000049824865598);  squeeze_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_74: f32[256] = torch.ops.aten.mul.Tensor(mul_73, 0.1);  mul_73 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_75: f32[256] = torch.ops.aten.mul.Tensor(primals_193, 0.9);  primals_193 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_55: f32[256] = torch.ops.aten.add.Tensor(mul_74, mul_75);  mul_74 = mul_75 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_40: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_32, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_41: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_40, -1);  unsqueeze_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_76: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(mul_70, unsqueeze_41);  mul_70 = unsqueeze_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_42: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_33, -1);  primals_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_43: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_42, -1);  unsqueeze_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_56: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(mul_76, unsqueeze_43);  mul_76 = unsqueeze_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_57: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(add_56, relu_6);  add_56 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_9: f32[64, 256, 56, 56] = torch.ops.aten.relu.default(add_57);  add_57 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_11: f32[64, 128, 56, 56] = torch.ops.aten.convolution.default(relu_9, primals_34, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_58: i64[] = torch.ops.aten.add.Tensor(primals_197, 1);  primals_197 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_11 = torch.ops.aten.var_mean.correction(convolution_11, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_24: f32[1, 128, 1, 1] = var_mean_11[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_25: f32[1, 128, 1, 1] = var_mean_11[1];  var_mean_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_59: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_24, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_11: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_59);  add_59 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_11: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(convolution_11, getitem_25)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_77: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(sub_11, rsqrt_11);  sub_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_33: f32[128] = torch.ops.aten.squeeze.dims(getitem_25, [0, 2, 3]);  getitem_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_34: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_11, [0, 2, 3]);  rsqrt_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_78: f32[128] = torch.ops.aten.mul.Tensor(squeeze_33, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_79: f32[128] = torch.ops.aten.mul.Tensor(primals_195, 0.9);  primals_195 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_60: f32[128] = torch.ops.aten.add.Tensor(mul_78, mul_79);  mul_78 = mul_79 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_35: f32[128] = torch.ops.aten.squeeze.dims(getitem_24, [0, 2, 3]);  getitem_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_80: f32[128] = torch.ops.aten.mul.Tensor(squeeze_35, 1.0000049824865598);  squeeze_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_81: f32[128] = torch.ops.aten.mul.Tensor(mul_80, 0.1);  mul_80 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_82: f32[128] = torch.ops.aten.mul.Tensor(primals_196, 0.9);  primals_196 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_61: f32[128] = torch.ops.aten.add.Tensor(mul_81, mul_82);  mul_81 = mul_82 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_44: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_35, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_45: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_44, -1);  unsqueeze_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_83: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(mul_77, unsqueeze_45);  mul_77 = unsqueeze_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_46: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_36, -1);  primals_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_47: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_46, -1);  unsqueeze_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_62: f32[64, 128, 56, 56] = torch.ops.aten.add.Tensor(mul_83, unsqueeze_47);  mul_83 = unsqueeze_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_10: f32[64, 128, 56, 56] = torch.ops.aten.relu.default(add_62);  add_62 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_12: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_10, primals_37, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_63: i64[] = torch.ops.aten.add.Tensor(primals_200, 1);  primals_200 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_12 = torch.ops.aten.var_mean.correction(convolution_12, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_26: f32[1, 128, 1, 1] = var_mean_12[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_27: f32[1, 128, 1, 1] = var_mean_12[1];  var_mean_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_64: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_26, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_12: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_64);  add_64 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_12: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_12, getitem_27)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_84: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_12, rsqrt_12);  sub_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_36: f32[128] = torch.ops.aten.squeeze.dims(getitem_27, [0, 2, 3]);  getitem_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_37: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_12, [0, 2, 3]);  rsqrt_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_85: f32[128] = torch.ops.aten.mul.Tensor(squeeze_36, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_86: f32[128] = torch.ops.aten.mul.Tensor(primals_198, 0.9);  primals_198 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_65: f32[128] = torch.ops.aten.add.Tensor(mul_85, mul_86);  mul_85 = mul_86 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_38: f32[128] = torch.ops.aten.squeeze.dims(getitem_26, [0, 2, 3]);  getitem_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_87: f32[128] = torch.ops.aten.mul.Tensor(squeeze_38, 1.0000199302441455);  squeeze_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_88: f32[128] = torch.ops.aten.mul.Tensor(mul_87, 0.1);  mul_87 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_89: f32[128] = torch.ops.aten.mul.Tensor(primals_199, 0.9);  primals_199 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_66: f32[128] = torch.ops.aten.add.Tensor(mul_88, mul_89);  mul_88 = mul_89 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_48: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_38, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_49: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_48, -1);  unsqueeze_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_90: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_84, unsqueeze_49);  mul_84 = unsqueeze_49 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_50: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_39, -1);  primals_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_51: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_50, -1);  unsqueeze_50 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_67: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_90, unsqueeze_51);  mul_90 = unsqueeze_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_11: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_67);  add_67 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_13: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_11, primals_40, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_68: i64[] = torch.ops.aten.add.Tensor(primals_203, 1);  primals_203 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_13 = torch.ops.aten.var_mean.correction(convolution_13, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_28: f32[1, 512, 1, 1] = var_mean_13[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_29: f32[1, 512, 1, 1] = var_mean_13[1];  var_mean_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_69: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_28, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_13: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_69);  add_69 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_13: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_13, getitem_29)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_91: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_13, rsqrt_13);  sub_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_39: f32[512] = torch.ops.aten.squeeze.dims(getitem_29, [0, 2, 3]);  getitem_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_40: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_13, [0, 2, 3]);  rsqrt_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_92: f32[512] = torch.ops.aten.mul.Tensor(squeeze_39, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_93: f32[512] = torch.ops.aten.mul.Tensor(primals_201, 0.9);  primals_201 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_70: f32[512] = torch.ops.aten.add.Tensor(mul_92, mul_93);  mul_92 = mul_93 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_41: f32[512] = torch.ops.aten.squeeze.dims(getitem_28, [0, 2, 3]);  getitem_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_94: f32[512] = torch.ops.aten.mul.Tensor(squeeze_41, 1.0000199302441455);  squeeze_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_95: f32[512] = torch.ops.aten.mul.Tensor(mul_94, 0.1);  mul_94 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_96: f32[512] = torch.ops.aten.mul.Tensor(primals_202, 0.9);  primals_202 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_71: f32[512] = torch.ops.aten.add.Tensor(mul_95, mul_96);  mul_95 = mul_96 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_52: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_41, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_53: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_52, -1);  unsqueeze_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_97: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_91, unsqueeze_53);  mul_91 = unsqueeze_53 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_54: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_42, -1);  primals_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_55: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_54, -1);  unsqueeze_54 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_72: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_97, unsqueeze_55);  mul_97 = unsqueeze_55 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_14: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_9, primals_43, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_73: i64[] = torch.ops.aten.add.Tensor(primals_206, 1);  primals_206 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_14 = torch.ops.aten.var_mean.correction(convolution_14, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_30: f32[1, 512, 1, 1] = var_mean_14[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_31: f32[1, 512, 1, 1] = var_mean_14[1];  var_mean_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_74: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_30, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_14: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_74);  add_74 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_14: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_14, getitem_31)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_98: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_14, rsqrt_14);  sub_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_42: f32[512] = torch.ops.aten.squeeze.dims(getitem_31, [0, 2, 3]);  getitem_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_43: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_14, [0, 2, 3]);  rsqrt_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_99: f32[512] = torch.ops.aten.mul.Tensor(squeeze_42, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_100: f32[512] = torch.ops.aten.mul.Tensor(primals_204, 0.9);  primals_204 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_75: f32[512] = torch.ops.aten.add.Tensor(mul_99, mul_100);  mul_99 = mul_100 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_44: f32[512] = torch.ops.aten.squeeze.dims(getitem_30, [0, 2, 3]);  getitem_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_101: f32[512] = torch.ops.aten.mul.Tensor(squeeze_44, 1.0000199302441455);  squeeze_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_102: f32[512] = torch.ops.aten.mul.Tensor(mul_101, 0.1);  mul_101 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_103: f32[512] = torch.ops.aten.mul.Tensor(primals_205, 0.9);  primals_205 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_76: f32[512] = torch.ops.aten.add.Tensor(mul_102, mul_103);  mul_102 = mul_103 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_56: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_44, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_57: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_56, -1);  unsqueeze_56 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_104: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_98, unsqueeze_57);  mul_98 = unsqueeze_57 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_58: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_45, -1);  primals_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_59: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_58, -1);  unsqueeze_58 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_77: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_104, unsqueeze_59);  mul_104 = unsqueeze_59 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_78: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(add_72, add_77);  add_72 = add_77 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_12: f32[64, 512, 28, 28] = torch.ops.aten.relu.default(add_78);  add_78 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_15: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_12, primals_46, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_79: i64[] = torch.ops.aten.add.Tensor(primals_209, 1);  primals_209 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_15 = torch.ops.aten.var_mean.correction(convolution_15, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_32: f32[1, 128, 1, 1] = var_mean_15[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_33: f32[1, 128, 1, 1] = var_mean_15[1];  var_mean_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_80: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_32, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_15: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_80);  add_80 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_15: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_15, getitem_33)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_105: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_15, rsqrt_15);  sub_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_45: f32[128] = torch.ops.aten.squeeze.dims(getitem_33, [0, 2, 3]);  getitem_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_46: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_15, [0, 2, 3]);  rsqrt_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_106: f32[128] = torch.ops.aten.mul.Tensor(squeeze_45, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_107: f32[128] = torch.ops.aten.mul.Tensor(primals_207, 0.9);  primals_207 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_81: f32[128] = torch.ops.aten.add.Tensor(mul_106, mul_107);  mul_106 = mul_107 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_47: f32[128] = torch.ops.aten.squeeze.dims(getitem_32, [0, 2, 3]);  getitem_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_108: f32[128] = torch.ops.aten.mul.Tensor(squeeze_47, 1.0000199302441455);  squeeze_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_109: f32[128] = torch.ops.aten.mul.Tensor(mul_108, 0.1);  mul_108 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_110: f32[128] = torch.ops.aten.mul.Tensor(primals_208, 0.9);  primals_208 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_82: f32[128] = torch.ops.aten.add.Tensor(mul_109, mul_110);  mul_109 = mul_110 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_60: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_47, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_61: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_60, -1);  unsqueeze_60 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_111: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_105, unsqueeze_61);  mul_105 = unsqueeze_61 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_62: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_48, -1);  primals_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_63: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_62, -1);  unsqueeze_62 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_83: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_111, unsqueeze_63);  mul_111 = unsqueeze_63 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_13: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_83);  add_83 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_16: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_13, primals_49, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_84: i64[] = torch.ops.aten.add.Tensor(primals_212, 1);  primals_212 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_16 = torch.ops.aten.var_mean.correction(convolution_16, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_34: f32[1, 128, 1, 1] = var_mean_16[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_35: f32[1, 128, 1, 1] = var_mean_16[1];  var_mean_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_85: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_34, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_16: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_85);  add_85 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_16: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_16, getitem_35)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_112: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_16, rsqrt_16);  sub_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_48: f32[128] = torch.ops.aten.squeeze.dims(getitem_35, [0, 2, 3]);  getitem_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_49: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_16, [0, 2, 3]);  rsqrt_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_113: f32[128] = torch.ops.aten.mul.Tensor(squeeze_48, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_114: f32[128] = torch.ops.aten.mul.Tensor(primals_210, 0.9);  primals_210 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_86: f32[128] = torch.ops.aten.add.Tensor(mul_113, mul_114);  mul_113 = mul_114 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_50: f32[128] = torch.ops.aten.squeeze.dims(getitem_34, [0, 2, 3]);  getitem_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_115: f32[128] = torch.ops.aten.mul.Tensor(squeeze_50, 1.0000199302441455);  squeeze_50 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_116: f32[128] = torch.ops.aten.mul.Tensor(mul_115, 0.1);  mul_115 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_117: f32[128] = torch.ops.aten.mul.Tensor(primals_211, 0.9);  primals_211 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_87: f32[128] = torch.ops.aten.add.Tensor(mul_116, mul_117);  mul_116 = mul_117 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_64: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_50, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_65: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_64, -1);  unsqueeze_64 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_118: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_112, unsqueeze_65);  mul_112 = unsqueeze_65 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_66: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_51, -1);  primals_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_67: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_66, -1);  unsqueeze_66 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_88: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_118, unsqueeze_67);  mul_118 = unsqueeze_67 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_14: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_88);  add_88 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_17: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_14, primals_52, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_89: i64[] = torch.ops.aten.add.Tensor(primals_215, 1);  primals_215 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_17 = torch.ops.aten.var_mean.correction(convolution_17, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_36: f32[1, 512, 1, 1] = var_mean_17[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_37: f32[1, 512, 1, 1] = var_mean_17[1];  var_mean_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_90: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_36, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_17: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_90);  add_90 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_17: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_17, getitem_37)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_119: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_17, rsqrt_17);  sub_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_51: f32[512] = torch.ops.aten.squeeze.dims(getitem_37, [0, 2, 3]);  getitem_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_52: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_17, [0, 2, 3]);  rsqrt_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_120: f32[512] = torch.ops.aten.mul.Tensor(squeeze_51, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_121: f32[512] = torch.ops.aten.mul.Tensor(primals_213, 0.9);  primals_213 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_91: f32[512] = torch.ops.aten.add.Tensor(mul_120, mul_121);  mul_120 = mul_121 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_53: f32[512] = torch.ops.aten.squeeze.dims(getitem_36, [0, 2, 3]);  getitem_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_122: f32[512] = torch.ops.aten.mul.Tensor(squeeze_53, 1.0000199302441455);  squeeze_53 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_123: f32[512] = torch.ops.aten.mul.Tensor(mul_122, 0.1);  mul_122 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_124: f32[512] = torch.ops.aten.mul.Tensor(primals_214, 0.9);  primals_214 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_92: f32[512] = torch.ops.aten.add.Tensor(mul_123, mul_124);  mul_123 = mul_124 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_68: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_53, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_69: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_68, -1);  unsqueeze_68 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_125: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_119, unsqueeze_69);  mul_119 = unsqueeze_69 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_70: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_54, -1);  primals_54 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_71: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_70, -1);  unsqueeze_70 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_93: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_125, unsqueeze_71);  mul_125 = unsqueeze_71 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_94: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(add_93, relu_12);  add_93 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_15: f32[64, 512, 28, 28] = torch.ops.aten.relu.default(add_94);  add_94 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_18: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_15, primals_55, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_95: i64[] = torch.ops.aten.add.Tensor(primals_218, 1);  primals_218 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_18 = torch.ops.aten.var_mean.correction(convolution_18, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_38: f32[1, 128, 1, 1] = var_mean_18[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_39: f32[1, 128, 1, 1] = var_mean_18[1];  var_mean_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_96: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_38, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_18: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_96);  add_96 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_18: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_18, getitem_39)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_126: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_18, rsqrt_18);  sub_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_54: f32[128] = torch.ops.aten.squeeze.dims(getitem_39, [0, 2, 3]);  getitem_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_55: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_18, [0, 2, 3]);  rsqrt_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_127: f32[128] = torch.ops.aten.mul.Tensor(squeeze_54, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_128: f32[128] = torch.ops.aten.mul.Tensor(primals_216, 0.9);  primals_216 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_97: f32[128] = torch.ops.aten.add.Tensor(mul_127, mul_128);  mul_127 = mul_128 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_56: f32[128] = torch.ops.aten.squeeze.dims(getitem_38, [0, 2, 3]);  getitem_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_129: f32[128] = torch.ops.aten.mul.Tensor(squeeze_56, 1.0000199302441455);  squeeze_56 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_130: f32[128] = torch.ops.aten.mul.Tensor(mul_129, 0.1);  mul_129 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_131: f32[128] = torch.ops.aten.mul.Tensor(primals_217, 0.9);  primals_217 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_98: f32[128] = torch.ops.aten.add.Tensor(mul_130, mul_131);  mul_130 = mul_131 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_72: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_56, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_73: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_72, -1);  unsqueeze_72 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_132: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_126, unsqueeze_73);  mul_126 = unsqueeze_73 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_74: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_57, -1);  primals_57 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_75: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_74, -1);  unsqueeze_74 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_99: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_132, unsqueeze_75);  mul_132 = unsqueeze_75 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_16: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_99);  add_99 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_19: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_16, primals_58, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_100: i64[] = torch.ops.aten.add.Tensor(primals_221, 1);  primals_221 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_19 = torch.ops.aten.var_mean.correction(convolution_19, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_40: f32[1, 128, 1, 1] = var_mean_19[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_41: f32[1, 128, 1, 1] = var_mean_19[1];  var_mean_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_101: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_40, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_19: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_101);  add_101 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_19: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_19, getitem_41)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_133: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_19, rsqrt_19);  sub_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_57: f32[128] = torch.ops.aten.squeeze.dims(getitem_41, [0, 2, 3]);  getitem_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_58: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_19, [0, 2, 3]);  rsqrt_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_134: f32[128] = torch.ops.aten.mul.Tensor(squeeze_57, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_135: f32[128] = torch.ops.aten.mul.Tensor(primals_219, 0.9);  primals_219 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_102: f32[128] = torch.ops.aten.add.Tensor(mul_134, mul_135);  mul_134 = mul_135 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_59: f32[128] = torch.ops.aten.squeeze.dims(getitem_40, [0, 2, 3]);  getitem_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_136: f32[128] = torch.ops.aten.mul.Tensor(squeeze_59, 1.0000199302441455);  squeeze_59 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_137: f32[128] = torch.ops.aten.mul.Tensor(mul_136, 0.1);  mul_136 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_138: f32[128] = torch.ops.aten.mul.Tensor(primals_220, 0.9);  primals_220 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_103: f32[128] = torch.ops.aten.add.Tensor(mul_137, mul_138);  mul_137 = mul_138 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_76: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_59, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_77: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_76, -1);  unsqueeze_76 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_139: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_133, unsqueeze_77);  mul_133 = unsqueeze_77 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_78: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_60, -1);  primals_60 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_79: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_78, -1);  unsqueeze_78 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_104: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_139, unsqueeze_79);  mul_139 = unsqueeze_79 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_17: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_104);  add_104 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_20: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_17, primals_61, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_105: i64[] = torch.ops.aten.add.Tensor(primals_224, 1);  primals_224 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_20 = torch.ops.aten.var_mean.correction(convolution_20, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_42: f32[1, 512, 1, 1] = var_mean_20[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_43: f32[1, 512, 1, 1] = var_mean_20[1];  var_mean_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_106: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_42, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_20: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_106);  add_106 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_20: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_20, getitem_43)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_140: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_20, rsqrt_20);  sub_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_60: f32[512] = torch.ops.aten.squeeze.dims(getitem_43, [0, 2, 3]);  getitem_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_61: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_20, [0, 2, 3]);  rsqrt_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_141: f32[512] = torch.ops.aten.mul.Tensor(squeeze_60, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_142: f32[512] = torch.ops.aten.mul.Tensor(primals_222, 0.9);  primals_222 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_107: f32[512] = torch.ops.aten.add.Tensor(mul_141, mul_142);  mul_141 = mul_142 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_62: f32[512] = torch.ops.aten.squeeze.dims(getitem_42, [0, 2, 3]);  getitem_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_143: f32[512] = torch.ops.aten.mul.Tensor(squeeze_62, 1.0000199302441455);  squeeze_62 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_144: f32[512] = torch.ops.aten.mul.Tensor(mul_143, 0.1);  mul_143 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_145: f32[512] = torch.ops.aten.mul.Tensor(primals_223, 0.9);  primals_223 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_108: f32[512] = torch.ops.aten.add.Tensor(mul_144, mul_145);  mul_144 = mul_145 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_80: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_62, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_81: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_80, -1);  unsqueeze_80 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_146: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_140, unsqueeze_81);  mul_140 = unsqueeze_81 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_82: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_63, -1);  primals_63 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_83: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_82, -1);  unsqueeze_82 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_109: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_146, unsqueeze_83);  mul_146 = unsqueeze_83 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_110: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(add_109, relu_15);  add_109 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_18: f32[64, 512, 28, 28] = torch.ops.aten.relu.default(add_110);  add_110 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_21: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_18, primals_64, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_111: i64[] = torch.ops.aten.add.Tensor(primals_227, 1);  primals_227 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_21 = torch.ops.aten.var_mean.correction(convolution_21, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_44: f32[1, 128, 1, 1] = var_mean_21[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_45: f32[1, 128, 1, 1] = var_mean_21[1];  var_mean_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_112: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_44, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_21: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_112);  add_112 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_21: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_21, getitem_45)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_147: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_21, rsqrt_21);  sub_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_63: f32[128] = torch.ops.aten.squeeze.dims(getitem_45, [0, 2, 3]);  getitem_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_64: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_21, [0, 2, 3]);  rsqrt_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_148: f32[128] = torch.ops.aten.mul.Tensor(squeeze_63, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_149: f32[128] = torch.ops.aten.mul.Tensor(primals_225, 0.9);  primals_225 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_113: f32[128] = torch.ops.aten.add.Tensor(mul_148, mul_149);  mul_148 = mul_149 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_65: f32[128] = torch.ops.aten.squeeze.dims(getitem_44, [0, 2, 3]);  getitem_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_150: f32[128] = torch.ops.aten.mul.Tensor(squeeze_65, 1.0000199302441455);  squeeze_65 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_151: f32[128] = torch.ops.aten.mul.Tensor(mul_150, 0.1);  mul_150 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_152: f32[128] = torch.ops.aten.mul.Tensor(primals_226, 0.9);  primals_226 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_114: f32[128] = torch.ops.aten.add.Tensor(mul_151, mul_152);  mul_151 = mul_152 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_84: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_65, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_85: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_84, -1);  unsqueeze_84 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_153: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_147, unsqueeze_85);  mul_147 = unsqueeze_85 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_86: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_66, -1);  primals_66 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_87: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_86, -1);  unsqueeze_86 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_115: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_153, unsqueeze_87);  mul_153 = unsqueeze_87 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_19: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_115);  add_115 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_22: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_19, primals_67, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_116: i64[] = torch.ops.aten.add.Tensor(primals_230, 1);  primals_230 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_22 = torch.ops.aten.var_mean.correction(convolution_22, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_46: f32[1, 128, 1, 1] = var_mean_22[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_47: f32[1, 128, 1, 1] = var_mean_22[1];  var_mean_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_117: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_46, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_22: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_117);  add_117 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_22: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_22, getitem_47)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_154: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_22, rsqrt_22);  sub_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_66: f32[128] = torch.ops.aten.squeeze.dims(getitem_47, [0, 2, 3]);  getitem_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_67: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_22, [0, 2, 3]);  rsqrt_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_155: f32[128] = torch.ops.aten.mul.Tensor(squeeze_66, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_156: f32[128] = torch.ops.aten.mul.Tensor(primals_228, 0.9);  primals_228 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_118: f32[128] = torch.ops.aten.add.Tensor(mul_155, mul_156);  mul_155 = mul_156 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_68: f32[128] = torch.ops.aten.squeeze.dims(getitem_46, [0, 2, 3]);  getitem_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_157: f32[128] = torch.ops.aten.mul.Tensor(squeeze_68, 1.0000199302441455);  squeeze_68 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_158: f32[128] = torch.ops.aten.mul.Tensor(mul_157, 0.1);  mul_157 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_159: f32[128] = torch.ops.aten.mul.Tensor(primals_229, 0.9);  primals_229 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_119: f32[128] = torch.ops.aten.add.Tensor(mul_158, mul_159);  mul_158 = mul_159 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_88: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_68, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_89: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_88, -1);  unsqueeze_88 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_160: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_154, unsqueeze_89);  mul_154 = unsqueeze_89 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_90: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_69, -1);  primals_69 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_91: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_90, -1);  unsqueeze_90 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_120: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_160, unsqueeze_91);  mul_160 = unsqueeze_91 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_20: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_120);  add_120 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_23: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_20, primals_70, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_121: i64[] = torch.ops.aten.add.Tensor(primals_233, 1);  primals_233 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_23 = torch.ops.aten.var_mean.correction(convolution_23, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_48: f32[1, 512, 1, 1] = var_mean_23[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_49: f32[1, 512, 1, 1] = var_mean_23[1];  var_mean_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_122: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_48, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_23: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_122);  add_122 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_23: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_23, getitem_49)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_161: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_23, rsqrt_23);  sub_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_69: f32[512] = torch.ops.aten.squeeze.dims(getitem_49, [0, 2, 3]);  getitem_49 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_70: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_23, [0, 2, 3]);  rsqrt_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_162: f32[512] = torch.ops.aten.mul.Tensor(squeeze_69, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_163: f32[512] = torch.ops.aten.mul.Tensor(primals_231, 0.9);  primals_231 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_123: f32[512] = torch.ops.aten.add.Tensor(mul_162, mul_163);  mul_162 = mul_163 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_71: f32[512] = torch.ops.aten.squeeze.dims(getitem_48, [0, 2, 3]);  getitem_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_164: f32[512] = torch.ops.aten.mul.Tensor(squeeze_71, 1.0000199302441455);  squeeze_71 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_165: f32[512] = torch.ops.aten.mul.Tensor(mul_164, 0.1);  mul_164 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_166: f32[512] = torch.ops.aten.mul.Tensor(primals_232, 0.9);  primals_232 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_124: f32[512] = torch.ops.aten.add.Tensor(mul_165, mul_166);  mul_165 = mul_166 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_92: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_71, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_93: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_92, -1);  unsqueeze_92 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_167: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_161, unsqueeze_93);  mul_161 = unsqueeze_93 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_94: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_72, -1);  primals_72 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_95: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_94, -1);  unsqueeze_94 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_125: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_167, unsqueeze_95);  mul_167 = unsqueeze_95 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_126: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(add_125, relu_18);  add_125 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_21: f32[64, 512, 28, 28] = torch.ops.aten.relu.default(add_126);  add_126 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_24: f32[64, 256, 28, 28] = torch.ops.aten.convolution.default(relu_21, primals_73, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_127: i64[] = torch.ops.aten.add.Tensor(primals_236, 1);  primals_236 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_24 = torch.ops.aten.var_mean.correction(convolution_24, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_50: f32[1, 256, 1, 1] = var_mean_24[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_51: f32[1, 256, 1, 1] = var_mean_24[1];  var_mean_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_128: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_50, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_24: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_128);  add_128 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_24: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(convolution_24, getitem_51)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_168: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(sub_24, rsqrt_24);  sub_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_72: f32[256] = torch.ops.aten.squeeze.dims(getitem_51, [0, 2, 3]);  getitem_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_73: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_24, [0, 2, 3]);  rsqrt_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_169: f32[256] = torch.ops.aten.mul.Tensor(squeeze_72, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_170: f32[256] = torch.ops.aten.mul.Tensor(primals_234, 0.9);  primals_234 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_129: f32[256] = torch.ops.aten.add.Tensor(mul_169, mul_170);  mul_169 = mul_170 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_74: f32[256] = torch.ops.aten.squeeze.dims(getitem_50, [0, 2, 3]);  getitem_50 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_171: f32[256] = torch.ops.aten.mul.Tensor(squeeze_74, 1.0000199302441455);  squeeze_74 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_172: f32[256] = torch.ops.aten.mul.Tensor(mul_171, 0.1);  mul_171 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_173: f32[256] = torch.ops.aten.mul.Tensor(primals_235, 0.9);  primals_235 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_130: f32[256] = torch.ops.aten.add.Tensor(mul_172, mul_173);  mul_172 = mul_173 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_96: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_74, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_97: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_96, -1);  unsqueeze_96 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_174: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(mul_168, unsqueeze_97);  mul_168 = unsqueeze_97 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_98: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_75, -1);  primals_75 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_99: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_98, -1);  unsqueeze_98 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_131: f32[64, 256, 28, 28] = torch.ops.aten.add.Tensor(mul_174, unsqueeze_99);  mul_174 = unsqueeze_99 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_22: f32[64, 256, 28, 28] = torch.ops.aten.relu.default(add_131);  add_131 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_25: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_22, primals_76, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_132: i64[] = torch.ops.aten.add.Tensor(primals_239, 1);  primals_239 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_25 = torch.ops.aten.var_mean.correction(convolution_25, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_52: f32[1, 256, 1, 1] = var_mean_25[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_53: f32[1, 256, 1, 1] = var_mean_25[1];  var_mean_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_133: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_52, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_25: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_133);  add_133 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_25: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_25, getitem_53)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_175: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_25, rsqrt_25);  sub_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_75: f32[256] = torch.ops.aten.squeeze.dims(getitem_53, [0, 2, 3]);  getitem_53 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_76: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_25, [0, 2, 3]);  rsqrt_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_176: f32[256] = torch.ops.aten.mul.Tensor(squeeze_75, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_177: f32[256] = torch.ops.aten.mul.Tensor(primals_237, 0.9);  primals_237 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_134: f32[256] = torch.ops.aten.add.Tensor(mul_176, mul_177);  mul_176 = mul_177 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_77: f32[256] = torch.ops.aten.squeeze.dims(getitem_52, [0, 2, 3]);  getitem_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_178: f32[256] = torch.ops.aten.mul.Tensor(squeeze_77, 1.0000797257434426);  squeeze_77 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_179: f32[256] = torch.ops.aten.mul.Tensor(mul_178, 0.1);  mul_178 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_180: f32[256] = torch.ops.aten.mul.Tensor(primals_238, 0.9);  primals_238 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_135: f32[256] = torch.ops.aten.add.Tensor(mul_179, mul_180);  mul_179 = mul_180 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_100: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_77, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_101: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_100, -1);  unsqueeze_100 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_181: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_175, unsqueeze_101);  mul_175 = unsqueeze_101 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_102: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_78, -1);  primals_78 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_103: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_102, -1);  unsqueeze_102 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_136: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_181, unsqueeze_103);  mul_181 = unsqueeze_103 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_23: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_136);  add_136 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_26: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_23, primals_79, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_137: i64[] = torch.ops.aten.add.Tensor(primals_242, 1);  primals_242 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_26 = torch.ops.aten.var_mean.correction(convolution_26, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_54: f32[1, 1024, 1, 1] = var_mean_26[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_55: f32[1, 1024, 1, 1] = var_mean_26[1];  var_mean_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_138: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_54, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_26: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_138);  add_138 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_26: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_26, getitem_55)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_182: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_26, rsqrt_26);  sub_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_78: f32[1024] = torch.ops.aten.squeeze.dims(getitem_55, [0, 2, 3]);  getitem_55 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_79: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_26, [0, 2, 3]);  rsqrt_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_183: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_78, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_184: f32[1024] = torch.ops.aten.mul.Tensor(primals_240, 0.9);  primals_240 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_139: f32[1024] = torch.ops.aten.add.Tensor(mul_183, mul_184);  mul_183 = mul_184 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_80: f32[1024] = torch.ops.aten.squeeze.dims(getitem_54, [0, 2, 3]);  getitem_54 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_185: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_80, 1.0000797257434426);  squeeze_80 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_186: f32[1024] = torch.ops.aten.mul.Tensor(mul_185, 0.1);  mul_185 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_187: f32[1024] = torch.ops.aten.mul.Tensor(primals_241, 0.9);  primals_241 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_140: f32[1024] = torch.ops.aten.add.Tensor(mul_186, mul_187);  mul_186 = mul_187 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_104: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_80, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_105: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_104, -1);  unsqueeze_104 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_188: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_182, unsqueeze_105);  mul_182 = unsqueeze_105 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_106: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_81, -1);  primals_81 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_107: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_106, -1);  unsqueeze_106 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_141: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_188, unsqueeze_107);  mul_188 = unsqueeze_107 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_27: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_21, primals_82, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_142: i64[] = torch.ops.aten.add.Tensor(primals_245, 1);  primals_245 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_27 = torch.ops.aten.var_mean.correction(convolution_27, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_56: f32[1, 1024, 1, 1] = var_mean_27[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_57: f32[1, 1024, 1, 1] = var_mean_27[1];  var_mean_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_143: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_56, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_27: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_143);  add_143 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_27: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_27, getitem_57)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_189: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_27, rsqrt_27);  sub_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_81: f32[1024] = torch.ops.aten.squeeze.dims(getitem_57, [0, 2, 3]);  getitem_57 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_82: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_27, [0, 2, 3]);  rsqrt_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_190: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_81, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_191: f32[1024] = torch.ops.aten.mul.Tensor(primals_243, 0.9);  primals_243 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_144: f32[1024] = torch.ops.aten.add.Tensor(mul_190, mul_191);  mul_190 = mul_191 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_83: f32[1024] = torch.ops.aten.squeeze.dims(getitem_56, [0, 2, 3]);  getitem_56 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_192: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_83, 1.0000797257434426);  squeeze_83 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_193: f32[1024] = torch.ops.aten.mul.Tensor(mul_192, 0.1);  mul_192 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_194: f32[1024] = torch.ops.aten.mul.Tensor(primals_244, 0.9);  primals_244 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_145: f32[1024] = torch.ops.aten.add.Tensor(mul_193, mul_194);  mul_193 = mul_194 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_108: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_83, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_109: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_108, -1);  unsqueeze_108 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_195: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_189, unsqueeze_109);  mul_189 = unsqueeze_109 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_110: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_84, -1);  primals_84 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_111: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_110, -1);  unsqueeze_110 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_146: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_195, unsqueeze_111);  mul_195 = unsqueeze_111 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_147: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_141, add_146);  add_141 = add_146 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_24: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_147);  add_147 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_28: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_24, primals_85, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_148: i64[] = torch.ops.aten.add.Tensor(primals_248, 1);  primals_248 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_28 = torch.ops.aten.var_mean.correction(convolution_28, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_58: f32[1, 256, 1, 1] = var_mean_28[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_59: f32[1, 256, 1, 1] = var_mean_28[1];  var_mean_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_149: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_58, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_28: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_149);  add_149 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_28: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_28, getitem_59)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_196: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_28, rsqrt_28);  sub_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_84: f32[256] = torch.ops.aten.squeeze.dims(getitem_59, [0, 2, 3]);  getitem_59 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_85: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_28, [0, 2, 3]);  rsqrt_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_197: f32[256] = torch.ops.aten.mul.Tensor(squeeze_84, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_198: f32[256] = torch.ops.aten.mul.Tensor(primals_246, 0.9);  primals_246 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_150: f32[256] = torch.ops.aten.add.Tensor(mul_197, mul_198);  mul_197 = mul_198 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_86: f32[256] = torch.ops.aten.squeeze.dims(getitem_58, [0, 2, 3]);  getitem_58 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_199: f32[256] = torch.ops.aten.mul.Tensor(squeeze_86, 1.0000797257434426);  squeeze_86 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_200: f32[256] = torch.ops.aten.mul.Tensor(mul_199, 0.1);  mul_199 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_201: f32[256] = torch.ops.aten.mul.Tensor(primals_247, 0.9);  primals_247 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_151: f32[256] = torch.ops.aten.add.Tensor(mul_200, mul_201);  mul_200 = mul_201 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_112: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_86, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_113: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_112, -1);  unsqueeze_112 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_202: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_196, unsqueeze_113);  mul_196 = unsqueeze_113 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_114: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_87, -1);  primals_87 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_115: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_114, -1);  unsqueeze_114 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_152: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_202, unsqueeze_115);  mul_202 = unsqueeze_115 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_25: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_152);  add_152 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_29: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_25, primals_88, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_153: i64[] = torch.ops.aten.add.Tensor(primals_251, 1);  primals_251 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_29 = torch.ops.aten.var_mean.correction(convolution_29, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_60: f32[1, 256, 1, 1] = var_mean_29[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_61: f32[1, 256, 1, 1] = var_mean_29[1];  var_mean_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_154: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_60, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_29: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_154);  add_154 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_29: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_29, getitem_61)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_203: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_29, rsqrt_29);  sub_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_87: f32[256] = torch.ops.aten.squeeze.dims(getitem_61, [0, 2, 3]);  getitem_61 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_88: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_29, [0, 2, 3]);  rsqrt_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_204: f32[256] = torch.ops.aten.mul.Tensor(squeeze_87, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_205: f32[256] = torch.ops.aten.mul.Tensor(primals_249, 0.9);  primals_249 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_155: f32[256] = torch.ops.aten.add.Tensor(mul_204, mul_205);  mul_204 = mul_205 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_89: f32[256] = torch.ops.aten.squeeze.dims(getitem_60, [0, 2, 3]);  getitem_60 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_206: f32[256] = torch.ops.aten.mul.Tensor(squeeze_89, 1.0000797257434426);  squeeze_89 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_207: f32[256] = torch.ops.aten.mul.Tensor(mul_206, 0.1);  mul_206 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_208: f32[256] = torch.ops.aten.mul.Tensor(primals_250, 0.9);  primals_250 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_156: f32[256] = torch.ops.aten.add.Tensor(mul_207, mul_208);  mul_207 = mul_208 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_116: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_89, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_117: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_116, -1);  unsqueeze_116 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_209: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_203, unsqueeze_117);  mul_203 = unsqueeze_117 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_118: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_90, -1);  primals_90 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_119: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_118, -1);  unsqueeze_118 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_157: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_209, unsqueeze_119);  mul_209 = unsqueeze_119 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_26: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_157);  add_157 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_30: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_26, primals_91, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_158: i64[] = torch.ops.aten.add.Tensor(primals_254, 1);  primals_254 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_30 = torch.ops.aten.var_mean.correction(convolution_30, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_62: f32[1, 1024, 1, 1] = var_mean_30[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_63: f32[1, 1024, 1, 1] = var_mean_30[1];  var_mean_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_159: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_62, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_30: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_159);  add_159 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_30: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_30, getitem_63)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_210: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_30, rsqrt_30);  sub_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_90: f32[1024] = torch.ops.aten.squeeze.dims(getitem_63, [0, 2, 3]);  getitem_63 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_91: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_30, [0, 2, 3]);  rsqrt_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_211: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_90, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_212: f32[1024] = torch.ops.aten.mul.Tensor(primals_252, 0.9);  primals_252 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_160: f32[1024] = torch.ops.aten.add.Tensor(mul_211, mul_212);  mul_211 = mul_212 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_92: f32[1024] = torch.ops.aten.squeeze.dims(getitem_62, [0, 2, 3]);  getitem_62 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_213: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_92, 1.0000797257434426);  squeeze_92 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_214: f32[1024] = torch.ops.aten.mul.Tensor(mul_213, 0.1);  mul_213 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_215: f32[1024] = torch.ops.aten.mul.Tensor(primals_253, 0.9);  primals_253 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_161: f32[1024] = torch.ops.aten.add.Tensor(mul_214, mul_215);  mul_214 = mul_215 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_120: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_92, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_121: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_120, -1);  unsqueeze_120 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_216: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_210, unsqueeze_121);  mul_210 = unsqueeze_121 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_122: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_93, -1);  primals_93 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_123: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_122, -1);  unsqueeze_122 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_162: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_216, unsqueeze_123);  mul_216 = unsqueeze_123 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_163: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_162, relu_24);  add_162 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_27: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_163);  add_163 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_31: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_27, primals_94, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_164: i64[] = torch.ops.aten.add.Tensor(primals_257, 1);  primals_257 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_31 = torch.ops.aten.var_mean.correction(convolution_31, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_64: f32[1, 256, 1, 1] = var_mean_31[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_65: f32[1, 256, 1, 1] = var_mean_31[1];  var_mean_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_165: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_64, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_31: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_165);  add_165 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_31: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_31, getitem_65)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_217: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_31, rsqrt_31);  sub_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_93: f32[256] = torch.ops.aten.squeeze.dims(getitem_65, [0, 2, 3]);  getitem_65 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_94: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_31, [0, 2, 3]);  rsqrt_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_218: f32[256] = torch.ops.aten.mul.Tensor(squeeze_93, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_219: f32[256] = torch.ops.aten.mul.Tensor(primals_255, 0.9);  primals_255 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_166: f32[256] = torch.ops.aten.add.Tensor(mul_218, mul_219);  mul_218 = mul_219 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_95: f32[256] = torch.ops.aten.squeeze.dims(getitem_64, [0, 2, 3]);  getitem_64 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_220: f32[256] = torch.ops.aten.mul.Tensor(squeeze_95, 1.0000797257434426);  squeeze_95 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_221: f32[256] = torch.ops.aten.mul.Tensor(mul_220, 0.1);  mul_220 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_222: f32[256] = torch.ops.aten.mul.Tensor(primals_256, 0.9);  primals_256 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_167: f32[256] = torch.ops.aten.add.Tensor(mul_221, mul_222);  mul_221 = mul_222 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_124: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_95, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_125: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_124, -1);  unsqueeze_124 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_223: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_217, unsqueeze_125);  mul_217 = unsqueeze_125 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_126: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_96, -1);  primals_96 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_127: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_126, -1);  unsqueeze_126 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_168: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_223, unsqueeze_127);  mul_223 = unsqueeze_127 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_28: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_168);  add_168 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_32: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_28, primals_97, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_169: i64[] = torch.ops.aten.add.Tensor(primals_260, 1);  primals_260 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_32 = torch.ops.aten.var_mean.correction(convolution_32, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_66: f32[1, 256, 1, 1] = var_mean_32[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_67: f32[1, 256, 1, 1] = var_mean_32[1];  var_mean_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_170: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_66, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_32: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_170);  add_170 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_32: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_32, getitem_67)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_224: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_32, rsqrt_32);  sub_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_96: f32[256] = torch.ops.aten.squeeze.dims(getitem_67, [0, 2, 3]);  getitem_67 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_97: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_32, [0, 2, 3]);  rsqrt_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_225: f32[256] = torch.ops.aten.mul.Tensor(squeeze_96, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_226: f32[256] = torch.ops.aten.mul.Tensor(primals_258, 0.9);  primals_258 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_171: f32[256] = torch.ops.aten.add.Tensor(mul_225, mul_226);  mul_225 = mul_226 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_98: f32[256] = torch.ops.aten.squeeze.dims(getitem_66, [0, 2, 3]);  getitem_66 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_227: f32[256] = torch.ops.aten.mul.Tensor(squeeze_98, 1.0000797257434426);  squeeze_98 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_228: f32[256] = torch.ops.aten.mul.Tensor(mul_227, 0.1);  mul_227 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_229: f32[256] = torch.ops.aten.mul.Tensor(primals_259, 0.9);  primals_259 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_172: f32[256] = torch.ops.aten.add.Tensor(mul_228, mul_229);  mul_228 = mul_229 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_128: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_98, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_129: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_128, -1);  unsqueeze_128 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_230: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_224, unsqueeze_129);  mul_224 = unsqueeze_129 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_130: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_99, -1);  primals_99 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_131: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_130, -1);  unsqueeze_130 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_173: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_230, unsqueeze_131);  mul_230 = unsqueeze_131 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_29: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_173);  add_173 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_33: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_29, primals_100, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_174: i64[] = torch.ops.aten.add.Tensor(primals_263, 1);  primals_263 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_33 = torch.ops.aten.var_mean.correction(convolution_33, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_68: f32[1, 1024, 1, 1] = var_mean_33[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_69: f32[1, 1024, 1, 1] = var_mean_33[1];  var_mean_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_175: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_68, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_33: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_175);  add_175 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_33: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_33, getitem_69)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_231: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_33, rsqrt_33);  sub_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_99: f32[1024] = torch.ops.aten.squeeze.dims(getitem_69, [0, 2, 3]);  getitem_69 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_100: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_33, [0, 2, 3]);  rsqrt_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_232: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_99, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_233: f32[1024] = torch.ops.aten.mul.Tensor(primals_261, 0.9);  primals_261 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_176: f32[1024] = torch.ops.aten.add.Tensor(mul_232, mul_233);  mul_232 = mul_233 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_101: f32[1024] = torch.ops.aten.squeeze.dims(getitem_68, [0, 2, 3]);  getitem_68 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_234: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_101, 1.0000797257434426);  squeeze_101 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_235: f32[1024] = torch.ops.aten.mul.Tensor(mul_234, 0.1);  mul_234 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_236: f32[1024] = torch.ops.aten.mul.Tensor(primals_262, 0.9);  primals_262 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_177: f32[1024] = torch.ops.aten.add.Tensor(mul_235, mul_236);  mul_235 = mul_236 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_132: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_101, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_133: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_132, -1);  unsqueeze_132 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_237: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_231, unsqueeze_133);  mul_231 = unsqueeze_133 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_134: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_102, -1);  primals_102 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_135: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_134, -1);  unsqueeze_134 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_178: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_237, unsqueeze_135);  mul_237 = unsqueeze_135 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_179: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_178, relu_27);  add_178 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_30: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_179);  add_179 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_34: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_30, primals_103, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_180: i64[] = torch.ops.aten.add.Tensor(primals_266, 1);  primals_266 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_34 = torch.ops.aten.var_mean.correction(convolution_34, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_70: f32[1, 256, 1, 1] = var_mean_34[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_71: f32[1, 256, 1, 1] = var_mean_34[1];  var_mean_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_181: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_70, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_34: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_181);  add_181 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_34: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_34, getitem_71)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_238: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_34, rsqrt_34);  sub_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_102: f32[256] = torch.ops.aten.squeeze.dims(getitem_71, [0, 2, 3]);  getitem_71 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_103: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_34, [0, 2, 3]);  rsqrt_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_239: f32[256] = torch.ops.aten.mul.Tensor(squeeze_102, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_240: f32[256] = torch.ops.aten.mul.Tensor(primals_264, 0.9);  primals_264 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_182: f32[256] = torch.ops.aten.add.Tensor(mul_239, mul_240);  mul_239 = mul_240 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_104: f32[256] = torch.ops.aten.squeeze.dims(getitem_70, [0, 2, 3]);  getitem_70 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_241: f32[256] = torch.ops.aten.mul.Tensor(squeeze_104, 1.0000797257434426);  squeeze_104 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_242: f32[256] = torch.ops.aten.mul.Tensor(mul_241, 0.1);  mul_241 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_243: f32[256] = torch.ops.aten.mul.Tensor(primals_265, 0.9);  primals_265 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_183: f32[256] = torch.ops.aten.add.Tensor(mul_242, mul_243);  mul_242 = mul_243 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_136: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_104, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_137: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_136, -1);  unsqueeze_136 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_244: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_238, unsqueeze_137);  mul_238 = unsqueeze_137 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_138: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_105, -1);  primals_105 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_139: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_138, -1);  unsqueeze_138 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_184: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_244, unsqueeze_139);  mul_244 = unsqueeze_139 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_31: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_184);  add_184 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_35: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_31, primals_106, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_185: i64[] = torch.ops.aten.add.Tensor(primals_269, 1);  primals_269 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_35 = torch.ops.aten.var_mean.correction(convolution_35, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_72: f32[1, 256, 1, 1] = var_mean_35[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_73: f32[1, 256, 1, 1] = var_mean_35[1];  var_mean_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_186: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_72, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_35: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_186);  add_186 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_35: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_35, getitem_73)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_245: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_35, rsqrt_35);  sub_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_105: f32[256] = torch.ops.aten.squeeze.dims(getitem_73, [0, 2, 3]);  getitem_73 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_106: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_35, [0, 2, 3]);  rsqrt_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_246: f32[256] = torch.ops.aten.mul.Tensor(squeeze_105, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_247: f32[256] = torch.ops.aten.mul.Tensor(primals_267, 0.9);  primals_267 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_187: f32[256] = torch.ops.aten.add.Tensor(mul_246, mul_247);  mul_246 = mul_247 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_107: f32[256] = torch.ops.aten.squeeze.dims(getitem_72, [0, 2, 3]);  getitem_72 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_248: f32[256] = torch.ops.aten.mul.Tensor(squeeze_107, 1.0000797257434426);  squeeze_107 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_249: f32[256] = torch.ops.aten.mul.Tensor(mul_248, 0.1);  mul_248 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_250: f32[256] = torch.ops.aten.mul.Tensor(primals_268, 0.9);  primals_268 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_188: f32[256] = torch.ops.aten.add.Tensor(mul_249, mul_250);  mul_249 = mul_250 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_140: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_107, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_141: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_140, -1);  unsqueeze_140 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_251: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_245, unsqueeze_141);  mul_245 = unsqueeze_141 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_142: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_108, -1);  primals_108 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_143: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_142, -1);  unsqueeze_142 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_189: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_251, unsqueeze_143);  mul_251 = unsqueeze_143 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_32: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_189);  add_189 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_36: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_32, primals_109, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_190: i64[] = torch.ops.aten.add.Tensor(primals_272, 1);  primals_272 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_36 = torch.ops.aten.var_mean.correction(convolution_36, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_74: f32[1, 1024, 1, 1] = var_mean_36[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_75: f32[1, 1024, 1, 1] = var_mean_36[1];  var_mean_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_191: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_74, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_36: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_191);  add_191 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_36: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_36, getitem_75)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_252: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_36, rsqrt_36);  sub_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_108: f32[1024] = torch.ops.aten.squeeze.dims(getitem_75, [0, 2, 3]);  getitem_75 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_109: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_36, [0, 2, 3]);  rsqrt_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_253: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_108, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_254: f32[1024] = torch.ops.aten.mul.Tensor(primals_270, 0.9);  primals_270 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_192: f32[1024] = torch.ops.aten.add.Tensor(mul_253, mul_254);  mul_253 = mul_254 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_110: f32[1024] = torch.ops.aten.squeeze.dims(getitem_74, [0, 2, 3]);  getitem_74 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_255: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_110, 1.0000797257434426);  squeeze_110 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_256: f32[1024] = torch.ops.aten.mul.Tensor(mul_255, 0.1);  mul_255 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_257: f32[1024] = torch.ops.aten.mul.Tensor(primals_271, 0.9);  primals_271 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_193: f32[1024] = torch.ops.aten.add.Tensor(mul_256, mul_257);  mul_256 = mul_257 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_144: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_110, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_145: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_144, -1);  unsqueeze_144 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_258: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_252, unsqueeze_145);  mul_252 = unsqueeze_145 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_146: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_111, -1);  primals_111 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_147: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_146, -1);  unsqueeze_146 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_194: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_258, unsqueeze_147);  mul_258 = unsqueeze_147 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_195: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_194, relu_30);  add_194 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_33: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_195);  add_195 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_37: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_33, primals_112, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_196: i64[] = torch.ops.aten.add.Tensor(primals_275, 1);  primals_275 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_37 = torch.ops.aten.var_mean.correction(convolution_37, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_76: f32[1, 256, 1, 1] = var_mean_37[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_77: f32[1, 256, 1, 1] = var_mean_37[1];  var_mean_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_197: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_76, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_37: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_197);  add_197 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_37: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_37, getitem_77)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_259: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_37, rsqrt_37);  sub_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_111: f32[256] = torch.ops.aten.squeeze.dims(getitem_77, [0, 2, 3]);  getitem_77 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_112: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_37, [0, 2, 3]);  rsqrt_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_260: f32[256] = torch.ops.aten.mul.Tensor(squeeze_111, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_261: f32[256] = torch.ops.aten.mul.Tensor(primals_273, 0.9);  primals_273 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_198: f32[256] = torch.ops.aten.add.Tensor(mul_260, mul_261);  mul_260 = mul_261 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_113: f32[256] = torch.ops.aten.squeeze.dims(getitem_76, [0, 2, 3]);  getitem_76 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_262: f32[256] = torch.ops.aten.mul.Tensor(squeeze_113, 1.0000797257434426);  squeeze_113 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_263: f32[256] = torch.ops.aten.mul.Tensor(mul_262, 0.1);  mul_262 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_264: f32[256] = torch.ops.aten.mul.Tensor(primals_274, 0.9);  primals_274 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_199: f32[256] = torch.ops.aten.add.Tensor(mul_263, mul_264);  mul_263 = mul_264 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_148: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_113, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_149: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_148, -1);  unsqueeze_148 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_265: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_259, unsqueeze_149);  mul_259 = unsqueeze_149 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_150: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_114, -1);  primals_114 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_151: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_150, -1);  unsqueeze_150 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_200: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_265, unsqueeze_151);  mul_265 = unsqueeze_151 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_34: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_200);  add_200 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_38: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_34, primals_115, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_201: i64[] = torch.ops.aten.add.Tensor(primals_278, 1);  primals_278 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_38 = torch.ops.aten.var_mean.correction(convolution_38, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_78: f32[1, 256, 1, 1] = var_mean_38[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_79: f32[1, 256, 1, 1] = var_mean_38[1];  var_mean_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_202: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_78, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_38: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_202);  add_202 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_38: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_38, getitem_79)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_266: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_38, rsqrt_38);  sub_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_114: f32[256] = torch.ops.aten.squeeze.dims(getitem_79, [0, 2, 3]);  getitem_79 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_115: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_38, [0, 2, 3]);  rsqrt_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_267: f32[256] = torch.ops.aten.mul.Tensor(squeeze_114, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_268: f32[256] = torch.ops.aten.mul.Tensor(primals_276, 0.9);  primals_276 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_203: f32[256] = torch.ops.aten.add.Tensor(mul_267, mul_268);  mul_267 = mul_268 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_116: f32[256] = torch.ops.aten.squeeze.dims(getitem_78, [0, 2, 3]);  getitem_78 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_269: f32[256] = torch.ops.aten.mul.Tensor(squeeze_116, 1.0000797257434426);  squeeze_116 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_270: f32[256] = torch.ops.aten.mul.Tensor(mul_269, 0.1);  mul_269 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_271: f32[256] = torch.ops.aten.mul.Tensor(primals_277, 0.9);  primals_277 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_204: f32[256] = torch.ops.aten.add.Tensor(mul_270, mul_271);  mul_270 = mul_271 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_152: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_116, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_153: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_152, -1);  unsqueeze_152 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_272: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_266, unsqueeze_153);  mul_266 = unsqueeze_153 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_154: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_117, -1);  primals_117 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_155: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_154, -1);  unsqueeze_154 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_205: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_272, unsqueeze_155);  mul_272 = unsqueeze_155 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_35: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_205);  add_205 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_39: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_35, primals_118, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_206: i64[] = torch.ops.aten.add.Tensor(primals_281, 1);  primals_281 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_39 = torch.ops.aten.var_mean.correction(convolution_39, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_80: f32[1, 1024, 1, 1] = var_mean_39[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_81: f32[1, 1024, 1, 1] = var_mean_39[1];  var_mean_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_207: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_80, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_39: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_207);  add_207 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_39: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_39, getitem_81)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_273: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_39, rsqrt_39);  sub_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_117: f32[1024] = torch.ops.aten.squeeze.dims(getitem_81, [0, 2, 3]);  getitem_81 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_118: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_39, [0, 2, 3]);  rsqrt_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_274: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_117, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_275: f32[1024] = torch.ops.aten.mul.Tensor(primals_279, 0.9);  primals_279 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_208: f32[1024] = torch.ops.aten.add.Tensor(mul_274, mul_275);  mul_274 = mul_275 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_119: f32[1024] = torch.ops.aten.squeeze.dims(getitem_80, [0, 2, 3]);  getitem_80 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_276: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_119, 1.0000797257434426);  squeeze_119 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_277: f32[1024] = torch.ops.aten.mul.Tensor(mul_276, 0.1);  mul_276 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_278: f32[1024] = torch.ops.aten.mul.Tensor(primals_280, 0.9);  primals_280 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_209: f32[1024] = torch.ops.aten.add.Tensor(mul_277, mul_278);  mul_277 = mul_278 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_156: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_119, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_157: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_156, -1);  unsqueeze_156 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_279: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_273, unsqueeze_157);  mul_273 = unsqueeze_157 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_158: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_120, -1);  primals_120 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_159: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_158, -1);  unsqueeze_158 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_210: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_279, unsqueeze_159);  mul_279 = unsqueeze_159 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_211: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_210, relu_33);  add_210 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_36: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_211);  add_211 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_40: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_36, primals_121, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_212: i64[] = torch.ops.aten.add.Tensor(primals_284, 1);  primals_284 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_40 = torch.ops.aten.var_mean.correction(convolution_40, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_82: f32[1, 256, 1, 1] = var_mean_40[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_83: f32[1, 256, 1, 1] = var_mean_40[1];  var_mean_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_213: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_82, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_40: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_213);  add_213 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_40: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_40, getitem_83)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_280: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_40, rsqrt_40);  sub_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_120: f32[256] = torch.ops.aten.squeeze.dims(getitem_83, [0, 2, 3]);  getitem_83 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_121: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_40, [0, 2, 3]);  rsqrt_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_281: f32[256] = torch.ops.aten.mul.Tensor(squeeze_120, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_282: f32[256] = torch.ops.aten.mul.Tensor(primals_282, 0.9);  primals_282 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_214: f32[256] = torch.ops.aten.add.Tensor(mul_281, mul_282);  mul_281 = mul_282 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_122: f32[256] = torch.ops.aten.squeeze.dims(getitem_82, [0, 2, 3]);  getitem_82 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_283: f32[256] = torch.ops.aten.mul.Tensor(squeeze_122, 1.0000797257434426);  squeeze_122 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_284: f32[256] = torch.ops.aten.mul.Tensor(mul_283, 0.1);  mul_283 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_285: f32[256] = torch.ops.aten.mul.Tensor(primals_283, 0.9);  primals_283 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_215: f32[256] = torch.ops.aten.add.Tensor(mul_284, mul_285);  mul_284 = mul_285 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_160: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_122, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_161: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_160, -1);  unsqueeze_160 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_286: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_280, unsqueeze_161);  mul_280 = unsqueeze_161 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_162: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_123, -1);  primals_123 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_163: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_162, -1);  unsqueeze_162 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_216: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_286, unsqueeze_163);  mul_286 = unsqueeze_163 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_37: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_216);  add_216 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_41: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_37, primals_124, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_217: i64[] = torch.ops.aten.add.Tensor(primals_287, 1);  primals_287 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_41 = torch.ops.aten.var_mean.correction(convolution_41, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_84: f32[1, 256, 1, 1] = var_mean_41[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_85: f32[1, 256, 1, 1] = var_mean_41[1];  var_mean_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_218: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_84, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_41: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_218);  add_218 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_41: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_41, getitem_85)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_287: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_41, rsqrt_41);  sub_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_123: f32[256] = torch.ops.aten.squeeze.dims(getitem_85, [0, 2, 3]);  getitem_85 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_124: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_41, [0, 2, 3]);  rsqrt_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_288: f32[256] = torch.ops.aten.mul.Tensor(squeeze_123, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_289: f32[256] = torch.ops.aten.mul.Tensor(primals_285, 0.9);  primals_285 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_219: f32[256] = torch.ops.aten.add.Tensor(mul_288, mul_289);  mul_288 = mul_289 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_125: f32[256] = torch.ops.aten.squeeze.dims(getitem_84, [0, 2, 3]);  getitem_84 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_290: f32[256] = torch.ops.aten.mul.Tensor(squeeze_125, 1.0000797257434426);  squeeze_125 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_291: f32[256] = torch.ops.aten.mul.Tensor(mul_290, 0.1);  mul_290 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_292: f32[256] = torch.ops.aten.mul.Tensor(primals_286, 0.9);  primals_286 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_220: f32[256] = torch.ops.aten.add.Tensor(mul_291, mul_292);  mul_291 = mul_292 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_164: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_125, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_165: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_164, -1);  unsqueeze_164 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_293: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_287, unsqueeze_165);  mul_287 = unsqueeze_165 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_166: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_126, -1);  primals_126 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_167: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_166, -1);  unsqueeze_166 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_221: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_293, unsqueeze_167);  mul_293 = unsqueeze_167 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_38: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_221);  add_221 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_42: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_38, primals_127, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_222: i64[] = torch.ops.aten.add.Tensor(primals_290, 1);  primals_290 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_42 = torch.ops.aten.var_mean.correction(convolution_42, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_86: f32[1, 1024, 1, 1] = var_mean_42[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_87: f32[1, 1024, 1, 1] = var_mean_42[1];  var_mean_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_223: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_86, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_42: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_223);  add_223 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_42: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_42, getitem_87)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_294: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_42, rsqrt_42);  sub_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_126: f32[1024] = torch.ops.aten.squeeze.dims(getitem_87, [0, 2, 3]);  getitem_87 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_127: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_42, [0, 2, 3]);  rsqrt_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_295: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_126, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_296: f32[1024] = torch.ops.aten.mul.Tensor(primals_288, 0.9);  primals_288 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_224: f32[1024] = torch.ops.aten.add.Tensor(mul_295, mul_296);  mul_295 = mul_296 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_128: f32[1024] = torch.ops.aten.squeeze.dims(getitem_86, [0, 2, 3]);  getitem_86 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_297: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_128, 1.0000797257434426);  squeeze_128 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_298: f32[1024] = torch.ops.aten.mul.Tensor(mul_297, 0.1);  mul_297 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_299: f32[1024] = torch.ops.aten.mul.Tensor(primals_289, 0.9);  primals_289 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_225: f32[1024] = torch.ops.aten.add.Tensor(mul_298, mul_299);  mul_298 = mul_299 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_168: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_128, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_169: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_168, -1);  unsqueeze_168 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_300: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_294, unsqueeze_169);  mul_294 = unsqueeze_169 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_170: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_129, -1);  primals_129 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_171: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_170, -1);  unsqueeze_170 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_226: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_300, unsqueeze_171);  mul_300 = unsqueeze_171 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_227: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_226, relu_36);  add_226 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_39: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_227);  add_227 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_43: f32[64, 512, 14, 14] = torch.ops.aten.convolution.default(relu_39, primals_130, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_228: i64[] = torch.ops.aten.add.Tensor(primals_293, 1);  primals_293 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_43 = torch.ops.aten.var_mean.correction(convolution_43, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_88: f32[1, 512, 1, 1] = var_mean_43[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_89: f32[1, 512, 1, 1] = var_mean_43[1];  var_mean_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_229: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_88, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_43: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_229);  add_229 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_43: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(convolution_43, getitem_89)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_301: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(sub_43, rsqrt_43);  sub_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_129: f32[512] = torch.ops.aten.squeeze.dims(getitem_89, [0, 2, 3]);  getitem_89 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_130: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_43, [0, 2, 3]);  rsqrt_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_302: f32[512] = torch.ops.aten.mul.Tensor(squeeze_129, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_303: f32[512] = torch.ops.aten.mul.Tensor(primals_291, 0.9);  primals_291 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_230: f32[512] = torch.ops.aten.add.Tensor(mul_302, mul_303);  mul_302 = mul_303 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_131: f32[512] = torch.ops.aten.squeeze.dims(getitem_88, [0, 2, 3]);  getitem_88 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_304: f32[512] = torch.ops.aten.mul.Tensor(squeeze_131, 1.0000797257434426);  squeeze_131 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_305: f32[512] = torch.ops.aten.mul.Tensor(mul_304, 0.1);  mul_304 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_306: f32[512] = torch.ops.aten.mul.Tensor(primals_292, 0.9);  primals_292 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_231: f32[512] = torch.ops.aten.add.Tensor(mul_305, mul_306);  mul_305 = mul_306 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_172: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_131, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_173: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_172, -1);  unsqueeze_172 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_307: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(mul_301, unsqueeze_173);  mul_301 = unsqueeze_173 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_174: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_132, -1);  primals_132 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_175: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_174, -1);  unsqueeze_174 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_232: f32[64, 512, 14, 14] = torch.ops.aten.add.Tensor(mul_307, unsqueeze_175);  mul_307 = unsqueeze_175 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_40: f32[64, 512, 14, 14] = torch.ops.aten.relu.default(add_232);  add_232 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_44: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_40, primals_133, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_233: i64[] = torch.ops.aten.add.Tensor(primals_296, 1);  primals_296 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_44 = torch.ops.aten.var_mean.correction(convolution_44, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_90: f32[1, 512, 1, 1] = var_mean_44[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_91: f32[1, 512, 1, 1] = var_mean_44[1];  var_mean_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_234: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_90, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_44: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_234);  add_234 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_44: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_44, getitem_91)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_308: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_44, rsqrt_44);  sub_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_132: f32[512] = torch.ops.aten.squeeze.dims(getitem_91, [0, 2, 3]);  getitem_91 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_133: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_44, [0, 2, 3]);  rsqrt_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_309: f32[512] = torch.ops.aten.mul.Tensor(squeeze_132, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_310: f32[512] = torch.ops.aten.mul.Tensor(primals_294, 0.9);  primals_294 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_235: f32[512] = torch.ops.aten.add.Tensor(mul_309, mul_310);  mul_309 = mul_310 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_134: f32[512] = torch.ops.aten.squeeze.dims(getitem_90, [0, 2, 3]);  getitem_90 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_311: f32[512] = torch.ops.aten.mul.Tensor(squeeze_134, 1.0003189792663476);  squeeze_134 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_312: f32[512] = torch.ops.aten.mul.Tensor(mul_311, 0.1);  mul_311 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_313: f32[512] = torch.ops.aten.mul.Tensor(primals_295, 0.9);  primals_295 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_236: f32[512] = torch.ops.aten.add.Tensor(mul_312, mul_313);  mul_312 = mul_313 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_176: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_134, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_177: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_176, -1);  unsqueeze_176 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_314: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_308, unsqueeze_177);  mul_308 = unsqueeze_177 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_178: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_135, -1);  primals_135 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_179: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_178, -1);  unsqueeze_178 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_237: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_314, unsqueeze_179);  mul_314 = unsqueeze_179 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_41: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_237);  add_237 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_45: f32[64, 2048, 7, 7] = torch.ops.aten.convolution.default(relu_41, primals_136, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_238: i64[] = torch.ops.aten.add.Tensor(primals_299, 1);  primals_299 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_45 = torch.ops.aten.var_mean.correction(convolution_45, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_92: f32[1, 2048, 1, 1] = var_mean_45[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_93: f32[1, 2048, 1, 1] = var_mean_45[1];  var_mean_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_239: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_92, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_45: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_239);  add_239 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_45: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_45, getitem_93)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_315: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_45, rsqrt_45);  sub_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_135: f32[2048] = torch.ops.aten.squeeze.dims(getitem_93, [0, 2, 3]);  getitem_93 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_136: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_45, [0, 2, 3]);  rsqrt_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_316: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_135, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_317: f32[2048] = torch.ops.aten.mul.Tensor(primals_297, 0.9);  primals_297 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_240: f32[2048] = torch.ops.aten.add.Tensor(mul_316, mul_317);  mul_316 = mul_317 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_137: f32[2048] = torch.ops.aten.squeeze.dims(getitem_92, [0, 2, 3]);  getitem_92 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_318: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_137, 1.0003189792663476);  squeeze_137 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_319: f32[2048] = torch.ops.aten.mul.Tensor(mul_318, 0.1);  mul_318 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_320: f32[2048] = torch.ops.aten.mul.Tensor(primals_298, 0.9);  primals_298 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_241: f32[2048] = torch.ops.aten.add.Tensor(mul_319, mul_320);  mul_319 = mul_320 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_180: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_137, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_181: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_180, -1);  unsqueeze_180 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_321: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(mul_315, unsqueeze_181);  mul_315 = unsqueeze_181 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_182: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_138, -1);  primals_138 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_183: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_182, -1);  unsqueeze_182 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_242: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(mul_321, unsqueeze_183);  mul_321 = unsqueeze_183 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_46: f32[64, 2048, 7, 7] = torch.ops.aten.convolution.default(relu_39, primals_139, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_243: i64[] = torch.ops.aten.add.Tensor(primals_302, 1);  primals_302 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_46 = torch.ops.aten.var_mean.correction(convolution_46, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_94: f32[1, 2048, 1, 1] = var_mean_46[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_95: f32[1, 2048, 1, 1] = var_mean_46[1];  var_mean_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_244: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_94, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_46: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_244);  add_244 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_46: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_46, getitem_95)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_322: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_46, rsqrt_46);  sub_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_138: f32[2048] = torch.ops.aten.squeeze.dims(getitem_95, [0, 2, 3]);  getitem_95 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_139: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_46, [0, 2, 3]);  rsqrt_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_323: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_138, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_324: f32[2048] = torch.ops.aten.mul.Tensor(primals_300, 0.9);  primals_300 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_245: f32[2048] = torch.ops.aten.add.Tensor(mul_323, mul_324);  mul_323 = mul_324 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_140: f32[2048] = torch.ops.aten.squeeze.dims(getitem_94, [0, 2, 3]);  getitem_94 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_325: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_140, 1.0003189792663476);  squeeze_140 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_326: f32[2048] = torch.ops.aten.mul.Tensor(mul_325, 0.1);  mul_325 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_327: f32[2048] = torch.ops.aten.mul.Tensor(primals_301, 0.9);  primals_301 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_246: f32[2048] = torch.ops.aten.add.Tensor(mul_326, mul_327);  mul_326 = mul_327 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_184: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_140, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_185: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_184, -1);  unsqueeze_184 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_328: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(mul_322, unsqueeze_185);  mul_322 = unsqueeze_185 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_186: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_141, -1);  primals_141 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_187: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_186, -1);  unsqueeze_186 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_247: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(mul_328, unsqueeze_187);  mul_328 = unsqueeze_187 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_248: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(add_242, add_247);  add_242 = add_247 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_42: f32[64, 2048, 7, 7] = torch.ops.aten.relu.default(add_248);  add_248 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_47: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_42, primals_142, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_249: i64[] = torch.ops.aten.add.Tensor(primals_305, 1);  primals_305 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_47 = torch.ops.aten.var_mean.correction(convolution_47, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_96: f32[1, 512, 1, 1] = var_mean_47[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_97: f32[1, 512, 1, 1] = var_mean_47[1];  var_mean_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_250: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_96, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_47: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_250);  add_250 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_47: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_47, getitem_97)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_329: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_47, rsqrt_47);  sub_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_141: f32[512] = torch.ops.aten.squeeze.dims(getitem_97, [0, 2, 3]);  getitem_97 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_142: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_47, [0, 2, 3]);  rsqrt_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_330: f32[512] = torch.ops.aten.mul.Tensor(squeeze_141, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_331: f32[512] = torch.ops.aten.mul.Tensor(primals_303, 0.9);  primals_303 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_251: f32[512] = torch.ops.aten.add.Tensor(mul_330, mul_331);  mul_330 = mul_331 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_143: f32[512] = torch.ops.aten.squeeze.dims(getitem_96, [0, 2, 3]);  getitem_96 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_332: f32[512] = torch.ops.aten.mul.Tensor(squeeze_143, 1.0003189792663476);  squeeze_143 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_333: f32[512] = torch.ops.aten.mul.Tensor(mul_332, 0.1);  mul_332 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_334: f32[512] = torch.ops.aten.mul.Tensor(primals_304, 0.9);  primals_304 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_252: f32[512] = torch.ops.aten.add.Tensor(mul_333, mul_334);  mul_333 = mul_334 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_188: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_143, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_189: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_188, -1);  unsqueeze_188 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_335: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_329, unsqueeze_189);  mul_329 = unsqueeze_189 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_190: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_144, -1);  primals_144 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_191: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_190, -1);  unsqueeze_190 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_253: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_335, unsqueeze_191);  mul_335 = unsqueeze_191 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_43: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_253);  add_253 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_48: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_43, primals_145, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_254: i64[] = torch.ops.aten.add.Tensor(primals_308, 1);  primals_308 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_48 = torch.ops.aten.var_mean.correction(convolution_48, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_98: f32[1, 512, 1, 1] = var_mean_48[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_99: f32[1, 512, 1, 1] = var_mean_48[1];  var_mean_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_255: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_98, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_48: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_255);  add_255 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_48: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_48, getitem_99)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_336: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_48, rsqrt_48);  sub_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_144: f32[512] = torch.ops.aten.squeeze.dims(getitem_99, [0, 2, 3]);  getitem_99 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_145: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_48, [0, 2, 3]);  rsqrt_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_337: f32[512] = torch.ops.aten.mul.Tensor(squeeze_144, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_338: f32[512] = torch.ops.aten.mul.Tensor(primals_306, 0.9);  primals_306 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_256: f32[512] = torch.ops.aten.add.Tensor(mul_337, mul_338);  mul_337 = mul_338 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_146: f32[512] = torch.ops.aten.squeeze.dims(getitem_98, [0, 2, 3]);  getitem_98 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_339: f32[512] = torch.ops.aten.mul.Tensor(squeeze_146, 1.0003189792663476);  squeeze_146 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_340: f32[512] = torch.ops.aten.mul.Tensor(mul_339, 0.1);  mul_339 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_341: f32[512] = torch.ops.aten.mul.Tensor(primals_307, 0.9);  primals_307 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_257: f32[512] = torch.ops.aten.add.Tensor(mul_340, mul_341);  mul_340 = mul_341 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_192: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_146, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_193: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_192, -1);  unsqueeze_192 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_342: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_336, unsqueeze_193);  mul_336 = unsqueeze_193 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_194: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_147, -1);  primals_147 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_195: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_194, -1);  unsqueeze_194 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_258: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_342, unsqueeze_195);  mul_342 = unsqueeze_195 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_44: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_258);  add_258 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_49: f32[64, 2048, 7, 7] = torch.ops.aten.convolution.default(relu_44, primals_148, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_259: i64[] = torch.ops.aten.add.Tensor(primals_311, 1);  primals_311 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_49 = torch.ops.aten.var_mean.correction(convolution_49, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_100: f32[1, 2048, 1, 1] = var_mean_49[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_101: f32[1, 2048, 1, 1] = var_mean_49[1];  var_mean_49 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_260: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_100, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_49: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_260);  add_260 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_49: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_49, getitem_101)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_343: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_49, rsqrt_49);  sub_49 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_147: f32[2048] = torch.ops.aten.squeeze.dims(getitem_101, [0, 2, 3]);  getitem_101 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_148: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_49, [0, 2, 3]);  rsqrt_49 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_344: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_147, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_345: f32[2048] = torch.ops.aten.mul.Tensor(primals_309, 0.9);  primals_309 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_261: f32[2048] = torch.ops.aten.add.Tensor(mul_344, mul_345);  mul_344 = mul_345 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_149: f32[2048] = torch.ops.aten.squeeze.dims(getitem_100, [0, 2, 3]);  getitem_100 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_346: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_149, 1.0003189792663476);  squeeze_149 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_347: f32[2048] = torch.ops.aten.mul.Tensor(mul_346, 0.1);  mul_346 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_348: f32[2048] = torch.ops.aten.mul.Tensor(primals_310, 0.9);  primals_310 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_262: f32[2048] = torch.ops.aten.add.Tensor(mul_347, mul_348);  mul_347 = mul_348 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_196: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_149, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_197: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_196, -1);  unsqueeze_196 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_349: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(mul_343, unsqueeze_197);  mul_343 = unsqueeze_197 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_198: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_150, -1);  primals_150 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_199: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_198, -1);  unsqueeze_198 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_263: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(mul_349, unsqueeze_199);  mul_349 = unsqueeze_199 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_264: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(add_263, relu_42);  add_263 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_45: f32[64, 2048, 7, 7] = torch.ops.aten.relu.default(add_264);  add_264 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_50: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_45, primals_151, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_265: i64[] = torch.ops.aten.add.Tensor(primals_314, 1);  primals_314 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_50 = torch.ops.aten.var_mean.correction(convolution_50, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_102: f32[1, 512, 1, 1] = var_mean_50[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_103: f32[1, 512, 1, 1] = var_mean_50[1];  var_mean_50 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_266: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_102, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_50: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_266);  add_266 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_50: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_50, getitem_103)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_350: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_50, rsqrt_50);  sub_50 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_150: f32[512] = torch.ops.aten.squeeze.dims(getitem_103, [0, 2, 3]);  getitem_103 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_151: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_50, [0, 2, 3]);  rsqrt_50 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_351: f32[512] = torch.ops.aten.mul.Tensor(squeeze_150, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_352: f32[512] = torch.ops.aten.mul.Tensor(primals_312, 0.9);  primals_312 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_267: f32[512] = torch.ops.aten.add.Tensor(mul_351, mul_352);  mul_351 = mul_352 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_152: f32[512] = torch.ops.aten.squeeze.dims(getitem_102, [0, 2, 3]);  getitem_102 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_353: f32[512] = torch.ops.aten.mul.Tensor(squeeze_152, 1.0003189792663476);  squeeze_152 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_354: f32[512] = torch.ops.aten.mul.Tensor(mul_353, 0.1);  mul_353 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_355: f32[512] = torch.ops.aten.mul.Tensor(primals_313, 0.9);  primals_313 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_268: f32[512] = torch.ops.aten.add.Tensor(mul_354, mul_355);  mul_354 = mul_355 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_200: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_152, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_201: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_200, -1);  unsqueeze_200 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_356: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_350, unsqueeze_201);  mul_350 = unsqueeze_201 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_202: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_153, -1);  primals_153 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_203: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_202, -1);  unsqueeze_202 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_269: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_356, unsqueeze_203);  mul_356 = unsqueeze_203 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_46: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_269);  add_269 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_51: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_46, primals_154, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_270: i64[] = torch.ops.aten.add.Tensor(primals_317, 1);  primals_317 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_51 = torch.ops.aten.var_mean.correction(convolution_51, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_104: f32[1, 512, 1, 1] = var_mean_51[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_105: f32[1, 512, 1, 1] = var_mean_51[1];  var_mean_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_271: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_104, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_51: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_271);  add_271 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_51: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_51, getitem_105)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_357: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_51, rsqrt_51);  sub_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_153: f32[512] = torch.ops.aten.squeeze.dims(getitem_105, [0, 2, 3]);  getitem_105 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_154: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_51, [0, 2, 3]);  rsqrt_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_358: f32[512] = torch.ops.aten.mul.Tensor(squeeze_153, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_359: f32[512] = torch.ops.aten.mul.Tensor(primals_315, 0.9);  primals_315 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_272: f32[512] = torch.ops.aten.add.Tensor(mul_358, mul_359);  mul_358 = mul_359 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_155: f32[512] = torch.ops.aten.squeeze.dims(getitem_104, [0, 2, 3]);  getitem_104 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_360: f32[512] = torch.ops.aten.mul.Tensor(squeeze_155, 1.0003189792663476);  squeeze_155 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_361: f32[512] = torch.ops.aten.mul.Tensor(mul_360, 0.1);  mul_360 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_362: f32[512] = torch.ops.aten.mul.Tensor(primals_316, 0.9);  primals_316 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_273: f32[512] = torch.ops.aten.add.Tensor(mul_361, mul_362);  mul_361 = mul_362 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_204: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_155, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_205: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_204, -1);  unsqueeze_204 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_363: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_357, unsqueeze_205);  mul_357 = unsqueeze_205 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_206: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_156, -1);  primals_156 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_207: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_206, -1);  unsqueeze_206 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_274: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_363, unsqueeze_207);  mul_363 = unsqueeze_207 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_47: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_274);  add_274 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_52: f32[64, 2048, 7, 7] = torch.ops.aten.convolution.default(relu_47, primals_157, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_275: i64[] = torch.ops.aten.add.Tensor(primals_320, 1);  primals_320 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         var_mean_52 = torch.ops.aten.var_mean.correction(convolution_52, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_106: f32[1, 2048, 1, 1] = var_mean_52[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_107: f32[1, 2048, 1, 1] = var_mean_52[1];  var_mean_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_276: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_106, 1e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         rsqrt_52: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_276);  add_276 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_52: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_52, getitem_107)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_364: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_52, rsqrt_52);  sub_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_156: f32[2048] = torch.ops.aten.squeeze.dims(getitem_107, [0, 2, 3]);  getitem_107 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_157: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_52, [0, 2, 3]);  rsqrt_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_365: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_156, 0.1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_366: f32[2048] = torch.ops.aten.mul.Tensor(primals_318, 0.9);  primals_318 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_277: f32[2048] = torch.ops.aten.add.Tensor(mul_365, mul_366);  mul_365 = mul_366 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         squeeze_158: f32[2048] = torch.ops.aten.squeeze.dims(getitem_106, [0, 2, 3]);  getitem_106 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_367: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_158, 1.0003189792663476);  squeeze_158 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_368: f32[2048] = torch.ops.aten.mul.Tensor(mul_367, 0.1);  mul_367 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_369: f32[2048] = torch.ops.aten.mul.Tensor(primals_319, 0.9);  primals_319 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_278: f32[2048] = torch.ops.aten.add.Tensor(mul_368, mul_369);  mul_368 = mul_369 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_208: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_158, -1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_209: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_208, -1);  unsqueeze_208 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_370: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(mul_364, unsqueeze_209);  mul_364 = unsqueeze_209 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_210: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_159, -1);  primals_159 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_211: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_210, -1);  unsqueeze_210 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_279: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(mul_370, unsqueeze_211);  mul_370 = unsqueeze_211 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_280: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(add_279, relu_45);  add_279 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         relu_48: f32[64, 2048, 7, 7] = torch.ops.aten.relu.default(add_280);  add_280 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:278, code: x = self.avgpool(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mean: f32[64, 2048, 1, 1] = torch.ops.aten.mean.dim(relu_48, [-1, -2], True)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:279, code: x = torch.flatten(x, 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         view: f32[64, 2048] = torch.ops.aten.view.default(mean, [64, 2048]);  mean = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:280, code: x = self.fc(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         permute: f32[2048, 1000] = torch.ops.aten.permute.default(primals_160, [1, 0]);  primals_160 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         addmm: f32[64, 1000] = torch.ops.aten.addmm.default(primals_161, view, permute);  primals_161 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         permute_1: f32[1000, 2048] = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mm: f32[64, 2048] = torch.ops.aten.mm.default(tangents_160, permute_1);  permute_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         permute_2: f32[1000, 64] = torch.ops.aten.permute.default(tangents_160, [1, 0])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mm_1: f32[1000, 2048] = torch.ops.aten.mm.default(permute_2, view);  permute_2 = view = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         permute_3: f32[2048, 1000] = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_1: f32[1, 1000] = torch.ops.aten.sum.dim_IntList(tangents_160, [0], True);  tangents_160 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         view_1: f32[1000] = torch.ops.aten.view.default(sum_1, [1000]);  sum_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         permute_4: f32[1000, 2048] = torch.ops.aten.permute.default(permute_3, [1, 0]);  permute_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:279, code: x = torch.flatten(x, 1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         view_2: f32[64, 2048, 1, 1] = torch.ops.aten.view.default(mm, [64, 2048, 1, 1]);  mm = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:278, code: x = self.avgpool(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         expand: f32[64, 2048, 7, 7] = torch.ops.aten.expand.default(view_2, [64, 2048, 7, 7]);  view_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         div: f32[64, 2048, 7, 7] = torch.ops.aten.div.Scalar(expand, 49);  expand = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le: b8[64, 2048, 7, 7] = torch.ops.aten.le.Scalar(relu_48, 0);  relu_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where: f32[64, 2048, 7, 7] = torch.ops.aten.where.self(le, scalar_tensor, div);  le = scalar_tensor = div = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_212: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_156, 0);  squeeze_156 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_213: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_212, 2);  unsqueeze_212 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_214: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_213, 3);  unsqueeze_213 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_2: f32[2048] = torch.ops.aten.sum.dim_IntList(where, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_53: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_52, unsqueeze_214)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_371: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(where, sub_53);  sub_53 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_3: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_371, [0, 2, 3]);  mul_371 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_372: f32[2048] = torch.ops.aten.mul.Tensor(sum_2, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_215: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_372, 0);  mul_372 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_216: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_215, 2);  unsqueeze_215 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_217: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_216, 3);  unsqueeze_216 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_373: f32[2048] = torch.ops.aten.mul.Tensor(sum_3, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_374: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_157, squeeze_157)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_375: f32[2048] = torch.ops.aten.mul.Tensor(mul_373, mul_374);  mul_373 = mul_374 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_218: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_375, 0);  mul_375 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_219: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_218, 2);  unsqueeze_218 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_220: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_219, 3);  unsqueeze_219 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_376: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_157, primals_158);  primals_158 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_221: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_376, 0);  mul_376 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_222: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_221, 2);  unsqueeze_221 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_223: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_222, 3);  unsqueeze_222 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_54: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_52, unsqueeze_214);  convolution_52 = unsqueeze_214 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_377: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_54, unsqueeze_220);  sub_54 = unsqueeze_220 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_55: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(where, mul_377);  mul_377 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_56: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(sub_55, unsqueeze_217);  sub_55 = unsqueeze_217 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_378: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_56, unsqueeze_223);  sub_56 = unsqueeze_223 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_379: f32[2048] = torch.ops.aten.mul.Tensor(sum_3, squeeze_157);  sum_3 = squeeze_157 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward = torch.ops.aten.convolution_backward.default(mul_378, relu_47, primals_157, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_378 = primals_157 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_108: f32[64, 512, 7, 7] = convolution_backward[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_109: f32[2048, 512, 1, 1] = convolution_backward[1];  convolution_backward = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_1: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_47, 0);  relu_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_1: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_1: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_1, scalar_tensor_1, getitem_108);  le_1 = scalar_tensor_1 = getitem_108 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_224: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_153, 0);  squeeze_153 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_225: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_224, 2);  unsqueeze_224 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_226: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_225, 3);  unsqueeze_225 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_4: f32[512] = torch.ops.aten.sum.dim_IntList(where_1, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_57: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_51, unsqueeze_226)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_380: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_1, sub_57);  sub_57 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_5: f32[512] = torch.ops.aten.sum.dim_IntList(mul_380, [0, 2, 3]);  mul_380 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_381: f32[512] = torch.ops.aten.mul.Tensor(sum_4, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_227: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_381, 0);  mul_381 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_228: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_227, 2);  unsqueeze_227 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_229: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_228, 3);  unsqueeze_228 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_382: f32[512] = torch.ops.aten.mul.Tensor(sum_5, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_383: f32[512] = torch.ops.aten.mul.Tensor(squeeze_154, squeeze_154)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_384: f32[512] = torch.ops.aten.mul.Tensor(mul_382, mul_383);  mul_382 = mul_383 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_230: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_384, 0);  mul_384 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_231: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_230, 2);  unsqueeze_230 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_232: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_231, 3);  unsqueeze_231 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_385: f32[512] = torch.ops.aten.mul.Tensor(squeeze_154, primals_155);  primals_155 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_233: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_385, 0);  mul_385 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_234: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_233, 2);  unsqueeze_233 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_235: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_234, 3);  unsqueeze_234 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_58: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_51, unsqueeze_226);  convolution_51 = unsqueeze_226 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_386: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_58, unsqueeze_232);  sub_58 = unsqueeze_232 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_59: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_1, mul_386);  where_1 = mul_386 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_60: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_59, unsqueeze_229);  sub_59 = unsqueeze_229 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_387: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_60, unsqueeze_235);  sub_60 = unsqueeze_235 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_388: f32[512] = torch.ops.aten.mul.Tensor(sum_5, squeeze_154);  sum_5 = squeeze_154 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_1 = torch.ops.aten.convolution_backward.default(mul_387, relu_46, primals_154, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_387 = primals_154 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_111: f32[64, 512, 7, 7] = convolution_backward_1[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_112: f32[512, 512, 3, 3] = convolution_backward_1[1];  convolution_backward_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_2: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_46, 0);  relu_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_2: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_2: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_2, scalar_tensor_2, getitem_111);  le_2 = scalar_tensor_2 = getitem_111 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_236: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_150, 0);  squeeze_150 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_237: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_236, 2);  unsqueeze_236 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_238: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_237, 3);  unsqueeze_237 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_6: f32[512] = torch.ops.aten.sum.dim_IntList(where_2, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_61: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_50, unsqueeze_238)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_389: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_2, sub_61);  sub_61 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_7: f32[512] = torch.ops.aten.sum.dim_IntList(mul_389, [0, 2, 3]);  mul_389 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_390: f32[512] = torch.ops.aten.mul.Tensor(sum_6, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_239: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_390, 0);  mul_390 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_240: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_239, 2);  unsqueeze_239 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_241: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_240, 3);  unsqueeze_240 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_391: f32[512] = torch.ops.aten.mul.Tensor(sum_7, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_392: f32[512] = torch.ops.aten.mul.Tensor(squeeze_151, squeeze_151)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_393: f32[512] = torch.ops.aten.mul.Tensor(mul_391, mul_392);  mul_391 = mul_392 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_242: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_393, 0);  mul_393 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_243: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_242, 2);  unsqueeze_242 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_244: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_243, 3);  unsqueeze_243 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_394: f32[512] = torch.ops.aten.mul.Tensor(squeeze_151, primals_152);  primals_152 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_245: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_394, 0);  mul_394 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_246: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_245, 2);  unsqueeze_245 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_247: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_246, 3);  unsqueeze_246 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_62: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_50, unsqueeze_238);  convolution_50 = unsqueeze_238 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_395: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_62, unsqueeze_244);  sub_62 = unsqueeze_244 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_63: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_2, mul_395);  where_2 = mul_395 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_64: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_63, unsqueeze_241);  sub_63 = unsqueeze_241 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_396: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_64, unsqueeze_247);  sub_64 = unsqueeze_247 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_397: f32[512] = torch.ops.aten.mul.Tensor(sum_7, squeeze_151);  sum_7 = squeeze_151 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_2 = torch.ops.aten.convolution_backward.default(mul_396, relu_45, primals_151, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_396 = primals_151 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_114: f32[64, 2048, 7, 7] = convolution_backward_2[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_115: f32[512, 2048, 1, 1] = convolution_backward_2[1];  convolution_backward_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_281: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(where, getitem_114);  where = getitem_114 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_3: b8[64, 2048, 7, 7] = torch.ops.aten.le.Scalar(relu_45, 0);  relu_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_3: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_3: f32[64, 2048, 7, 7] = torch.ops.aten.where.self(le_3, scalar_tensor_3, add_281);  le_3 = scalar_tensor_3 = add_281 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_248: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_147, 0);  squeeze_147 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_249: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_248, 2);  unsqueeze_248 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_250: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_249, 3);  unsqueeze_249 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_8: f32[2048] = torch.ops.aten.sum.dim_IntList(where_3, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_65: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_49, unsqueeze_250)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_398: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(where_3, sub_65);  sub_65 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_9: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_398, [0, 2, 3]);  mul_398 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_399: f32[2048] = torch.ops.aten.mul.Tensor(sum_8, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_251: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_399, 0);  mul_399 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_252: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_251, 2);  unsqueeze_251 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_253: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_252, 3);  unsqueeze_252 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_400: f32[2048] = torch.ops.aten.mul.Tensor(sum_9, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_401: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_148, squeeze_148)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_402: f32[2048] = torch.ops.aten.mul.Tensor(mul_400, mul_401);  mul_400 = mul_401 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_254: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_402, 0);  mul_402 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_255: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_254, 2);  unsqueeze_254 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_256: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_255, 3);  unsqueeze_255 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_403: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_148, primals_149);  primals_149 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_257: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_403, 0);  mul_403 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_258: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_257, 2);  unsqueeze_257 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_259: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_258, 3);  unsqueeze_258 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_66: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_49, unsqueeze_250);  convolution_49 = unsqueeze_250 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_404: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_66, unsqueeze_256);  sub_66 = unsqueeze_256 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_67: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(where_3, mul_404);  mul_404 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_68: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(sub_67, unsqueeze_253);  sub_67 = unsqueeze_253 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_405: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_68, unsqueeze_259);  sub_68 = unsqueeze_259 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_406: f32[2048] = torch.ops.aten.mul.Tensor(sum_9, squeeze_148);  sum_9 = squeeze_148 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_3 = torch.ops.aten.convolution_backward.default(mul_405, relu_44, primals_148, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_405 = primals_148 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_117: f32[64, 512, 7, 7] = convolution_backward_3[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_118: f32[2048, 512, 1, 1] = convolution_backward_3[1];  convolution_backward_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_4: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_44, 0);  relu_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_4: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_4: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_4, scalar_tensor_4, getitem_117);  le_4 = scalar_tensor_4 = getitem_117 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_260: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_144, 0);  squeeze_144 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_261: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_260, 2);  unsqueeze_260 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_262: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_261, 3);  unsqueeze_261 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_10: f32[512] = torch.ops.aten.sum.dim_IntList(where_4, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_69: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_48, unsqueeze_262)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_407: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_4, sub_69);  sub_69 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_11: f32[512] = torch.ops.aten.sum.dim_IntList(mul_407, [0, 2, 3]);  mul_407 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_408: f32[512] = torch.ops.aten.mul.Tensor(sum_10, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_263: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_408, 0);  mul_408 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_264: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_263, 2);  unsqueeze_263 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_265: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_264, 3);  unsqueeze_264 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_409: f32[512] = torch.ops.aten.mul.Tensor(sum_11, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_410: f32[512] = torch.ops.aten.mul.Tensor(squeeze_145, squeeze_145)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_411: f32[512] = torch.ops.aten.mul.Tensor(mul_409, mul_410);  mul_409 = mul_410 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_266: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_411, 0);  mul_411 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_267: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_266, 2);  unsqueeze_266 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_268: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_267, 3);  unsqueeze_267 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_412: f32[512] = torch.ops.aten.mul.Tensor(squeeze_145, primals_146);  primals_146 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_269: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_412, 0);  mul_412 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_270: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_269, 2);  unsqueeze_269 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_271: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_270, 3);  unsqueeze_270 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_70: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_48, unsqueeze_262);  convolution_48 = unsqueeze_262 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_413: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_70, unsqueeze_268);  sub_70 = unsqueeze_268 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_71: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_4, mul_413);  where_4 = mul_413 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_72: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_71, unsqueeze_265);  sub_71 = unsqueeze_265 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_414: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_72, unsqueeze_271);  sub_72 = unsqueeze_271 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_415: f32[512] = torch.ops.aten.mul.Tensor(sum_11, squeeze_145);  sum_11 = squeeze_145 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_4 = torch.ops.aten.convolution_backward.default(mul_414, relu_43, primals_145, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_414 = primals_145 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_120: f32[64, 512, 7, 7] = convolution_backward_4[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_121: f32[512, 512, 3, 3] = convolution_backward_4[1];  convolution_backward_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_5: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_43, 0);  relu_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_5: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_5: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_5, scalar_tensor_5, getitem_120);  le_5 = scalar_tensor_5 = getitem_120 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_272: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_141, 0);  squeeze_141 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_273: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_272, 2);  unsqueeze_272 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_274: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_273, 3);  unsqueeze_273 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_12: f32[512] = torch.ops.aten.sum.dim_IntList(where_5, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_73: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_47, unsqueeze_274)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_416: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_5, sub_73);  sub_73 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_13: f32[512] = torch.ops.aten.sum.dim_IntList(mul_416, [0, 2, 3]);  mul_416 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_417: f32[512] = torch.ops.aten.mul.Tensor(sum_12, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_275: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_417, 0);  mul_417 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_276: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_275, 2);  unsqueeze_275 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_277: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_276, 3);  unsqueeze_276 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_418: f32[512] = torch.ops.aten.mul.Tensor(sum_13, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_419: f32[512] = torch.ops.aten.mul.Tensor(squeeze_142, squeeze_142)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_420: f32[512] = torch.ops.aten.mul.Tensor(mul_418, mul_419);  mul_418 = mul_419 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_278: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_420, 0);  mul_420 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_279: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_278, 2);  unsqueeze_278 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_280: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_279, 3);  unsqueeze_279 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_421: f32[512] = torch.ops.aten.mul.Tensor(squeeze_142, primals_143);  primals_143 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_281: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_421, 0);  mul_421 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_282: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_281, 2);  unsqueeze_281 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_283: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_282, 3);  unsqueeze_282 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_74: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_47, unsqueeze_274);  convolution_47 = unsqueeze_274 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_422: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_74, unsqueeze_280);  sub_74 = unsqueeze_280 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_75: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_5, mul_422);  where_5 = mul_422 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_76: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_75, unsqueeze_277);  sub_75 = unsqueeze_277 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_423: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_76, unsqueeze_283);  sub_76 = unsqueeze_283 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_424: f32[512] = torch.ops.aten.mul.Tensor(sum_13, squeeze_142);  sum_13 = squeeze_142 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_5 = torch.ops.aten.convolution_backward.default(mul_423, relu_42, primals_142, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_423 = primals_142 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_123: f32[64, 2048, 7, 7] = convolution_backward_5[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_124: f32[512, 2048, 1, 1] = convolution_backward_5[1];  convolution_backward_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_282: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(where_3, getitem_123);  where_3 = getitem_123 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_6: b8[64, 2048, 7, 7] = torch.ops.aten.le.Scalar(relu_42, 0);  relu_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_6: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_6: f32[64, 2048, 7, 7] = torch.ops.aten.where.self(le_6, scalar_tensor_6, add_282);  le_6 = scalar_tensor_6 = add_282 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_284: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_138, 0);  squeeze_138 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_285: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_284, 2);  unsqueeze_284 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_286: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_285, 3);  unsqueeze_285 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_14: f32[2048] = torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_77: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_46, unsqueeze_286)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_425: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(where_6, sub_77);  sub_77 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_15: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_425, [0, 2, 3]);  mul_425 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_426: f32[2048] = torch.ops.aten.mul.Tensor(sum_14, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_287: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_426, 0);  mul_426 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_288: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_287, 2);  unsqueeze_287 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_289: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_288, 3);  unsqueeze_288 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_427: f32[2048] = torch.ops.aten.mul.Tensor(sum_15, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_428: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_139, squeeze_139)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_429: f32[2048] = torch.ops.aten.mul.Tensor(mul_427, mul_428);  mul_427 = mul_428 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_290: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_429, 0);  mul_429 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_291: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_290, 2);  unsqueeze_290 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_292: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_291, 3);  unsqueeze_291 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_430: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_139, primals_140);  primals_140 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_293: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_430, 0);  mul_430 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_294: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_293, 2);  unsqueeze_293 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_295: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_294, 3);  unsqueeze_294 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_78: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_46, unsqueeze_286);  convolution_46 = unsqueeze_286 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_431: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_78, unsqueeze_292);  sub_78 = unsqueeze_292 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_79: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(where_6, mul_431);  mul_431 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_80: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(sub_79, unsqueeze_289);  sub_79 = unsqueeze_289 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_432: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_80, unsqueeze_295);  sub_80 = unsqueeze_295 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_433: f32[2048] = torch.ops.aten.mul.Tensor(sum_15, squeeze_139);  sum_15 = squeeze_139 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_6 = torch.ops.aten.convolution_backward.default(mul_432, relu_39, primals_139, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_432 = primals_139 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_126: f32[64, 1024, 14, 14] = convolution_backward_6[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_127: f32[2048, 1024, 1, 1] = convolution_backward_6[1];  convolution_backward_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_296: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_135, 0);  squeeze_135 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_297: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_296, 2);  unsqueeze_296 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_298: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_297, 3);  unsqueeze_297 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_16: f32[2048] = torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_81: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_45, unsqueeze_298)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_434: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(where_6, sub_81);  sub_81 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_17: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_434, [0, 2, 3]);  mul_434 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_435: f32[2048] = torch.ops.aten.mul.Tensor(sum_16, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_299: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_435, 0);  mul_435 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_300: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_299, 2);  unsqueeze_299 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_301: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_300, 3);  unsqueeze_300 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_436: f32[2048] = torch.ops.aten.mul.Tensor(sum_17, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_437: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_136, squeeze_136)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_438: f32[2048] = torch.ops.aten.mul.Tensor(mul_436, mul_437);  mul_436 = mul_437 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_302: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_438, 0);  mul_438 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_303: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_302, 2);  unsqueeze_302 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_304: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_303, 3);  unsqueeze_303 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_439: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_136, primals_137);  primals_137 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_305: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_439, 0);  mul_439 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_306: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_305, 2);  unsqueeze_305 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_307: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_306, 3);  unsqueeze_306 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_82: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_45, unsqueeze_298);  convolution_45 = unsqueeze_298 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_440: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_82, unsqueeze_304);  sub_82 = unsqueeze_304 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_83: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(where_6, mul_440);  where_6 = mul_440 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_84: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(sub_83, unsqueeze_301);  sub_83 = unsqueeze_301 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_441: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_84, unsqueeze_307);  sub_84 = unsqueeze_307 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_442: f32[2048] = torch.ops.aten.mul.Tensor(sum_17, squeeze_136);  sum_17 = squeeze_136 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_7 = torch.ops.aten.convolution_backward.default(mul_441, relu_41, primals_136, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_441 = primals_136 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_129: f32[64, 512, 7, 7] = convolution_backward_7[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_130: f32[2048, 512, 1, 1] = convolution_backward_7[1];  convolution_backward_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_7: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_41, 0);  relu_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_7: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_7: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_7, scalar_tensor_7, getitem_129);  le_7 = scalar_tensor_7 = getitem_129 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_308: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_132, 0);  squeeze_132 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_309: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_308, 2);  unsqueeze_308 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_310: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_309, 3);  unsqueeze_309 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_18: f32[512] = torch.ops.aten.sum.dim_IntList(where_7, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_85: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_44, unsqueeze_310)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_443: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_7, sub_85);  sub_85 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_19: f32[512] = torch.ops.aten.sum.dim_IntList(mul_443, [0, 2, 3]);  mul_443 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_444: f32[512] = torch.ops.aten.mul.Tensor(sum_18, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_311: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_444, 0);  mul_444 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_312: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_311, 2);  unsqueeze_311 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_313: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_312, 3);  unsqueeze_312 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_445: f32[512] = torch.ops.aten.mul.Tensor(sum_19, 0.00031887755102040814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_446: f32[512] = torch.ops.aten.mul.Tensor(squeeze_133, squeeze_133)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_447: f32[512] = torch.ops.aten.mul.Tensor(mul_445, mul_446);  mul_445 = mul_446 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_314: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_447, 0);  mul_447 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_315: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_314, 2);  unsqueeze_314 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_316: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_315, 3);  unsqueeze_315 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_448: f32[512] = torch.ops.aten.mul.Tensor(squeeze_133, primals_134);  primals_134 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_317: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_448, 0);  mul_448 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_318: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_317, 2);  unsqueeze_317 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_319: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_318, 3);  unsqueeze_318 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_86: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_44, unsqueeze_310);  convolution_44 = unsqueeze_310 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_449: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_86, unsqueeze_316);  sub_86 = unsqueeze_316 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_87: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_7, mul_449);  where_7 = mul_449 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_88: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_87, unsqueeze_313);  sub_87 = unsqueeze_313 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_450: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_88, unsqueeze_319);  sub_88 = unsqueeze_319 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_451: f32[512] = torch.ops.aten.mul.Tensor(sum_19, squeeze_133);  sum_19 = squeeze_133 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_8 = torch.ops.aten.convolution_backward.default(mul_450, relu_40, primals_133, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_450 = primals_133 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_132: f32[64, 512, 14, 14] = convolution_backward_8[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_133: f32[512, 512, 3, 3] = convolution_backward_8[1];  convolution_backward_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_8: b8[64, 512, 14, 14] = torch.ops.aten.le.Scalar(relu_40, 0);  relu_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_8: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_8: f32[64, 512, 14, 14] = torch.ops.aten.where.self(le_8, scalar_tensor_8, getitem_132);  le_8 = scalar_tensor_8 = getitem_132 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_320: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_129, 0);  squeeze_129 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_321: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_320, 2);  unsqueeze_320 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_322: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_321, 3);  unsqueeze_321 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_20: f32[512] = torch.ops.aten.sum.dim_IntList(where_8, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_89: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(convolution_43, unsqueeze_322)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_452: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(where_8, sub_89);  sub_89 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_21: f32[512] = torch.ops.aten.sum.dim_IntList(mul_452, [0, 2, 3]);  mul_452 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_453: f32[512] = torch.ops.aten.mul.Tensor(sum_20, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_323: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_453, 0);  mul_453 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_324: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_323, 2);  unsqueeze_323 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_325: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_324, 3);  unsqueeze_324 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_454: f32[512] = torch.ops.aten.mul.Tensor(sum_21, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_455: f32[512] = torch.ops.aten.mul.Tensor(squeeze_130, squeeze_130)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_456: f32[512] = torch.ops.aten.mul.Tensor(mul_454, mul_455);  mul_454 = mul_455 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_326: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_456, 0);  mul_456 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_327: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_326, 2);  unsqueeze_326 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_328: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_327, 3);  unsqueeze_327 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_457: f32[512] = torch.ops.aten.mul.Tensor(squeeze_130, primals_131);  primals_131 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_329: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_457, 0);  mul_457 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_330: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_329, 2);  unsqueeze_329 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_331: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_330, 3);  unsqueeze_330 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_90: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(convolution_43, unsqueeze_322);  convolution_43 = unsqueeze_322 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_458: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(sub_90, unsqueeze_328);  sub_90 = unsqueeze_328 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_91: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(where_8, mul_458);  where_8 = mul_458 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_92: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(sub_91, unsqueeze_325);  sub_91 = unsqueeze_325 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_459: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(sub_92, unsqueeze_331);  sub_92 = unsqueeze_331 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_460: f32[512] = torch.ops.aten.mul.Tensor(sum_21, squeeze_130);  sum_21 = squeeze_130 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_9 = torch.ops.aten.convolution_backward.default(mul_459, relu_39, primals_130, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_459 = primals_130 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_135: f32[64, 1024, 14, 14] = convolution_backward_9[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_136: f32[512, 1024, 1, 1] = convolution_backward_9[1];  convolution_backward_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_283: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(getitem_126, getitem_135);  getitem_126 = getitem_135 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_9: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_39, 0);  relu_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_9: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_9: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_9, scalar_tensor_9, add_283);  le_9 = scalar_tensor_9 = add_283 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_332: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_126, 0);  squeeze_126 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_333: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_332, 2);  unsqueeze_332 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_334: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_333, 3);  unsqueeze_333 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_22: f32[1024] = torch.ops.aten.sum.dim_IntList(where_9, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_93: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_42, unsqueeze_334)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_461: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_9, sub_93);  sub_93 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_23: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_461, [0, 2, 3]);  mul_461 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_462: f32[1024] = torch.ops.aten.mul.Tensor(sum_22, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_335: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_462, 0);  mul_462 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_336: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_335, 2);  unsqueeze_335 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_337: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_336, 3);  unsqueeze_336 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_463: f32[1024] = torch.ops.aten.mul.Tensor(sum_23, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_464: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_127, squeeze_127)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_465: f32[1024] = torch.ops.aten.mul.Tensor(mul_463, mul_464);  mul_463 = mul_464 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_338: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_465, 0);  mul_465 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_339: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_338, 2);  unsqueeze_338 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_340: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_339, 3);  unsqueeze_339 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_466: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_127, primals_128);  primals_128 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_341: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_466, 0);  mul_466 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_342: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_341, 2);  unsqueeze_341 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_343: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_342, 3);  unsqueeze_342 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_94: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_42, unsqueeze_334);  convolution_42 = unsqueeze_334 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_467: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_94, unsqueeze_340);  sub_94 = unsqueeze_340 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_95: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_9, mul_467);  mul_467 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_96: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_95, unsqueeze_337);  sub_95 = unsqueeze_337 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_468: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_96, unsqueeze_343);  sub_96 = unsqueeze_343 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_469: f32[1024] = torch.ops.aten.mul.Tensor(sum_23, squeeze_127);  sum_23 = squeeze_127 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_10 = torch.ops.aten.convolution_backward.default(mul_468, relu_38, primals_127, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_468 = primals_127 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_138: f32[64, 256, 14, 14] = convolution_backward_10[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_139: f32[1024, 256, 1, 1] = convolution_backward_10[1];  convolution_backward_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_10: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_38, 0);  relu_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_10: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_10: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_10, scalar_tensor_10, getitem_138);  le_10 = scalar_tensor_10 = getitem_138 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_344: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_123, 0);  squeeze_123 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_345: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_344, 2);  unsqueeze_344 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_346: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_345, 3);  unsqueeze_345 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_24: f32[256] = torch.ops.aten.sum.dim_IntList(where_10, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_97: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_41, unsqueeze_346)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_470: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_10, sub_97);  sub_97 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_25: f32[256] = torch.ops.aten.sum.dim_IntList(mul_470, [0, 2, 3]);  mul_470 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_471: f32[256] = torch.ops.aten.mul.Tensor(sum_24, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_347: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_471, 0);  mul_471 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_348: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_347, 2);  unsqueeze_347 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_349: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_348, 3);  unsqueeze_348 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_472: f32[256] = torch.ops.aten.mul.Tensor(sum_25, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_473: f32[256] = torch.ops.aten.mul.Tensor(squeeze_124, squeeze_124)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_474: f32[256] = torch.ops.aten.mul.Tensor(mul_472, mul_473);  mul_472 = mul_473 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_350: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_474, 0);  mul_474 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_351: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_350, 2);  unsqueeze_350 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_352: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_351, 3);  unsqueeze_351 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_475: f32[256] = torch.ops.aten.mul.Tensor(squeeze_124, primals_125);  primals_125 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_353: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_475, 0);  mul_475 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_354: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_353, 2);  unsqueeze_353 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_355: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_354, 3);  unsqueeze_354 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_98: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_41, unsqueeze_346);  convolution_41 = unsqueeze_346 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_476: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_98, unsqueeze_352);  sub_98 = unsqueeze_352 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_99: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_10, mul_476);  where_10 = mul_476 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_100: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_99, unsqueeze_349);  sub_99 = unsqueeze_349 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_477: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_100, unsqueeze_355);  sub_100 = unsqueeze_355 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_478: f32[256] = torch.ops.aten.mul.Tensor(sum_25, squeeze_124);  sum_25 = squeeze_124 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_11 = torch.ops.aten.convolution_backward.default(mul_477, relu_37, primals_124, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_477 = primals_124 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_141: f32[64, 256, 14, 14] = convolution_backward_11[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_142: f32[256, 256, 3, 3] = convolution_backward_11[1];  convolution_backward_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_11: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_37, 0);  relu_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_11: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_11: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_11, scalar_tensor_11, getitem_141);  le_11 = scalar_tensor_11 = getitem_141 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_356: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_120, 0);  squeeze_120 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_357: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_356, 2);  unsqueeze_356 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_358: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_357, 3);  unsqueeze_357 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_26: f32[256] = torch.ops.aten.sum.dim_IntList(where_11, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_101: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_40, unsqueeze_358)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_479: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_11, sub_101);  sub_101 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_27: f32[256] = torch.ops.aten.sum.dim_IntList(mul_479, [0, 2, 3]);  mul_479 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_480: f32[256] = torch.ops.aten.mul.Tensor(sum_26, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_359: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_480, 0);  mul_480 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_360: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_359, 2);  unsqueeze_359 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_361: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_360, 3);  unsqueeze_360 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_481: f32[256] = torch.ops.aten.mul.Tensor(sum_27, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_482: f32[256] = torch.ops.aten.mul.Tensor(squeeze_121, squeeze_121)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_483: f32[256] = torch.ops.aten.mul.Tensor(mul_481, mul_482);  mul_481 = mul_482 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_362: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_483, 0);  mul_483 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_363: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_362, 2);  unsqueeze_362 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_364: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_363, 3);  unsqueeze_363 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_484: f32[256] = torch.ops.aten.mul.Tensor(squeeze_121, primals_122);  primals_122 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_365: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_484, 0);  mul_484 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_366: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_365, 2);  unsqueeze_365 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_367: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_366, 3);  unsqueeze_366 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_102: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_40, unsqueeze_358);  convolution_40 = unsqueeze_358 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_485: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_102, unsqueeze_364);  sub_102 = unsqueeze_364 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_103: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_11, mul_485);  where_11 = mul_485 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_104: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_103, unsqueeze_361);  sub_103 = unsqueeze_361 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_486: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_104, unsqueeze_367);  sub_104 = unsqueeze_367 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_487: f32[256] = torch.ops.aten.mul.Tensor(sum_27, squeeze_121);  sum_27 = squeeze_121 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_12 = torch.ops.aten.convolution_backward.default(mul_486, relu_36, primals_121, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_486 = primals_121 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_144: f32[64, 1024, 14, 14] = convolution_backward_12[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_145: f32[256, 1024, 1, 1] = convolution_backward_12[1];  convolution_backward_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_284: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_9, getitem_144);  where_9 = getitem_144 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_12: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_36, 0);  relu_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_12: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_12: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_12, scalar_tensor_12, add_284);  le_12 = scalar_tensor_12 = add_284 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_368: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_117, 0);  squeeze_117 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_369: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_368, 2);  unsqueeze_368 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_370: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_369, 3);  unsqueeze_369 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_28: f32[1024] = torch.ops.aten.sum.dim_IntList(where_12, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_105: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_39, unsqueeze_370)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_488: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_12, sub_105);  sub_105 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_29: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_488, [0, 2, 3]);  mul_488 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_489: f32[1024] = torch.ops.aten.mul.Tensor(sum_28, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_371: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_489, 0);  mul_489 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_372: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_371, 2);  unsqueeze_371 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_373: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_372, 3);  unsqueeze_372 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_490: f32[1024] = torch.ops.aten.mul.Tensor(sum_29, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_491: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_118, squeeze_118)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_492: f32[1024] = torch.ops.aten.mul.Tensor(mul_490, mul_491);  mul_490 = mul_491 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_374: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_492, 0);  mul_492 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_375: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_374, 2);  unsqueeze_374 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_376: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_375, 3);  unsqueeze_375 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_493: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_118, primals_119);  primals_119 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_377: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_493, 0);  mul_493 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_378: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_377, 2);  unsqueeze_377 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_379: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_378, 3);  unsqueeze_378 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_106: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_39, unsqueeze_370);  convolution_39 = unsqueeze_370 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_494: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_106, unsqueeze_376);  sub_106 = unsqueeze_376 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_107: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_12, mul_494);  mul_494 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_108: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_107, unsqueeze_373);  sub_107 = unsqueeze_373 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_495: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_108, unsqueeze_379);  sub_108 = unsqueeze_379 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_496: f32[1024] = torch.ops.aten.mul.Tensor(sum_29, squeeze_118);  sum_29 = squeeze_118 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_13 = torch.ops.aten.convolution_backward.default(mul_495, relu_35, primals_118, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_495 = primals_118 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_147: f32[64, 256, 14, 14] = convolution_backward_13[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_148: f32[1024, 256, 1, 1] = convolution_backward_13[1];  convolution_backward_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_13: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_35, 0);  relu_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_13: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_13: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_13, scalar_tensor_13, getitem_147);  le_13 = scalar_tensor_13 = getitem_147 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_380: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_114, 0);  squeeze_114 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_381: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_380, 2);  unsqueeze_380 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_382: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_381, 3);  unsqueeze_381 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_30: f32[256] = torch.ops.aten.sum.dim_IntList(where_13, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_109: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_38, unsqueeze_382)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_497: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_13, sub_109);  sub_109 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_31: f32[256] = torch.ops.aten.sum.dim_IntList(mul_497, [0, 2, 3]);  mul_497 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_498: f32[256] = torch.ops.aten.mul.Tensor(sum_30, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_383: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_498, 0);  mul_498 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_384: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_383, 2);  unsqueeze_383 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_385: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_384, 3);  unsqueeze_384 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_499: f32[256] = torch.ops.aten.mul.Tensor(sum_31, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_500: f32[256] = torch.ops.aten.mul.Tensor(squeeze_115, squeeze_115)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_501: f32[256] = torch.ops.aten.mul.Tensor(mul_499, mul_500);  mul_499 = mul_500 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_386: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_501, 0);  mul_501 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_387: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_386, 2);  unsqueeze_386 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_388: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_387, 3);  unsqueeze_387 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_502: f32[256] = torch.ops.aten.mul.Tensor(squeeze_115, primals_116);  primals_116 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_389: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_502, 0);  mul_502 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_390: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_389, 2);  unsqueeze_389 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_391: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_390, 3);  unsqueeze_390 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_110: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_38, unsqueeze_382);  convolution_38 = unsqueeze_382 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_503: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_110, unsqueeze_388);  sub_110 = unsqueeze_388 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_111: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_13, mul_503);  where_13 = mul_503 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_112: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_111, unsqueeze_385);  sub_111 = unsqueeze_385 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_504: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_112, unsqueeze_391);  sub_112 = unsqueeze_391 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_505: f32[256] = torch.ops.aten.mul.Tensor(sum_31, squeeze_115);  sum_31 = squeeze_115 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_14 = torch.ops.aten.convolution_backward.default(mul_504, relu_34, primals_115, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_504 = primals_115 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_150: f32[64, 256, 14, 14] = convolution_backward_14[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_151: f32[256, 256, 3, 3] = convolution_backward_14[1];  convolution_backward_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_14: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_34, 0);  relu_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_14: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_14: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_14, scalar_tensor_14, getitem_150);  le_14 = scalar_tensor_14 = getitem_150 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_392: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_111, 0);  squeeze_111 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_393: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_392, 2);  unsqueeze_392 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_394: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_393, 3);  unsqueeze_393 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_32: f32[256] = torch.ops.aten.sum.dim_IntList(where_14, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_113: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_37, unsqueeze_394)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_506: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_14, sub_113);  sub_113 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_33: f32[256] = torch.ops.aten.sum.dim_IntList(mul_506, [0, 2, 3]);  mul_506 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_507: f32[256] = torch.ops.aten.mul.Tensor(sum_32, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_395: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_507, 0);  mul_507 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_396: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_395, 2);  unsqueeze_395 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_397: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_396, 3);  unsqueeze_396 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_508: f32[256] = torch.ops.aten.mul.Tensor(sum_33, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_509: f32[256] = torch.ops.aten.mul.Tensor(squeeze_112, squeeze_112)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_510: f32[256] = torch.ops.aten.mul.Tensor(mul_508, mul_509);  mul_508 = mul_509 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_398: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_510, 0);  mul_510 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_399: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_398, 2);  unsqueeze_398 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_400: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_399, 3);  unsqueeze_399 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_511: f32[256] = torch.ops.aten.mul.Tensor(squeeze_112, primals_113);  primals_113 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_401: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_511, 0);  mul_511 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_402: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_401, 2);  unsqueeze_401 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_403: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_402, 3);  unsqueeze_402 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_114: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_37, unsqueeze_394);  convolution_37 = unsqueeze_394 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_512: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_114, unsqueeze_400);  sub_114 = unsqueeze_400 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_115: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_14, mul_512);  where_14 = mul_512 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_116: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_115, unsqueeze_397);  sub_115 = unsqueeze_397 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_513: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_116, unsqueeze_403);  sub_116 = unsqueeze_403 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_514: f32[256] = torch.ops.aten.mul.Tensor(sum_33, squeeze_112);  sum_33 = squeeze_112 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_15 = torch.ops.aten.convolution_backward.default(mul_513, relu_33, primals_112, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_513 = primals_112 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_153: f32[64, 1024, 14, 14] = convolution_backward_15[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_154: f32[256, 1024, 1, 1] = convolution_backward_15[1];  convolution_backward_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_285: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_12, getitem_153);  where_12 = getitem_153 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_15: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_33, 0);  relu_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_15: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_15: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_15, scalar_tensor_15, add_285);  le_15 = scalar_tensor_15 = add_285 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_404: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_108, 0);  squeeze_108 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_405: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_404, 2);  unsqueeze_404 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_406: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_405, 3);  unsqueeze_405 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_34: f32[1024] = torch.ops.aten.sum.dim_IntList(where_15, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_117: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_36, unsqueeze_406)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_515: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_15, sub_117);  sub_117 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_35: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_515, [0, 2, 3]);  mul_515 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_516: f32[1024] = torch.ops.aten.mul.Tensor(sum_34, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_407: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_516, 0);  mul_516 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_408: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_407, 2);  unsqueeze_407 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_409: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_408, 3);  unsqueeze_408 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_517: f32[1024] = torch.ops.aten.mul.Tensor(sum_35, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_518: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_109, squeeze_109)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_519: f32[1024] = torch.ops.aten.mul.Tensor(mul_517, mul_518);  mul_517 = mul_518 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_410: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_519, 0);  mul_519 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_411: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_410, 2);  unsqueeze_410 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_412: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_411, 3);  unsqueeze_411 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_520: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_109, primals_110);  primals_110 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_413: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_520, 0);  mul_520 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_414: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_413, 2);  unsqueeze_413 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_415: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_414, 3);  unsqueeze_414 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_118: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_36, unsqueeze_406);  convolution_36 = unsqueeze_406 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_521: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_118, unsqueeze_412);  sub_118 = unsqueeze_412 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_119: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_15, mul_521);  mul_521 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_120: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_119, unsqueeze_409);  sub_119 = unsqueeze_409 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_522: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_120, unsqueeze_415);  sub_120 = unsqueeze_415 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_523: f32[1024] = torch.ops.aten.mul.Tensor(sum_35, squeeze_109);  sum_35 = squeeze_109 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_16 = torch.ops.aten.convolution_backward.default(mul_522, relu_32, primals_109, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_522 = primals_109 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_156: f32[64, 256, 14, 14] = convolution_backward_16[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_157: f32[1024, 256, 1, 1] = convolution_backward_16[1];  convolution_backward_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_16: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_32, 0);  relu_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_16: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_16: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_16, scalar_tensor_16, getitem_156);  le_16 = scalar_tensor_16 = getitem_156 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_416: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_105, 0);  squeeze_105 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_417: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_416, 2);  unsqueeze_416 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_418: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_417, 3);  unsqueeze_417 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_36: f32[256] = torch.ops.aten.sum.dim_IntList(where_16, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_121: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_35, unsqueeze_418)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_524: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_16, sub_121);  sub_121 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_37: f32[256] = torch.ops.aten.sum.dim_IntList(mul_524, [0, 2, 3]);  mul_524 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_525: f32[256] = torch.ops.aten.mul.Tensor(sum_36, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_419: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_525, 0);  mul_525 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_420: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_419, 2);  unsqueeze_419 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_421: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_420, 3);  unsqueeze_420 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_526: f32[256] = torch.ops.aten.mul.Tensor(sum_37, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_527: f32[256] = torch.ops.aten.mul.Tensor(squeeze_106, squeeze_106)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_528: f32[256] = torch.ops.aten.mul.Tensor(mul_526, mul_527);  mul_526 = mul_527 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_422: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_528, 0);  mul_528 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_423: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_422, 2);  unsqueeze_422 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_424: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_423, 3);  unsqueeze_423 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_529: f32[256] = torch.ops.aten.mul.Tensor(squeeze_106, primals_107);  primals_107 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_425: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_529, 0);  mul_529 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_426: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_425, 2);  unsqueeze_425 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_427: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_426, 3);  unsqueeze_426 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_122: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_35, unsqueeze_418);  convolution_35 = unsqueeze_418 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_530: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_122, unsqueeze_424);  sub_122 = unsqueeze_424 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_123: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_16, mul_530);  where_16 = mul_530 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_124: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_123, unsqueeze_421);  sub_123 = unsqueeze_421 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_531: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_124, unsqueeze_427);  sub_124 = unsqueeze_427 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_532: f32[256] = torch.ops.aten.mul.Tensor(sum_37, squeeze_106);  sum_37 = squeeze_106 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_17 = torch.ops.aten.convolution_backward.default(mul_531, relu_31, primals_106, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_531 = primals_106 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_159: f32[64, 256, 14, 14] = convolution_backward_17[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_160: f32[256, 256, 3, 3] = convolution_backward_17[1];  convolution_backward_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_17: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_31, 0);  relu_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_17: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_17: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_17, scalar_tensor_17, getitem_159);  le_17 = scalar_tensor_17 = getitem_159 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_428: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_102, 0);  squeeze_102 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_429: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_428, 2);  unsqueeze_428 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_430: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_429, 3);  unsqueeze_429 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_38: f32[256] = torch.ops.aten.sum.dim_IntList(where_17, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_125: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_34, unsqueeze_430)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_533: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_17, sub_125);  sub_125 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_39: f32[256] = torch.ops.aten.sum.dim_IntList(mul_533, [0, 2, 3]);  mul_533 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_534: f32[256] = torch.ops.aten.mul.Tensor(sum_38, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_431: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_534, 0);  mul_534 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_432: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_431, 2);  unsqueeze_431 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_433: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_432, 3);  unsqueeze_432 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_535: f32[256] = torch.ops.aten.mul.Tensor(sum_39, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_536: f32[256] = torch.ops.aten.mul.Tensor(squeeze_103, squeeze_103)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_537: f32[256] = torch.ops.aten.mul.Tensor(mul_535, mul_536);  mul_535 = mul_536 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_434: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_537, 0);  mul_537 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_435: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_434, 2);  unsqueeze_434 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_436: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_435, 3);  unsqueeze_435 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_538: f32[256] = torch.ops.aten.mul.Tensor(squeeze_103, primals_104);  primals_104 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_437: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_538, 0);  mul_538 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_438: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_437, 2);  unsqueeze_437 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_439: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_438, 3);  unsqueeze_438 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_126: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_34, unsqueeze_430);  convolution_34 = unsqueeze_430 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_539: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_126, unsqueeze_436);  sub_126 = unsqueeze_436 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_127: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_17, mul_539);  where_17 = mul_539 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_128: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_127, unsqueeze_433);  sub_127 = unsqueeze_433 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_540: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_128, unsqueeze_439);  sub_128 = unsqueeze_439 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_541: f32[256] = torch.ops.aten.mul.Tensor(sum_39, squeeze_103);  sum_39 = squeeze_103 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_18 = torch.ops.aten.convolution_backward.default(mul_540, relu_30, primals_103, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_540 = primals_103 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_162: f32[64, 1024, 14, 14] = convolution_backward_18[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_163: f32[256, 1024, 1, 1] = convolution_backward_18[1];  convolution_backward_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_286: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_15, getitem_162);  where_15 = getitem_162 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_18: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_30, 0);  relu_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_18: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_18: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_18, scalar_tensor_18, add_286);  le_18 = scalar_tensor_18 = add_286 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_440: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_99, 0);  squeeze_99 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_441: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_440, 2);  unsqueeze_440 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_442: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_441, 3);  unsqueeze_441 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_40: f32[1024] = torch.ops.aten.sum.dim_IntList(where_18, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_129: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_33, unsqueeze_442)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_542: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_18, sub_129);  sub_129 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_41: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_542, [0, 2, 3]);  mul_542 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_543: f32[1024] = torch.ops.aten.mul.Tensor(sum_40, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_443: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_543, 0);  mul_543 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_444: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_443, 2);  unsqueeze_443 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_445: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_444, 3);  unsqueeze_444 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_544: f32[1024] = torch.ops.aten.mul.Tensor(sum_41, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_545: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_100, squeeze_100)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_546: f32[1024] = torch.ops.aten.mul.Tensor(mul_544, mul_545);  mul_544 = mul_545 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_446: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_546, 0);  mul_546 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_447: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_446, 2);  unsqueeze_446 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_448: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_447, 3);  unsqueeze_447 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_547: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_100, primals_101);  primals_101 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_449: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_547, 0);  mul_547 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_450: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_449, 2);  unsqueeze_449 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_451: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_450, 3);  unsqueeze_450 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_130: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_33, unsqueeze_442);  convolution_33 = unsqueeze_442 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_548: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_130, unsqueeze_448);  sub_130 = unsqueeze_448 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_131: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_18, mul_548);  mul_548 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_132: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_131, unsqueeze_445);  sub_131 = unsqueeze_445 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_549: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_132, unsqueeze_451);  sub_132 = unsqueeze_451 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_550: f32[1024] = torch.ops.aten.mul.Tensor(sum_41, squeeze_100);  sum_41 = squeeze_100 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_19 = torch.ops.aten.convolution_backward.default(mul_549, relu_29, primals_100, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_549 = primals_100 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_165: f32[64, 256, 14, 14] = convolution_backward_19[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_166: f32[1024, 256, 1, 1] = convolution_backward_19[1];  convolution_backward_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_19: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_29, 0);  relu_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_19: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_19: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_19, scalar_tensor_19, getitem_165);  le_19 = scalar_tensor_19 = getitem_165 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_452: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_96, 0);  squeeze_96 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_453: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_452, 2);  unsqueeze_452 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_454: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_453, 3);  unsqueeze_453 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_42: f32[256] = torch.ops.aten.sum.dim_IntList(where_19, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_133: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_32, unsqueeze_454)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_551: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_19, sub_133);  sub_133 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_43: f32[256] = torch.ops.aten.sum.dim_IntList(mul_551, [0, 2, 3]);  mul_551 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_552: f32[256] = torch.ops.aten.mul.Tensor(sum_42, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_455: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_552, 0);  mul_552 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_456: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_455, 2);  unsqueeze_455 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_457: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_456, 3);  unsqueeze_456 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_553: f32[256] = torch.ops.aten.mul.Tensor(sum_43, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_554: f32[256] = torch.ops.aten.mul.Tensor(squeeze_97, squeeze_97)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_555: f32[256] = torch.ops.aten.mul.Tensor(mul_553, mul_554);  mul_553 = mul_554 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_458: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_555, 0);  mul_555 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_459: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_458, 2);  unsqueeze_458 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_460: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_459, 3);  unsqueeze_459 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_556: f32[256] = torch.ops.aten.mul.Tensor(squeeze_97, primals_98);  primals_98 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_461: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_556, 0);  mul_556 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_462: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_461, 2);  unsqueeze_461 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_463: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_462, 3);  unsqueeze_462 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_134: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_32, unsqueeze_454);  convolution_32 = unsqueeze_454 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_557: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_134, unsqueeze_460);  sub_134 = unsqueeze_460 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_135: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_19, mul_557);  where_19 = mul_557 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_136: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_135, unsqueeze_457);  sub_135 = unsqueeze_457 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_558: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_136, unsqueeze_463);  sub_136 = unsqueeze_463 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_559: f32[256] = torch.ops.aten.mul.Tensor(sum_43, squeeze_97);  sum_43 = squeeze_97 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_20 = torch.ops.aten.convolution_backward.default(mul_558, relu_28, primals_97, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_558 = primals_97 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_168: f32[64, 256, 14, 14] = convolution_backward_20[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_169: f32[256, 256, 3, 3] = convolution_backward_20[1];  convolution_backward_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_20: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_28, 0);  relu_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_20: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_20: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_20, scalar_tensor_20, getitem_168);  le_20 = scalar_tensor_20 = getitem_168 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_464: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_93, 0);  squeeze_93 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_465: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_464, 2);  unsqueeze_464 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_466: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_465, 3);  unsqueeze_465 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_44: f32[256] = torch.ops.aten.sum.dim_IntList(where_20, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_137: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_31, unsqueeze_466)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_560: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_20, sub_137);  sub_137 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_45: f32[256] = torch.ops.aten.sum.dim_IntList(mul_560, [0, 2, 3]);  mul_560 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_561: f32[256] = torch.ops.aten.mul.Tensor(sum_44, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_467: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_561, 0);  mul_561 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_468: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_467, 2);  unsqueeze_467 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_469: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_468, 3);  unsqueeze_468 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_562: f32[256] = torch.ops.aten.mul.Tensor(sum_45, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_563: f32[256] = torch.ops.aten.mul.Tensor(squeeze_94, squeeze_94)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_564: f32[256] = torch.ops.aten.mul.Tensor(mul_562, mul_563);  mul_562 = mul_563 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_470: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_564, 0);  mul_564 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_471: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_470, 2);  unsqueeze_470 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_472: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_471, 3);  unsqueeze_471 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_565: f32[256] = torch.ops.aten.mul.Tensor(squeeze_94, primals_95);  primals_95 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_473: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_565, 0);  mul_565 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_474: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_473, 2);  unsqueeze_473 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_475: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_474, 3);  unsqueeze_474 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_138: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_31, unsqueeze_466);  convolution_31 = unsqueeze_466 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_566: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_138, unsqueeze_472);  sub_138 = unsqueeze_472 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_139: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_20, mul_566);  where_20 = mul_566 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_140: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_139, unsqueeze_469);  sub_139 = unsqueeze_469 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_567: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_140, unsqueeze_475);  sub_140 = unsqueeze_475 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_568: f32[256] = torch.ops.aten.mul.Tensor(sum_45, squeeze_94);  sum_45 = squeeze_94 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_21 = torch.ops.aten.convolution_backward.default(mul_567, relu_27, primals_94, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_567 = primals_94 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_171: f32[64, 1024, 14, 14] = convolution_backward_21[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_172: f32[256, 1024, 1, 1] = convolution_backward_21[1];  convolution_backward_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_287: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_18, getitem_171);  where_18 = getitem_171 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_21: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_27, 0);  relu_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_21: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_21: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_21, scalar_tensor_21, add_287);  le_21 = scalar_tensor_21 = add_287 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_476: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_90, 0);  squeeze_90 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_477: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_476, 2);  unsqueeze_476 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_478: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_477, 3);  unsqueeze_477 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_46: f32[1024] = torch.ops.aten.sum.dim_IntList(where_21, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_141: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_30, unsqueeze_478)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_569: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_21, sub_141);  sub_141 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_47: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_569, [0, 2, 3]);  mul_569 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_570: f32[1024] = torch.ops.aten.mul.Tensor(sum_46, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_479: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_570, 0);  mul_570 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_480: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_479, 2);  unsqueeze_479 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_481: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_480, 3);  unsqueeze_480 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_571: f32[1024] = torch.ops.aten.mul.Tensor(sum_47, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_572: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_91, squeeze_91)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_573: f32[1024] = torch.ops.aten.mul.Tensor(mul_571, mul_572);  mul_571 = mul_572 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_482: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_573, 0);  mul_573 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_483: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_482, 2);  unsqueeze_482 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_484: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_483, 3);  unsqueeze_483 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_574: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_91, primals_92);  primals_92 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_485: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_574, 0);  mul_574 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_486: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_485, 2);  unsqueeze_485 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_487: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_486, 3);  unsqueeze_486 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_142: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_30, unsqueeze_478);  convolution_30 = unsqueeze_478 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_575: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_142, unsqueeze_484);  sub_142 = unsqueeze_484 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_143: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_21, mul_575);  mul_575 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_144: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_143, unsqueeze_481);  sub_143 = unsqueeze_481 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_576: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_144, unsqueeze_487);  sub_144 = unsqueeze_487 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_577: f32[1024] = torch.ops.aten.mul.Tensor(sum_47, squeeze_91);  sum_47 = squeeze_91 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_22 = torch.ops.aten.convolution_backward.default(mul_576, relu_26, primals_91, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_576 = primals_91 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_174: f32[64, 256, 14, 14] = convolution_backward_22[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_175: f32[1024, 256, 1, 1] = convolution_backward_22[1];  convolution_backward_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_22: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_26, 0);  relu_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_22: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_22: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_22, scalar_tensor_22, getitem_174);  le_22 = scalar_tensor_22 = getitem_174 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_488: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_87, 0);  squeeze_87 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_489: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_488, 2);  unsqueeze_488 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_490: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_489, 3);  unsqueeze_489 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_48: f32[256] = torch.ops.aten.sum.dim_IntList(where_22, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_145: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_29, unsqueeze_490)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_578: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_22, sub_145);  sub_145 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_49: f32[256] = torch.ops.aten.sum.dim_IntList(mul_578, [0, 2, 3]);  mul_578 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_579: f32[256] = torch.ops.aten.mul.Tensor(sum_48, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_491: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_579, 0);  mul_579 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_492: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_491, 2);  unsqueeze_491 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_493: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_492, 3);  unsqueeze_492 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_580: f32[256] = torch.ops.aten.mul.Tensor(sum_49, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_581: f32[256] = torch.ops.aten.mul.Tensor(squeeze_88, squeeze_88)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_582: f32[256] = torch.ops.aten.mul.Tensor(mul_580, mul_581);  mul_580 = mul_581 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_494: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_582, 0);  mul_582 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_495: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_494, 2);  unsqueeze_494 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_496: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_495, 3);  unsqueeze_495 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_583: f32[256] = torch.ops.aten.mul.Tensor(squeeze_88, primals_89);  primals_89 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_497: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_583, 0);  mul_583 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_498: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_497, 2);  unsqueeze_497 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_499: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_498, 3);  unsqueeze_498 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_146: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_29, unsqueeze_490);  convolution_29 = unsqueeze_490 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_584: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_146, unsqueeze_496);  sub_146 = unsqueeze_496 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_147: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_22, mul_584);  where_22 = mul_584 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_148: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_147, unsqueeze_493);  sub_147 = unsqueeze_493 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_585: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_148, unsqueeze_499);  sub_148 = unsqueeze_499 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_586: f32[256] = torch.ops.aten.mul.Tensor(sum_49, squeeze_88);  sum_49 = squeeze_88 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_23 = torch.ops.aten.convolution_backward.default(mul_585, relu_25, primals_88, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_585 = primals_88 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_177: f32[64, 256, 14, 14] = convolution_backward_23[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_178: f32[256, 256, 3, 3] = convolution_backward_23[1];  convolution_backward_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_23: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_25, 0);  relu_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_23: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_23: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_23, scalar_tensor_23, getitem_177);  le_23 = scalar_tensor_23 = getitem_177 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_500: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_84, 0);  squeeze_84 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_501: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_500, 2);  unsqueeze_500 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_502: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_501, 3);  unsqueeze_501 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_50: f32[256] = torch.ops.aten.sum.dim_IntList(where_23, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_149: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_28, unsqueeze_502)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_587: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_23, sub_149);  sub_149 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_51: f32[256] = torch.ops.aten.sum.dim_IntList(mul_587, [0, 2, 3]);  mul_587 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_588: f32[256] = torch.ops.aten.mul.Tensor(sum_50, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_503: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_588, 0);  mul_588 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_504: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_503, 2);  unsqueeze_503 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_505: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_504, 3);  unsqueeze_504 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_589: f32[256] = torch.ops.aten.mul.Tensor(sum_51, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_590: f32[256] = torch.ops.aten.mul.Tensor(squeeze_85, squeeze_85)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_591: f32[256] = torch.ops.aten.mul.Tensor(mul_589, mul_590);  mul_589 = mul_590 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_506: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_591, 0);  mul_591 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_507: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_506, 2);  unsqueeze_506 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_508: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_507, 3);  unsqueeze_507 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_592: f32[256] = torch.ops.aten.mul.Tensor(squeeze_85, primals_86);  primals_86 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_509: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_592, 0);  mul_592 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_510: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_509, 2);  unsqueeze_509 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_511: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_510, 3);  unsqueeze_510 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_150: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_28, unsqueeze_502);  convolution_28 = unsqueeze_502 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_593: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_150, unsqueeze_508);  sub_150 = unsqueeze_508 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_151: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_23, mul_593);  where_23 = mul_593 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_152: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_151, unsqueeze_505);  sub_151 = unsqueeze_505 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_594: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_152, unsqueeze_511);  sub_152 = unsqueeze_511 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_595: f32[256] = torch.ops.aten.mul.Tensor(sum_51, squeeze_85);  sum_51 = squeeze_85 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_24 = torch.ops.aten.convolution_backward.default(mul_594, relu_24, primals_85, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_594 = primals_85 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_180: f32[64, 1024, 14, 14] = convolution_backward_24[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_181: f32[256, 1024, 1, 1] = convolution_backward_24[1];  convolution_backward_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_288: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_21, getitem_180);  where_21 = getitem_180 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_24: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_24, 0);  relu_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_24: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_24: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_24, scalar_tensor_24, add_288);  le_24 = scalar_tensor_24 = add_288 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_512: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_81, 0);  squeeze_81 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_513: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_512, 2);  unsqueeze_512 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_514: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_513, 3);  unsqueeze_513 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_52: f32[1024] = torch.ops.aten.sum.dim_IntList(where_24, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_153: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_27, unsqueeze_514)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_596: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_24, sub_153);  sub_153 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_53: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_596, [0, 2, 3]);  mul_596 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_597: f32[1024] = torch.ops.aten.mul.Tensor(sum_52, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_515: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_597, 0);  mul_597 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_516: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_515, 2);  unsqueeze_515 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_517: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_516, 3);  unsqueeze_516 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_598: f32[1024] = torch.ops.aten.mul.Tensor(sum_53, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_599: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_82, squeeze_82)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_600: f32[1024] = torch.ops.aten.mul.Tensor(mul_598, mul_599);  mul_598 = mul_599 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_518: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_600, 0);  mul_600 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_519: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_518, 2);  unsqueeze_518 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_520: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_519, 3);  unsqueeze_519 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_601: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_82, primals_83);  primals_83 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_521: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_601, 0);  mul_601 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_522: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_521, 2);  unsqueeze_521 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_523: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_522, 3);  unsqueeze_522 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_154: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_27, unsqueeze_514);  convolution_27 = unsqueeze_514 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_602: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_154, unsqueeze_520);  sub_154 = unsqueeze_520 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_155: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_24, mul_602);  mul_602 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_156: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_155, unsqueeze_517);  sub_155 = unsqueeze_517 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_603: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_156, unsqueeze_523);  sub_156 = unsqueeze_523 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_604: f32[1024] = torch.ops.aten.mul.Tensor(sum_53, squeeze_82);  sum_53 = squeeze_82 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_25 = torch.ops.aten.convolution_backward.default(mul_603, relu_21, primals_82, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_603 = primals_82 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_183: f32[64, 512, 28, 28] = convolution_backward_25[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_184: f32[1024, 512, 1, 1] = convolution_backward_25[1];  convolution_backward_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_524: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_78, 0);  squeeze_78 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_525: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_524, 2);  unsqueeze_524 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_526: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_525, 3);  unsqueeze_525 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_54: f32[1024] = torch.ops.aten.sum.dim_IntList(where_24, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_157: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_26, unsqueeze_526)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_605: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_24, sub_157);  sub_157 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_55: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_605, [0, 2, 3]);  mul_605 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_606: f32[1024] = torch.ops.aten.mul.Tensor(sum_54, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_527: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_606, 0);  mul_606 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_528: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_527, 2);  unsqueeze_527 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_529: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_528, 3);  unsqueeze_528 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_607: f32[1024] = torch.ops.aten.mul.Tensor(sum_55, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_608: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_79, squeeze_79)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_609: f32[1024] = torch.ops.aten.mul.Tensor(mul_607, mul_608);  mul_607 = mul_608 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_530: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_609, 0);  mul_609 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_531: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_530, 2);  unsqueeze_530 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_532: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_531, 3);  unsqueeze_531 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_610: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_79, primals_80);  primals_80 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_533: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_610, 0);  mul_610 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_534: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_533, 2);  unsqueeze_533 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_535: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_534, 3);  unsqueeze_534 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_158: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_26, unsqueeze_526);  convolution_26 = unsqueeze_526 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_611: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_158, unsqueeze_532);  sub_158 = unsqueeze_532 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_159: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_24, mul_611);  where_24 = mul_611 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_160: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_159, unsqueeze_529);  sub_159 = unsqueeze_529 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_612: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_160, unsqueeze_535);  sub_160 = unsqueeze_535 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_613: f32[1024] = torch.ops.aten.mul.Tensor(sum_55, squeeze_79);  sum_55 = squeeze_79 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_26 = torch.ops.aten.convolution_backward.default(mul_612, relu_23, primals_79, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_612 = primals_79 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_186: f32[64, 256, 14, 14] = convolution_backward_26[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_187: f32[1024, 256, 1, 1] = convolution_backward_26[1];  convolution_backward_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_25: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_23, 0);  relu_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_25: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_25: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_25, scalar_tensor_25, getitem_186);  le_25 = scalar_tensor_25 = getitem_186 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_536: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_75, 0);  squeeze_75 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_537: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_536, 2);  unsqueeze_536 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_538: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_537, 3);  unsqueeze_537 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_56: f32[256] = torch.ops.aten.sum.dim_IntList(where_25, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_161: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_25, unsqueeze_538)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_614: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_25, sub_161);  sub_161 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_57: f32[256] = torch.ops.aten.sum.dim_IntList(mul_614, [0, 2, 3]);  mul_614 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_615: f32[256] = torch.ops.aten.mul.Tensor(sum_56, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_539: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_615, 0);  mul_615 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_540: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_539, 2);  unsqueeze_539 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_541: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_540, 3);  unsqueeze_540 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_616: f32[256] = torch.ops.aten.mul.Tensor(sum_57, 7.971938775510203e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_617: f32[256] = torch.ops.aten.mul.Tensor(squeeze_76, squeeze_76)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_618: f32[256] = torch.ops.aten.mul.Tensor(mul_616, mul_617);  mul_616 = mul_617 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_542: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_618, 0);  mul_618 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_543: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_542, 2);  unsqueeze_542 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_544: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_543, 3);  unsqueeze_543 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_619: f32[256] = torch.ops.aten.mul.Tensor(squeeze_76, primals_77);  primals_77 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_545: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_619, 0);  mul_619 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_546: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_545, 2);  unsqueeze_545 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_547: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_546, 3);  unsqueeze_546 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_162: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_25, unsqueeze_538);  convolution_25 = unsqueeze_538 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_620: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_162, unsqueeze_544);  sub_162 = unsqueeze_544 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_163: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_25, mul_620);  where_25 = mul_620 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_164: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_163, unsqueeze_541);  sub_163 = unsqueeze_541 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_621: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_164, unsqueeze_547);  sub_164 = unsqueeze_547 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_622: f32[256] = torch.ops.aten.mul.Tensor(sum_57, squeeze_76);  sum_57 = squeeze_76 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_27 = torch.ops.aten.convolution_backward.default(mul_621, relu_22, primals_76, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_621 = primals_76 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_189: f32[64, 256, 28, 28] = convolution_backward_27[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_190: f32[256, 256, 3, 3] = convolution_backward_27[1];  convolution_backward_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_26: b8[64, 256, 28, 28] = torch.ops.aten.le.Scalar(relu_22, 0);  relu_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_26: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_26: f32[64, 256, 28, 28] = torch.ops.aten.where.self(le_26, scalar_tensor_26, getitem_189);  le_26 = scalar_tensor_26 = getitem_189 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_548: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_72, 0);  squeeze_72 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_549: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_548, 2);  unsqueeze_548 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_550: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_549, 3);  unsqueeze_549 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_58: f32[256] = torch.ops.aten.sum.dim_IntList(where_26, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_165: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(convolution_24, unsqueeze_550)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_623: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(where_26, sub_165);  sub_165 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_59: f32[256] = torch.ops.aten.sum.dim_IntList(mul_623, [0, 2, 3]);  mul_623 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_624: f32[256] = torch.ops.aten.mul.Tensor(sum_58, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_551: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_624, 0);  mul_624 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_552: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_551, 2);  unsqueeze_551 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_553: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_552, 3);  unsqueeze_552 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_625: f32[256] = torch.ops.aten.mul.Tensor(sum_59, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_626: f32[256] = torch.ops.aten.mul.Tensor(squeeze_73, squeeze_73)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_627: f32[256] = torch.ops.aten.mul.Tensor(mul_625, mul_626);  mul_625 = mul_626 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_554: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_627, 0);  mul_627 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_555: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_554, 2);  unsqueeze_554 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_556: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_555, 3);  unsqueeze_555 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_628: f32[256] = torch.ops.aten.mul.Tensor(squeeze_73, primals_74);  primals_74 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_557: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_628, 0);  mul_628 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_558: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_557, 2);  unsqueeze_557 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_559: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_558, 3);  unsqueeze_558 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_166: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(convolution_24, unsqueeze_550);  convolution_24 = unsqueeze_550 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_629: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(sub_166, unsqueeze_556);  sub_166 = unsqueeze_556 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_167: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(where_26, mul_629);  where_26 = mul_629 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_168: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(sub_167, unsqueeze_553);  sub_167 = unsqueeze_553 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_630: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(sub_168, unsqueeze_559);  sub_168 = unsqueeze_559 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_631: f32[256] = torch.ops.aten.mul.Tensor(sum_59, squeeze_73);  sum_59 = squeeze_73 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_28 = torch.ops.aten.convolution_backward.default(mul_630, relu_21, primals_73, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_630 = primals_73 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_192: f32[64, 512, 28, 28] = convolution_backward_28[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_193: f32[256, 512, 1, 1] = convolution_backward_28[1];  convolution_backward_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_289: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(getitem_183, getitem_192);  getitem_183 = getitem_192 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_27: b8[64, 512, 28, 28] = torch.ops.aten.le.Scalar(relu_21, 0);  relu_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_27: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_27: f32[64, 512, 28, 28] = torch.ops.aten.where.self(le_27, scalar_tensor_27, add_289);  le_27 = scalar_tensor_27 = add_289 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_560: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_69, 0);  squeeze_69 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_561: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_560, 2);  unsqueeze_560 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_562: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_561, 3);  unsqueeze_561 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_60: f32[512] = torch.ops.aten.sum.dim_IntList(where_27, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_169: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_23, unsqueeze_562)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_632: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_27, sub_169);  sub_169 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_61: f32[512] = torch.ops.aten.sum.dim_IntList(mul_632, [0, 2, 3]);  mul_632 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_633: f32[512] = torch.ops.aten.mul.Tensor(sum_60, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_563: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_633, 0);  mul_633 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_564: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_563, 2);  unsqueeze_563 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_565: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_564, 3);  unsqueeze_564 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_634: f32[512] = torch.ops.aten.mul.Tensor(sum_61, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_635: f32[512] = torch.ops.aten.mul.Tensor(squeeze_70, squeeze_70)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_636: f32[512] = torch.ops.aten.mul.Tensor(mul_634, mul_635);  mul_634 = mul_635 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_566: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_636, 0);  mul_636 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_567: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_566, 2);  unsqueeze_566 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_568: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_567, 3);  unsqueeze_567 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_637: f32[512] = torch.ops.aten.mul.Tensor(squeeze_70, primals_71);  primals_71 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_569: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_637, 0);  mul_637 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_570: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_569, 2);  unsqueeze_569 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_571: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_570, 3);  unsqueeze_570 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_170: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_23, unsqueeze_562);  convolution_23 = unsqueeze_562 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_638: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_170, unsqueeze_568);  sub_170 = unsqueeze_568 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_171: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_27, mul_638);  mul_638 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_172: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_171, unsqueeze_565);  sub_171 = unsqueeze_565 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_639: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_172, unsqueeze_571);  sub_172 = unsqueeze_571 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_640: f32[512] = torch.ops.aten.mul.Tensor(sum_61, squeeze_70);  sum_61 = squeeze_70 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_29 = torch.ops.aten.convolution_backward.default(mul_639, relu_20, primals_70, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_639 = primals_70 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_195: f32[64, 128, 28, 28] = convolution_backward_29[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_196: f32[512, 128, 1, 1] = convolution_backward_29[1];  convolution_backward_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_28: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_20, 0);  relu_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_28: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_28: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_28, scalar_tensor_28, getitem_195);  le_28 = scalar_tensor_28 = getitem_195 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_572: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_66, 0);  squeeze_66 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_573: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_572, 2);  unsqueeze_572 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_574: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_573, 3);  unsqueeze_573 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_62: f32[128] = torch.ops.aten.sum.dim_IntList(where_28, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_173: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_22, unsqueeze_574)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_641: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_28, sub_173);  sub_173 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_63: f32[128] = torch.ops.aten.sum.dim_IntList(mul_641, [0, 2, 3]);  mul_641 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_642: f32[128] = torch.ops.aten.mul.Tensor(sum_62, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_575: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_642, 0);  mul_642 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_576: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_575, 2);  unsqueeze_575 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_577: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_576, 3);  unsqueeze_576 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_643: f32[128] = torch.ops.aten.mul.Tensor(sum_63, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_644: f32[128] = torch.ops.aten.mul.Tensor(squeeze_67, squeeze_67)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_645: f32[128] = torch.ops.aten.mul.Tensor(mul_643, mul_644);  mul_643 = mul_644 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_578: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_645, 0);  mul_645 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_579: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_578, 2);  unsqueeze_578 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_580: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_579, 3);  unsqueeze_579 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_646: f32[128] = torch.ops.aten.mul.Tensor(squeeze_67, primals_68);  primals_68 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_581: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_646, 0);  mul_646 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_582: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_581, 2);  unsqueeze_581 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_583: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_582, 3);  unsqueeze_582 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_174: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_22, unsqueeze_574);  convolution_22 = unsqueeze_574 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_647: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_174, unsqueeze_580);  sub_174 = unsqueeze_580 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_175: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_28, mul_647);  where_28 = mul_647 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_176: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_175, unsqueeze_577);  sub_175 = unsqueeze_577 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_648: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_176, unsqueeze_583);  sub_176 = unsqueeze_583 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_649: f32[128] = torch.ops.aten.mul.Tensor(sum_63, squeeze_67);  sum_63 = squeeze_67 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_30 = torch.ops.aten.convolution_backward.default(mul_648, relu_19, primals_67, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_648 = primals_67 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_198: f32[64, 128, 28, 28] = convolution_backward_30[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_199: f32[128, 128, 3, 3] = convolution_backward_30[1];  convolution_backward_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_29: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_19, 0);  relu_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_29: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_29: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_29, scalar_tensor_29, getitem_198);  le_29 = scalar_tensor_29 = getitem_198 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_584: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_63, 0);  squeeze_63 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_585: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_584, 2);  unsqueeze_584 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_586: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_585, 3);  unsqueeze_585 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_64: f32[128] = torch.ops.aten.sum.dim_IntList(where_29, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_177: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_21, unsqueeze_586)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_650: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_29, sub_177);  sub_177 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_65: f32[128] = torch.ops.aten.sum.dim_IntList(mul_650, [0, 2, 3]);  mul_650 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_651: f32[128] = torch.ops.aten.mul.Tensor(sum_64, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_587: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_651, 0);  mul_651 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_588: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_587, 2);  unsqueeze_587 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_589: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_588, 3);  unsqueeze_588 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_652: f32[128] = torch.ops.aten.mul.Tensor(sum_65, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_653: f32[128] = torch.ops.aten.mul.Tensor(squeeze_64, squeeze_64)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_654: f32[128] = torch.ops.aten.mul.Tensor(mul_652, mul_653);  mul_652 = mul_653 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_590: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_654, 0);  mul_654 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_591: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_590, 2);  unsqueeze_590 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_592: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_591, 3);  unsqueeze_591 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_655: f32[128] = torch.ops.aten.mul.Tensor(squeeze_64, primals_65);  primals_65 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_593: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_655, 0);  mul_655 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_594: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_593, 2);  unsqueeze_593 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_595: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_594, 3);  unsqueeze_594 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_178: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_21, unsqueeze_586);  convolution_21 = unsqueeze_586 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_656: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_178, unsqueeze_592);  sub_178 = unsqueeze_592 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_179: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_29, mul_656);  where_29 = mul_656 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_180: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_179, unsqueeze_589);  sub_179 = unsqueeze_589 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_657: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_180, unsqueeze_595);  sub_180 = unsqueeze_595 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_658: f32[128] = torch.ops.aten.mul.Tensor(sum_65, squeeze_64);  sum_65 = squeeze_64 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_31 = torch.ops.aten.convolution_backward.default(mul_657, relu_18, primals_64, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_657 = primals_64 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_201: f32[64, 512, 28, 28] = convolution_backward_31[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_202: f32[128, 512, 1, 1] = convolution_backward_31[1];  convolution_backward_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_290: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(where_27, getitem_201);  where_27 = getitem_201 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_30: b8[64, 512, 28, 28] = torch.ops.aten.le.Scalar(relu_18, 0);  relu_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_30: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_30: f32[64, 512, 28, 28] = torch.ops.aten.where.self(le_30, scalar_tensor_30, add_290);  le_30 = scalar_tensor_30 = add_290 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_596: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_60, 0);  squeeze_60 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_597: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_596, 2);  unsqueeze_596 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_598: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_597, 3);  unsqueeze_597 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_66: f32[512] = torch.ops.aten.sum.dim_IntList(where_30, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_181: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_20, unsqueeze_598)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_659: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_30, sub_181);  sub_181 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_67: f32[512] = torch.ops.aten.sum.dim_IntList(mul_659, [0, 2, 3]);  mul_659 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_660: f32[512] = torch.ops.aten.mul.Tensor(sum_66, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_599: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_660, 0);  mul_660 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_600: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_599, 2);  unsqueeze_599 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_601: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_600, 3);  unsqueeze_600 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_661: f32[512] = torch.ops.aten.mul.Tensor(sum_67, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_662: f32[512] = torch.ops.aten.mul.Tensor(squeeze_61, squeeze_61)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_663: f32[512] = torch.ops.aten.mul.Tensor(mul_661, mul_662);  mul_661 = mul_662 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_602: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_663, 0);  mul_663 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_603: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_602, 2);  unsqueeze_602 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_604: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_603, 3);  unsqueeze_603 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_664: f32[512] = torch.ops.aten.mul.Tensor(squeeze_61, primals_62);  primals_62 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_605: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_664, 0);  mul_664 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_606: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_605, 2);  unsqueeze_605 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_607: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_606, 3);  unsqueeze_606 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_182: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_20, unsqueeze_598);  convolution_20 = unsqueeze_598 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_665: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_182, unsqueeze_604);  sub_182 = unsqueeze_604 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_183: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_30, mul_665);  mul_665 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_184: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_183, unsqueeze_601);  sub_183 = unsqueeze_601 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_666: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_184, unsqueeze_607);  sub_184 = unsqueeze_607 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_667: f32[512] = torch.ops.aten.mul.Tensor(sum_67, squeeze_61);  sum_67 = squeeze_61 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_32 = torch.ops.aten.convolution_backward.default(mul_666, relu_17, primals_61, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_666 = primals_61 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_204: f32[64, 128, 28, 28] = convolution_backward_32[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_205: f32[512, 128, 1, 1] = convolution_backward_32[1];  convolution_backward_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_31: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_17, 0);  relu_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_31: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_31: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_31, scalar_tensor_31, getitem_204);  le_31 = scalar_tensor_31 = getitem_204 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_608: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_57, 0);  squeeze_57 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_609: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_608, 2);  unsqueeze_608 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_610: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_609, 3);  unsqueeze_609 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_68: f32[128] = torch.ops.aten.sum.dim_IntList(where_31, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_185: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_610)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_668: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_31, sub_185);  sub_185 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_69: f32[128] = torch.ops.aten.sum.dim_IntList(mul_668, [0, 2, 3]);  mul_668 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_669: f32[128] = torch.ops.aten.mul.Tensor(sum_68, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_611: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_669, 0);  mul_669 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_612: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_611, 2);  unsqueeze_611 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_613: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_612, 3);  unsqueeze_612 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_670: f32[128] = torch.ops.aten.mul.Tensor(sum_69, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_671: f32[128] = torch.ops.aten.mul.Tensor(squeeze_58, squeeze_58)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_672: f32[128] = torch.ops.aten.mul.Tensor(mul_670, mul_671);  mul_670 = mul_671 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_614: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_672, 0);  mul_672 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_615: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_614, 2);  unsqueeze_614 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_616: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_615, 3);  unsqueeze_615 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_673: f32[128] = torch.ops.aten.mul.Tensor(squeeze_58, primals_59);  primals_59 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_617: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_673, 0);  mul_673 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_618: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_617, 2);  unsqueeze_617 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_619: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_618, 3);  unsqueeze_618 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_186: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_610);  convolution_19 = unsqueeze_610 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_674: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_186, unsqueeze_616);  sub_186 = unsqueeze_616 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_187: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_31, mul_674);  where_31 = mul_674 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_188: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_187, unsqueeze_613);  sub_187 = unsqueeze_613 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_675: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_188, unsqueeze_619);  sub_188 = unsqueeze_619 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_676: f32[128] = torch.ops.aten.mul.Tensor(sum_69, squeeze_58);  sum_69 = squeeze_58 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_33 = torch.ops.aten.convolution_backward.default(mul_675, relu_16, primals_58, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_675 = primals_58 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_207: f32[64, 128, 28, 28] = convolution_backward_33[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_208: f32[128, 128, 3, 3] = convolution_backward_33[1];  convolution_backward_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_32: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_16, 0);  relu_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_32: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_32: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_32, scalar_tensor_32, getitem_207);  le_32 = scalar_tensor_32 = getitem_207 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_620: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_54, 0);  squeeze_54 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_621: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_620, 2);  unsqueeze_620 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_622: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_621, 3);  unsqueeze_621 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_70: f32[128] = torch.ops.aten.sum.dim_IntList(where_32, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_189: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_622)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_677: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_32, sub_189);  sub_189 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_71: f32[128] = torch.ops.aten.sum.dim_IntList(mul_677, [0, 2, 3]);  mul_677 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_678: f32[128] = torch.ops.aten.mul.Tensor(sum_70, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_623: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_678, 0);  mul_678 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_624: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_623, 2);  unsqueeze_623 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_625: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_624, 3);  unsqueeze_624 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_679: f32[128] = torch.ops.aten.mul.Tensor(sum_71, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_680: f32[128] = torch.ops.aten.mul.Tensor(squeeze_55, squeeze_55)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_681: f32[128] = torch.ops.aten.mul.Tensor(mul_679, mul_680);  mul_679 = mul_680 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_626: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_681, 0);  mul_681 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_627: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_626, 2);  unsqueeze_626 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_628: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_627, 3);  unsqueeze_627 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_682: f32[128] = torch.ops.aten.mul.Tensor(squeeze_55, primals_56);  primals_56 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_629: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_682, 0);  mul_682 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_630: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_629, 2);  unsqueeze_629 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_631: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_630, 3);  unsqueeze_630 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_190: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_622);  convolution_18 = unsqueeze_622 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_683: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_190, unsqueeze_628);  sub_190 = unsqueeze_628 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_191: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_32, mul_683);  where_32 = mul_683 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_192: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_191, unsqueeze_625);  sub_191 = unsqueeze_625 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_684: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_192, unsqueeze_631);  sub_192 = unsqueeze_631 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_685: f32[128] = torch.ops.aten.mul.Tensor(sum_71, squeeze_55);  sum_71 = squeeze_55 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_34 = torch.ops.aten.convolution_backward.default(mul_684, relu_15, primals_55, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_684 = primals_55 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_210: f32[64, 512, 28, 28] = convolution_backward_34[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_211: f32[128, 512, 1, 1] = convolution_backward_34[1];  convolution_backward_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_291: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(where_30, getitem_210);  where_30 = getitem_210 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_33: b8[64, 512, 28, 28] = torch.ops.aten.le.Scalar(relu_15, 0);  relu_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_33: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_33: f32[64, 512, 28, 28] = torch.ops.aten.where.self(le_33, scalar_tensor_33, add_291);  le_33 = scalar_tensor_33 = add_291 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_632: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_51, 0);  squeeze_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_633: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_632, 2);  unsqueeze_632 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_634: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_633, 3);  unsqueeze_633 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_72: f32[512] = torch.ops.aten.sum.dim_IntList(where_33, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_193: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_634)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_686: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_33, sub_193);  sub_193 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_73: f32[512] = torch.ops.aten.sum.dim_IntList(mul_686, [0, 2, 3]);  mul_686 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_687: f32[512] = torch.ops.aten.mul.Tensor(sum_72, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_635: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_687, 0);  mul_687 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_636: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_635, 2);  unsqueeze_635 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_637: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_636, 3);  unsqueeze_636 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_688: f32[512] = torch.ops.aten.mul.Tensor(sum_73, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_689: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, squeeze_52)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_690: f32[512] = torch.ops.aten.mul.Tensor(mul_688, mul_689);  mul_688 = mul_689 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_638: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_690, 0);  mul_690 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_639: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_638, 2);  unsqueeze_638 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_640: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_639, 3);  unsqueeze_639 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_691: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, primals_53);  primals_53 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_641: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_691, 0);  mul_691 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_642: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_641, 2);  unsqueeze_641 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_643: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_642, 3);  unsqueeze_642 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_194: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_634);  convolution_17 = unsqueeze_634 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_692: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_194, unsqueeze_640);  sub_194 = unsqueeze_640 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_195: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_33, mul_692);  mul_692 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_196: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_195, unsqueeze_637);  sub_195 = unsqueeze_637 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_693: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_196, unsqueeze_643);  sub_196 = unsqueeze_643 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_694: f32[512] = torch.ops.aten.mul.Tensor(sum_73, squeeze_52);  sum_73 = squeeze_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_35 = torch.ops.aten.convolution_backward.default(mul_693, relu_14, primals_52, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_693 = primals_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_213: f32[64, 128, 28, 28] = convolution_backward_35[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_214: f32[512, 128, 1, 1] = convolution_backward_35[1];  convolution_backward_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_34: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_14, 0);  relu_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_34: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_34: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_34, scalar_tensor_34, getitem_213);  le_34 = scalar_tensor_34 = getitem_213 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_644: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_48, 0);  squeeze_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_645: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_644, 2);  unsqueeze_644 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_646: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_645, 3);  unsqueeze_645 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_74: f32[128] = torch.ops.aten.sum.dim_IntList(where_34, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_197: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_646)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_695: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_34, sub_197);  sub_197 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_75: f32[128] = torch.ops.aten.sum.dim_IntList(mul_695, [0, 2, 3]);  mul_695 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_696: f32[128] = torch.ops.aten.mul.Tensor(sum_74, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_647: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_696, 0);  mul_696 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_648: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_647, 2);  unsqueeze_647 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_649: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_648, 3);  unsqueeze_648 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_697: f32[128] = torch.ops.aten.mul.Tensor(sum_75, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_698: f32[128] = torch.ops.aten.mul.Tensor(squeeze_49, squeeze_49)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_699: f32[128] = torch.ops.aten.mul.Tensor(mul_697, mul_698);  mul_697 = mul_698 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_650: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_699, 0);  mul_699 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_651: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_650, 2);  unsqueeze_650 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_652: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_651, 3);  unsqueeze_651 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_700: f32[128] = torch.ops.aten.mul.Tensor(squeeze_49, primals_50);  primals_50 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_653: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_700, 0);  mul_700 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_654: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_653, 2);  unsqueeze_653 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_655: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_654, 3);  unsqueeze_654 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_198: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_646);  convolution_16 = unsqueeze_646 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_701: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_198, unsqueeze_652);  sub_198 = unsqueeze_652 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_199: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_34, mul_701);  where_34 = mul_701 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_200: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_199, unsqueeze_649);  sub_199 = unsqueeze_649 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_702: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_200, unsqueeze_655);  sub_200 = unsqueeze_655 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_703: f32[128] = torch.ops.aten.mul.Tensor(sum_75, squeeze_49);  sum_75 = squeeze_49 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_36 = torch.ops.aten.convolution_backward.default(mul_702, relu_13, primals_49, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_702 = primals_49 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_216: f32[64, 128, 28, 28] = convolution_backward_36[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_217: f32[128, 128, 3, 3] = convolution_backward_36[1];  convolution_backward_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_35: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_13, 0);  relu_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_35: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_35: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_35, scalar_tensor_35, getitem_216);  le_35 = scalar_tensor_35 = getitem_216 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_656: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_45, 0);  squeeze_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_657: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_656, 2);  unsqueeze_656 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_658: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_657, 3);  unsqueeze_657 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_76: f32[128] = torch.ops.aten.sum.dim_IntList(where_35, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_201: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_658)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_704: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_35, sub_201);  sub_201 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_77: f32[128] = torch.ops.aten.sum.dim_IntList(mul_704, [0, 2, 3]);  mul_704 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_705: f32[128] = torch.ops.aten.mul.Tensor(sum_76, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_659: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_705, 0);  mul_705 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_660: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_659, 2);  unsqueeze_659 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_661: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_660, 3);  unsqueeze_660 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_706: f32[128] = torch.ops.aten.mul.Tensor(sum_77, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_707: f32[128] = torch.ops.aten.mul.Tensor(squeeze_46, squeeze_46)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_708: f32[128] = torch.ops.aten.mul.Tensor(mul_706, mul_707);  mul_706 = mul_707 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_662: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_708, 0);  mul_708 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_663: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_662, 2);  unsqueeze_662 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_664: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_663, 3);  unsqueeze_663 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_709: f32[128] = torch.ops.aten.mul.Tensor(squeeze_46, primals_47);  primals_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_665: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_709, 0);  mul_709 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_666: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_665, 2);  unsqueeze_665 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_667: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_666, 3);  unsqueeze_666 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_202: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_658);  convolution_15 = unsqueeze_658 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_710: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_202, unsqueeze_664);  sub_202 = unsqueeze_664 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_203: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_35, mul_710);  where_35 = mul_710 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_204: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_203, unsqueeze_661);  sub_203 = unsqueeze_661 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_711: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_204, unsqueeze_667);  sub_204 = unsqueeze_667 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_712: f32[128] = torch.ops.aten.mul.Tensor(sum_77, squeeze_46);  sum_77 = squeeze_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_37 = torch.ops.aten.convolution_backward.default(mul_711, relu_12, primals_46, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_711 = primals_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_219: f32[64, 512, 28, 28] = convolution_backward_37[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_220: f32[128, 512, 1, 1] = convolution_backward_37[1];  convolution_backward_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_292: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(where_33, getitem_219);  where_33 = getitem_219 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_36: b8[64, 512, 28, 28] = torch.ops.aten.le.Scalar(relu_12, 0);  relu_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_36: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_36: f32[64, 512, 28, 28] = torch.ops.aten.where.self(le_36, scalar_tensor_36, add_292);  le_36 = scalar_tensor_36 = add_292 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_668: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_42, 0);  squeeze_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_669: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_668, 2);  unsqueeze_668 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_670: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_669, 3);  unsqueeze_669 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_78: f32[512] = torch.ops.aten.sum.dim_IntList(where_36, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_205: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_670)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_713: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_36, sub_205);  sub_205 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_79: f32[512] = torch.ops.aten.sum.dim_IntList(mul_713, [0, 2, 3]);  mul_713 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_714: f32[512] = torch.ops.aten.mul.Tensor(sum_78, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_671: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_714, 0);  mul_714 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_672: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_671, 2);  unsqueeze_671 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_673: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_672, 3);  unsqueeze_672 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_715: f32[512] = torch.ops.aten.mul.Tensor(sum_79, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_716: f32[512] = torch.ops.aten.mul.Tensor(squeeze_43, squeeze_43)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_717: f32[512] = torch.ops.aten.mul.Tensor(mul_715, mul_716);  mul_715 = mul_716 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_674: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_717, 0);  mul_717 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_675: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_674, 2);  unsqueeze_674 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_676: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_675, 3);  unsqueeze_675 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_718: f32[512] = torch.ops.aten.mul.Tensor(squeeze_43, primals_44);  primals_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_677: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_718, 0);  mul_718 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_678: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_677, 2);  unsqueeze_677 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_679: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_678, 3);  unsqueeze_678 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_206: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_670);  convolution_14 = unsqueeze_670 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_719: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_206, unsqueeze_676);  sub_206 = unsqueeze_676 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_207: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_36, mul_719);  mul_719 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_208: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_207, unsqueeze_673);  sub_207 = unsqueeze_673 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_720: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_208, unsqueeze_679);  sub_208 = unsqueeze_679 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_721: f32[512] = torch.ops.aten.mul.Tensor(sum_79, squeeze_43);  sum_79 = squeeze_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_38 = torch.ops.aten.convolution_backward.default(mul_720, relu_9, primals_43, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_720 = primals_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_222: f32[64, 256, 56, 56] = convolution_backward_38[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_223: f32[512, 256, 1, 1] = convolution_backward_38[1];  convolution_backward_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_680: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_39, 0);  squeeze_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_681: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_680, 2);  unsqueeze_680 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_682: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_681, 3);  unsqueeze_681 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_80: f32[512] = torch.ops.aten.sum.dim_IntList(where_36, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_209: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_682)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_722: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_36, sub_209);  sub_209 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_81: f32[512] = torch.ops.aten.sum.dim_IntList(mul_722, [0, 2, 3]);  mul_722 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_723: f32[512] = torch.ops.aten.mul.Tensor(sum_80, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_683: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_723, 0);  mul_723 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_684: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_683, 2);  unsqueeze_683 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_685: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_684, 3);  unsqueeze_684 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_724: f32[512] = torch.ops.aten.mul.Tensor(sum_81, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_725: f32[512] = torch.ops.aten.mul.Tensor(squeeze_40, squeeze_40)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_726: f32[512] = torch.ops.aten.mul.Tensor(mul_724, mul_725);  mul_724 = mul_725 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_686: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_726, 0);  mul_726 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_687: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_686, 2);  unsqueeze_686 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_688: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_687, 3);  unsqueeze_687 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_727: f32[512] = torch.ops.aten.mul.Tensor(squeeze_40, primals_41);  primals_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_689: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_727, 0);  mul_727 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_690: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_689, 2);  unsqueeze_689 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_691: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_690, 3);  unsqueeze_690 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_210: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_682);  convolution_13 = unsqueeze_682 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_728: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_210, unsqueeze_688);  sub_210 = unsqueeze_688 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_211: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_36, mul_728);  where_36 = mul_728 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_212: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_211, unsqueeze_685);  sub_211 = unsqueeze_685 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_729: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_212, unsqueeze_691);  sub_212 = unsqueeze_691 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_730: f32[512] = torch.ops.aten.mul.Tensor(sum_81, squeeze_40);  sum_81 = squeeze_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_39 = torch.ops.aten.convolution_backward.default(mul_729, relu_11, primals_40, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_729 = primals_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_225: f32[64, 128, 28, 28] = convolution_backward_39[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_226: f32[512, 128, 1, 1] = convolution_backward_39[1];  convolution_backward_39 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_37: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_11, 0);  relu_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_37: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_37: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_37, scalar_tensor_37, getitem_225);  le_37 = scalar_tensor_37 = getitem_225 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_692: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_36, 0);  squeeze_36 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_693: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_692, 2);  unsqueeze_692 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_694: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_693, 3);  unsqueeze_693 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_82: f32[128] = torch.ops.aten.sum.dim_IntList(where_37, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_213: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_694)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_731: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_37, sub_213);  sub_213 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_83: f32[128] = torch.ops.aten.sum.dim_IntList(mul_731, [0, 2, 3]);  mul_731 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_732: f32[128] = torch.ops.aten.mul.Tensor(sum_82, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_695: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_732, 0);  mul_732 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_696: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_695, 2);  unsqueeze_695 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_697: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_696, 3);  unsqueeze_696 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_733: f32[128] = torch.ops.aten.mul.Tensor(sum_83, 1.992984693877551e-05)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_734: f32[128] = torch.ops.aten.mul.Tensor(squeeze_37, squeeze_37)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_735: f32[128] = torch.ops.aten.mul.Tensor(mul_733, mul_734);  mul_733 = mul_734 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_698: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_735, 0);  mul_735 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_699: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_698, 2);  unsqueeze_698 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_700: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_699, 3);  unsqueeze_699 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_736: f32[128] = torch.ops.aten.mul.Tensor(squeeze_37, primals_38);  primals_38 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_701: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_736, 0);  mul_736 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_702: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_701, 2);  unsqueeze_701 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_703: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_702, 3);  unsqueeze_702 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_214: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_694);  convolution_12 = unsqueeze_694 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_737: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_214, unsqueeze_700);  sub_214 = unsqueeze_700 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_215: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_37, mul_737);  where_37 = mul_737 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_216: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_215, unsqueeze_697);  sub_215 = unsqueeze_697 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_738: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_216, unsqueeze_703);  sub_216 = unsqueeze_703 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_739: f32[128] = torch.ops.aten.mul.Tensor(sum_83, squeeze_37);  sum_83 = squeeze_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_40 = torch.ops.aten.convolution_backward.default(mul_738, relu_10, primals_37, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_738 = primals_37 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_228: f32[64, 128, 56, 56] = convolution_backward_40[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_229: f32[128, 128, 3, 3] = convolution_backward_40[1];  convolution_backward_40 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_38: b8[64, 128, 56, 56] = torch.ops.aten.le.Scalar(relu_10, 0);  relu_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_38: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_38: f32[64, 128, 56, 56] = torch.ops.aten.where.self(le_38, scalar_tensor_38, getitem_228);  le_38 = scalar_tensor_38 = getitem_228 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_704: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_33, 0);  squeeze_33 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_705: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_704, 2);  unsqueeze_704 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_706: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_705, 3);  unsqueeze_705 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_84: f32[128] = torch.ops.aten.sum.dim_IntList(where_38, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_217: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_706)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_740: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(where_38, sub_217);  sub_217 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_85: f32[128] = torch.ops.aten.sum.dim_IntList(mul_740, [0, 2, 3]);  mul_740 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_741: f32[128] = torch.ops.aten.mul.Tensor(sum_84, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_707: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_741, 0);  mul_741 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_708: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_707, 2);  unsqueeze_707 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_709: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_708, 3);  unsqueeze_708 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_742: f32[128] = torch.ops.aten.mul.Tensor(sum_85, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_743: f32[128] = torch.ops.aten.mul.Tensor(squeeze_34, squeeze_34)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_744: f32[128] = torch.ops.aten.mul.Tensor(mul_742, mul_743);  mul_742 = mul_743 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_710: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_744, 0);  mul_744 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_711: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_710, 2);  unsqueeze_710 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_712: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_711, 3);  unsqueeze_711 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_745: f32[128] = torch.ops.aten.mul.Tensor(squeeze_34, primals_35);  primals_35 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_713: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_745, 0);  mul_745 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_714: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_713, 2);  unsqueeze_713 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_715: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_714, 3);  unsqueeze_714 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_218: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_706);  convolution_11 = unsqueeze_706 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_746: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(sub_218, unsqueeze_712);  sub_218 = unsqueeze_712 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_219: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(where_38, mul_746);  where_38 = mul_746 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_220: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(sub_219, unsqueeze_709);  sub_219 = unsqueeze_709 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_747: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(sub_220, unsqueeze_715);  sub_220 = unsqueeze_715 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_748: f32[128] = torch.ops.aten.mul.Tensor(sum_85, squeeze_34);  sum_85 = squeeze_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_41 = torch.ops.aten.convolution_backward.default(mul_747, relu_9, primals_34, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_747 = primals_34 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_231: f32[64, 256, 56, 56] = convolution_backward_41[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_232: f32[128, 256, 1, 1] = convolution_backward_41[1];  convolution_backward_41 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_293: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(getitem_222, getitem_231);  getitem_222 = getitem_231 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_39: b8[64, 256, 56, 56] = torch.ops.aten.le.Scalar(relu_9, 0);  relu_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_39: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_39: f32[64, 256, 56, 56] = torch.ops.aten.where.self(le_39, scalar_tensor_39, add_293);  le_39 = scalar_tensor_39 = add_293 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_716: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_30, 0);  squeeze_30 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_717: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_716, 2);  unsqueeze_716 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_718: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_717, 3);  unsqueeze_717 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_86: f32[256] = torch.ops.aten.sum.dim_IntList(where_39, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_221: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_718)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_749: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(where_39, sub_221);  sub_221 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_87: f32[256] = torch.ops.aten.sum.dim_IntList(mul_749, [0, 2, 3]);  mul_749 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_750: f32[256] = torch.ops.aten.mul.Tensor(sum_86, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_719: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_750, 0);  mul_750 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_720: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_719, 2);  unsqueeze_719 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_721: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_720, 3);  unsqueeze_720 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_751: f32[256] = torch.ops.aten.mul.Tensor(sum_87, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_752: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, squeeze_31)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_753: f32[256] = torch.ops.aten.mul.Tensor(mul_751, mul_752);  mul_751 = mul_752 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_722: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_753, 0);  mul_753 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_723: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_722, 2);  unsqueeze_722 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_724: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_723, 3);  unsqueeze_723 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_754: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, primals_32);  primals_32 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_725: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_754, 0);  mul_754 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_726: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_725, 2);  unsqueeze_725 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_727: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_726, 3);  unsqueeze_726 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_222: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_718);  convolution_10 = unsqueeze_718 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_755: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_222, unsqueeze_724);  sub_222 = unsqueeze_724 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_223: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(where_39, mul_755);  mul_755 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_224: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(sub_223, unsqueeze_721);  sub_223 = unsqueeze_721 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_756: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_224, unsqueeze_727);  sub_224 = unsqueeze_727 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_757: f32[256] = torch.ops.aten.mul.Tensor(sum_87, squeeze_31);  sum_87 = squeeze_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_42 = torch.ops.aten.convolution_backward.default(mul_756, relu_8, primals_31, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_756 = primals_31 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_234: f32[64, 64, 56, 56] = convolution_backward_42[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_235: f32[256, 64, 1, 1] = convolution_backward_42[1];  convolution_backward_42 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_40: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_8, 0);  relu_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_40: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_40: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_40, scalar_tensor_40, getitem_234);  le_40 = scalar_tensor_40 = getitem_234 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_728: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_27, 0);  squeeze_27 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_729: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_728, 2);  unsqueeze_728 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_730: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_729, 3);  unsqueeze_729 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_88: f32[64] = torch.ops.aten.sum.dim_IntList(where_40, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_225: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_730)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_758: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_40, sub_225);  sub_225 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_89: f32[64] = torch.ops.aten.sum.dim_IntList(mul_758, [0, 2, 3]);  mul_758 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_759: f32[64] = torch.ops.aten.mul.Tensor(sum_88, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_731: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_759, 0);  mul_759 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_732: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_731, 2);  unsqueeze_731 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_733: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_732, 3);  unsqueeze_732 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_760: f32[64] = torch.ops.aten.mul.Tensor(sum_89, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_761: f32[64] = torch.ops.aten.mul.Tensor(squeeze_28, squeeze_28)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_762: f32[64] = torch.ops.aten.mul.Tensor(mul_760, mul_761);  mul_760 = mul_761 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_734: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_762, 0);  mul_762 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_735: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_734, 2);  unsqueeze_734 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_736: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_735, 3);  unsqueeze_735 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_763: f32[64] = torch.ops.aten.mul.Tensor(squeeze_28, primals_29);  primals_29 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_737: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_763, 0);  mul_763 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_738: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_737, 2);  unsqueeze_737 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_739: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_738, 3);  unsqueeze_738 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_226: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_730);  convolution_9 = unsqueeze_730 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_764: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_226, unsqueeze_736);  sub_226 = unsqueeze_736 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_227: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_40, mul_764);  where_40 = mul_764 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_228: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_227, unsqueeze_733);  sub_227 = unsqueeze_733 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_765: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_228, unsqueeze_739);  sub_228 = unsqueeze_739 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_766: f32[64] = torch.ops.aten.mul.Tensor(sum_89, squeeze_28);  sum_89 = squeeze_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_43 = torch.ops.aten.convolution_backward.default(mul_765, relu_7, primals_28, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_765 = primals_28 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_237: f32[64, 64, 56, 56] = convolution_backward_43[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_238: f32[64, 64, 3, 3] = convolution_backward_43[1];  convolution_backward_43 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_41: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_7, 0);  relu_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_41: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_41: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_41, scalar_tensor_41, getitem_237);  le_41 = scalar_tensor_41 = getitem_237 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_740: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_24, 0);  squeeze_24 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_741: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_740, 2);  unsqueeze_740 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_742: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_741, 3);  unsqueeze_741 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_90: f32[64] = torch.ops.aten.sum.dim_IntList(where_41, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_229: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_742)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_767: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_41, sub_229);  sub_229 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_91: f32[64] = torch.ops.aten.sum.dim_IntList(mul_767, [0, 2, 3]);  mul_767 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_768: f32[64] = torch.ops.aten.mul.Tensor(sum_90, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_743: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_768, 0);  mul_768 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_744: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_743, 2);  unsqueeze_743 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_745: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_744, 3);  unsqueeze_744 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_769: f32[64] = torch.ops.aten.mul.Tensor(sum_91, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_770: f32[64] = torch.ops.aten.mul.Tensor(squeeze_25, squeeze_25)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_771: f32[64] = torch.ops.aten.mul.Tensor(mul_769, mul_770);  mul_769 = mul_770 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_746: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_771, 0);  mul_771 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_747: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_746, 2);  unsqueeze_746 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_748: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_747, 3);  unsqueeze_747 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_772: f32[64] = torch.ops.aten.mul.Tensor(squeeze_25, primals_26);  primals_26 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_749: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_772, 0);  mul_772 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_750: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_749, 2);  unsqueeze_749 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_751: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_750, 3);  unsqueeze_750 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_230: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_742);  convolution_8 = unsqueeze_742 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_773: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_230, unsqueeze_748);  sub_230 = unsqueeze_748 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_231: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_41, mul_773);  where_41 = mul_773 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_232: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_231, unsqueeze_745);  sub_231 = unsqueeze_745 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_774: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_232, unsqueeze_751);  sub_232 = unsqueeze_751 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_775: f32[64] = torch.ops.aten.mul.Tensor(sum_91, squeeze_25);  sum_91 = squeeze_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_44 = torch.ops.aten.convolution_backward.default(mul_774, relu_6, primals_25, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_774 = primals_25 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_240: f32[64, 256, 56, 56] = convolution_backward_44[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_241: f32[64, 256, 1, 1] = convolution_backward_44[1];  convolution_backward_44 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_294: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(where_39, getitem_240);  where_39 = getitem_240 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_42: b8[64, 256, 56, 56] = torch.ops.aten.le.Scalar(relu_6, 0);  relu_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_42: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_42: f32[64, 256, 56, 56] = torch.ops.aten.where.self(le_42, scalar_tensor_42, add_294);  le_42 = scalar_tensor_42 = add_294 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_752: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_21, 0);  squeeze_21 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_753: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_752, 2);  unsqueeze_752 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_754: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_753, 3);  unsqueeze_753 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_92: f32[256] = torch.ops.aten.sum.dim_IntList(where_42, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_233: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_754)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_776: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(where_42, sub_233);  sub_233 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_93: f32[256] = torch.ops.aten.sum.dim_IntList(mul_776, [0, 2, 3]);  mul_776 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_777: f32[256] = torch.ops.aten.mul.Tensor(sum_92, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_755: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_777, 0);  mul_777 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_756: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_755, 2);  unsqueeze_755 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_757: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_756, 3);  unsqueeze_756 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_778: f32[256] = torch.ops.aten.mul.Tensor(sum_93, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_779: f32[256] = torch.ops.aten.mul.Tensor(squeeze_22, squeeze_22)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_780: f32[256] = torch.ops.aten.mul.Tensor(mul_778, mul_779);  mul_778 = mul_779 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_758: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_780, 0);  mul_780 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_759: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_758, 2);  unsqueeze_758 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_760: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_759, 3);  unsqueeze_759 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_781: f32[256] = torch.ops.aten.mul.Tensor(squeeze_22, primals_23);  primals_23 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_761: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_781, 0);  mul_781 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_762: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_761, 2);  unsqueeze_761 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_763: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_762, 3);  unsqueeze_762 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_234: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_754);  convolution_7 = unsqueeze_754 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_782: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_234, unsqueeze_760);  sub_234 = unsqueeze_760 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_235: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(where_42, mul_782);  mul_782 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_236: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(sub_235, unsqueeze_757);  sub_235 = unsqueeze_757 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_783: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_236, unsqueeze_763);  sub_236 = unsqueeze_763 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_784: f32[256] = torch.ops.aten.mul.Tensor(sum_93, squeeze_22);  sum_93 = squeeze_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_45 = torch.ops.aten.convolution_backward.default(mul_783, relu_5, primals_22, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_783 = primals_22 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_243: f32[64, 64, 56, 56] = convolution_backward_45[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_244: f32[256, 64, 1, 1] = convolution_backward_45[1];  convolution_backward_45 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_43: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_5, 0);  relu_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_43: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_43: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_43, scalar_tensor_43, getitem_243);  le_43 = scalar_tensor_43 = getitem_243 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_764: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_18, 0);  squeeze_18 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_765: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_764, 2);  unsqueeze_764 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_766: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_765, 3);  unsqueeze_765 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_94: f32[64] = torch.ops.aten.sum.dim_IntList(where_43, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_237: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_766)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_785: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_43, sub_237);  sub_237 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_95: f32[64] = torch.ops.aten.sum.dim_IntList(mul_785, [0, 2, 3]);  mul_785 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_786: f32[64] = torch.ops.aten.mul.Tensor(sum_94, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_767: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_786, 0);  mul_786 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_768: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_767, 2);  unsqueeze_767 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_769: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_768, 3);  unsqueeze_768 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_787: f32[64] = torch.ops.aten.mul.Tensor(sum_95, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_788: f32[64] = torch.ops.aten.mul.Tensor(squeeze_19, squeeze_19)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_789: f32[64] = torch.ops.aten.mul.Tensor(mul_787, mul_788);  mul_787 = mul_788 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_770: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_789, 0);  mul_789 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_771: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_770, 2);  unsqueeze_770 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_772: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_771, 3);  unsqueeze_771 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_790: f32[64] = torch.ops.aten.mul.Tensor(squeeze_19, primals_20);  primals_20 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_773: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_790, 0);  mul_790 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_774: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_773, 2);  unsqueeze_773 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_775: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_774, 3);  unsqueeze_774 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_238: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_766);  convolution_6 = unsqueeze_766 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_791: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_238, unsqueeze_772);  sub_238 = unsqueeze_772 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_239: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_43, mul_791);  where_43 = mul_791 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_240: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_239, unsqueeze_769);  sub_239 = unsqueeze_769 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_792: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_240, unsqueeze_775);  sub_240 = unsqueeze_775 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_793: f32[64] = torch.ops.aten.mul.Tensor(sum_95, squeeze_19);  sum_95 = squeeze_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_46 = torch.ops.aten.convolution_backward.default(mul_792, relu_4, primals_19, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_792 = primals_19 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_246: f32[64, 64, 56, 56] = convolution_backward_46[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_247: f32[64, 64, 3, 3] = convolution_backward_46[1];  convolution_backward_46 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_44: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_4, 0);  relu_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_44: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_44: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_44, scalar_tensor_44, getitem_246);  le_44 = scalar_tensor_44 = getitem_246 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_776: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_15, 0);  squeeze_15 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_777: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_776, 2);  unsqueeze_776 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_778: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_777, 3);  unsqueeze_777 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_96: f32[64] = torch.ops.aten.sum.dim_IntList(where_44, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_241: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_778)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_794: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_44, sub_241);  sub_241 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_97: f32[64] = torch.ops.aten.sum.dim_IntList(mul_794, [0, 2, 3]);  mul_794 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_795: f32[64] = torch.ops.aten.mul.Tensor(sum_96, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_779: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_795, 0);  mul_795 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_780: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_779, 2);  unsqueeze_779 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_781: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_780, 3);  unsqueeze_780 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_796: f32[64] = torch.ops.aten.mul.Tensor(sum_97, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_797: f32[64] = torch.ops.aten.mul.Tensor(squeeze_16, squeeze_16)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_798: f32[64] = torch.ops.aten.mul.Tensor(mul_796, mul_797);  mul_796 = mul_797 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_782: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_798, 0);  mul_798 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_783: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_782, 2);  unsqueeze_782 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_784: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_783, 3);  unsqueeze_783 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_799: f32[64] = torch.ops.aten.mul.Tensor(squeeze_16, primals_17);  primals_17 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_785: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_799, 0);  mul_799 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_786: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_785, 2);  unsqueeze_785 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_787: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_786, 3);  unsqueeze_786 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_242: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_778);  convolution_5 = unsqueeze_778 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_800: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_242, unsqueeze_784);  sub_242 = unsqueeze_784 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_243: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_44, mul_800);  where_44 = mul_800 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_244: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_243, unsqueeze_781);  sub_243 = unsqueeze_781 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_801: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_244, unsqueeze_787);  sub_244 = unsqueeze_787 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_802: f32[64] = torch.ops.aten.mul.Tensor(sum_97, squeeze_16);  sum_97 = squeeze_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_47 = torch.ops.aten.convolution_backward.default(mul_801, relu_3, primals_16, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_801 = primals_16 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_249: f32[64, 256, 56, 56] = convolution_backward_47[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_250: f32[64, 256, 1, 1] = convolution_backward_47[1];  convolution_backward_47 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_295: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(where_42, getitem_249);  where_42 = getitem_249 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_45: b8[64, 256, 56, 56] = torch.ops.aten.le.Scalar(relu_3, 0);  relu_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_45: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_45: f32[64, 256, 56, 56] = torch.ops.aten.where.self(le_45, scalar_tensor_45, add_295);  le_45 = scalar_tensor_45 = add_295 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_788: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_12, 0);  squeeze_12 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_789: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_788, 2);  unsqueeze_788 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_790: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_789, 3);  unsqueeze_789 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_98: f32[256] = torch.ops.aten.sum.dim_IntList(where_45, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_245: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_790)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_803: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(where_45, sub_245);  sub_245 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_99: f32[256] = torch.ops.aten.sum.dim_IntList(mul_803, [0, 2, 3]);  mul_803 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_804: f32[256] = torch.ops.aten.mul.Tensor(sum_98, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_791: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_804, 0);  mul_804 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_792: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_791, 2);  unsqueeze_791 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_793: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_792, 3);  unsqueeze_792 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_805: f32[256] = torch.ops.aten.mul.Tensor(sum_99, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_806: f32[256] = torch.ops.aten.mul.Tensor(squeeze_13, squeeze_13)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_807: f32[256] = torch.ops.aten.mul.Tensor(mul_805, mul_806);  mul_805 = mul_806 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_794: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_807, 0);  mul_807 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_795: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_794, 2);  unsqueeze_794 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_796: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_795, 3);  unsqueeze_795 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_808: f32[256] = torch.ops.aten.mul.Tensor(squeeze_13, primals_14);  primals_14 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_797: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_808, 0);  mul_808 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_798: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_797, 2);  unsqueeze_797 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_799: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_798, 3);  unsqueeze_798 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_246: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_790);  convolution_4 = unsqueeze_790 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_809: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_246, unsqueeze_796);  sub_246 = unsqueeze_796 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_247: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(where_45, mul_809);  mul_809 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_248: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(sub_247, unsqueeze_793);  sub_247 = unsqueeze_793 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_810: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_248, unsqueeze_799);  sub_248 = unsqueeze_799 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_811: f32[256] = torch.ops.aten.mul.Tensor(sum_99, squeeze_13);  sum_99 = squeeze_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_48 = torch.ops.aten.convolution_backward.default(mul_810, getitem_2, primals_13, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_810 = primals_13 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_252: f32[64, 64, 56, 56] = convolution_backward_48[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_253: f32[256, 64, 1, 1] = convolution_backward_48[1];  convolution_backward_48 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_800: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_9, 0);  squeeze_9 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_801: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_800, 2);  unsqueeze_800 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_802: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_801, 3);  unsqueeze_801 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_100: f32[256] = torch.ops.aten.sum.dim_IntList(where_45, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_249: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_802)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_812: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(where_45, sub_249);  sub_249 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_101: f32[256] = torch.ops.aten.sum.dim_IntList(mul_812, [0, 2, 3]);  mul_812 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_813: f32[256] = torch.ops.aten.mul.Tensor(sum_100, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_803: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_813, 0);  mul_813 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_804: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_803, 2);  unsqueeze_803 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_805: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_804, 3);  unsqueeze_804 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_814: f32[256] = torch.ops.aten.mul.Tensor(sum_101, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_815: f32[256] = torch.ops.aten.mul.Tensor(squeeze_10, squeeze_10)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_816: f32[256] = torch.ops.aten.mul.Tensor(mul_814, mul_815);  mul_814 = mul_815 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_806: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_816, 0);  mul_816 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_807: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_806, 2);  unsqueeze_806 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_808: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_807, 3);  unsqueeze_807 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_817: f32[256] = torch.ops.aten.mul.Tensor(squeeze_10, primals_11);  primals_11 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_809: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_817, 0);  mul_817 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_810: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_809, 2);  unsqueeze_809 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_811: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_810, 3);  unsqueeze_810 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_250: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_802);  convolution_3 = unsqueeze_802 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_818: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_250, unsqueeze_808);  sub_250 = unsqueeze_808 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_251: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(where_45, mul_818);  where_45 = mul_818 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_252: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(sub_251, unsqueeze_805);  sub_251 = unsqueeze_805 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_819: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_252, unsqueeze_811);  sub_252 = unsqueeze_811 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_820: f32[256] = torch.ops.aten.mul.Tensor(sum_101, squeeze_10);  sum_101 = squeeze_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_49 = torch.ops.aten.convolution_backward.default(mul_819, relu_2, primals_10, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_819 = primals_10 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_255: f32[64, 64, 56, 56] = convolution_backward_49[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_256: f32[256, 64, 1, 1] = convolution_backward_49[1];  convolution_backward_49 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_46: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_2, 0);  relu_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_46: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_46: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_46, scalar_tensor_46, getitem_255);  le_46 = scalar_tensor_46 = getitem_255 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_812: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_6, 0);  squeeze_6 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_813: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_812, 2);  unsqueeze_812 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_814: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_813, 3);  unsqueeze_813 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_102: f32[64] = torch.ops.aten.sum.dim_IntList(where_46, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_253: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_814)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_821: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_46, sub_253);  sub_253 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_103: f32[64] = torch.ops.aten.sum.dim_IntList(mul_821, [0, 2, 3]);  mul_821 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_822: f32[64] = torch.ops.aten.mul.Tensor(sum_102, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_815: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_822, 0);  mul_822 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_816: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_815, 2);  unsqueeze_815 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_817: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_816, 3);  unsqueeze_816 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_823: f32[64] = torch.ops.aten.mul.Tensor(sum_103, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_824: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, squeeze_7)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_825: f32[64] = torch.ops.aten.mul.Tensor(mul_823, mul_824);  mul_823 = mul_824 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_818: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_825, 0);  mul_825 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_819: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_818, 2);  unsqueeze_818 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_820: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_819, 3);  unsqueeze_819 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_826: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, primals_8);  primals_8 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_821: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_826, 0);  mul_826 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_822: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_821, 2);  unsqueeze_821 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_823: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_822, 3);  unsqueeze_822 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_254: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_814);  convolution_2 = unsqueeze_814 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_827: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_254, unsqueeze_820);  sub_254 = unsqueeze_820 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_255: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_46, mul_827);  where_46 = mul_827 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_256: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_255, unsqueeze_817);  sub_255 = unsqueeze_817 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_828: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_256, unsqueeze_823);  sub_256 = unsqueeze_823 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_829: f32[64] = torch.ops.aten.mul.Tensor(sum_103, squeeze_7);  sum_103 = squeeze_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_50 = torch.ops.aten.convolution_backward.default(mul_828, relu_1, primals_7, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_828 = primals_7 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_258: f32[64, 64, 56, 56] = convolution_backward_50[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_259: f32[64, 64, 3, 3] = convolution_backward_50[1];  convolution_backward_50 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_47: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_1, 0);  relu_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_47: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_47: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_47, scalar_tensor_47, getitem_258);  le_47 = scalar_tensor_47 = getitem_258 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_824: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_3, 0);  squeeze_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_825: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_824, 2);  unsqueeze_824 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_826: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_825, 3);  unsqueeze_825 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_104: f32[64] = torch.ops.aten.sum.dim_IntList(where_47, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_257: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_826)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_830: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_47, sub_257);  sub_257 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_105: f32[64] = torch.ops.aten.sum.dim_IntList(mul_830, [0, 2, 3]);  mul_830 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_831: f32[64] = torch.ops.aten.mul.Tensor(sum_104, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_827: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_831, 0);  mul_831 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_828: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_827, 2);  unsqueeze_827 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_829: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_828, 3);  unsqueeze_828 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_832: f32[64] = torch.ops.aten.mul.Tensor(sum_105, 4.982461734693877e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_833: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, squeeze_4)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_834: f32[64] = torch.ops.aten.mul.Tensor(mul_832, mul_833);  mul_832 = mul_833 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_830: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_834, 0);  mul_834 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_831: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_830, 2);  unsqueeze_830 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_832: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_831, 3);  unsqueeze_831 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_835: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, primals_5);  primals_5 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_833: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_835, 0);  mul_835 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_834: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_833, 2);  unsqueeze_833 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_835: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_834, 3);  unsqueeze_834 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_258: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_826);  convolution_1 = unsqueeze_826 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_836: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_258, unsqueeze_832);  sub_258 = unsqueeze_832 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_259: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_47, mul_836);  where_47 = mul_836 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_260: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_259, unsqueeze_829);  sub_259 = unsqueeze_829 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_837: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_260, unsqueeze_835);  sub_260 = unsqueeze_835 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_838: f32[64] = torch.ops.aten.mul.Tensor(sum_105, squeeze_4);  sum_105 = squeeze_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_51 = torch.ops.aten.convolution_backward.default(mul_837, getitem_2, primals_4, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_837 = getitem_2 = primals_4 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_261: f32[64, 64, 56, 56] = convolution_backward_51[0]
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_262: f32[64, 64, 1, 1] = convolution_backward_51[1];  convolution_backward_51 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         add_296: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(getitem_252, getitem_261);  getitem_252 = getitem_261 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:271, code: x = self.maxpool(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         max_pool2d_with_indices_backward: f32[64, 64, 112, 112] = torch.ops.aten.max_pool2d_with_indices_backward.default(add_296, relu, [3, 3], [2, 2], [1, 1], [1, 1], False, getitem_3);  add_296 = getitem_3 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:270, code: x = self.relu(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         le_48: b8[64, 64, 112, 112] = torch.ops.aten.le.Scalar(relu, 0);  relu = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         scalar_tensor_48: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         where_48: f32[64, 64, 112, 112] = torch.ops.aten.where.self(le_48, scalar_tensor_48, max_pool2d_with_indices_backward);  le_48 = scalar_tensor_48 = max_pool2d_with_indices_backward = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:269, code: x = self.bn1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_836: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze, 0);  squeeze = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_837: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_836, 2);  unsqueeze_836 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_838: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_837, 3);  unsqueeze_837 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_106: f32[64] = torch.ops.aten.sum.dim_IntList(where_48, [0, 2, 3])
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_261: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(convolution, unsqueeze_838)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_839: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(where_48, sub_261);  sub_261 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sum_107: f32[64] = torch.ops.aten.sum.dim_IntList(mul_839, [0, 2, 3]);  mul_839 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_840: f32[64] = torch.ops.aten.mul.Tensor(sum_106, 1.2456154336734693e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_839: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_840, 0);  mul_840 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_840: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_839, 2);  unsqueeze_839 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_841: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_840, 3);  unsqueeze_840 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_841: f32[64] = torch.ops.aten.mul.Tensor(sum_107, 1.2456154336734693e-06)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_842: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, squeeze_1)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_843: f32[64] = torch.ops.aten.mul.Tensor(mul_841, mul_842);  mul_841 = mul_842 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_842: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_843, 0);  mul_843 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_843: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_842, 2);  unsqueeze_842 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_844: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_843, 3);  unsqueeze_843 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_844: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, primals_2);  primals_2 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_845: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_844, 0);  mul_844 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_846: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_845, 2);  unsqueeze_845 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         unsqueeze_847: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_846, 3);  unsqueeze_846 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_262: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(convolution, unsqueeze_838);  convolution = unsqueeze_838 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_845: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(sub_262, unsqueeze_844);  sub_262 = unsqueeze_844 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_263: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(where_48, mul_845);  where_48 = mul_845 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         sub_264: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(sub_263, unsqueeze_841);  sub_263 = unsqueeze_841 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_846: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(sub_264, unsqueeze_847);  sub_264 = unsqueeze_847 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         mul_847: f32[64] = torch.ops.aten.mul.Tensor(sum_107, squeeze_1);  sum_107 = squeeze_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:268, code: x = self.conv1(x)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         convolution_backward_52 = torch.ops.aten.convolution_backward.default(mul_846, primals_321, primals_1, [0], [2, 2], [3, 3], [1, 1], False, [0, 0], 1, [False, True, False]);  mul_846 = primals_321 = primals_1 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         getitem_265: f32[64, 3, 7, 7] = convolution_backward_52[1];  convolution_backward_52 = None
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         return pytree.tree_unflatten([add_2, add_3, add, add_7, add_8, add_5, add_12, add_13, add_10, add_17, add_18, add_15, add_22, add_23, add_20, add_28, add_29, add_26, add_33, add_34, add_31, add_38, add_39, add_36, add_44, add_45, add_42, add_49, add_50, add_47, add_54, add_55, add_52, add_60, add_61, add_58, add_65, add_66, add_63, add_70, add_71, add_68, add_75, add_76, add_73, add_81, add_82, add_79, add_86, add_87, add_84, add_91, add_92, add_89, add_97, add_98, add_95, add_102, add_103, add_100, add_107, add_108, add_105, add_113, add_114, add_111, add_118, add_119, add_116, add_123, add_124, add_121, add_129, add_130, add_127, add_134, add_135, add_132, add_139, add_140, add_137, add_144, add_145, add_142, add_150, add_151, add_148, add_155, add_156, add_153, add_160, add_161, add_158, add_166, add_167, add_164, add_171, add_172, add_169, add_176, add_177, add_174, add_182, add_183, add_180, add_187, add_188, add_185, add_192, add_193, add_190, add_198, add_199, add_196, add_203, add_204, add_201, add_208, add_209, add_206, add_214, add_215, add_212, add_219, add_220, add_217, add_224, add_225, add_222, add_230, add_231, add_228, add_235, add_236, add_233, add_240, add_241, add_238, add_245, add_246, add_243, add_251, add_252, add_249, add_256, add_257, add_254, add_261, add_262, add_259, add_267, add_268, add_265, add_272, add_273, add_270, add_277, add_278, add_275, addmm, getitem_265, mul_847, sum_106, getitem_262, mul_838, sum_104, getitem_259, mul_829, sum_102, getitem_256, mul_820, sum_100, getitem_253, mul_811, sum_98, getitem_250, mul_802, sum_96, getitem_247, mul_793, sum_94, getitem_244, mul_784, sum_92, getitem_241, mul_775, sum_90, getitem_238, mul_766, sum_88, getitem_235, mul_757, sum_86, getitem_232, mul_748, sum_84, getitem_229, mul_739, sum_82, getitem_226, mul_730, sum_80, getitem_223, mul_721, sum_78, getitem_220, mul_712, sum_76, getitem_217, mul_703, sum_74, getitem_214, mul_694, sum_72, getitem_211, mul_685, sum_70, getitem_208, mul_676, sum_68, getitem_205, mul_667, sum_66, getitem_202, mul_658, sum_64, getitem_199, mul_649, sum_62, getitem_196, mul_640, sum_60, getitem_193, mul_631, sum_58, getitem_190, mul_622, sum_56, getitem_187, mul_613, sum_54, getitem_184, mul_604, sum_52, getitem_181, mul_595, sum_50, getitem_178, mul_586, sum_48, getitem_175, mul_577, sum_46, getitem_172, mul_568, sum_44, getitem_169, mul_559, sum_42, getitem_166, mul_550, sum_40, getitem_163, mul_541, sum_38, getitem_160, mul_532, sum_36, getitem_157, mul_523, sum_34, getitem_154, mul_514, sum_32, getitem_151, mul_505, sum_30, getitem_148, mul_496, sum_28, getitem_145, mul_487, sum_26, getitem_142, mul_478, sum_24, getitem_139, mul_469, sum_22, getitem_136, mul_460, sum_20, getitem_133, mul_451, sum_18, getitem_130, mul_442, sum_16, getitem_127, mul_433, sum_14, getitem_124, mul_424, sum_12, getitem_121, mul_415, sum_10, getitem_118, mul_406, sum_8, getitem_115, mul_397, sum_6, getitem_112, mul_388, sum_4, getitem_109, mul_379, sum_2, permute_4, view_1, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], self._out_spec)
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO]         
[2023-12-28 21:22:55,294] [0/0] torch._functorch.aot_autograd.__aot_joint_graph: [INFO] 
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO] TRACED GRAPH
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]  ===== Forward graph 0 =====
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]  <eval_with_key>.156 class GraphModule(torch.nn.Module):
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]     def forward(self, primals_1: f32[64, 3, 7, 7], primals_2: f32[64], primals_3: f32[64], primals_4: f32[64, 64, 1, 1], primals_5: f32[64], primals_6: f32[64], primals_7: f32[64, 64, 3, 3], primals_8: f32[64], primals_9: f32[64], primals_10: f32[256, 64, 1, 1], primals_11: f32[256], primals_12: f32[256], primals_13: f32[256, 64, 1, 1], primals_14: f32[256], primals_15: f32[256], primals_16: f32[64, 256, 1, 1], primals_17: f32[64], primals_18: f32[64], primals_19: f32[64, 64, 3, 3], primals_20: f32[64], primals_21: f32[64], primals_22: f32[256, 64, 1, 1], primals_23: f32[256], primals_24: f32[256], primals_25: f32[64, 256, 1, 1], primals_26: f32[64], primals_27: f32[64], primals_28: f32[64, 64, 3, 3], primals_29: f32[64], primals_30: f32[64], primals_31: f32[256, 64, 1, 1], primals_32: f32[256], primals_33: f32[256], primals_34: f32[128, 256, 1, 1], primals_35: f32[128], primals_36: f32[128], primals_37: f32[128, 128, 3, 3], primals_38: f32[128], primals_39: f32[128], primals_40: f32[512, 128, 1, 1], primals_41: f32[512], primals_42: f32[512], primals_43: f32[512, 256, 1, 1], primals_44: f32[512], primals_45: f32[512], primals_46: f32[128, 512, 1, 1], primals_47: f32[128], primals_48: f32[128], primals_49: f32[128, 128, 3, 3], primals_50: f32[128], primals_51: f32[128], primals_52: f32[512, 128, 1, 1], primals_53: f32[512], primals_54: f32[512], primals_55: f32[128, 512, 1, 1], primals_56: f32[128], primals_57: f32[128], primals_58: f32[128, 128, 3, 3], primals_59: f32[128], primals_60: f32[128], primals_61: f32[512, 128, 1, 1], primals_62: f32[512], primals_63: f32[512], primals_64: f32[128, 512, 1, 1], primals_65: f32[128], primals_66: f32[128], primals_67: f32[128, 128, 3, 3], primals_68: f32[128], primals_69: f32[128], primals_70: f32[512, 128, 1, 1], primals_71: f32[512], primals_72: f32[512], primals_73: f32[256, 512, 1, 1], primals_74: f32[256], primals_75: f32[256], primals_76: f32[256, 256, 3, 3], primals_77: f32[256], primals_78: f32[256], primals_79: f32[1024, 256, 1, 1], primals_80: f32[1024], primals_81: f32[1024], primals_82: f32[1024, 512, 1, 1], primals_83: f32[1024], primals_84: f32[1024], primals_85: f32[256, 1024, 1, 1], primals_86: f32[256], primals_87: f32[256], primals_88: f32[256, 256, 3, 3], primals_89: f32[256], primals_90: f32[256], primals_91: f32[1024, 256, 1, 1], primals_92: f32[1024], primals_93: f32[1024], primals_94: f32[256, 1024, 1, 1], primals_95: f32[256], primals_96: f32[256], primals_97: f32[256, 256, 3, 3], primals_98: f32[256], primals_99: f32[256], primals_100: f32[1024, 256, 1, 1], primals_101: f32[1024], primals_102: f32[1024], primals_103: f32[256, 1024, 1, 1], primals_104: f32[256], primals_105: f32[256], primals_106: f32[256, 256, 3, 3], primals_107: f32[256], primals_108: f32[256], primals_109: f32[1024, 256, 1, 1], primals_110: f32[1024], primals_111: f32[1024], primals_112: f32[256, 1024, 1, 1], primals_113: f32[256], primals_114: f32[256], primals_115: f32[256, 256, 3, 3], primals_116: f32[256], primals_117: f32[256], primals_118: f32[1024, 256, 1, 1], primals_119: f32[1024], primals_120: f32[1024], primals_121: f32[256, 1024, 1, 1], primals_122: f32[256], primals_123: f32[256], primals_124: f32[256, 256, 3, 3], primals_125: f32[256], primals_126: f32[256], primals_127: f32[1024, 256, 1, 1], primals_128: f32[1024], primals_129: f32[1024], primals_130: f32[512, 1024, 1, 1], primals_131: f32[512], primals_132: f32[512], primals_133: f32[512, 512, 3, 3], primals_134: f32[512], primals_135: f32[512], primals_136: f32[2048, 512, 1, 1], primals_137: f32[2048], primals_138: f32[2048], primals_139: f32[2048, 1024, 1, 1], primals_140: f32[2048], primals_141: f32[2048], primals_142: f32[512, 2048, 1, 1], primals_143: f32[512], primals_144: f32[512], primals_145: f32[512, 512, 3, 3], primals_146: f32[512], primals_147: f32[512], primals_148: f32[2048, 512, 1, 1], primals_149: f32[2048], primals_150: f32[2048], primals_151: f32[512, 2048, 1, 1], primals_152: f32[512], primals_153: f32[512], primals_154: f32[512, 512, 3, 3], primals_155: f32[512], primals_156: f32[512], primals_157: f32[2048, 512, 1, 1], primals_158: f32[2048], primals_159: f32[2048], primals_160: f32[1000, 2048], primals_161: f32[1000], primals_162: f32[64], primals_163: f32[64], primals_164: i64[], primals_165: f32[64], primals_166: f32[64], primals_167: i64[], primals_168: f32[64], primals_169: f32[64], primals_170: i64[], primals_171: f32[256], primals_172: f32[256], primals_173: i64[], primals_174: f32[256], primals_175: f32[256], primals_176: i64[], primals_177: f32[64], primals_178: f32[64], primals_179: i64[], primals_180: f32[64], primals_181: f32[64], primals_182: i64[], primals_183: f32[256], primals_184: f32[256], primals_185: i64[], primals_186: f32[64], primals_187: f32[64], primals_188: i64[], primals_189: f32[64], primals_190: f32[64], primals_191: i64[], primals_192: f32[256], primals_193: f32[256], primals_194: i64[], primals_195: f32[128], primals_196: f32[128], primals_197: i64[], primals_198: f32[128], primals_199: f32[128], primals_200: i64[], primals_201: f32[512], primals_202: f32[512], primals_203: i64[], primals_204: f32[512], primals_205: f32[512], primals_206: i64[], primals_207: f32[128], primals_208: f32[128], primals_209: i64[], primals_210: f32[128], primals_211: f32[128], primals_212: i64[], primals_213: f32[512], primals_214: f32[512], primals_215: i64[], primals_216: f32[128], primals_217: f32[128], primals_218: i64[], primals_219: f32[128], primals_220: f32[128], primals_221: i64[], primals_222: f32[512], primals_223: f32[512], primals_224: i64[], primals_225: f32[128], primals_226: f32[128], primals_227: i64[], primals_228: f32[128], primals_229: f32[128], primals_230: i64[], primals_231: f32[512], primals_232: f32[512], primals_233: i64[], primals_234: f32[256], primals_235: f32[256], primals_236: i64[], primals_237: f32[256], primals_238: f32[256], primals_239: i64[], primals_240: f32[1024], primals_241: f32[1024], primals_242: i64[], primals_243: f32[1024], primals_244: f32[1024], primals_245: i64[], primals_246: f32[256], primals_247: f32[256], primals_248: i64[], primals_249: f32[256], primals_250: f32[256], primals_251: i64[], primals_252: f32[1024], primals_253: f32[1024], primals_254: i64[], primals_255: f32[256], primals_256: f32[256], primals_257: i64[], primals_258: f32[256], primals_259: f32[256], primals_260: i64[], primals_261: f32[1024], primals_262: f32[1024], primals_263: i64[], primals_264: f32[256], primals_265: f32[256], primals_266: i64[], primals_267: f32[256], primals_268: f32[256], primals_269: i64[], primals_270: f32[1024], primals_271: f32[1024], primals_272: i64[], primals_273: f32[256], primals_274: f32[256], primals_275: i64[], primals_276: f32[256], primals_277: f32[256], primals_278: i64[], primals_279: f32[1024], primals_280: f32[1024], primals_281: i64[], primals_282: f32[256], primals_283: f32[256], primals_284: i64[], primals_285: f32[256], primals_286: f32[256], primals_287: i64[], primals_288: f32[1024], primals_289: f32[1024], primals_290: i64[], primals_291: f32[512], primals_292: f32[512], primals_293: i64[], primals_294: f32[512], primals_295: f32[512], primals_296: i64[], primals_297: f32[2048], primals_298: f32[2048], primals_299: i64[], primals_300: f32[2048], primals_301: f32[2048], primals_302: i64[], primals_303: f32[512], primals_304: f32[512], primals_305: i64[], primals_306: f32[512], primals_307: f32[512], primals_308: i64[], primals_309: f32[2048], primals_310: f32[2048], primals_311: i64[], primals_312: f32[512], primals_313: f32[512], primals_314: i64[], primals_315: f32[512], primals_316: f32[512], primals_317: i64[], primals_318: f32[2048], primals_319: f32[2048], primals_320: i64[], primals_321: f32[64, 3, 224, 224]):
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:268, code: x = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution: f32[64, 64, 112, 112] = torch.ops.aten.convolution.default(primals_321, primals_1, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:269, code: x = self.bn1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add: i64[] = torch.ops.aten.add.Tensor(primals_164, 1);  primals_164 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean = torch.ops.aten.var_mean.correction(convolution, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem: f32[1, 64, 1, 1] = var_mean[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_1: f32[1, 64, 1, 1] = var_mean[1];  var_mean = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_1: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(convolution, getitem_1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze: f32[64] = torch.ops.aten.squeeze.dims(getitem_1, [0, 2, 3]);  getitem_1 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_1: f32[64] = torch.ops.aten.squeeze.dims(rsqrt, [0, 2, 3]);  rsqrt = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_1: f32[64] = torch.ops.aten.mul.Tensor(squeeze, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_2: f32[64] = torch.ops.aten.mul.Tensor(primals_162, 0.9);  primals_162 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_2: f32[64] = torch.ops.aten.add.Tensor(mul_1, mul_2);  mul_1 = mul_2 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_2: f32[64] = torch.ops.aten.squeeze.dims(getitem, [0, 2, 3]);  getitem = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_3: f32[64] = torch.ops.aten.mul.Tensor(squeeze_2, 1.0000012456169853);  squeeze_2 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_4: f32[64] = torch.ops.aten.mul.Tensor(mul_3, 0.1);  mul_3 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_5: f32[64] = torch.ops.aten.mul.Tensor(primals_163, 0.9);  primals_163 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_3: f32[64] = torch.ops.aten.add.Tensor(mul_4, mul_5);  mul_4 = mul_5 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_2, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_1: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze, -1);  unsqueeze = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_6: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(mul, unsqueeze_1);  mul = unsqueeze_1 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_2: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_3, -1);  primals_3 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_3: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_2, -1);  unsqueeze_2 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_4: f32[64, 64, 112, 112] = torch.ops.aten.add.Tensor(mul_6, unsqueeze_3);  mul_6 = unsqueeze_3 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:270, code: x = self.relu(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu: f32[64, 64, 112, 112] = torch.ops.aten.relu.default(add_4);  add_4 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:271, code: x = self.maxpool(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         max_pool2d_with_indices = torch.ops.aten.max_pool2d_with_indices.default(relu, [3, 3], [2, 2], [1, 1])
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_2: f32[64, 64, 56, 56] = max_pool2d_with_indices[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_3: i64[64, 64, 56, 56] = max_pool2d_with_indices[1];  max_pool2d_with_indices = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_1: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(getitem_2, primals_4, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_5: i64[] = torch.ops.aten.add.Tensor(primals_167, 1);  primals_167 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_1 = torch.ops.aten.var_mean.correction(convolution_1, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_4: f32[1, 64, 1, 1] = var_mean_1[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_5: f32[1, 64, 1, 1] = var_mean_1[1];  var_mean_1 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_6: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_4, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_1: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_6);  add_6 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_1: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_1, getitem_5)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_7: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_1, rsqrt_1);  sub_1 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_3: f32[64] = torch.ops.aten.squeeze.dims(getitem_5, [0, 2, 3]);  getitem_5 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_4: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_1, [0, 2, 3]);  rsqrt_1 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_8: f32[64] = torch.ops.aten.mul.Tensor(squeeze_3, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_9: f32[64] = torch.ops.aten.mul.Tensor(primals_165, 0.9);  primals_165 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_7: f32[64] = torch.ops.aten.add.Tensor(mul_8, mul_9);  mul_8 = mul_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_5: f32[64] = torch.ops.aten.squeeze.dims(getitem_4, [0, 2, 3]);  getitem_4 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_10: f32[64] = torch.ops.aten.mul.Tensor(squeeze_5, 1.0000049824865598);  squeeze_5 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_11: f32[64] = torch.ops.aten.mul.Tensor(mul_10, 0.1);  mul_10 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_12: f32[64] = torch.ops.aten.mul.Tensor(primals_166, 0.9);  primals_166 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_8: f32[64] = torch.ops.aten.add.Tensor(mul_11, mul_12);  mul_11 = mul_12 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_4: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_5, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_5: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_4, -1);  unsqueeze_4 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_13: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_7, unsqueeze_5);  mul_7 = unsqueeze_5 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_6: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_6, -1);  primals_6 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_7: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_6, -1);  unsqueeze_6 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_9: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_13, unsqueeze_7);  mul_13 = unsqueeze_7 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_1: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_9);  add_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_2: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_1, primals_7, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_10: i64[] = torch.ops.aten.add.Tensor(primals_170, 1);  primals_170 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_2 = torch.ops.aten.var_mean.correction(convolution_2, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_6: f32[1, 64, 1, 1] = var_mean_2[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_7: f32[1, 64, 1, 1] = var_mean_2[1];  var_mean_2 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_11: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_6, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_2: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_11);  add_11 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_2: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_2, getitem_7)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_14: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_2, rsqrt_2);  sub_2 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_6: f32[64] = torch.ops.aten.squeeze.dims(getitem_7, [0, 2, 3]);  getitem_7 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_7: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_2, [0, 2, 3]);  rsqrt_2 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_15: f32[64] = torch.ops.aten.mul.Tensor(squeeze_6, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_16: f32[64] = torch.ops.aten.mul.Tensor(primals_168, 0.9);  primals_168 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_12: f32[64] = torch.ops.aten.add.Tensor(mul_15, mul_16);  mul_15 = mul_16 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_8: f32[64] = torch.ops.aten.squeeze.dims(getitem_6, [0, 2, 3]);  getitem_6 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_17: f32[64] = torch.ops.aten.mul.Tensor(squeeze_8, 1.0000049824865598);  squeeze_8 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_18: f32[64] = torch.ops.aten.mul.Tensor(mul_17, 0.1);  mul_17 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_19: f32[64] = torch.ops.aten.mul.Tensor(primals_169, 0.9);  primals_169 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_13: f32[64] = torch.ops.aten.add.Tensor(mul_18, mul_19);  mul_18 = mul_19 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_8: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_8, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_9: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_8, -1);  unsqueeze_8 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_20: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_14, unsqueeze_9);  mul_14 = unsqueeze_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_10: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_9, -1);  primals_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_11: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_10, -1);  unsqueeze_10 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_14: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_20, unsqueeze_11);  mul_20 = unsqueeze_11 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_2: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_14);  add_14 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_3: f32[64, 256, 56, 56] = torch.ops.aten.convolution.default(relu_2, primals_10, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_15: i64[] = torch.ops.aten.add.Tensor(primals_173, 1);  primals_173 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_3 = torch.ops.aten.var_mean.correction(convolution_3, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_8: f32[1, 256, 1, 1] = var_mean_3[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_9: f32[1, 256, 1, 1] = var_mean_3[1];  var_mean_3 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_16: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_8, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_3: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_3: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_3, getitem_9)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_21: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_3, rsqrt_3);  sub_3 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_9: f32[256] = torch.ops.aten.squeeze.dims(getitem_9, [0, 2, 3]);  getitem_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_10: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_3, [0, 2, 3]);  rsqrt_3 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_22: f32[256] = torch.ops.aten.mul.Tensor(squeeze_9, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_23: f32[256] = torch.ops.aten.mul.Tensor(primals_171, 0.9);  primals_171 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_17: f32[256] = torch.ops.aten.add.Tensor(mul_22, mul_23);  mul_22 = mul_23 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_11: f32[256] = torch.ops.aten.squeeze.dims(getitem_8, [0, 2, 3]);  getitem_8 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_24: f32[256] = torch.ops.aten.mul.Tensor(squeeze_11, 1.0000049824865598);  squeeze_11 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_25: f32[256] = torch.ops.aten.mul.Tensor(mul_24, 0.1);  mul_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_26: f32[256] = torch.ops.aten.mul.Tensor(primals_172, 0.9);  primals_172 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_18: f32[256] = torch.ops.aten.add.Tensor(mul_25, mul_26);  mul_25 = mul_26 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_12: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_11, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_13: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_12, -1);  unsqueeze_12 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_27: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(mul_21, unsqueeze_13);  mul_21 = unsqueeze_13 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_14: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_12, -1);  primals_12 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_15: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_14, -1);  unsqueeze_14 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_19: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(mul_27, unsqueeze_15);  mul_27 = unsqueeze_15 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_4: f32[64, 256, 56, 56] = torch.ops.aten.convolution.default(getitem_2, primals_13, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_20: i64[] = torch.ops.aten.add.Tensor(primals_176, 1);  primals_176 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_4 = torch.ops.aten.var_mean.correction(convolution_4, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_10: f32[1, 256, 1, 1] = var_mean_4[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_11: f32[1, 256, 1, 1] = var_mean_4[1];  var_mean_4 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_21: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_10, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_4: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_21);  add_21 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_4: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_4, getitem_11)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_28: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_4, rsqrt_4);  sub_4 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_12: f32[256] = torch.ops.aten.squeeze.dims(getitem_11, [0, 2, 3]);  getitem_11 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_13: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_4, [0, 2, 3]);  rsqrt_4 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_29: f32[256] = torch.ops.aten.mul.Tensor(squeeze_12, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_30: f32[256] = torch.ops.aten.mul.Tensor(primals_174, 0.9);  primals_174 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_22: f32[256] = torch.ops.aten.add.Tensor(mul_29, mul_30);  mul_29 = mul_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_14: f32[256] = torch.ops.aten.squeeze.dims(getitem_10, [0, 2, 3]);  getitem_10 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_31: f32[256] = torch.ops.aten.mul.Tensor(squeeze_14, 1.0000049824865598);  squeeze_14 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_32: f32[256] = torch.ops.aten.mul.Tensor(mul_31, 0.1);  mul_31 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_33: f32[256] = torch.ops.aten.mul.Tensor(primals_175, 0.9);  primals_175 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_23: f32[256] = torch.ops.aten.add.Tensor(mul_32, mul_33);  mul_32 = mul_33 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_16: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_14, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_17: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_16, -1);  unsqueeze_16 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_34: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(mul_28, unsqueeze_17);  mul_28 = unsqueeze_17 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_18: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_15, -1);  primals_15 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_19: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_18, -1);  unsqueeze_18 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_24: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(mul_34, unsqueeze_19);  mul_34 = unsqueeze_19 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_25: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(add_19, add_24);  add_19 = add_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_3: f32[64, 256, 56, 56] = torch.ops.aten.relu.default(add_25);  add_25 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_5: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_3, primals_16, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_26: i64[] = torch.ops.aten.add.Tensor(primals_179, 1);  primals_179 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_5 = torch.ops.aten.var_mean.correction(convolution_5, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_12: f32[1, 64, 1, 1] = var_mean_5[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_13: f32[1, 64, 1, 1] = var_mean_5[1];  var_mean_5 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_27: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_12, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_5: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_27);  add_27 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_5: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_5, getitem_13)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_35: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_5, rsqrt_5);  sub_5 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_15: f32[64] = torch.ops.aten.squeeze.dims(getitem_13, [0, 2, 3]);  getitem_13 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_16: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_5, [0, 2, 3]);  rsqrt_5 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_36: f32[64] = torch.ops.aten.mul.Tensor(squeeze_15, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_37: f32[64] = torch.ops.aten.mul.Tensor(primals_177, 0.9);  primals_177 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_28: f32[64] = torch.ops.aten.add.Tensor(mul_36, mul_37);  mul_36 = mul_37 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_17: f32[64] = torch.ops.aten.squeeze.dims(getitem_12, [0, 2, 3]);  getitem_12 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_38: f32[64] = torch.ops.aten.mul.Tensor(squeeze_17, 1.0000049824865598);  squeeze_17 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_39: f32[64] = torch.ops.aten.mul.Tensor(mul_38, 0.1);  mul_38 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_40: f32[64] = torch.ops.aten.mul.Tensor(primals_178, 0.9);  primals_178 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_29: f32[64] = torch.ops.aten.add.Tensor(mul_39, mul_40);  mul_39 = mul_40 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_20: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_17, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_21: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_20, -1);  unsqueeze_20 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_41: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_35, unsqueeze_21);  mul_35 = unsqueeze_21 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_22: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_18, -1);  primals_18 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_23: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_22, -1);  unsqueeze_22 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_30: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_41, unsqueeze_23);  mul_41 = unsqueeze_23 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_4: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_30);  add_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_6: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_4, primals_19, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_31: i64[] = torch.ops.aten.add.Tensor(primals_182, 1);  primals_182 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_6 = torch.ops.aten.var_mean.correction(convolution_6, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_14: f32[1, 64, 1, 1] = var_mean_6[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_15: f32[1, 64, 1, 1] = var_mean_6[1];  var_mean_6 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_32: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_14, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_6: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_32);  add_32 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_6: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_6, getitem_15)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_42: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_6, rsqrt_6);  sub_6 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_18: f32[64] = torch.ops.aten.squeeze.dims(getitem_15, [0, 2, 3]);  getitem_15 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_19: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_6, [0, 2, 3]);  rsqrt_6 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_43: f32[64] = torch.ops.aten.mul.Tensor(squeeze_18, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_44: f32[64] = torch.ops.aten.mul.Tensor(primals_180, 0.9);  primals_180 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_33: f32[64] = torch.ops.aten.add.Tensor(mul_43, mul_44);  mul_43 = mul_44 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_20: f32[64] = torch.ops.aten.squeeze.dims(getitem_14, [0, 2, 3]);  getitem_14 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_45: f32[64] = torch.ops.aten.mul.Tensor(squeeze_20, 1.0000049824865598);  squeeze_20 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_46: f32[64] = torch.ops.aten.mul.Tensor(mul_45, 0.1);  mul_45 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_47: f32[64] = torch.ops.aten.mul.Tensor(primals_181, 0.9);  primals_181 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_34: f32[64] = torch.ops.aten.add.Tensor(mul_46, mul_47);  mul_46 = mul_47 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_24: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_20, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_25: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_24, -1);  unsqueeze_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_48: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_42, unsqueeze_25);  mul_42 = unsqueeze_25 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_26: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_21, -1);  primals_21 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_27: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_26, -1);  unsqueeze_26 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_35: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_48, unsqueeze_27);  mul_48 = unsqueeze_27 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_5: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_35);  add_35 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_7: f32[64, 256, 56, 56] = torch.ops.aten.convolution.default(relu_5, primals_22, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_36: i64[] = torch.ops.aten.add.Tensor(primals_185, 1);  primals_185 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_7 = torch.ops.aten.var_mean.correction(convolution_7, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_16: f32[1, 256, 1, 1] = var_mean_7[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_17: f32[1, 256, 1, 1] = var_mean_7[1];  var_mean_7 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_37: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_16, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_7: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_37);  add_37 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_7: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_7, getitem_17)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_49: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_7, rsqrt_7);  sub_7 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_21: f32[256] = torch.ops.aten.squeeze.dims(getitem_17, [0, 2, 3]);  getitem_17 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_22: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_7, [0, 2, 3]);  rsqrt_7 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_50: f32[256] = torch.ops.aten.mul.Tensor(squeeze_21, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_51: f32[256] = torch.ops.aten.mul.Tensor(primals_183, 0.9);  primals_183 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_38: f32[256] = torch.ops.aten.add.Tensor(mul_50, mul_51);  mul_50 = mul_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_23: f32[256] = torch.ops.aten.squeeze.dims(getitem_16, [0, 2, 3]);  getitem_16 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_52: f32[256] = torch.ops.aten.mul.Tensor(squeeze_23, 1.0000049824865598);  squeeze_23 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_53: f32[256] = torch.ops.aten.mul.Tensor(mul_52, 0.1);  mul_52 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_54: f32[256] = torch.ops.aten.mul.Tensor(primals_184, 0.9);  primals_184 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_39: f32[256] = torch.ops.aten.add.Tensor(mul_53, mul_54);  mul_53 = mul_54 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_28: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_23, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_29: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_28, -1);  unsqueeze_28 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_55: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(mul_49, unsqueeze_29);  mul_49 = unsqueeze_29 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_30: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_24, -1);  primals_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_31: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_30, -1);  unsqueeze_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_40: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(mul_55, unsqueeze_31);  mul_55 = unsqueeze_31 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_41: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(add_40, relu_3);  add_40 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_6: f32[64, 256, 56, 56] = torch.ops.aten.relu.default(add_41);  add_41 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_8: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_6, primals_25, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_42: i64[] = torch.ops.aten.add.Tensor(primals_188, 1);  primals_188 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_8 = torch.ops.aten.var_mean.correction(convolution_8, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_18: f32[1, 64, 1, 1] = var_mean_8[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_19: f32[1, 64, 1, 1] = var_mean_8[1];  var_mean_8 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_43: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_18, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_8: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_43);  add_43 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_8: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_8, getitem_19)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_56: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_8, rsqrt_8);  sub_8 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_24: f32[64] = torch.ops.aten.squeeze.dims(getitem_19, [0, 2, 3]);  getitem_19 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_25: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_8, [0, 2, 3]);  rsqrt_8 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_57: f32[64] = torch.ops.aten.mul.Tensor(squeeze_24, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_58: f32[64] = torch.ops.aten.mul.Tensor(primals_186, 0.9);  primals_186 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_44: f32[64] = torch.ops.aten.add.Tensor(mul_57, mul_58);  mul_57 = mul_58 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_26: f32[64] = torch.ops.aten.squeeze.dims(getitem_18, [0, 2, 3]);  getitem_18 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_59: f32[64] = torch.ops.aten.mul.Tensor(squeeze_26, 1.0000049824865598);  squeeze_26 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_60: f32[64] = torch.ops.aten.mul.Tensor(mul_59, 0.1);  mul_59 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_61: f32[64] = torch.ops.aten.mul.Tensor(primals_187, 0.9);  primals_187 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_45: f32[64] = torch.ops.aten.add.Tensor(mul_60, mul_61);  mul_60 = mul_61 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_32: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_26, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_33: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_32, -1);  unsqueeze_32 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_62: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_56, unsqueeze_33);  mul_56 = unsqueeze_33 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_34: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_27, -1);  primals_27 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_35: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_34, -1);  unsqueeze_34 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_46: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_62, unsqueeze_35);  mul_62 = unsqueeze_35 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_7: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_46);  add_46 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_9: f32[64, 64, 56, 56] = torch.ops.aten.convolution.default(relu_7, primals_28, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_47: i64[] = torch.ops.aten.add.Tensor(primals_191, 1);  primals_191 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_9 = torch.ops.aten.var_mean.correction(convolution_9, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_20: f32[1, 64, 1, 1] = var_mean_9[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_21: f32[1, 64, 1, 1] = var_mean_9[1];  var_mean_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_48: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_20, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_9: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_48);  add_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_9: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_9, getitem_21)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_63: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_9, rsqrt_9);  sub_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_27: f32[64] = torch.ops.aten.squeeze.dims(getitem_21, [0, 2, 3]);  getitem_21 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_28: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_9, [0, 2, 3]);  rsqrt_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_64: f32[64] = torch.ops.aten.mul.Tensor(squeeze_27, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_65: f32[64] = torch.ops.aten.mul.Tensor(primals_189, 0.9);  primals_189 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_49: f32[64] = torch.ops.aten.add.Tensor(mul_64, mul_65);  mul_64 = mul_65 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_29: f32[64] = torch.ops.aten.squeeze.dims(getitem_20, [0, 2, 3]);  getitem_20 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_66: f32[64] = torch.ops.aten.mul.Tensor(squeeze_29, 1.0000049824865598);  squeeze_29 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_67: f32[64] = torch.ops.aten.mul.Tensor(mul_66, 0.1);  mul_66 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_68: f32[64] = torch.ops.aten.mul.Tensor(primals_190, 0.9);  primals_190 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_50: f32[64] = torch.ops.aten.add.Tensor(mul_67, mul_68);  mul_67 = mul_68 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_36: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_29, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_37: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_36, -1);  unsqueeze_36 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_69: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(mul_63, unsqueeze_37);  mul_63 = unsqueeze_37 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_38: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_30, -1);  primals_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_39: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_38, -1);  unsqueeze_38 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_51: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(mul_69, unsqueeze_39);  mul_69 = unsqueeze_39 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_8: f32[64, 64, 56, 56] = torch.ops.aten.relu.default(add_51);  add_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_10: f32[64, 256, 56, 56] = torch.ops.aten.convolution.default(relu_8, primals_31, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_52: i64[] = torch.ops.aten.add.Tensor(primals_194, 1);  primals_194 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_10 = torch.ops.aten.var_mean.correction(convolution_10, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_22: f32[1, 256, 1, 1] = var_mean_10[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_23: f32[1, 256, 1, 1] = var_mean_10[1];  var_mean_10 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_53: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_22, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_10: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_53);  add_53 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_10: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_10, getitem_23)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_70: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_10, rsqrt_10);  sub_10 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_30: f32[256] = torch.ops.aten.squeeze.dims(getitem_23, [0, 2, 3]);  getitem_23 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_31: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_10, [0, 2, 3]);  rsqrt_10 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_71: f32[256] = torch.ops.aten.mul.Tensor(squeeze_30, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_72: f32[256] = torch.ops.aten.mul.Tensor(primals_192, 0.9);  primals_192 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_54: f32[256] = torch.ops.aten.add.Tensor(mul_71, mul_72);  mul_71 = mul_72 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_32: f32[256] = torch.ops.aten.squeeze.dims(getitem_22, [0, 2, 3]);  getitem_22 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_73: f32[256] = torch.ops.aten.mul.Tensor(squeeze_32, 1.0000049824865598);  squeeze_32 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_74: f32[256] = torch.ops.aten.mul.Tensor(mul_73, 0.1);  mul_73 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_75: f32[256] = torch.ops.aten.mul.Tensor(primals_193, 0.9);  primals_193 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_55: f32[256] = torch.ops.aten.add.Tensor(mul_74, mul_75);  mul_74 = mul_75 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_40: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_32, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_41: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_40, -1);  unsqueeze_40 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_76: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(mul_70, unsqueeze_41);  mul_70 = unsqueeze_41 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_42: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_33, -1);  primals_33 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_43: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_42, -1);  unsqueeze_42 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_56: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(mul_76, unsqueeze_43);  mul_76 = unsqueeze_43 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_57: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(add_56, relu_6);  add_56 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_9: f32[64, 256, 56, 56] = torch.ops.aten.relu.default(add_57);  add_57 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_11: f32[64, 128, 56, 56] = torch.ops.aten.convolution.default(relu_9, primals_34, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_58: i64[] = torch.ops.aten.add.Tensor(primals_197, 1);  primals_197 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_11 = torch.ops.aten.var_mean.correction(convolution_11, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_24: f32[1, 128, 1, 1] = var_mean_11[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_25: f32[1, 128, 1, 1] = var_mean_11[1];  var_mean_11 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_59: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_24, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_11: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_59);  add_59 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_11: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(convolution_11, getitem_25)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_77: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(sub_11, rsqrt_11);  sub_11 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_33: f32[128] = torch.ops.aten.squeeze.dims(getitem_25, [0, 2, 3]);  getitem_25 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_34: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_11, [0, 2, 3]);  rsqrt_11 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_78: f32[128] = torch.ops.aten.mul.Tensor(squeeze_33, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_79: f32[128] = torch.ops.aten.mul.Tensor(primals_195, 0.9);  primals_195 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_60: f32[128] = torch.ops.aten.add.Tensor(mul_78, mul_79);  mul_78 = mul_79 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_35: f32[128] = torch.ops.aten.squeeze.dims(getitem_24, [0, 2, 3]);  getitem_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_80: f32[128] = torch.ops.aten.mul.Tensor(squeeze_35, 1.0000049824865598);  squeeze_35 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_81: f32[128] = torch.ops.aten.mul.Tensor(mul_80, 0.1);  mul_80 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_82: f32[128] = torch.ops.aten.mul.Tensor(primals_196, 0.9);  primals_196 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_61: f32[128] = torch.ops.aten.add.Tensor(mul_81, mul_82);  mul_81 = mul_82 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_44: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_35, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_45: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_44, -1);  unsqueeze_44 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_83: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(mul_77, unsqueeze_45);  mul_77 = unsqueeze_45 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_46: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_36, -1);  primals_36 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_47: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_46, -1);  unsqueeze_46 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_62: f32[64, 128, 56, 56] = torch.ops.aten.add.Tensor(mul_83, unsqueeze_47);  mul_83 = unsqueeze_47 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_10: f32[64, 128, 56, 56] = torch.ops.aten.relu.default(add_62);  add_62 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_12: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_10, primals_37, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_63: i64[] = torch.ops.aten.add.Tensor(primals_200, 1);  primals_200 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_12 = torch.ops.aten.var_mean.correction(convolution_12, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_26: f32[1, 128, 1, 1] = var_mean_12[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_27: f32[1, 128, 1, 1] = var_mean_12[1];  var_mean_12 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_64: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_26, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_12: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_64);  add_64 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_12: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_12, getitem_27)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_84: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_12, rsqrt_12);  sub_12 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_36: f32[128] = torch.ops.aten.squeeze.dims(getitem_27, [0, 2, 3]);  getitem_27 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_37: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_12, [0, 2, 3]);  rsqrt_12 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_85: f32[128] = torch.ops.aten.mul.Tensor(squeeze_36, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_86: f32[128] = torch.ops.aten.mul.Tensor(primals_198, 0.9);  primals_198 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_65: f32[128] = torch.ops.aten.add.Tensor(mul_85, mul_86);  mul_85 = mul_86 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_38: f32[128] = torch.ops.aten.squeeze.dims(getitem_26, [0, 2, 3]);  getitem_26 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_87: f32[128] = torch.ops.aten.mul.Tensor(squeeze_38, 1.0000199302441455);  squeeze_38 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_88: f32[128] = torch.ops.aten.mul.Tensor(mul_87, 0.1);  mul_87 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_89: f32[128] = torch.ops.aten.mul.Tensor(primals_199, 0.9);  primals_199 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_66: f32[128] = torch.ops.aten.add.Tensor(mul_88, mul_89);  mul_88 = mul_89 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_48: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_38, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_49: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_48, -1);  unsqueeze_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_90: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_84, unsqueeze_49);  mul_84 = unsqueeze_49 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_50: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_39, -1);  primals_39 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_51: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_50, -1);  unsqueeze_50 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_67: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_90, unsqueeze_51);  mul_90 = unsqueeze_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_11: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_67);  add_67 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_13: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_11, primals_40, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_68: i64[] = torch.ops.aten.add.Tensor(primals_203, 1);  primals_203 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_13 = torch.ops.aten.var_mean.correction(convolution_13, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_28: f32[1, 512, 1, 1] = var_mean_13[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_29: f32[1, 512, 1, 1] = var_mean_13[1];  var_mean_13 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_69: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_28, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_13: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_69);  add_69 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_13: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_13, getitem_29)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_91: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_13, rsqrt_13);  sub_13 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_39: f32[512] = torch.ops.aten.squeeze.dims(getitem_29, [0, 2, 3]);  getitem_29 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_40: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_13, [0, 2, 3]);  rsqrt_13 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_92: f32[512] = torch.ops.aten.mul.Tensor(squeeze_39, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_93: f32[512] = torch.ops.aten.mul.Tensor(primals_201, 0.9);  primals_201 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_70: f32[512] = torch.ops.aten.add.Tensor(mul_92, mul_93);  mul_92 = mul_93 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_41: f32[512] = torch.ops.aten.squeeze.dims(getitem_28, [0, 2, 3]);  getitem_28 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_94: f32[512] = torch.ops.aten.mul.Tensor(squeeze_41, 1.0000199302441455);  squeeze_41 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_95: f32[512] = torch.ops.aten.mul.Tensor(mul_94, 0.1);  mul_94 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_96: f32[512] = torch.ops.aten.mul.Tensor(primals_202, 0.9);  primals_202 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_71: f32[512] = torch.ops.aten.add.Tensor(mul_95, mul_96);  mul_95 = mul_96 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_52: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_41, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_53: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_52, -1);  unsqueeze_52 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_97: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_91, unsqueeze_53);  mul_91 = unsqueeze_53 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_54: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_42, -1);  primals_42 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_55: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_54, -1);  unsqueeze_54 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_72: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_97, unsqueeze_55);  mul_97 = unsqueeze_55 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_14: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_9, primals_43, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_73: i64[] = torch.ops.aten.add.Tensor(primals_206, 1);  primals_206 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_14 = torch.ops.aten.var_mean.correction(convolution_14, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_30: f32[1, 512, 1, 1] = var_mean_14[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_31: f32[1, 512, 1, 1] = var_mean_14[1];  var_mean_14 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_74: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_30, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_14: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_74);  add_74 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_14: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_14, getitem_31)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_98: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_14, rsqrt_14);  sub_14 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_42: f32[512] = torch.ops.aten.squeeze.dims(getitem_31, [0, 2, 3]);  getitem_31 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_43: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_14, [0, 2, 3]);  rsqrt_14 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_99: f32[512] = torch.ops.aten.mul.Tensor(squeeze_42, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_100: f32[512] = torch.ops.aten.mul.Tensor(primals_204, 0.9);  primals_204 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_75: f32[512] = torch.ops.aten.add.Tensor(mul_99, mul_100);  mul_99 = mul_100 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_44: f32[512] = torch.ops.aten.squeeze.dims(getitem_30, [0, 2, 3]);  getitem_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_101: f32[512] = torch.ops.aten.mul.Tensor(squeeze_44, 1.0000199302441455);  squeeze_44 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_102: f32[512] = torch.ops.aten.mul.Tensor(mul_101, 0.1);  mul_101 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_103: f32[512] = torch.ops.aten.mul.Tensor(primals_205, 0.9);  primals_205 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_76: f32[512] = torch.ops.aten.add.Tensor(mul_102, mul_103);  mul_102 = mul_103 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_56: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_44, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_57: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_56, -1);  unsqueeze_56 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_104: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_98, unsqueeze_57);  mul_98 = unsqueeze_57 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_58: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_45, -1);  primals_45 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_59: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_58, -1);  unsqueeze_58 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_77: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_104, unsqueeze_59);  mul_104 = unsqueeze_59 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_78: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(add_72, add_77);  add_72 = add_77 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_12: f32[64, 512, 28, 28] = torch.ops.aten.relu.default(add_78);  add_78 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_15: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_12, primals_46, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_79: i64[] = torch.ops.aten.add.Tensor(primals_209, 1);  primals_209 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_15 = torch.ops.aten.var_mean.correction(convolution_15, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_32: f32[1, 128, 1, 1] = var_mean_15[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_33: f32[1, 128, 1, 1] = var_mean_15[1];  var_mean_15 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_80: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_32, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_15: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_80);  add_80 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_15: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_15, getitem_33)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_105: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_15, rsqrt_15);  sub_15 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_45: f32[128] = torch.ops.aten.squeeze.dims(getitem_33, [0, 2, 3]);  getitem_33 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_46: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_15, [0, 2, 3]);  rsqrt_15 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_106: f32[128] = torch.ops.aten.mul.Tensor(squeeze_45, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_107: f32[128] = torch.ops.aten.mul.Tensor(primals_207, 0.9);  primals_207 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_81: f32[128] = torch.ops.aten.add.Tensor(mul_106, mul_107);  mul_106 = mul_107 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_47: f32[128] = torch.ops.aten.squeeze.dims(getitem_32, [0, 2, 3]);  getitem_32 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_108: f32[128] = torch.ops.aten.mul.Tensor(squeeze_47, 1.0000199302441455);  squeeze_47 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_109: f32[128] = torch.ops.aten.mul.Tensor(mul_108, 0.1);  mul_108 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_110: f32[128] = torch.ops.aten.mul.Tensor(primals_208, 0.9);  primals_208 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_82: f32[128] = torch.ops.aten.add.Tensor(mul_109, mul_110);  mul_109 = mul_110 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_60: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_47, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_61: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_60, -1);  unsqueeze_60 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_111: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_105, unsqueeze_61);  mul_105 = unsqueeze_61 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_62: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_48, -1);  primals_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_63: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_62, -1);  unsqueeze_62 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_83: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_111, unsqueeze_63);  mul_111 = unsqueeze_63 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_13: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_83);  add_83 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_16: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_13, primals_49, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_84: i64[] = torch.ops.aten.add.Tensor(primals_212, 1);  primals_212 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_16 = torch.ops.aten.var_mean.correction(convolution_16, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_34: f32[1, 128, 1, 1] = var_mean_16[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_35: f32[1, 128, 1, 1] = var_mean_16[1];  var_mean_16 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_85: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_34, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_16: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_85);  add_85 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_16: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_16, getitem_35)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_112: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_16, rsqrt_16);  sub_16 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_48: f32[128] = torch.ops.aten.squeeze.dims(getitem_35, [0, 2, 3]);  getitem_35 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_49: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_16, [0, 2, 3]);  rsqrt_16 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_113: f32[128] = torch.ops.aten.mul.Tensor(squeeze_48, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_114: f32[128] = torch.ops.aten.mul.Tensor(primals_210, 0.9);  primals_210 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_86: f32[128] = torch.ops.aten.add.Tensor(mul_113, mul_114);  mul_113 = mul_114 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_50: f32[128] = torch.ops.aten.squeeze.dims(getitem_34, [0, 2, 3]);  getitem_34 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_115: f32[128] = torch.ops.aten.mul.Tensor(squeeze_50, 1.0000199302441455);  squeeze_50 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_116: f32[128] = torch.ops.aten.mul.Tensor(mul_115, 0.1);  mul_115 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_117: f32[128] = torch.ops.aten.mul.Tensor(primals_211, 0.9);  primals_211 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_87: f32[128] = torch.ops.aten.add.Tensor(mul_116, mul_117);  mul_116 = mul_117 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_64: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_50, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_65: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_64, -1);  unsqueeze_64 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_118: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_112, unsqueeze_65);  mul_112 = unsqueeze_65 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_66: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_51, -1);  primals_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_67: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_66, -1);  unsqueeze_66 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_88: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_118, unsqueeze_67);  mul_118 = unsqueeze_67 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_14: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_88);  add_88 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_17: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_14, primals_52, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_89: i64[] = torch.ops.aten.add.Tensor(primals_215, 1);  primals_215 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_17 = torch.ops.aten.var_mean.correction(convolution_17, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_36: f32[1, 512, 1, 1] = var_mean_17[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_37: f32[1, 512, 1, 1] = var_mean_17[1];  var_mean_17 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_90: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_36, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_17: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_90);  add_90 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_17: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_17, getitem_37)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_119: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_17, rsqrt_17);  sub_17 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_51: f32[512] = torch.ops.aten.squeeze.dims(getitem_37, [0, 2, 3]);  getitem_37 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_52: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_17, [0, 2, 3]);  rsqrt_17 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_120: f32[512] = torch.ops.aten.mul.Tensor(squeeze_51, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_121: f32[512] = torch.ops.aten.mul.Tensor(primals_213, 0.9);  primals_213 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_91: f32[512] = torch.ops.aten.add.Tensor(mul_120, mul_121);  mul_120 = mul_121 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_53: f32[512] = torch.ops.aten.squeeze.dims(getitem_36, [0, 2, 3]);  getitem_36 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_122: f32[512] = torch.ops.aten.mul.Tensor(squeeze_53, 1.0000199302441455);  squeeze_53 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_123: f32[512] = torch.ops.aten.mul.Tensor(mul_122, 0.1);  mul_122 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_124: f32[512] = torch.ops.aten.mul.Tensor(primals_214, 0.9);  primals_214 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_92: f32[512] = torch.ops.aten.add.Tensor(mul_123, mul_124);  mul_123 = mul_124 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_68: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_53, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_69: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_68, -1);  unsqueeze_68 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_125: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_119, unsqueeze_69);  mul_119 = unsqueeze_69 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_70: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_54, -1);  primals_54 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_71: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_70, -1);  unsqueeze_70 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_93: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_125, unsqueeze_71);  mul_125 = unsqueeze_71 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_94: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(add_93, relu_12);  add_93 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_15: f32[64, 512, 28, 28] = torch.ops.aten.relu.default(add_94);  add_94 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_18: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_15, primals_55, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_95: i64[] = torch.ops.aten.add.Tensor(primals_218, 1);  primals_218 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_18 = torch.ops.aten.var_mean.correction(convolution_18, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_38: f32[1, 128, 1, 1] = var_mean_18[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_39: f32[1, 128, 1, 1] = var_mean_18[1];  var_mean_18 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_96: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_38, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_18: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_96);  add_96 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_18: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_18, getitem_39)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_126: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_18, rsqrt_18);  sub_18 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_54: f32[128] = torch.ops.aten.squeeze.dims(getitem_39, [0, 2, 3]);  getitem_39 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_55: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_18, [0, 2, 3]);  rsqrt_18 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_127: f32[128] = torch.ops.aten.mul.Tensor(squeeze_54, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_128: f32[128] = torch.ops.aten.mul.Tensor(primals_216, 0.9);  primals_216 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_97: f32[128] = torch.ops.aten.add.Tensor(mul_127, mul_128);  mul_127 = mul_128 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_56: f32[128] = torch.ops.aten.squeeze.dims(getitem_38, [0, 2, 3]);  getitem_38 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_129: f32[128] = torch.ops.aten.mul.Tensor(squeeze_56, 1.0000199302441455);  squeeze_56 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_130: f32[128] = torch.ops.aten.mul.Tensor(mul_129, 0.1);  mul_129 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_131: f32[128] = torch.ops.aten.mul.Tensor(primals_217, 0.9);  primals_217 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_98: f32[128] = torch.ops.aten.add.Tensor(mul_130, mul_131);  mul_130 = mul_131 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_72: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_56, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_73: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_72, -1);  unsqueeze_72 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_132: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_126, unsqueeze_73);  mul_126 = unsqueeze_73 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_74: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_57, -1);  primals_57 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_75: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_74, -1);  unsqueeze_74 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_99: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_132, unsqueeze_75);  mul_132 = unsqueeze_75 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_16: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_99);  add_99 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_19: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_16, primals_58, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_100: i64[] = torch.ops.aten.add.Tensor(primals_221, 1);  primals_221 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_19 = torch.ops.aten.var_mean.correction(convolution_19, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_40: f32[1, 128, 1, 1] = var_mean_19[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_41: f32[1, 128, 1, 1] = var_mean_19[1];  var_mean_19 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_101: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_40, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_19: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_101);  add_101 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_19: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_19, getitem_41)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_133: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_19, rsqrt_19);  sub_19 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_57: f32[128] = torch.ops.aten.squeeze.dims(getitem_41, [0, 2, 3]);  getitem_41 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_58: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_19, [0, 2, 3]);  rsqrt_19 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_134: f32[128] = torch.ops.aten.mul.Tensor(squeeze_57, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_135: f32[128] = torch.ops.aten.mul.Tensor(primals_219, 0.9);  primals_219 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_102: f32[128] = torch.ops.aten.add.Tensor(mul_134, mul_135);  mul_134 = mul_135 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_59: f32[128] = torch.ops.aten.squeeze.dims(getitem_40, [0, 2, 3]);  getitem_40 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_136: f32[128] = torch.ops.aten.mul.Tensor(squeeze_59, 1.0000199302441455);  squeeze_59 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_137: f32[128] = torch.ops.aten.mul.Tensor(mul_136, 0.1);  mul_136 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_138: f32[128] = torch.ops.aten.mul.Tensor(primals_220, 0.9);  primals_220 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_103: f32[128] = torch.ops.aten.add.Tensor(mul_137, mul_138);  mul_137 = mul_138 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_76: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_59, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_77: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_76, -1);  unsqueeze_76 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_139: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_133, unsqueeze_77);  mul_133 = unsqueeze_77 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_78: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_60, -1);  primals_60 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_79: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_78, -1);  unsqueeze_78 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_104: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_139, unsqueeze_79);  mul_139 = unsqueeze_79 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_17: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_104);  add_104 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_20: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_17, primals_61, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_105: i64[] = torch.ops.aten.add.Tensor(primals_224, 1);  primals_224 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_20 = torch.ops.aten.var_mean.correction(convolution_20, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_42: f32[1, 512, 1, 1] = var_mean_20[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_43: f32[1, 512, 1, 1] = var_mean_20[1];  var_mean_20 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_106: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_42, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_20: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_106);  add_106 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_20: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_20, getitem_43)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_140: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_20, rsqrt_20);  sub_20 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_60: f32[512] = torch.ops.aten.squeeze.dims(getitem_43, [0, 2, 3]);  getitem_43 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_61: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_20, [0, 2, 3]);  rsqrt_20 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_141: f32[512] = torch.ops.aten.mul.Tensor(squeeze_60, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_142: f32[512] = torch.ops.aten.mul.Tensor(primals_222, 0.9);  primals_222 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_107: f32[512] = torch.ops.aten.add.Tensor(mul_141, mul_142);  mul_141 = mul_142 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_62: f32[512] = torch.ops.aten.squeeze.dims(getitem_42, [0, 2, 3]);  getitem_42 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_143: f32[512] = torch.ops.aten.mul.Tensor(squeeze_62, 1.0000199302441455);  squeeze_62 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_144: f32[512] = torch.ops.aten.mul.Tensor(mul_143, 0.1);  mul_143 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_145: f32[512] = torch.ops.aten.mul.Tensor(primals_223, 0.9);  primals_223 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_108: f32[512] = torch.ops.aten.add.Tensor(mul_144, mul_145);  mul_144 = mul_145 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_80: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_62, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_81: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_80, -1);  unsqueeze_80 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_146: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_140, unsqueeze_81);  mul_140 = unsqueeze_81 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_82: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_63, -1);  primals_63 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_83: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_82, -1);  unsqueeze_82 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_109: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_146, unsqueeze_83);  mul_146 = unsqueeze_83 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_110: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(add_109, relu_15);  add_109 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_18: f32[64, 512, 28, 28] = torch.ops.aten.relu.default(add_110);  add_110 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_21: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_18, primals_64, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_111: i64[] = torch.ops.aten.add.Tensor(primals_227, 1);  primals_227 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_21 = torch.ops.aten.var_mean.correction(convolution_21, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_44: f32[1, 128, 1, 1] = var_mean_21[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_45: f32[1, 128, 1, 1] = var_mean_21[1];  var_mean_21 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_112: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_44, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_21: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_112);  add_112 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_21: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_21, getitem_45)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_147: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_21, rsqrt_21);  sub_21 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_63: f32[128] = torch.ops.aten.squeeze.dims(getitem_45, [0, 2, 3]);  getitem_45 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_64: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_21, [0, 2, 3]);  rsqrt_21 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_148: f32[128] = torch.ops.aten.mul.Tensor(squeeze_63, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_149: f32[128] = torch.ops.aten.mul.Tensor(primals_225, 0.9);  primals_225 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_113: f32[128] = torch.ops.aten.add.Tensor(mul_148, mul_149);  mul_148 = mul_149 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_65: f32[128] = torch.ops.aten.squeeze.dims(getitem_44, [0, 2, 3]);  getitem_44 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_150: f32[128] = torch.ops.aten.mul.Tensor(squeeze_65, 1.0000199302441455);  squeeze_65 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_151: f32[128] = torch.ops.aten.mul.Tensor(mul_150, 0.1);  mul_150 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_152: f32[128] = torch.ops.aten.mul.Tensor(primals_226, 0.9);  primals_226 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_114: f32[128] = torch.ops.aten.add.Tensor(mul_151, mul_152);  mul_151 = mul_152 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_84: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_65, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_85: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_84, -1);  unsqueeze_84 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_153: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_147, unsqueeze_85);  mul_147 = unsqueeze_85 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_86: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_66, -1);  primals_66 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_87: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_86, -1);  unsqueeze_86 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_115: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_153, unsqueeze_87);  mul_153 = unsqueeze_87 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_19: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_115);  add_115 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_22: f32[64, 128, 28, 28] = torch.ops.aten.convolution.default(relu_19, primals_67, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_116: i64[] = torch.ops.aten.add.Tensor(primals_230, 1);  primals_230 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_22 = torch.ops.aten.var_mean.correction(convolution_22, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_46: f32[1, 128, 1, 1] = var_mean_22[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_47: f32[1, 128, 1, 1] = var_mean_22[1];  var_mean_22 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_117: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_46, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_22: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_117);  add_117 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_22: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_22, getitem_47)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_154: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_22, rsqrt_22);  sub_22 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_66: f32[128] = torch.ops.aten.squeeze.dims(getitem_47, [0, 2, 3]);  getitem_47 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_67: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_22, [0, 2, 3]);  rsqrt_22 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_155: f32[128] = torch.ops.aten.mul.Tensor(squeeze_66, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_156: f32[128] = torch.ops.aten.mul.Tensor(primals_228, 0.9);  primals_228 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_118: f32[128] = torch.ops.aten.add.Tensor(mul_155, mul_156);  mul_155 = mul_156 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_68: f32[128] = torch.ops.aten.squeeze.dims(getitem_46, [0, 2, 3]);  getitem_46 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_157: f32[128] = torch.ops.aten.mul.Tensor(squeeze_68, 1.0000199302441455);  squeeze_68 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_158: f32[128] = torch.ops.aten.mul.Tensor(mul_157, 0.1);  mul_157 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_159: f32[128] = torch.ops.aten.mul.Tensor(primals_229, 0.9);  primals_229 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_119: f32[128] = torch.ops.aten.add.Tensor(mul_158, mul_159);  mul_158 = mul_159 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_88: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_68, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_89: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_88, -1);  unsqueeze_88 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_160: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(mul_154, unsqueeze_89);  mul_154 = unsqueeze_89 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_90: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_69, -1);  primals_69 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_91: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_90, -1);  unsqueeze_90 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_120: f32[64, 128, 28, 28] = torch.ops.aten.add.Tensor(mul_160, unsqueeze_91);  mul_160 = unsqueeze_91 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_20: f32[64, 128, 28, 28] = torch.ops.aten.relu.default(add_120);  add_120 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_23: f32[64, 512, 28, 28] = torch.ops.aten.convolution.default(relu_20, primals_70, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_121: i64[] = torch.ops.aten.add.Tensor(primals_233, 1);  primals_233 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_23 = torch.ops.aten.var_mean.correction(convolution_23, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_48: f32[1, 512, 1, 1] = var_mean_23[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_49: f32[1, 512, 1, 1] = var_mean_23[1];  var_mean_23 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_122: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_48, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_23: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_122);  add_122 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_23: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_23, getitem_49)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_161: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_23, rsqrt_23);  sub_23 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_69: f32[512] = torch.ops.aten.squeeze.dims(getitem_49, [0, 2, 3]);  getitem_49 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_70: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_23, [0, 2, 3]);  rsqrt_23 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_162: f32[512] = torch.ops.aten.mul.Tensor(squeeze_69, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_163: f32[512] = torch.ops.aten.mul.Tensor(primals_231, 0.9);  primals_231 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_123: f32[512] = torch.ops.aten.add.Tensor(mul_162, mul_163);  mul_162 = mul_163 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_71: f32[512] = torch.ops.aten.squeeze.dims(getitem_48, [0, 2, 3]);  getitem_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_164: f32[512] = torch.ops.aten.mul.Tensor(squeeze_71, 1.0000199302441455);  squeeze_71 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_165: f32[512] = torch.ops.aten.mul.Tensor(mul_164, 0.1);  mul_164 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_166: f32[512] = torch.ops.aten.mul.Tensor(primals_232, 0.9);  primals_232 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_124: f32[512] = torch.ops.aten.add.Tensor(mul_165, mul_166);  mul_165 = mul_166 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_92: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_71, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_93: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_92, -1);  unsqueeze_92 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_167: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(mul_161, unsqueeze_93);  mul_161 = unsqueeze_93 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_94: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_72, -1);  primals_72 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_95: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_94, -1);  unsqueeze_94 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_125: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(mul_167, unsqueeze_95);  mul_167 = unsqueeze_95 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_126: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(add_125, relu_18);  add_125 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_21: f32[64, 512, 28, 28] = torch.ops.aten.relu.default(add_126);  add_126 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_24: f32[64, 256, 28, 28] = torch.ops.aten.convolution.default(relu_21, primals_73, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_127: i64[] = torch.ops.aten.add.Tensor(primals_236, 1);  primals_236 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_24 = torch.ops.aten.var_mean.correction(convolution_24, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_50: f32[1, 256, 1, 1] = var_mean_24[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_51: f32[1, 256, 1, 1] = var_mean_24[1];  var_mean_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_128: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_50, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_24: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_128);  add_128 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_24: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(convolution_24, getitem_51)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_168: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(sub_24, rsqrt_24);  sub_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_72: f32[256] = torch.ops.aten.squeeze.dims(getitem_51, [0, 2, 3]);  getitem_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_73: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_24, [0, 2, 3]);  rsqrt_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_169: f32[256] = torch.ops.aten.mul.Tensor(squeeze_72, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_170: f32[256] = torch.ops.aten.mul.Tensor(primals_234, 0.9);  primals_234 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_129: f32[256] = torch.ops.aten.add.Tensor(mul_169, mul_170);  mul_169 = mul_170 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_74: f32[256] = torch.ops.aten.squeeze.dims(getitem_50, [0, 2, 3]);  getitem_50 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_171: f32[256] = torch.ops.aten.mul.Tensor(squeeze_74, 1.0000199302441455);  squeeze_74 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_172: f32[256] = torch.ops.aten.mul.Tensor(mul_171, 0.1);  mul_171 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_173: f32[256] = torch.ops.aten.mul.Tensor(primals_235, 0.9);  primals_235 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_130: f32[256] = torch.ops.aten.add.Tensor(mul_172, mul_173);  mul_172 = mul_173 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_96: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_74, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_97: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_96, -1);  unsqueeze_96 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_174: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(mul_168, unsqueeze_97);  mul_168 = unsqueeze_97 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_98: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_75, -1);  primals_75 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_99: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_98, -1);  unsqueeze_98 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_131: f32[64, 256, 28, 28] = torch.ops.aten.add.Tensor(mul_174, unsqueeze_99);  mul_174 = unsqueeze_99 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_22: f32[64, 256, 28, 28] = torch.ops.aten.relu.default(add_131);  add_131 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_25: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_22, primals_76, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_132: i64[] = torch.ops.aten.add.Tensor(primals_239, 1);  primals_239 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_25 = torch.ops.aten.var_mean.correction(convolution_25, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_52: f32[1, 256, 1, 1] = var_mean_25[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_53: f32[1, 256, 1, 1] = var_mean_25[1];  var_mean_25 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_133: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_52, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_25: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_133);  add_133 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_25: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_25, getitem_53)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_175: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_25, rsqrt_25);  sub_25 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_75: f32[256] = torch.ops.aten.squeeze.dims(getitem_53, [0, 2, 3]);  getitem_53 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_76: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_25, [0, 2, 3]);  rsqrt_25 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_176: f32[256] = torch.ops.aten.mul.Tensor(squeeze_75, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_177: f32[256] = torch.ops.aten.mul.Tensor(primals_237, 0.9);  primals_237 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_134: f32[256] = torch.ops.aten.add.Tensor(mul_176, mul_177);  mul_176 = mul_177 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_77: f32[256] = torch.ops.aten.squeeze.dims(getitem_52, [0, 2, 3]);  getitem_52 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_178: f32[256] = torch.ops.aten.mul.Tensor(squeeze_77, 1.0000797257434426);  squeeze_77 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_179: f32[256] = torch.ops.aten.mul.Tensor(mul_178, 0.1);  mul_178 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_180: f32[256] = torch.ops.aten.mul.Tensor(primals_238, 0.9);  primals_238 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_135: f32[256] = torch.ops.aten.add.Tensor(mul_179, mul_180);  mul_179 = mul_180 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_100: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_77, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_101: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_100, -1);  unsqueeze_100 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_181: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_175, unsqueeze_101);  mul_175 = unsqueeze_101 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_102: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_78, -1);  primals_78 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_103: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_102, -1);  unsqueeze_102 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_136: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_181, unsqueeze_103);  mul_181 = unsqueeze_103 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_23: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_136);  add_136 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_26: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_23, primals_79, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_137: i64[] = torch.ops.aten.add.Tensor(primals_242, 1);  primals_242 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_26 = torch.ops.aten.var_mean.correction(convolution_26, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_54: f32[1, 1024, 1, 1] = var_mean_26[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_55: f32[1, 1024, 1, 1] = var_mean_26[1];  var_mean_26 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_138: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_54, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_26: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_138);  add_138 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_26: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_26, getitem_55)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_182: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_26, rsqrt_26);  sub_26 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_78: f32[1024] = torch.ops.aten.squeeze.dims(getitem_55, [0, 2, 3]);  getitem_55 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_79: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_26, [0, 2, 3]);  rsqrt_26 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_183: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_78, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_184: f32[1024] = torch.ops.aten.mul.Tensor(primals_240, 0.9);  primals_240 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_139: f32[1024] = torch.ops.aten.add.Tensor(mul_183, mul_184);  mul_183 = mul_184 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_80: f32[1024] = torch.ops.aten.squeeze.dims(getitem_54, [0, 2, 3]);  getitem_54 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_185: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_80, 1.0000797257434426);  squeeze_80 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_186: f32[1024] = torch.ops.aten.mul.Tensor(mul_185, 0.1);  mul_185 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_187: f32[1024] = torch.ops.aten.mul.Tensor(primals_241, 0.9);  primals_241 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_140: f32[1024] = torch.ops.aten.add.Tensor(mul_186, mul_187);  mul_186 = mul_187 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_104: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_80, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_105: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_104, -1);  unsqueeze_104 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_188: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_182, unsqueeze_105);  mul_182 = unsqueeze_105 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_106: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_81, -1);  primals_81 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_107: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_106, -1);  unsqueeze_106 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_141: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_188, unsqueeze_107);  mul_188 = unsqueeze_107 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_27: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_21, primals_82, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_142: i64[] = torch.ops.aten.add.Tensor(primals_245, 1);  primals_245 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_27 = torch.ops.aten.var_mean.correction(convolution_27, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_56: f32[1, 1024, 1, 1] = var_mean_27[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_57: f32[1, 1024, 1, 1] = var_mean_27[1];  var_mean_27 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_143: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_56, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_27: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_143);  add_143 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_27: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_27, getitem_57)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_189: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_27, rsqrt_27);  sub_27 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_81: f32[1024] = torch.ops.aten.squeeze.dims(getitem_57, [0, 2, 3]);  getitem_57 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_82: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_27, [0, 2, 3]);  rsqrt_27 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_190: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_81, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_191: f32[1024] = torch.ops.aten.mul.Tensor(primals_243, 0.9);  primals_243 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_144: f32[1024] = torch.ops.aten.add.Tensor(mul_190, mul_191);  mul_190 = mul_191 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_83: f32[1024] = torch.ops.aten.squeeze.dims(getitem_56, [0, 2, 3]);  getitem_56 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_192: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_83, 1.0000797257434426);  squeeze_83 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_193: f32[1024] = torch.ops.aten.mul.Tensor(mul_192, 0.1);  mul_192 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_194: f32[1024] = torch.ops.aten.mul.Tensor(primals_244, 0.9);  primals_244 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_145: f32[1024] = torch.ops.aten.add.Tensor(mul_193, mul_194);  mul_193 = mul_194 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_108: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_83, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_109: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_108, -1);  unsqueeze_108 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_195: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_189, unsqueeze_109);  mul_189 = unsqueeze_109 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_110: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_84, -1);  primals_84 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_111: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_110, -1);  unsqueeze_110 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_146: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_195, unsqueeze_111);  mul_195 = unsqueeze_111 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_147: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_141, add_146);  add_141 = add_146 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_24: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_147);  add_147 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_28: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_24, primals_85, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_148: i64[] = torch.ops.aten.add.Tensor(primals_248, 1);  primals_248 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_28 = torch.ops.aten.var_mean.correction(convolution_28, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_58: f32[1, 256, 1, 1] = var_mean_28[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_59: f32[1, 256, 1, 1] = var_mean_28[1];  var_mean_28 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_149: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_58, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_28: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_149);  add_149 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_28: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_28, getitem_59)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_196: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_28, rsqrt_28);  sub_28 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_84: f32[256] = torch.ops.aten.squeeze.dims(getitem_59, [0, 2, 3]);  getitem_59 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_85: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_28, [0, 2, 3]);  rsqrt_28 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_197: f32[256] = torch.ops.aten.mul.Tensor(squeeze_84, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_198: f32[256] = torch.ops.aten.mul.Tensor(primals_246, 0.9);  primals_246 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_150: f32[256] = torch.ops.aten.add.Tensor(mul_197, mul_198);  mul_197 = mul_198 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_86: f32[256] = torch.ops.aten.squeeze.dims(getitem_58, [0, 2, 3]);  getitem_58 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_199: f32[256] = torch.ops.aten.mul.Tensor(squeeze_86, 1.0000797257434426);  squeeze_86 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_200: f32[256] = torch.ops.aten.mul.Tensor(mul_199, 0.1);  mul_199 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_201: f32[256] = torch.ops.aten.mul.Tensor(primals_247, 0.9);  primals_247 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_151: f32[256] = torch.ops.aten.add.Tensor(mul_200, mul_201);  mul_200 = mul_201 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_112: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_86, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_113: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_112, -1);  unsqueeze_112 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_202: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_196, unsqueeze_113);  mul_196 = unsqueeze_113 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_114: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_87, -1);  primals_87 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_115: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_114, -1);  unsqueeze_114 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_152: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_202, unsqueeze_115);  mul_202 = unsqueeze_115 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_25: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_152);  add_152 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_29: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_25, primals_88, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_153: i64[] = torch.ops.aten.add.Tensor(primals_251, 1);  primals_251 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_29 = torch.ops.aten.var_mean.correction(convolution_29, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_60: f32[1, 256, 1, 1] = var_mean_29[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_61: f32[1, 256, 1, 1] = var_mean_29[1];  var_mean_29 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_154: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_60, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_29: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_154);  add_154 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_29: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_29, getitem_61)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_203: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_29, rsqrt_29);  sub_29 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_87: f32[256] = torch.ops.aten.squeeze.dims(getitem_61, [0, 2, 3]);  getitem_61 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_88: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_29, [0, 2, 3]);  rsqrt_29 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_204: f32[256] = torch.ops.aten.mul.Tensor(squeeze_87, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_205: f32[256] = torch.ops.aten.mul.Tensor(primals_249, 0.9);  primals_249 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_155: f32[256] = torch.ops.aten.add.Tensor(mul_204, mul_205);  mul_204 = mul_205 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_89: f32[256] = torch.ops.aten.squeeze.dims(getitem_60, [0, 2, 3]);  getitem_60 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_206: f32[256] = torch.ops.aten.mul.Tensor(squeeze_89, 1.0000797257434426);  squeeze_89 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_207: f32[256] = torch.ops.aten.mul.Tensor(mul_206, 0.1);  mul_206 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_208: f32[256] = torch.ops.aten.mul.Tensor(primals_250, 0.9);  primals_250 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_156: f32[256] = torch.ops.aten.add.Tensor(mul_207, mul_208);  mul_207 = mul_208 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_116: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_89, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_117: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_116, -1);  unsqueeze_116 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_209: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_203, unsqueeze_117);  mul_203 = unsqueeze_117 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_118: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_90, -1);  primals_90 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_119: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_118, -1);  unsqueeze_118 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_157: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_209, unsqueeze_119);  mul_209 = unsqueeze_119 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_26: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_157);  add_157 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_30: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_26, primals_91, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_158: i64[] = torch.ops.aten.add.Tensor(primals_254, 1);  primals_254 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_30 = torch.ops.aten.var_mean.correction(convolution_30, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_62: f32[1, 1024, 1, 1] = var_mean_30[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_63: f32[1, 1024, 1, 1] = var_mean_30[1];  var_mean_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_159: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_62, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_30: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_159);  add_159 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_30: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_30, getitem_63)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_210: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_30, rsqrt_30);  sub_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_90: f32[1024] = torch.ops.aten.squeeze.dims(getitem_63, [0, 2, 3]);  getitem_63 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_91: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_30, [0, 2, 3]);  rsqrt_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_211: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_90, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_212: f32[1024] = torch.ops.aten.mul.Tensor(primals_252, 0.9);  primals_252 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_160: f32[1024] = torch.ops.aten.add.Tensor(mul_211, mul_212);  mul_211 = mul_212 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_92: f32[1024] = torch.ops.aten.squeeze.dims(getitem_62, [0, 2, 3]);  getitem_62 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_213: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_92, 1.0000797257434426);  squeeze_92 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_214: f32[1024] = torch.ops.aten.mul.Tensor(mul_213, 0.1);  mul_213 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_215: f32[1024] = torch.ops.aten.mul.Tensor(primals_253, 0.9);  primals_253 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_161: f32[1024] = torch.ops.aten.add.Tensor(mul_214, mul_215);  mul_214 = mul_215 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_120: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_92, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_121: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_120, -1);  unsqueeze_120 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_216: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_210, unsqueeze_121);  mul_210 = unsqueeze_121 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_122: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_93, -1);  primals_93 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_123: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_122, -1);  unsqueeze_122 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_162: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_216, unsqueeze_123);  mul_216 = unsqueeze_123 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_163: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_162, relu_24);  add_162 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_27: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_163);  add_163 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_31: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_27, primals_94, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_164: i64[] = torch.ops.aten.add.Tensor(primals_257, 1);  primals_257 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_31 = torch.ops.aten.var_mean.correction(convolution_31, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_64: f32[1, 256, 1, 1] = var_mean_31[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_65: f32[1, 256, 1, 1] = var_mean_31[1];  var_mean_31 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_165: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_64, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_31: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_165);  add_165 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_31: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_31, getitem_65)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_217: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_31, rsqrt_31);  sub_31 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_93: f32[256] = torch.ops.aten.squeeze.dims(getitem_65, [0, 2, 3]);  getitem_65 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_94: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_31, [0, 2, 3]);  rsqrt_31 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_218: f32[256] = torch.ops.aten.mul.Tensor(squeeze_93, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_219: f32[256] = torch.ops.aten.mul.Tensor(primals_255, 0.9);  primals_255 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_166: f32[256] = torch.ops.aten.add.Tensor(mul_218, mul_219);  mul_218 = mul_219 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_95: f32[256] = torch.ops.aten.squeeze.dims(getitem_64, [0, 2, 3]);  getitem_64 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_220: f32[256] = torch.ops.aten.mul.Tensor(squeeze_95, 1.0000797257434426);  squeeze_95 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_221: f32[256] = torch.ops.aten.mul.Tensor(mul_220, 0.1);  mul_220 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_222: f32[256] = torch.ops.aten.mul.Tensor(primals_256, 0.9);  primals_256 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_167: f32[256] = torch.ops.aten.add.Tensor(mul_221, mul_222);  mul_221 = mul_222 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_124: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_95, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_125: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_124, -1);  unsqueeze_124 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_223: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_217, unsqueeze_125);  mul_217 = unsqueeze_125 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_126: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_96, -1);  primals_96 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_127: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_126, -1);  unsqueeze_126 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_168: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_223, unsqueeze_127);  mul_223 = unsqueeze_127 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_28: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_168);  add_168 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_32: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_28, primals_97, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_169: i64[] = torch.ops.aten.add.Tensor(primals_260, 1);  primals_260 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_32 = torch.ops.aten.var_mean.correction(convolution_32, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_66: f32[1, 256, 1, 1] = var_mean_32[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_67: f32[1, 256, 1, 1] = var_mean_32[1];  var_mean_32 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_170: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_66, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_32: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_170);  add_170 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_32: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_32, getitem_67)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_224: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_32, rsqrt_32);  sub_32 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_96: f32[256] = torch.ops.aten.squeeze.dims(getitem_67, [0, 2, 3]);  getitem_67 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_97: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_32, [0, 2, 3]);  rsqrt_32 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_225: f32[256] = torch.ops.aten.mul.Tensor(squeeze_96, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_226: f32[256] = torch.ops.aten.mul.Tensor(primals_258, 0.9);  primals_258 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_171: f32[256] = torch.ops.aten.add.Tensor(mul_225, mul_226);  mul_225 = mul_226 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_98: f32[256] = torch.ops.aten.squeeze.dims(getitem_66, [0, 2, 3]);  getitem_66 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_227: f32[256] = torch.ops.aten.mul.Tensor(squeeze_98, 1.0000797257434426);  squeeze_98 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_228: f32[256] = torch.ops.aten.mul.Tensor(mul_227, 0.1);  mul_227 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_229: f32[256] = torch.ops.aten.mul.Tensor(primals_259, 0.9);  primals_259 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_172: f32[256] = torch.ops.aten.add.Tensor(mul_228, mul_229);  mul_228 = mul_229 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_128: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_98, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_129: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_128, -1);  unsqueeze_128 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_230: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_224, unsqueeze_129);  mul_224 = unsqueeze_129 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_130: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_99, -1);  primals_99 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_131: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_130, -1);  unsqueeze_130 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_173: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_230, unsqueeze_131);  mul_230 = unsqueeze_131 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_29: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_173);  add_173 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_33: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_29, primals_100, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_174: i64[] = torch.ops.aten.add.Tensor(primals_263, 1);  primals_263 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_33 = torch.ops.aten.var_mean.correction(convolution_33, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_68: f32[1, 1024, 1, 1] = var_mean_33[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_69: f32[1, 1024, 1, 1] = var_mean_33[1];  var_mean_33 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_175: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_68, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_33: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_175);  add_175 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_33: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_33, getitem_69)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_231: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_33, rsqrt_33);  sub_33 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_99: f32[1024] = torch.ops.aten.squeeze.dims(getitem_69, [0, 2, 3]);  getitem_69 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_100: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_33, [0, 2, 3]);  rsqrt_33 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_232: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_99, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_233: f32[1024] = torch.ops.aten.mul.Tensor(primals_261, 0.9);  primals_261 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_176: f32[1024] = torch.ops.aten.add.Tensor(mul_232, mul_233);  mul_232 = mul_233 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_101: f32[1024] = torch.ops.aten.squeeze.dims(getitem_68, [0, 2, 3]);  getitem_68 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_234: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_101, 1.0000797257434426);  squeeze_101 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_235: f32[1024] = torch.ops.aten.mul.Tensor(mul_234, 0.1);  mul_234 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_236: f32[1024] = torch.ops.aten.mul.Tensor(primals_262, 0.9);  primals_262 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_177: f32[1024] = torch.ops.aten.add.Tensor(mul_235, mul_236);  mul_235 = mul_236 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_132: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_101, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_133: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_132, -1);  unsqueeze_132 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_237: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_231, unsqueeze_133);  mul_231 = unsqueeze_133 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_134: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_102, -1);  primals_102 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_135: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_134, -1);  unsqueeze_134 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_178: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_237, unsqueeze_135);  mul_237 = unsqueeze_135 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_179: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_178, relu_27);  add_178 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_30: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_179);  add_179 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_34: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_30, primals_103, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_180: i64[] = torch.ops.aten.add.Tensor(primals_266, 1);  primals_266 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_34 = torch.ops.aten.var_mean.correction(convolution_34, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_70: f32[1, 256, 1, 1] = var_mean_34[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_71: f32[1, 256, 1, 1] = var_mean_34[1];  var_mean_34 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_181: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_70, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_34: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_181);  add_181 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_34: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_34, getitem_71)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_238: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_34, rsqrt_34);  sub_34 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_102: f32[256] = torch.ops.aten.squeeze.dims(getitem_71, [0, 2, 3]);  getitem_71 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_103: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_34, [0, 2, 3]);  rsqrt_34 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_239: f32[256] = torch.ops.aten.mul.Tensor(squeeze_102, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_240: f32[256] = torch.ops.aten.mul.Tensor(primals_264, 0.9);  primals_264 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_182: f32[256] = torch.ops.aten.add.Tensor(mul_239, mul_240);  mul_239 = mul_240 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_104: f32[256] = torch.ops.aten.squeeze.dims(getitem_70, [0, 2, 3]);  getitem_70 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_241: f32[256] = torch.ops.aten.mul.Tensor(squeeze_104, 1.0000797257434426);  squeeze_104 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_242: f32[256] = torch.ops.aten.mul.Tensor(mul_241, 0.1);  mul_241 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_243: f32[256] = torch.ops.aten.mul.Tensor(primals_265, 0.9);  primals_265 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_183: f32[256] = torch.ops.aten.add.Tensor(mul_242, mul_243);  mul_242 = mul_243 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_136: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_104, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_137: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_136, -1);  unsqueeze_136 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_244: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_238, unsqueeze_137);  mul_238 = unsqueeze_137 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_138: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_105, -1);  primals_105 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_139: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_138, -1);  unsqueeze_138 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_184: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_244, unsqueeze_139);  mul_244 = unsqueeze_139 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_31: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_184);  add_184 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_35: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_31, primals_106, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_185: i64[] = torch.ops.aten.add.Tensor(primals_269, 1);  primals_269 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_35 = torch.ops.aten.var_mean.correction(convolution_35, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_72: f32[1, 256, 1, 1] = var_mean_35[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_73: f32[1, 256, 1, 1] = var_mean_35[1];  var_mean_35 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_186: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_72, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_35: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_186);  add_186 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_35: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_35, getitem_73)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_245: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_35, rsqrt_35);  sub_35 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_105: f32[256] = torch.ops.aten.squeeze.dims(getitem_73, [0, 2, 3]);  getitem_73 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_106: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_35, [0, 2, 3]);  rsqrt_35 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_246: f32[256] = torch.ops.aten.mul.Tensor(squeeze_105, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_247: f32[256] = torch.ops.aten.mul.Tensor(primals_267, 0.9);  primals_267 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_187: f32[256] = torch.ops.aten.add.Tensor(mul_246, mul_247);  mul_246 = mul_247 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_107: f32[256] = torch.ops.aten.squeeze.dims(getitem_72, [0, 2, 3]);  getitem_72 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_248: f32[256] = torch.ops.aten.mul.Tensor(squeeze_107, 1.0000797257434426);  squeeze_107 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_249: f32[256] = torch.ops.aten.mul.Tensor(mul_248, 0.1);  mul_248 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_250: f32[256] = torch.ops.aten.mul.Tensor(primals_268, 0.9);  primals_268 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_188: f32[256] = torch.ops.aten.add.Tensor(mul_249, mul_250);  mul_249 = mul_250 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_140: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_107, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_141: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_140, -1);  unsqueeze_140 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_251: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_245, unsqueeze_141);  mul_245 = unsqueeze_141 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_142: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_108, -1);  primals_108 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_143: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_142, -1);  unsqueeze_142 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_189: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_251, unsqueeze_143);  mul_251 = unsqueeze_143 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_32: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_189);  add_189 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_36: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_32, primals_109, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_190: i64[] = torch.ops.aten.add.Tensor(primals_272, 1);  primals_272 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_36 = torch.ops.aten.var_mean.correction(convolution_36, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_74: f32[1, 1024, 1, 1] = var_mean_36[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_75: f32[1, 1024, 1, 1] = var_mean_36[1];  var_mean_36 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_191: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_74, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_36: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_191);  add_191 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_36: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_36, getitem_75)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_252: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_36, rsqrt_36);  sub_36 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_108: f32[1024] = torch.ops.aten.squeeze.dims(getitem_75, [0, 2, 3]);  getitem_75 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_109: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_36, [0, 2, 3]);  rsqrt_36 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_253: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_108, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_254: f32[1024] = torch.ops.aten.mul.Tensor(primals_270, 0.9);  primals_270 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_192: f32[1024] = torch.ops.aten.add.Tensor(mul_253, mul_254);  mul_253 = mul_254 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_110: f32[1024] = torch.ops.aten.squeeze.dims(getitem_74, [0, 2, 3]);  getitem_74 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_255: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_110, 1.0000797257434426);  squeeze_110 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_256: f32[1024] = torch.ops.aten.mul.Tensor(mul_255, 0.1);  mul_255 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_257: f32[1024] = torch.ops.aten.mul.Tensor(primals_271, 0.9);  primals_271 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_193: f32[1024] = torch.ops.aten.add.Tensor(mul_256, mul_257);  mul_256 = mul_257 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_144: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_110, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_145: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_144, -1);  unsqueeze_144 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_258: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_252, unsqueeze_145);  mul_252 = unsqueeze_145 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_146: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_111, -1);  primals_111 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_147: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_146, -1);  unsqueeze_146 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_194: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_258, unsqueeze_147);  mul_258 = unsqueeze_147 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_195: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_194, relu_30);  add_194 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_33: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_195);  add_195 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_37: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_33, primals_112, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_196: i64[] = torch.ops.aten.add.Tensor(primals_275, 1);  primals_275 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_37 = torch.ops.aten.var_mean.correction(convolution_37, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_76: f32[1, 256, 1, 1] = var_mean_37[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_77: f32[1, 256, 1, 1] = var_mean_37[1];  var_mean_37 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_197: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_76, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_37: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_197);  add_197 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_37: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_37, getitem_77)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_259: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_37, rsqrt_37);  sub_37 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_111: f32[256] = torch.ops.aten.squeeze.dims(getitem_77, [0, 2, 3]);  getitem_77 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_112: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_37, [0, 2, 3]);  rsqrt_37 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_260: f32[256] = torch.ops.aten.mul.Tensor(squeeze_111, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_261: f32[256] = torch.ops.aten.mul.Tensor(primals_273, 0.9);  primals_273 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_198: f32[256] = torch.ops.aten.add.Tensor(mul_260, mul_261);  mul_260 = mul_261 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_113: f32[256] = torch.ops.aten.squeeze.dims(getitem_76, [0, 2, 3]);  getitem_76 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_262: f32[256] = torch.ops.aten.mul.Tensor(squeeze_113, 1.0000797257434426);  squeeze_113 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_263: f32[256] = torch.ops.aten.mul.Tensor(mul_262, 0.1);  mul_262 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_264: f32[256] = torch.ops.aten.mul.Tensor(primals_274, 0.9);  primals_274 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_199: f32[256] = torch.ops.aten.add.Tensor(mul_263, mul_264);  mul_263 = mul_264 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_148: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_113, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_149: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_148, -1);  unsqueeze_148 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_265: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_259, unsqueeze_149);  mul_259 = unsqueeze_149 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_150: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_114, -1);  primals_114 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_151: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_150, -1);  unsqueeze_150 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_200: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_265, unsqueeze_151);  mul_265 = unsqueeze_151 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_34: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_200);  add_200 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_38: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_34, primals_115, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_201: i64[] = torch.ops.aten.add.Tensor(primals_278, 1);  primals_278 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_38 = torch.ops.aten.var_mean.correction(convolution_38, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_78: f32[1, 256, 1, 1] = var_mean_38[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_79: f32[1, 256, 1, 1] = var_mean_38[1];  var_mean_38 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_202: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_78, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_38: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_202);  add_202 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_38: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_38, getitem_79)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_266: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_38, rsqrt_38);  sub_38 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_114: f32[256] = torch.ops.aten.squeeze.dims(getitem_79, [0, 2, 3]);  getitem_79 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_115: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_38, [0, 2, 3]);  rsqrt_38 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_267: f32[256] = torch.ops.aten.mul.Tensor(squeeze_114, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_268: f32[256] = torch.ops.aten.mul.Tensor(primals_276, 0.9);  primals_276 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_203: f32[256] = torch.ops.aten.add.Tensor(mul_267, mul_268);  mul_267 = mul_268 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_116: f32[256] = torch.ops.aten.squeeze.dims(getitem_78, [0, 2, 3]);  getitem_78 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_269: f32[256] = torch.ops.aten.mul.Tensor(squeeze_116, 1.0000797257434426);  squeeze_116 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_270: f32[256] = torch.ops.aten.mul.Tensor(mul_269, 0.1);  mul_269 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_271: f32[256] = torch.ops.aten.mul.Tensor(primals_277, 0.9);  primals_277 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_204: f32[256] = torch.ops.aten.add.Tensor(mul_270, mul_271);  mul_270 = mul_271 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_152: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_116, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_153: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_152, -1);  unsqueeze_152 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_272: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_266, unsqueeze_153);  mul_266 = unsqueeze_153 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_154: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_117, -1);  primals_117 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_155: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_154, -1);  unsqueeze_154 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_205: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_272, unsqueeze_155);  mul_272 = unsqueeze_155 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_35: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_205);  add_205 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_39: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_35, primals_118, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_206: i64[] = torch.ops.aten.add.Tensor(primals_281, 1);  primals_281 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_39 = torch.ops.aten.var_mean.correction(convolution_39, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_80: f32[1, 1024, 1, 1] = var_mean_39[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_81: f32[1, 1024, 1, 1] = var_mean_39[1];  var_mean_39 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_207: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_80, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_39: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_207);  add_207 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_39: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_39, getitem_81)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_273: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_39, rsqrt_39);  sub_39 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_117: f32[1024] = torch.ops.aten.squeeze.dims(getitem_81, [0, 2, 3]);  getitem_81 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_118: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_39, [0, 2, 3]);  rsqrt_39 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_274: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_117, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_275: f32[1024] = torch.ops.aten.mul.Tensor(primals_279, 0.9);  primals_279 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_208: f32[1024] = torch.ops.aten.add.Tensor(mul_274, mul_275);  mul_274 = mul_275 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_119: f32[1024] = torch.ops.aten.squeeze.dims(getitem_80, [0, 2, 3]);  getitem_80 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_276: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_119, 1.0000797257434426);  squeeze_119 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_277: f32[1024] = torch.ops.aten.mul.Tensor(mul_276, 0.1);  mul_276 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_278: f32[1024] = torch.ops.aten.mul.Tensor(primals_280, 0.9);  primals_280 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_209: f32[1024] = torch.ops.aten.add.Tensor(mul_277, mul_278);  mul_277 = mul_278 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_156: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_119, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_157: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_156, -1);  unsqueeze_156 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_279: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_273, unsqueeze_157);  mul_273 = unsqueeze_157 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_158: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_120, -1);  primals_120 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_159: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_158, -1);  unsqueeze_158 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_210: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_279, unsqueeze_159);  mul_279 = unsqueeze_159 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_211: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_210, relu_33);  add_210 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_36: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_211);  add_211 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_40: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_36, primals_121, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_212: i64[] = torch.ops.aten.add.Tensor(primals_284, 1);  primals_284 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_40 = torch.ops.aten.var_mean.correction(convolution_40, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_82: f32[1, 256, 1, 1] = var_mean_40[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_83: f32[1, 256, 1, 1] = var_mean_40[1];  var_mean_40 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_213: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_82, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_40: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_213);  add_213 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_40: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_40, getitem_83)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_280: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_40, rsqrt_40);  sub_40 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_120: f32[256] = torch.ops.aten.squeeze.dims(getitem_83, [0, 2, 3]);  getitem_83 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_121: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_40, [0, 2, 3]);  rsqrt_40 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_281: f32[256] = torch.ops.aten.mul.Tensor(squeeze_120, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_282: f32[256] = torch.ops.aten.mul.Tensor(primals_282, 0.9);  primals_282 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_214: f32[256] = torch.ops.aten.add.Tensor(mul_281, mul_282);  mul_281 = mul_282 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_122: f32[256] = torch.ops.aten.squeeze.dims(getitem_82, [0, 2, 3]);  getitem_82 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_283: f32[256] = torch.ops.aten.mul.Tensor(squeeze_122, 1.0000797257434426);  squeeze_122 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_284: f32[256] = torch.ops.aten.mul.Tensor(mul_283, 0.1);  mul_283 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_285: f32[256] = torch.ops.aten.mul.Tensor(primals_283, 0.9);  primals_283 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_215: f32[256] = torch.ops.aten.add.Tensor(mul_284, mul_285);  mul_284 = mul_285 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_160: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_122, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_161: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_160, -1);  unsqueeze_160 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_286: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_280, unsqueeze_161);  mul_280 = unsqueeze_161 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_162: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_123, -1);  primals_123 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_163: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_162, -1);  unsqueeze_162 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_216: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_286, unsqueeze_163);  mul_286 = unsqueeze_163 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_37: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_216);  add_216 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_41: f32[64, 256, 14, 14] = torch.ops.aten.convolution.default(relu_37, primals_124, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_217: i64[] = torch.ops.aten.add.Tensor(primals_287, 1);  primals_287 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_41 = torch.ops.aten.var_mean.correction(convolution_41, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_84: f32[1, 256, 1, 1] = var_mean_41[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_85: f32[1, 256, 1, 1] = var_mean_41[1];  var_mean_41 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_218: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_84, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_41: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_218);  add_218 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_41: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_41, getitem_85)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_287: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_41, rsqrt_41);  sub_41 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_123: f32[256] = torch.ops.aten.squeeze.dims(getitem_85, [0, 2, 3]);  getitem_85 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_124: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_41, [0, 2, 3]);  rsqrt_41 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_288: f32[256] = torch.ops.aten.mul.Tensor(squeeze_123, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_289: f32[256] = torch.ops.aten.mul.Tensor(primals_285, 0.9);  primals_285 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_219: f32[256] = torch.ops.aten.add.Tensor(mul_288, mul_289);  mul_288 = mul_289 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_125: f32[256] = torch.ops.aten.squeeze.dims(getitem_84, [0, 2, 3]);  getitem_84 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_290: f32[256] = torch.ops.aten.mul.Tensor(squeeze_125, 1.0000797257434426);  squeeze_125 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_291: f32[256] = torch.ops.aten.mul.Tensor(mul_290, 0.1);  mul_290 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_292: f32[256] = torch.ops.aten.mul.Tensor(primals_286, 0.9);  primals_286 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_220: f32[256] = torch.ops.aten.add.Tensor(mul_291, mul_292);  mul_291 = mul_292 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_164: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_125, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_165: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_164, -1);  unsqueeze_164 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_293: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(mul_287, unsqueeze_165);  mul_287 = unsqueeze_165 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_166: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_126, -1);  primals_126 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_167: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_166, -1);  unsqueeze_166 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_221: f32[64, 256, 14, 14] = torch.ops.aten.add.Tensor(mul_293, unsqueeze_167);  mul_293 = unsqueeze_167 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_38: f32[64, 256, 14, 14] = torch.ops.aten.relu.default(add_221);  add_221 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_42: f32[64, 1024, 14, 14] = torch.ops.aten.convolution.default(relu_38, primals_127, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_222: i64[] = torch.ops.aten.add.Tensor(primals_290, 1);  primals_290 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_42 = torch.ops.aten.var_mean.correction(convolution_42, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_86: f32[1, 1024, 1, 1] = var_mean_42[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_87: f32[1, 1024, 1, 1] = var_mean_42[1];  var_mean_42 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_223: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_86, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_42: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_223);  add_223 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_42: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_42, getitem_87)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_294: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_42, rsqrt_42);  sub_42 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_126: f32[1024] = torch.ops.aten.squeeze.dims(getitem_87, [0, 2, 3]);  getitem_87 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_127: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_42, [0, 2, 3]);  rsqrt_42 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_295: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_126, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_296: f32[1024] = torch.ops.aten.mul.Tensor(primals_288, 0.9);  primals_288 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_224: f32[1024] = torch.ops.aten.add.Tensor(mul_295, mul_296);  mul_295 = mul_296 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_128: f32[1024] = torch.ops.aten.squeeze.dims(getitem_86, [0, 2, 3]);  getitem_86 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_297: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_128, 1.0000797257434426);  squeeze_128 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_298: f32[1024] = torch.ops.aten.mul.Tensor(mul_297, 0.1);  mul_297 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_299: f32[1024] = torch.ops.aten.mul.Tensor(primals_289, 0.9);  primals_289 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_225: f32[1024] = torch.ops.aten.add.Tensor(mul_298, mul_299);  mul_298 = mul_299 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_168: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_128, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_169: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_168, -1);  unsqueeze_168 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_300: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(mul_294, unsqueeze_169);  mul_294 = unsqueeze_169 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_170: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_129, -1);  primals_129 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_171: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_170, -1);  unsqueeze_170 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_226: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(mul_300, unsqueeze_171);  mul_300 = unsqueeze_171 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_227: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(add_226, relu_36);  add_226 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_39: f32[64, 1024, 14, 14] = torch.ops.aten.relu.default(add_227);  add_227 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_43: f32[64, 512, 14, 14] = torch.ops.aten.convolution.default(relu_39, primals_130, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_228: i64[] = torch.ops.aten.add.Tensor(primals_293, 1);  primals_293 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_43 = torch.ops.aten.var_mean.correction(convolution_43, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_88: f32[1, 512, 1, 1] = var_mean_43[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_89: f32[1, 512, 1, 1] = var_mean_43[1];  var_mean_43 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_229: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_88, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_43: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_229);  add_229 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_43: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(convolution_43, getitem_89)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_301: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(sub_43, rsqrt_43);  sub_43 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_129: f32[512] = torch.ops.aten.squeeze.dims(getitem_89, [0, 2, 3]);  getitem_89 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_130: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_43, [0, 2, 3]);  rsqrt_43 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_302: f32[512] = torch.ops.aten.mul.Tensor(squeeze_129, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_303: f32[512] = torch.ops.aten.mul.Tensor(primals_291, 0.9);  primals_291 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_230: f32[512] = torch.ops.aten.add.Tensor(mul_302, mul_303);  mul_302 = mul_303 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_131: f32[512] = torch.ops.aten.squeeze.dims(getitem_88, [0, 2, 3]);  getitem_88 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_304: f32[512] = torch.ops.aten.mul.Tensor(squeeze_131, 1.0000797257434426);  squeeze_131 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_305: f32[512] = torch.ops.aten.mul.Tensor(mul_304, 0.1);  mul_304 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_306: f32[512] = torch.ops.aten.mul.Tensor(primals_292, 0.9);  primals_292 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_231: f32[512] = torch.ops.aten.add.Tensor(mul_305, mul_306);  mul_305 = mul_306 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_172: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_131, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_173: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_172, -1);  unsqueeze_172 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_307: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(mul_301, unsqueeze_173);  mul_301 = unsqueeze_173 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_174: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_132, -1);  primals_132 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_175: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_174, -1);  unsqueeze_174 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_232: f32[64, 512, 14, 14] = torch.ops.aten.add.Tensor(mul_307, unsqueeze_175);  mul_307 = unsqueeze_175 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_40: f32[64, 512, 14, 14] = torch.ops.aten.relu.default(add_232);  add_232 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_44: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_40, primals_133, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_233: i64[] = torch.ops.aten.add.Tensor(primals_296, 1);  primals_296 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_44 = torch.ops.aten.var_mean.correction(convolution_44, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_90: f32[1, 512, 1, 1] = var_mean_44[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_91: f32[1, 512, 1, 1] = var_mean_44[1];  var_mean_44 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_234: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_90, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_44: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_234);  add_234 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_44: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_44, getitem_91)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_308: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_44, rsqrt_44);  sub_44 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_132: f32[512] = torch.ops.aten.squeeze.dims(getitem_91, [0, 2, 3]);  getitem_91 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_133: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_44, [0, 2, 3]);  rsqrt_44 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_309: f32[512] = torch.ops.aten.mul.Tensor(squeeze_132, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_310: f32[512] = torch.ops.aten.mul.Tensor(primals_294, 0.9);  primals_294 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_235: f32[512] = torch.ops.aten.add.Tensor(mul_309, mul_310);  mul_309 = mul_310 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_134: f32[512] = torch.ops.aten.squeeze.dims(getitem_90, [0, 2, 3]);  getitem_90 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_311: f32[512] = torch.ops.aten.mul.Tensor(squeeze_134, 1.0003189792663476);  squeeze_134 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_312: f32[512] = torch.ops.aten.mul.Tensor(mul_311, 0.1);  mul_311 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_313: f32[512] = torch.ops.aten.mul.Tensor(primals_295, 0.9);  primals_295 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_236: f32[512] = torch.ops.aten.add.Tensor(mul_312, mul_313);  mul_312 = mul_313 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_176: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_134, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_177: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_176, -1);  unsqueeze_176 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_314: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_308, unsqueeze_177);  mul_308 = unsqueeze_177 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_178: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_135, -1);  primals_135 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_179: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_178, -1);  unsqueeze_178 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_237: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_314, unsqueeze_179);  mul_314 = unsqueeze_179 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_41: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_237);  add_237 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_45: f32[64, 2048, 7, 7] = torch.ops.aten.convolution.default(relu_41, primals_136, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_238: i64[] = torch.ops.aten.add.Tensor(primals_299, 1);  primals_299 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_45 = torch.ops.aten.var_mean.correction(convolution_45, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_92: f32[1, 2048, 1, 1] = var_mean_45[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_93: f32[1, 2048, 1, 1] = var_mean_45[1];  var_mean_45 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_239: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_92, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_45: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_239);  add_239 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_45: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_45, getitem_93)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_315: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_45, rsqrt_45);  sub_45 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_135: f32[2048] = torch.ops.aten.squeeze.dims(getitem_93, [0, 2, 3]);  getitem_93 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_136: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_45, [0, 2, 3]);  rsqrt_45 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_316: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_135, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_317: f32[2048] = torch.ops.aten.mul.Tensor(primals_297, 0.9);  primals_297 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_240: f32[2048] = torch.ops.aten.add.Tensor(mul_316, mul_317);  mul_316 = mul_317 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_137: f32[2048] = torch.ops.aten.squeeze.dims(getitem_92, [0, 2, 3]);  getitem_92 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_318: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_137, 1.0003189792663476);  squeeze_137 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_319: f32[2048] = torch.ops.aten.mul.Tensor(mul_318, 0.1);  mul_318 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_320: f32[2048] = torch.ops.aten.mul.Tensor(primals_298, 0.9);  primals_298 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_241: f32[2048] = torch.ops.aten.add.Tensor(mul_319, mul_320);  mul_319 = mul_320 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_180: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_137, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_181: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_180, -1);  unsqueeze_180 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_321: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(mul_315, unsqueeze_181);  mul_315 = unsqueeze_181 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_182: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_138, -1);  primals_138 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_183: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_182, -1);  unsqueeze_182 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_242: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(mul_321, unsqueeze_183);  mul_321 = unsqueeze_183 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_46: f32[64, 2048, 7, 7] = torch.ops.aten.convolution.default(relu_39, primals_139, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_243: i64[] = torch.ops.aten.add.Tensor(primals_302, 1);  primals_302 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_46 = torch.ops.aten.var_mean.correction(convolution_46, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_94: f32[1, 2048, 1, 1] = var_mean_46[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_95: f32[1, 2048, 1, 1] = var_mean_46[1];  var_mean_46 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_244: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_94, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_46: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_244);  add_244 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_46: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_46, getitem_95)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_322: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_46, rsqrt_46);  sub_46 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_138: f32[2048] = torch.ops.aten.squeeze.dims(getitem_95, [0, 2, 3]);  getitem_95 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_139: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_46, [0, 2, 3]);  rsqrt_46 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_323: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_138, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_324: f32[2048] = torch.ops.aten.mul.Tensor(primals_300, 0.9);  primals_300 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_245: f32[2048] = torch.ops.aten.add.Tensor(mul_323, mul_324);  mul_323 = mul_324 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_140: f32[2048] = torch.ops.aten.squeeze.dims(getitem_94, [0, 2, 3]);  getitem_94 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_325: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_140, 1.0003189792663476);  squeeze_140 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_326: f32[2048] = torch.ops.aten.mul.Tensor(mul_325, 0.1);  mul_325 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_327: f32[2048] = torch.ops.aten.mul.Tensor(primals_301, 0.9);  primals_301 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_246: f32[2048] = torch.ops.aten.add.Tensor(mul_326, mul_327);  mul_326 = mul_327 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_184: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_140, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_185: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_184, -1);  unsqueeze_184 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_328: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(mul_322, unsqueeze_185);  mul_322 = unsqueeze_185 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_186: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_141, -1);  primals_141 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_187: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_186, -1);  unsqueeze_186 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_247: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(mul_328, unsqueeze_187);  mul_328 = unsqueeze_187 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_248: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(add_242, add_247);  add_242 = add_247 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_42: f32[64, 2048, 7, 7] = torch.ops.aten.relu.default(add_248);  add_248 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_47: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_42, primals_142, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_249: i64[] = torch.ops.aten.add.Tensor(primals_305, 1);  primals_305 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_47 = torch.ops.aten.var_mean.correction(convolution_47, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_96: f32[1, 512, 1, 1] = var_mean_47[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_97: f32[1, 512, 1, 1] = var_mean_47[1];  var_mean_47 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_250: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_96, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_47: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_250);  add_250 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_47: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_47, getitem_97)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_329: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_47, rsqrt_47);  sub_47 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_141: f32[512] = torch.ops.aten.squeeze.dims(getitem_97, [0, 2, 3]);  getitem_97 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_142: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_47, [0, 2, 3]);  rsqrt_47 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_330: f32[512] = torch.ops.aten.mul.Tensor(squeeze_141, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_331: f32[512] = torch.ops.aten.mul.Tensor(primals_303, 0.9);  primals_303 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_251: f32[512] = torch.ops.aten.add.Tensor(mul_330, mul_331);  mul_330 = mul_331 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_143: f32[512] = torch.ops.aten.squeeze.dims(getitem_96, [0, 2, 3]);  getitem_96 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_332: f32[512] = torch.ops.aten.mul.Tensor(squeeze_143, 1.0003189792663476);  squeeze_143 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_333: f32[512] = torch.ops.aten.mul.Tensor(mul_332, 0.1);  mul_332 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_334: f32[512] = torch.ops.aten.mul.Tensor(primals_304, 0.9);  primals_304 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_252: f32[512] = torch.ops.aten.add.Tensor(mul_333, mul_334);  mul_333 = mul_334 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_188: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_143, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_189: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_188, -1);  unsqueeze_188 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_335: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_329, unsqueeze_189);  mul_329 = unsqueeze_189 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_190: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_144, -1);  primals_144 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_191: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_190, -1);  unsqueeze_190 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_253: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_335, unsqueeze_191);  mul_335 = unsqueeze_191 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_43: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_253);  add_253 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_48: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_43, primals_145, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_254: i64[] = torch.ops.aten.add.Tensor(primals_308, 1);  primals_308 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_48 = torch.ops.aten.var_mean.correction(convolution_48, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_98: f32[1, 512, 1, 1] = var_mean_48[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_99: f32[1, 512, 1, 1] = var_mean_48[1];  var_mean_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_255: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_98, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_48: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_255);  add_255 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_48: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_48, getitem_99)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_336: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_48, rsqrt_48);  sub_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_144: f32[512] = torch.ops.aten.squeeze.dims(getitem_99, [0, 2, 3]);  getitem_99 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_145: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_48, [0, 2, 3]);  rsqrt_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_337: f32[512] = torch.ops.aten.mul.Tensor(squeeze_144, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_338: f32[512] = torch.ops.aten.mul.Tensor(primals_306, 0.9);  primals_306 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_256: f32[512] = torch.ops.aten.add.Tensor(mul_337, mul_338);  mul_337 = mul_338 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_146: f32[512] = torch.ops.aten.squeeze.dims(getitem_98, [0, 2, 3]);  getitem_98 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_339: f32[512] = torch.ops.aten.mul.Tensor(squeeze_146, 1.0003189792663476);  squeeze_146 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_340: f32[512] = torch.ops.aten.mul.Tensor(mul_339, 0.1);  mul_339 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_341: f32[512] = torch.ops.aten.mul.Tensor(primals_307, 0.9);  primals_307 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_257: f32[512] = torch.ops.aten.add.Tensor(mul_340, mul_341);  mul_340 = mul_341 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_192: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_146, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_193: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_192, -1);  unsqueeze_192 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_342: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_336, unsqueeze_193);  mul_336 = unsqueeze_193 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_194: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_147, -1);  primals_147 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_195: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_194, -1);  unsqueeze_194 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_258: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_342, unsqueeze_195);  mul_342 = unsqueeze_195 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_44: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_258);  add_258 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_49: f32[64, 2048, 7, 7] = torch.ops.aten.convolution.default(relu_44, primals_148, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_259: i64[] = torch.ops.aten.add.Tensor(primals_311, 1);  primals_311 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_49 = torch.ops.aten.var_mean.correction(convolution_49, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_100: f32[1, 2048, 1, 1] = var_mean_49[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_101: f32[1, 2048, 1, 1] = var_mean_49[1];  var_mean_49 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_260: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_100, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_49: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_260);  add_260 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_49: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_49, getitem_101)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_343: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_49, rsqrt_49);  sub_49 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_147: f32[2048] = torch.ops.aten.squeeze.dims(getitem_101, [0, 2, 3]);  getitem_101 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_148: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_49, [0, 2, 3]);  rsqrt_49 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_344: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_147, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_345: f32[2048] = torch.ops.aten.mul.Tensor(primals_309, 0.9);  primals_309 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_261: f32[2048] = torch.ops.aten.add.Tensor(mul_344, mul_345);  mul_344 = mul_345 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_149: f32[2048] = torch.ops.aten.squeeze.dims(getitem_100, [0, 2, 3]);  getitem_100 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_346: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_149, 1.0003189792663476);  squeeze_149 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_347: f32[2048] = torch.ops.aten.mul.Tensor(mul_346, 0.1);  mul_346 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_348: f32[2048] = torch.ops.aten.mul.Tensor(primals_310, 0.9);  primals_310 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_262: f32[2048] = torch.ops.aten.add.Tensor(mul_347, mul_348);  mul_347 = mul_348 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_196: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_149, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_197: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_196, -1);  unsqueeze_196 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_349: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(mul_343, unsqueeze_197);  mul_343 = unsqueeze_197 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_198: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_150, -1);  primals_150 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_199: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_198, -1);  unsqueeze_198 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_263: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(mul_349, unsqueeze_199);  mul_349 = unsqueeze_199 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_264: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(add_263, relu_42);  add_263 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_45: f32[64, 2048, 7, 7] = torch.ops.aten.relu.default(add_264);  add_264 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_50: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_45, primals_151, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_265: i64[] = torch.ops.aten.add.Tensor(primals_314, 1);  primals_314 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_50 = torch.ops.aten.var_mean.correction(convolution_50, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_102: f32[1, 512, 1, 1] = var_mean_50[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_103: f32[1, 512, 1, 1] = var_mean_50[1];  var_mean_50 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_266: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_102, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_50: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_266);  add_266 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_50: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_50, getitem_103)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_350: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_50, rsqrt_50);  sub_50 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_150: f32[512] = torch.ops.aten.squeeze.dims(getitem_103, [0, 2, 3]);  getitem_103 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_151: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_50, [0, 2, 3]);  rsqrt_50 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_351: f32[512] = torch.ops.aten.mul.Tensor(squeeze_150, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_352: f32[512] = torch.ops.aten.mul.Tensor(primals_312, 0.9);  primals_312 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_267: f32[512] = torch.ops.aten.add.Tensor(mul_351, mul_352);  mul_351 = mul_352 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_152: f32[512] = torch.ops.aten.squeeze.dims(getitem_102, [0, 2, 3]);  getitem_102 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_353: f32[512] = torch.ops.aten.mul.Tensor(squeeze_152, 1.0003189792663476);  squeeze_152 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_354: f32[512] = torch.ops.aten.mul.Tensor(mul_353, 0.1);  mul_353 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_355: f32[512] = torch.ops.aten.mul.Tensor(primals_313, 0.9);  primals_313 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_268: f32[512] = torch.ops.aten.add.Tensor(mul_354, mul_355);  mul_354 = mul_355 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_200: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_152, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_201: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_200, -1);  unsqueeze_200 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_356: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_350, unsqueeze_201);  mul_350 = unsqueeze_201 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_202: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_153, -1);  primals_153 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_203: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_202, -1);  unsqueeze_202 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_269: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_356, unsqueeze_203);  mul_356 = unsqueeze_203 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_46: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_269);  add_269 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_51: f32[64, 512, 7, 7] = torch.ops.aten.convolution.default(relu_46, primals_154, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_270: i64[] = torch.ops.aten.add.Tensor(primals_317, 1);  primals_317 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_51 = torch.ops.aten.var_mean.correction(convolution_51, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_104: f32[1, 512, 1, 1] = var_mean_51[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_105: f32[1, 512, 1, 1] = var_mean_51[1];  var_mean_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_271: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_104, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_51: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_271);  add_271 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_51: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_51, getitem_105)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_357: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_51, rsqrt_51);  sub_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_153: f32[512] = torch.ops.aten.squeeze.dims(getitem_105, [0, 2, 3]);  getitem_105 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_154: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_51, [0, 2, 3]);  rsqrt_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_358: f32[512] = torch.ops.aten.mul.Tensor(squeeze_153, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_359: f32[512] = torch.ops.aten.mul.Tensor(primals_315, 0.9);  primals_315 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_272: f32[512] = torch.ops.aten.add.Tensor(mul_358, mul_359);  mul_358 = mul_359 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_155: f32[512] = torch.ops.aten.squeeze.dims(getitem_104, [0, 2, 3]);  getitem_104 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_360: f32[512] = torch.ops.aten.mul.Tensor(squeeze_155, 1.0003189792663476);  squeeze_155 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_361: f32[512] = torch.ops.aten.mul.Tensor(mul_360, 0.1);  mul_360 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_362: f32[512] = torch.ops.aten.mul.Tensor(primals_316, 0.9);  primals_316 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_273: f32[512] = torch.ops.aten.add.Tensor(mul_361, mul_362);  mul_361 = mul_362 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_204: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_155, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_205: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_204, -1);  unsqueeze_204 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_363: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(mul_357, unsqueeze_205);  mul_357 = unsqueeze_205 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_206: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_156, -1);  primals_156 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_207: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_206, -1);  unsqueeze_206 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_274: f32[64, 512, 7, 7] = torch.ops.aten.add.Tensor(mul_363, unsqueeze_207);  mul_363 = unsqueeze_207 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_47: f32[64, 512, 7, 7] = torch.ops.aten.relu.default(add_274);  add_274 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_52: f32[64, 2048, 7, 7] = torch.ops.aten.convolution.default(relu_47, primals_157, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_275: i64[] = torch.ops.aten.add.Tensor(primals_320, 1);  primals_320 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_52 = torch.ops.aten.var_mean.correction(convolution_52, [0, 2, 3], correction = 0, keepdim = True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_106: f32[1, 2048, 1, 1] = var_mean_52[0]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_107: f32[1, 2048, 1, 1] = var_mean_52[1];  var_mean_52 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_276: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_106, 1e-05)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_52: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_276);  add_276 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_52: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_52, getitem_107)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_364: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_52, rsqrt_52);  sub_52 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_156: f32[2048] = torch.ops.aten.squeeze.dims(getitem_107, [0, 2, 3]);  getitem_107 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_157: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_52, [0, 2, 3]);  rsqrt_52 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_365: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_156, 0.1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_366: f32[2048] = torch.ops.aten.mul.Tensor(primals_318, 0.9);  primals_318 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_277: f32[2048] = torch.ops.aten.add.Tensor(mul_365, mul_366);  mul_365 = mul_366 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_158: f32[2048] = torch.ops.aten.squeeze.dims(getitem_106, [0, 2, 3]);  getitem_106 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_367: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_158, 1.0003189792663476);  squeeze_158 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_368: f32[2048] = torch.ops.aten.mul.Tensor(mul_367, 0.1);  mul_367 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_369: f32[2048] = torch.ops.aten.mul.Tensor(primals_319, 0.9);  primals_319 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_278: f32[2048] = torch.ops.aten.add.Tensor(mul_368, mul_369);  mul_368 = mul_369 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_208: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_158, -1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_209: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_208, -1);  unsqueeze_208 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_370: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(mul_364, unsqueeze_209);  mul_364 = unsqueeze_209 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_210: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_159, -1);  primals_159 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_211: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_210, -1);  unsqueeze_210 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_279: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(mul_370, unsqueeze_211);  mul_370 = unsqueeze_211 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:160, code: out += identity
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_280: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(add_279, relu_45);  add_279 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_48: f32[64, 2048, 7, 7] = torch.ops.aten.relu.default(add_280);  add_280 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:278, code: x = self.avgpool(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mean: f32[64, 2048, 1, 1] = torch.ops.aten.mean.dim(relu_48, [-1, -2], True)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:279, code: x = torch.flatten(x, 1)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         view: f32[64, 2048] = torch.ops.aten.view.default(mean, [64, 2048]);  mean = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:280, code: x = self.fc(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute: f32[2048, 1000] = torch.ops.aten.permute.default(primals_160, [1, 0]);  primals_160 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         addmm: f32[64, 1000] = torch.ops.aten.addmm.default(primals_161, view, permute);  primals_161 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute_1: f32[1000, 2048] = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le: b8[64, 2048, 7, 7] = torch.ops.aten.le.Scalar(relu_48, 0);  relu_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_212: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_156, 0);  squeeze_156 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_213: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_212, 2);  unsqueeze_212 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_214: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_213, 3);  unsqueeze_213 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_224: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_153, 0);  squeeze_153 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_225: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_224, 2);  unsqueeze_224 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_226: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_225, 3);  unsqueeze_225 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_236: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_150, 0);  squeeze_150 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_237: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_236, 2);  unsqueeze_236 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_238: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_237, 3);  unsqueeze_237 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_248: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_147, 0);  squeeze_147 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_249: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_248, 2);  unsqueeze_248 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_250: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_249, 3);  unsqueeze_249 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_260: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_144, 0);  squeeze_144 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_261: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_260, 2);  unsqueeze_260 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_262: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_261, 3);  unsqueeze_261 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_272: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_141, 0);  squeeze_141 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_273: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_272, 2);  unsqueeze_272 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_274: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_273, 3);  unsqueeze_273 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_284: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_138, 0);  squeeze_138 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_285: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_284, 2);  unsqueeze_284 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_286: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_285, 3);  unsqueeze_285 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_296: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_135, 0);  squeeze_135 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_297: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_296, 2);  unsqueeze_296 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_298: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_297, 3);  unsqueeze_297 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_308: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_132, 0);  squeeze_132 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_309: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_308, 2);  unsqueeze_308 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_310: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_309, 3);  unsqueeze_309 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_320: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_129, 0);  squeeze_129 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_321: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_320, 2);  unsqueeze_320 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_322: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_321, 3);  unsqueeze_321 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_332: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_126, 0);  squeeze_126 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_333: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_332, 2);  unsqueeze_332 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_334: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_333, 3);  unsqueeze_333 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_344: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_123, 0);  squeeze_123 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_345: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_344, 2);  unsqueeze_344 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_346: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_345, 3);  unsqueeze_345 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_356: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_120, 0);  squeeze_120 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_357: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_356, 2);  unsqueeze_356 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_358: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_357, 3);  unsqueeze_357 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_368: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_117, 0);  squeeze_117 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_369: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_368, 2);  unsqueeze_368 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_370: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_369, 3);  unsqueeze_369 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_380: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_114, 0);  squeeze_114 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_381: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_380, 2);  unsqueeze_380 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_382: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_381, 3);  unsqueeze_381 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_392: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_111, 0);  squeeze_111 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_393: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_392, 2);  unsqueeze_392 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_394: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_393, 3);  unsqueeze_393 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_404: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_108, 0);  squeeze_108 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_405: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_404, 2);  unsqueeze_404 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_406: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_405, 3);  unsqueeze_405 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_416: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_105, 0);  squeeze_105 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_417: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_416, 2);  unsqueeze_416 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_418: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_417, 3);  unsqueeze_417 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_428: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_102, 0);  squeeze_102 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_429: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_428, 2);  unsqueeze_428 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_430: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_429, 3);  unsqueeze_429 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_440: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_99, 0);  squeeze_99 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_441: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_440, 2);  unsqueeze_440 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_442: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_441, 3);  unsqueeze_441 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_452: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_96, 0);  squeeze_96 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_453: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_452, 2);  unsqueeze_452 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_454: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_453, 3);  unsqueeze_453 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_464: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_93, 0);  squeeze_93 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_465: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_464, 2);  unsqueeze_464 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_466: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_465, 3);  unsqueeze_465 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_476: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_90, 0);  squeeze_90 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_477: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_476, 2);  unsqueeze_476 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_478: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_477, 3);  unsqueeze_477 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_488: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_87, 0);  squeeze_87 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_489: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_488, 2);  unsqueeze_488 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_490: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_489, 3);  unsqueeze_489 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_500: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_84, 0);  squeeze_84 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_501: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_500, 2);  unsqueeze_500 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_502: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_501, 3);  unsqueeze_501 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_512: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_81, 0);  squeeze_81 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_513: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_512, 2);  unsqueeze_512 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_514: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_513, 3);  unsqueeze_513 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_524: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_78, 0);  squeeze_78 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_525: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_524, 2);  unsqueeze_524 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_526: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_525, 3);  unsqueeze_525 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_536: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_75, 0);  squeeze_75 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_537: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_536, 2);  unsqueeze_536 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_538: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_537, 3);  unsqueeze_537 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_548: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_72, 0);  squeeze_72 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_549: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_548, 2);  unsqueeze_548 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_550: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_549, 3);  unsqueeze_549 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_560: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_69, 0);  squeeze_69 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_561: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_560, 2);  unsqueeze_560 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_562: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_561, 3);  unsqueeze_561 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_572: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_66, 0);  squeeze_66 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_573: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_572, 2);  unsqueeze_572 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_574: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_573, 3);  unsqueeze_573 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_584: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_63, 0);  squeeze_63 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_585: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_584, 2);  unsqueeze_584 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_586: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_585, 3);  unsqueeze_585 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_596: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_60, 0);  squeeze_60 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_597: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_596, 2);  unsqueeze_596 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_598: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_597, 3);  unsqueeze_597 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_608: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_57, 0);  squeeze_57 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_609: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_608, 2);  unsqueeze_608 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_610: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_609, 3);  unsqueeze_609 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_620: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_54, 0);  squeeze_54 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_621: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_620, 2);  unsqueeze_620 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_622: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_621, 3);  unsqueeze_621 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_632: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_51, 0);  squeeze_51 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_633: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_632, 2);  unsqueeze_632 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_634: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_633, 3);  unsqueeze_633 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_644: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_48, 0);  squeeze_48 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_645: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_644, 2);  unsqueeze_644 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_646: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_645, 3);  unsqueeze_645 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_656: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_45, 0);  squeeze_45 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_657: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_656, 2);  unsqueeze_656 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_658: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_657, 3);  unsqueeze_657 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_668: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_42, 0);  squeeze_42 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_669: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_668, 2);  unsqueeze_668 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_670: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_669, 3);  unsqueeze_669 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_680: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_39, 0);  squeeze_39 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_681: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_680, 2);  unsqueeze_680 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_682: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_681, 3);  unsqueeze_681 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_692: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_36, 0);  squeeze_36 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_693: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_692, 2);  unsqueeze_692 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_694: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_693, 3);  unsqueeze_693 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_704: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_33, 0);  squeeze_33 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_705: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_704, 2);  unsqueeze_704 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_706: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_705, 3);  unsqueeze_705 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_716: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_30, 0);  squeeze_30 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_717: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_716, 2);  unsqueeze_716 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_718: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_717, 3);  unsqueeze_717 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_728: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_27, 0);  squeeze_27 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_729: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_728, 2);  unsqueeze_728 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_730: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_729, 3);  unsqueeze_729 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_740: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_24, 0);  squeeze_24 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_741: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_740, 2);  unsqueeze_740 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_742: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_741, 3);  unsqueeze_741 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_752: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_21, 0);  squeeze_21 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_753: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_752, 2);  unsqueeze_752 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_754: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_753, 3);  unsqueeze_753 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_764: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_18, 0);  squeeze_18 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_765: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_764, 2);  unsqueeze_764 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_766: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_765, 3);  unsqueeze_765 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_776: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_15, 0);  squeeze_15 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_777: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_776, 2);  unsqueeze_776 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_778: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_777, 3);  unsqueeze_777 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_788: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_12, 0);  squeeze_12 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_789: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_788, 2);  unsqueeze_788 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_790: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_789, 3);  unsqueeze_789 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_800: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_9, 0);  squeeze_9 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_801: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_800, 2);  unsqueeze_800 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_802: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_801, 3);  unsqueeze_801 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_812: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_6, 0);  squeeze_6 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_813: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_812, 2);  unsqueeze_812 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_814: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_813, 3);  unsqueeze_813 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_824: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_3, 0);  squeeze_3 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_825: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_824, 2);  unsqueeze_824 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_826: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_825, 3);  unsqueeze_825 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:269, code: x = self.bn1(x)
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_836: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze, 0);  squeeze = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_837: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_836, 2);  unsqueeze_836 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_838: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_837, 3);  unsqueeze_837 = None
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         return [add_2, add_3, add, add_7, add_8, add_5, add_12, add_13, add_10, add_17, add_18, add_15, add_22, add_23, add_20, add_28, add_29, add_26, add_33, add_34, add_31, add_38, add_39, add_36, add_44, add_45, add_42, add_49, add_50, add_47, add_54, add_55, add_52, add_60, add_61, add_58, add_65, add_66, add_63, add_70, add_71, add_68, add_75, add_76, add_73, add_81, add_82, add_79, add_86, add_87, add_84, add_91, add_92, add_89, add_97, add_98, add_95, add_102, add_103, add_100, add_107, add_108, add_105, add_113, add_114, add_111, add_118, add_119, add_116, add_123, add_124, add_121, add_129, add_130, add_127, add_134, add_135, add_132, add_139, add_140, add_137, add_144, add_145, add_142, add_150, add_151, add_148, add_155, add_156, add_153, add_160, add_161, add_158, add_166, add_167, add_164, add_171, add_172, add_169, add_176, add_177, add_174, add_182, add_183, add_180, add_187, add_188, add_185, add_192, add_193, add_190, add_198, add_199, add_196, add_203, add_204, add_201, add_208, add_209, add_206, add_214, add_215, add_212, add_219, add_220, add_217, add_224, add_225, add_222, add_230, add_231, add_228, add_235, add_236, add_233, add_240, add_241, add_238, add_245, add_246, add_243, add_251, add_252, add_249, add_256, add_257, add_254, add_261, add_262, add_259, add_267, add_268, add_265, add_272, add_273, add_270, add_277, add_278, add_275, addmm, primals_1, primals_2, primals_4, primals_5, primals_7, primals_8, primals_10, primals_11, primals_13, primals_14, primals_16, primals_17, primals_19, primals_20, primals_22, primals_23, primals_25, primals_26, primals_28, primals_29, primals_31, primals_32, primals_34, primals_35, primals_37, primals_38, primals_40, primals_41, primals_43, primals_44, primals_46, primals_47, primals_49, primals_50, primals_52, primals_53, primals_55, primals_56, primals_58, primals_59, primals_61, primals_62, primals_64, primals_65, primals_67, primals_68, primals_70, primals_71, primals_73, primals_74, primals_76, primals_77, primals_79, primals_80, primals_82, primals_83, primals_85, primals_86, primals_88, primals_89, primals_91, primals_92, primals_94, primals_95, primals_97, primals_98, primals_100, primals_101, primals_103, primals_104, primals_106, primals_107, primals_109, primals_110, primals_112, primals_113, primals_115, primals_116, primals_118, primals_119, primals_121, primals_122, primals_124, primals_125, primals_127, primals_128, primals_130, primals_131, primals_133, primals_134, primals_136, primals_137, primals_139, primals_140, primals_142, primals_143, primals_145, primals_146, primals_148, primals_149, primals_151, primals_152, primals_154, primals_155, primals_157, primals_158, primals_321, convolution, squeeze_1, relu, getitem_2, getitem_3, convolution_1, squeeze_4, relu_1, convolution_2, squeeze_7, relu_2, convolution_3, squeeze_10, convolution_4, squeeze_13, relu_3, convolution_5, squeeze_16, relu_4, convolution_6, squeeze_19, relu_5, convolution_7, squeeze_22, relu_6, convolution_8, squeeze_25, relu_7, convolution_9, squeeze_28, relu_8, convolution_10, squeeze_31, relu_9, convolution_11, squeeze_34, relu_10, convolution_12, squeeze_37, relu_11, convolution_13, squeeze_40, convolution_14, squeeze_43, relu_12, convolution_15, squeeze_46, relu_13, convolution_16, squeeze_49, relu_14, convolution_17, squeeze_52, relu_15, convolution_18, squeeze_55, relu_16, convolution_19, squeeze_58, relu_17, convolution_20, squeeze_61, relu_18, convolution_21, squeeze_64, relu_19, convolution_22, squeeze_67, relu_20, convolution_23, squeeze_70, relu_21, convolution_24, squeeze_73, relu_22, convolution_25, squeeze_76, relu_23, convolution_26, squeeze_79, convolution_27, squeeze_82, relu_24, convolution_28, squeeze_85, relu_25, convolution_29, squeeze_88, relu_26, convolution_30, squeeze_91, relu_27, convolution_31, squeeze_94, relu_28, convolution_32, squeeze_97, relu_29, convolution_33, squeeze_100, relu_30, convolution_34, squeeze_103, relu_31, convolution_35, squeeze_106, relu_32, convolution_36, squeeze_109, relu_33, convolution_37, squeeze_112, relu_34, convolution_38, squeeze_115, relu_35, convolution_39, squeeze_118, relu_36, convolution_40, squeeze_121, relu_37, convolution_41, squeeze_124, relu_38, convolution_42, squeeze_127, relu_39, convolution_43, squeeze_130, relu_40, convolution_44, squeeze_133, relu_41, convolution_45, squeeze_136, convolution_46, squeeze_139, relu_42, convolution_47, squeeze_142, relu_43, convolution_48, squeeze_145, relu_44, convolution_49, squeeze_148, relu_45, convolution_50, squeeze_151, relu_46, convolution_51, squeeze_154, relu_47, convolution_52, squeeze_157, view, permute_1, le, unsqueeze_214, unsqueeze_226, unsqueeze_238, unsqueeze_250, unsqueeze_262, unsqueeze_274, unsqueeze_286, unsqueeze_298, unsqueeze_310, unsqueeze_322, unsqueeze_334, unsqueeze_346, unsqueeze_358, unsqueeze_370, unsqueeze_382, unsqueeze_394, unsqueeze_406, unsqueeze_418, unsqueeze_430, unsqueeze_442, unsqueeze_454, unsqueeze_466, unsqueeze_478, unsqueeze_490, unsqueeze_502, unsqueeze_514, unsqueeze_526, unsqueeze_538, unsqueeze_550, unsqueeze_562, unsqueeze_574, unsqueeze_586, unsqueeze_598, unsqueeze_610, unsqueeze_622, unsqueeze_634, unsqueeze_646, unsqueeze_658, unsqueeze_670, unsqueeze_682, unsqueeze_694, unsqueeze_706, unsqueeze_718, unsqueeze_730, unsqueeze_742, unsqueeze_754, unsqueeze_766, unsqueeze_778, unsqueeze_790, unsqueeze_802, unsqueeze_814, unsqueeze_826, unsqueeze_838]
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:22:59,927] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO] 
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO] TRACED GRAPH
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]  ===== Backward graph 0 =====
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]  <eval_with_key>.157 class GraphModule(torch.nn.Module):
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]     def forward(self, primals_1: f32[64, 3, 7, 7], primals_2: f32[64], primals_4: f32[64, 64, 1, 1], primals_5: f32[64], primals_7: f32[64, 64, 3, 3], primals_8: f32[64], primals_10: f32[256, 64, 1, 1], primals_11: f32[256], primals_13: f32[256, 64, 1, 1], primals_14: f32[256], primals_16: f32[64, 256, 1, 1], primals_17: f32[64], primals_19: f32[64, 64, 3, 3], primals_20: f32[64], primals_22: f32[256, 64, 1, 1], primals_23: f32[256], primals_25: f32[64, 256, 1, 1], primals_26: f32[64], primals_28: f32[64, 64, 3, 3], primals_29: f32[64], primals_31: f32[256, 64, 1, 1], primals_32: f32[256], primals_34: f32[128, 256, 1, 1], primals_35: f32[128], primals_37: f32[128, 128, 3, 3], primals_38: f32[128], primals_40: f32[512, 128, 1, 1], primals_41: f32[512], primals_43: f32[512, 256, 1, 1], primals_44: f32[512], primals_46: f32[128, 512, 1, 1], primals_47: f32[128], primals_49: f32[128, 128, 3, 3], primals_50: f32[128], primals_52: f32[512, 128, 1, 1], primals_53: f32[512], primals_55: f32[128, 512, 1, 1], primals_56: f32[128], primals_58: f32[128, 128, 3, 3], primals_59: f32[128], primals_61: f32[512, 128, 1, 1], primals_62: f32[512], primals_64: f32[128, 512, 1, 1], primals_65: f32[128], primals_67: f32[128, 128, 3, 3], primals_68: f32[128], primals_70: f32[512, 128, 1, 1], primals_71: f32[512], primals_73: f32[256, 512, 1, 1], primals_74: f32[256], primals_76: f32[256, 256, 3, 3], primals_77: f32[256], primals_79: f32[1024, 256, 1, 1], primals_80: f32[1024], primals_82: f32[1024, 512, 1, 1], primals_83: f32[1024], primals_85: f32[256, 1024, 1, 1], primals_86: f32[256], primals_88: f32[256, 256, 3, 3], primals_89: f32[256], primals_91: f32[1024, 256, 1, 1], primals_92: f32[1024], primals_94: f32[256, 1024, 1, 1], primals_95: f32[256], primals_97: f32[256, 256, 3, 3], primals_98: f32[256], primals_100: f32[1024, 256, 1, 1], primals_101: f32[1024], primals_103: f32[256, 1024, 1, 1], primals_104: f32[256], primals_106: f32[256, 256, 3, 3], primals_107: f32[256], primals_109: f32[1024, 256, 1, 1], primals_110: f32[1024], primals_112: f32[256, 1024, 1, 1], primals_113: f32[256], primals_115: f32[256, 256, 3, 3], primals_116: f32[256], primals_118: f32[1024, 256, 1, 1], primals_119: f32[1024], primals_121: f32[256, 1024, 1, 1], primals_122: f32[256], primals_124: f32[256, 256, 3, 3], primals_125: f32[256], primals_127: f32[1024, 256, 1, 1], primals_128: f32[1024], primals_130: f32[512, 1024, 1, 1], primals_131: f32[512], primals_133: f32[512, 512, 3, 3], primals_134: f32[512], primals_136: f32[2048, 512, 1, 1], primals_137: f32[2048], primals_139: f32[2048, 1024, 1, 1], primals_140: f32[2048], primals_142: f32[512, 2048, 1, 1], primals_143: f32[512], primals_145: f32[512, 512, 3, 3], primals_146: f32[512], primals_148: f32[2048, 512, 1, 1], primals_149: f32[2048], primals_151: f32[512, 2048, 1, 1], primals_152: f32[512], primals_154: f32[512, 512, 3, 3], primals_155: f32[512], primals_157: f32[2048, 512, 1, 1], primals_158: f32[2048], primals_321: f32[64, 3, 224, 224], convolution: f32[64, 64, 112, 112], squeeze_1: f32[64], relu: f32[64, 64, 112, 112], getitem_2: f32[64, 64, 56, 56], getitem_3: i64[64, 64, 56, 56], convolution_1: f32[64, 64, 56, 56], squeeze_4: f32[64], relu_1: f32[64, 64, 56, 56], convolution_2: f32[64, 64, 56, 56], squeeze_7: f32[64], relu_2: f32[64, 64, 56, 56], convolution_3: f32[64, 256, 56, 56], squeeze_10: f32[256], convolution_4: f32[64, 256, 56, 56], squeeze_13: f32[256], relu_3: f32[64, 256, 56, 56], convolution_5: f32[64, 64, 56, 56], squeeze_16: f32[64], relu_4: f32[64, 64, 56, 56], convolution_6: f32[64, 64, 56, 56], squeeze_19: f32[64], relu_5: f32[64, 64, 56, 56], convolution_7: f32[64, 256, 56, 56], squeeze_22: f32[256], relu_6: f32[64, 256, 56, 56], convolution_8: f32[64, 64, 56, 56], squeeze_25: f32[64], relu_7: f32[64, 64, 56, 56], convolution_9: f32[64, 64, 56, 56], squeeze_28: f32[64], relu_8: f32[64, 64, 56, 56], convolution_10: f32[64, 256, 56, 56], squeeze_31: f32[256], relu_9: f32[64, 256, 56, 56], convolution_11: f32[64, 128, 56, 56], squeeze_34: f32[128], relu_10: f32[64, 128, 56, 56], convolution_12: f32[64, 128, 28, 28], squeeze_37: f32[128], relu_11: f32[64, 128, 28, 28], convolution_13: f32[64, 512, 28, 28], squeeze_40: f32[512], convolution_14: f32[64, 512, 28, 28], squeeze_43: f32[512], relu_12: f32[64, 512, 28, 28], convolution_15: f32[64, 128, 28, 28], squeeze_46: f32[128], relu_13: f32[64, 128, 28, 28], convolution_16: f32[64, 128, 28, 28], squeeze_49: f32[128], relu_14: f32[64, 128, 28, 28], convolution_17: f32[64, 512, 28, 28], squeeze_52: f32[512], relu_15: f32[64, 512, 28, 28], convolution_18: f32[64, 128, 28, 28], squeeze_55: f32[128], relu_16: f32[64, 128, 28, 28], convolution_19: f32[64, 128, 28, 28], squeeze_58: f32[128], relu_17: f32[64, 128, 28, 28], convolution_20: f32[64, 512, 28, 28], squeeze_61: f32[512], relu_18: f32[64, 512, 28, 28], convolution_21: f32[64, 128, 28, 28], squeeze_64: f32[128], relu_19: f32[64, 128, 28, 28], convolution_22: f32[64, 128, 28, 28], squeeze_67: f32[128], relu_20: f32[64, 128, 28, 28], convolution_23: f32[64, 512, 28, 28], squeeze_70: f32[512], relu_21: f32[64, 512, 28, 28], convolution_24: f32[64, 256, 28, 28], squeeze_73: f32[256], relu_22: f32[64, 256, 28, 28], convolution_25: f32[64, 256, 14, 14], squeeze_76: f32[256], relu_23: f32[64, 256, 14, 14], convolution_26: f32[64, 1024, 14, 14], squeeze_79: f32[1024], convolution_27: f32[64, 1024, 14, 14], squeeze_82: f32[1024], relu_24: f32[64, 1024, 14, 14], convolution_28: f32[64, 256, 14, 14], squeeze_85: f32[256], relu_25: f32[64, 256, 14, 14], convolution_29: f32[64, 256, 14, 14], squeeze_88: f32[256], relu_26: f32[64, 256, 14, 14], convolution_30: f32[64, 1024, 14, 14], squeeze_91: f32[1024], relu_27: f32[64, 1024, 14, 14], convolution_31: f32[64, 256, 14, 14], squeeze_94: f32[256], relu_28: f32[64, 256, 14, 14], convolution_32: f32[64, 256, 14, 14], squeeze_97: f32[256], relu_29: f32[64, 256, 14, 14], convolution_33: f32[64, 1024, 14, 14], squeeze_100: f32[1024], relu_30: f32[64, 1024, 14, 14], convolution_34: f32[64, 256, 14, 14], squeeze_103: f32[256], relu_31: f32[64, 256, 14, 14], convolution_35: f32[64, 256, 14, 14], squeeze_106: f32[256], relu_32: f32[64, 256, 14, 14], convolution_36: f32[64, 1024, 14, 14], squeeze_109: f32[1024], relu_33: f32[64, 1024, 14, 14], convolution_37: f32[64, 256, 14, 14], squeeze_112: f32[256], relu_34: f32[64, 256, 14, 14], convolution_38: f32[64, 256, 14, 14], squeeze_115: f32[256], relu_35: f32[64, 256, 14, 14], convolution_39: f32[64, 1024, 14, 14], squeeze_118: f32[1024], relu_36: f32[64, 1024, 14, 14], convolution_40: f32[64, 256, 14, 14], squeeze_121: f32[256], relu_37: f32[64, 256, 14, 14], convolution_41: f32[64, 256, 14, 14], squeeze_124: f32[256], relu_38: f32[64, 256, 14, 14], convolution_42: f32[64, 1024, 14, 14], squeeze_127: f32[1024], relu_39: f32[64, 1024, 14, 14], convolution_43: f32[64, 512, 14, 14], squeeze_130: f32[512], relu_40: f32[64, 512, 14, 14], convolution_44: f32[64, 512, 7, 7], squeeze_133: f32[512], relu_41: f32[64, 512, 7, 7], convolution_45: f32[64, 2048, 7, 7], squeeze_136: f32[2048], convolution_46: f32[64, 2048, 7, 7], squeeze_139: f32[2048], relu_42: f32[64, 2048, 7, 7], convolution_47: f32[64, 512, 7, 7], squeeze_142: f32[512], relu_43: f32[64, 512, 7, 7], convolution_48: f32[64, 512, 7, 7], squeeze_145: f32[512], relu_44: f32[64, 512, 7, 7], convolution_49: f32[64, 2048, 7, 7], squeeze_148: f32[2048], relu_45: f32[64, 2048, 7, 7], convolution_50: f32[64, 512, 7, 7], squeeze_151: f32[512], relu_46: f32[64, 512, 7, 7], convolution_51: f32[64, 512, 7, 7], squeeze_154: f32[512], relu_47: f32[64, 512, 7, 7], convolution_52: f32[64, 2048, 7, 7], squeeze_157: f32[2048], view: f32[64, 2048], permute_1: f32[1000, 2048], le: b8[64, 2048, 7, 7], unsqueeze_214: f32[1, 2048, 1, 1], unsqueeze_226: f32[1, 512, 1, 1], unsqueeze_238: f32[1, 512, 1, 1], unsqueeze_250: f32[1, 2048, 1, 1], unsqueeze_262: f32[1, 512, 1, 1], unsqueeze_274: f32[1, 512, 1, 1], unsqueeze_286: f32[1, 2048, 1, 1], unsqueeze_298: f32[1, 2048, 1, 1], unsqueeze_310: f32[1, 512, 1, 1], unsqueeze_322: f32[1, 512, 1, 1], unsqueeze_334: f32[1, 1024, 1, 1], unsqueeze_346: f32[1, 256, 1, 1], unsqueeze_358: f32[1, 256, 1, 1], unsqueeze_370: f32[1, 1024, 1, 1], unsqueeze_382: f32[1, 256, 1, 1], unsqueeze_394: f32[1, 256, 1, 1], unsqueeze_406: f32[1, 1024, 1, 1], unsqueeze_418: f32[1, 256, 1, 1], unsqueeze_430: f32[1, 256, 1, 1], unsqueeze_442: f32[1, 1024, 1, 1], unsqueeze_454: f32[1, 256, 1, 1], unsqueeze_466: f32[1, 256, 1, 1], unsqueeze_478: f32[1, 1024, 1, 1], unsqueeze_490: f32[1, 256, 1, 1], unsqueeze_502: f32[1, 256, 1, 1], unsqueeze_514: f32[1, 1024, 1, 1], unsqueeze_526: f32[1, 1024, 1, 1], unsqueeze_538: f32[1, 256, 1, 1], unsqueeze_550: f32[1, 256, 1, 1], unsqueeze_562: f32[1, 512, 1, 1], unsqueeze_574: f32[1, 128, 1, 1], unsqueeze_586: f32[1, 128, 1, 1], unsqueeze_598: f32[1, 512, 1, 1], unsqueeze_610: f32[1, 128, 1, 1], unsqueeze_622: f32[1, 128, 1, 1], unsqueeze_634: f32[1, 512, 1, 1], unsqueeze_646: f32[1, 128, 1, 1], unsqueeze_658: f32[1, 128, 1, 1], unsqueeze_670: f32[1, 512, 1, 1], unsqueeze_682: f32[1, 512, 1, 1], unsqueeze_694: f32[1, 128, 1, 1], unsqueeze_706: f32[1, 128, 1, 1], unsqueeze_718: f32[1, 256, 1, 1], unsqueeze_730: f32[1, 64, 1, 1], unsqueeze_742: f32[1, 64, 1, 1], unsqueeze_754: f32[1, 256, 1, 1], unsqueeze_766: f32[1, 64, 1, 1], unsqueeze_778: f32[1, 64, 1, 1], unsqueeze_790: f32[1, 256, 1, 1], unsqueeze_802: f32[1, 256, 1, 1], unsqueeze_814: f32[1, 64, 1, 1], unsqueeze_826: f32[1, 64, 1, 1], unsqueeze_838: f32[1, 64, 1, 1], tangents_1: f32[64], tangents_2: f32[64], tangents_3: i64[], tangents_4: f32[64], tangents_5: f32[64], tangents_6: i64[], tangents_7: f32[64], tangents_8: f32[64], tangents_9: i64[], tangents_10: f32[256], tangents_11: f32[256], tangents_12: i64[], tangents_13: f32[256], tangents_14: f32[256], tangents_15: i64[], tangents_16: f32[64], tangents_17: f32[64], tangents_18: i64[], tangents_19: f32[64], tangents_20: f32[64], tangents_21: i64[], tangents_22: f32[256], tangents_23: f32[256], tangents_24: i64[], tangents_25: f32[64], tangents_26: f32[64], tangents_27: i64[], tangents_28: f32[64], tangents_29: f32[64], tangents_30: i64[], tangents_31: f32[256], tangents_32: f32[256], tangents_33: i64[], tangents_34: f32[128], tangents_35: f32[128], tangents_36: i64[], tangents_37: f32[128], tangents_38: f32[128], tangents_39: i64[], tangents_40: f32[512], tangents_41: f32[512], tangents_42: i64[], tangents_43: f32[512], tangents_44: f32[512], tangents_45: i64[], tangents_46: f32[128], tangents_47: f32[128], tangents_48: i64[], tangents_49: f32[128], tangents_50: f32[128], tangents_51: i64[], tangents_52: f32[512], tangents_53: f32[512], tangents_54: i64[], tangents_55: f32[128], tangents_56: f32[128], tangents_57: i64[], tangents_58: f32[128], tangents_59: f32[128], tangents_60: i64[], tangents_61: f32[512], tangents_62: f32[512], tangents_63: i64[], tangents_64: f32[128], tangents_65: f32[128], tangents_66: i64[], tangents_67: f32[128], tangents_68: f32[128], tangents_69: i64[], tangents_70: f32[512], tangents_71: f32[512], tangents_72: i64[], tangents_73: f32[256], tangents_74: f32[256], tangents_75: i64[], tangents_76: f32[256], tangents_77: f32[256], tangents_78: i64[], tangents_79: f32[1024], tangents_80: f32[1024], tangents_81: i64[], tangents_82: f32[1024], tangents_83: f32[1024], tangents_84: i64[], tangents_85: f32[256], tangents_86: f32[256], tangents_87: i64[], tangents_88: f32[256], tangents_89: f32[256], tangents_90: i64[], tangents_91: f32[1024], tangents_92: f32[1024], tangents_93: i64[], tangents_94: f32[256], tangents_95: f32[256], tangents_96: i64[], tangents_97: f32[256], tangents_98: f32[256], tangents_99: i64[], tangents_100: f32[1024], tangents_101: f32[1024], tangents_102: i64[], tangents_103: f32[256], tangents_104: f32[256], tangents_105: i64[], tangents_106: f32[256], tangents_107: f32[256], tangents_108: i64[], tangents_109: f32[1024], tangents_110: f32[1024], tangents_111: i64[], tangents_112: f32[256], tangents_113: f32[256], tangents_114: i64[], tangents_115: f32[256], tangents_116: f32[256], tangents_117: i64[], tangents_118: f32[1024], tangents_119: f32[1024], tangents_120: i64[], tangents_121: f32[256], tangents_122: f32[256], tangents_123: i64[], tangents_124: f32[256], tangents_125: f32[256], tangents_126: i64[], tangents_127: f32[1024], tangents_128: f32[1024], tangents_129: i64[], tangents_130: f32[512], tangents_131: f32[512], tangents_132: i64[], tangents_133: f32[512], tangents_134: f32[512], tangents_135: i64[], tangents_136: f32[2048], tangents_137: f32[2048], tangents_138: i64[], tangents_139: f32[2048], tangents_140: f32[2048], tangents_141: i64[], tangents_142: f32[512], tangents_143: f32[512], tangents_144: i64[], tangents_145: f32[512], tangents_146: f32[512], tangents_147: i64[], tangents_148: f32[2048], tangents_149: f32[2048], tangents_150: i64[], tangents_151: f32[512], tangents_152: f32[512], tangents_153: i64[], tangents_154: f32[512], tangents_155: f32[512], tangents_156: i64[], tangents_157: f32[2048], tangents_158: f32[2048], tangents_159: i64[], tangents_160: f32[64, 1000]):
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:280, code: x = self.fc(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mm: f32[64, 2048] = torch.ops.aten.mm.default(tangents_160, permute_1);  permute_1 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute_2: f32[1000, 64] = torch.ops.aten.permute.default(tangents_160, [1, 0])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mm_1: f32[1000, 2048] = torch.ops.aten.mm.default(permute_2, view);  permute_2 = view = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute_3: f32[2048, 1000] = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_1: f32[1, 1000] = torch.ops.aten.sum.dim_IntList(tangents_160, [0], True);  tangents_160 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         view_1: f32[1000] = torch.ops.aten.view.default(sum_1, [1000]);  sum_1 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute_4: f32[1000, 2048] = torch.ops.aten.permute.default(permute_3, [1, 0]);  permute_3 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:279, code: x = torch.flatten(x, 1)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         view_2: f32[64, 2048, 1, 1] = torch.ops.aten.view.default(mm, [64, 2048, 1, 1]);  mm = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:278, code: x = self.avgpool(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         expand: f32[64, 2048, 7, 7] = torch.ops.aten.expand.default(view_2, [64, 2048, 7, 7]);  view_2 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         div: f32[64, 2048, 7, 7] = torch.ops.aten.div.Scalar(expand, 49);  expand = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         full_default: f32[] = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where: f32[64, 2048, 7, 7] = torch.ops.aten.where.self(le, full_default, div);  le = div = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_2: f32[2048] = torch.ops.aten.sum.dim_IntList(where, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_53: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_52, unsqueeze_214);  convolution_52 = unsqueeze_214 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_371: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(where, sub_53)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_3: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_371, [0, 2, 3]);  mul_371 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_372: f32[2048] = torch.ops.aten.mul.Tensor(sum_2, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_215: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_372, 0);  mul_372 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_216: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_215, 2);  unsqueeze_215 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_217: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_216, 3);  unsqueeze_216 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_373: f32[2048] = torch.ops.aten.mul.Tensor(sum_3, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_374: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_157, squeeze_157)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_375: f32[2048] = torch.ops.aten.mul.Tensor(mul_373, mul_374);  mul_373 = mul_374 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_218: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_375, 0);  mul_375 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_219: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_218, 2);  unsqueeze_218 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_220: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_219, 3);  unsqueeze_219 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_376: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_157, primals_158);  primals_158 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_221: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_376, 0);  mul_376 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_222: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_221, 2);  unsqueeze_221 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_223: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_222, 3);  unsqueeze_222 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_377: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_53, unsqueeze_220);  sub_53 = unsqueeze_220 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_55: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(where, mul_377);  mul_377 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_56: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(sub_55, unsqueeze_217);  sub_55 = unsqueeze_217 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_378: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_56, unsqueeze_223);  sub_56 = unsqueeze_223 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_379: f32[2048] = torch.ops.aten.mul.Tensor(sum_3, squeeze_157);  sum_3 = squeeze_157 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward = torch.ops.aten.convolution_backward.default(mul_378, relu_47, primals_157, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_378 = primals_157 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_108: f32[64, 512, 7, 7] = convolution_backward[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_109: f32[2048, 512, 1, 1] = convolution_backward[1];  convolution_backward = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_1: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_47, 0);  relu_47 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_1: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_1, full_default, getitem_108);  le_1 = getitem_108 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_4: f32[512] = torch.ops.aten.sum.dim_IntList(where_1, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_57: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_51, unsqueeze_226);  convolution_51 = unsqueeze_226 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_380: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_1, sub_57)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_5: f32[512] = torch.ops.aten.sum.dim_IntList(mul_380, [0, 2, 3]);  mul_380 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_381: f32[512] = torch.ops.aten.mul.Tensor(sum_4, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_227: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_381, 0);  mul_381 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_228: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_227, 2);  unsqueeze_227 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_229: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_228, 3);  unsqueeze_228 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_382: f32[512] = torch.ops.aten.mul.Tensor(sum_5, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_383: f32[512] = torch.ops.aten.mul.Tensor(squeeze_154, squeeze_154)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_384: f32[512] = torch.ops.aten.mul.Tensor(mul_382, mul_383);  mul_382 = mul_383 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_230: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_384, 0);  mul_384 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_231: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_230, 2);  unsqueeze_230 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_232: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_231, 3);  unsqueeze_231 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_385: f32[512] = torch.ops.aten.mul.Tensor(squeeze_154, primals_155);  primals_155 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_233: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_385, 0);  mul_385 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_234: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_233, 2);  unsqueeze_233 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_235: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_234, 3);  unsqueeze_234 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_386: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_57, unsqueeze_232);  sub_57 = unsqueeze_232 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_59: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_1, mul_386);  where_1 = mul_386 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_60: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_59, unsqueeze_229);  sub_59 = unsqueeze_229 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_387: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_60, unsqueeze_235);  sub_60 = unsqueeze_235 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_388: f32[512] = torch.ops.aten.mul.Tensor(sum_5, squeeze_154);  sum_5 = squeeze_154 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_1 = torch.ops.aten.convolution_backward.default(mul_387, relu_46, primals_154, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_387 = primals_154 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_111: f32[64, 512, 7, 7] = convolution_backward_1[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_112: f32[512, 512, 3, 3] = convolution_backward_1[1];  convolution_backward_1 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_2: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_46, 0);  relu_46 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_2: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_2, full_default, getitem_111);  le_2 = getitem_111 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_6: f32[512] = torch.ops.aten.sum.dim_IntList(where_2, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_61: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_50, unsqueeze_238);  convolution_50 = unsqueeze_238 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_389: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_2, sub_61)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_7: f32[512] = torch.ops.aten.sum.dim_IntList(mul_389, [0, 2, 3]);  mul_389 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_390: f32[512] = torch.ops.aten.mul.Tensor(sum_6, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_239: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_390, 0);  mul_390 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_240: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_239, 2);  unsqueeze_239 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_241: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_240, 3);  unsqueeze_240 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_391: f32[512] = torch.ops.aten.mul.Tensor(sum_7, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_392: f32[512] = torch.ops.aten.mul.Tensor(squeeze_151, squeeze_151)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_393: f32[512] = torch.ops.aten.mul.Tensor(mul_391, mul_392);  mul_391 = mul_392 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_242: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_393, 0);  mul_393 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_243: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_242, 2);  unsqueeze_242 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_244: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_243, 3);  unsqueeze_243 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_394: f32[512] = torch.ops.aten.mul.Tensor(squeeze_151, primals_152);  primals_152 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_245: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_394, 0);  mul_394 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_246: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_245, 2);  unsqueeze_245 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_247: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_246, 3);  unsqueeze_246 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_395: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_61, unsqueeze_244);  sub_61 = unsqueeze_244 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_63: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_2, mul_395);  where_2 = mul_395 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_64: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_63, unsqueeze_241);  sub_63 = unsqueeze_241 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_396: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_64, unsqueeze_247);  sub_64 = unsqueeze_247 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_397: f32[512] = torch.ops.aten.mul.Tensor(sum_7, squeeze_151);  sum_7 = squeeze_151 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_2 = torch.ops.aten.convolution_backward.default(mul_396, relu_45, primals_151, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_396 = primals_151 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_114: f32[64, 2048, 7, 7] = convolution_backward_2[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_115: f32[512, 2048, 1, 1] = convolution_backward_2[1];  convolution_backward_2 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_281: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(where, getitem_114);  where = getitem_114 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_3: b8[64, 2048, 7, 7] = torch.ops.aten.le.Scalar(relu_45, 0);  relu_45 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_3: f32[64, 2048, 7, 7] = torch.ops.aten.where.self(le_3, full_default, add_281);  le_3 = add_281 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_8: f32[2048] = torch.ops.aten.sum.dim_IntList(where_3, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_65: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_49, unsqueeze_250);  convolution_49 = unsqueeze_250 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_398: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(where_3, sub_65)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_9: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_398, [0, 2, 3]);  mul_398 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_399: f32[2048] = torch.ops.aten.mul.Tensor(sum_8, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_251: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_399, 0);  mul_399 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_252: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_251, 2);  unsqueeze_251 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_253: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_252, 3);  unsqueeze_252 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_400: f32[2048] = torch.ops.aten.mul.Tensor(sum_9, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_401: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_148, squeeze_148)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_402: f32[2048] = torch.ops.aten.mul.Tensor(mul_400, mul_401);  mul_400 = mul_401 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_254: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_402, 0);  mul_402 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_255: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_254, 2);  unsqueeze_254 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_256: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_255, 3);  unsqueeze_255 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_403: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_148, primals_149);  primals_149 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_257: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_403, 0);  mul_403 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_258: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_257, 2);  unsqueeze_257 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_259: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_258, 3);  unsqueeze_258 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_404: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_65, unsqueeze_256);  sub_65 = unsqueeze_256 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_67: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(where_3, mul_404);  mul_404 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_68: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(sub_67, unsqueeze_253);  sub_67 = unsqueeze_253 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_405: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_68, unsqueeze_259);  sub_68 = unsqueeze_259 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_406: f32[2048] = torch.ops.aten.mul.Tensor(sum_9, squeeze_148);  sum_9 = squeeze_148 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_3 = torch.ops.aten.convolution_backward.default(mul_405, relu_44, primals_148, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_405 = primals_148 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_117: f32[64, 512, 7, 7] = convolution_backward_3[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_118: f32[2048, 512, 1, 1] = convolution_backward_3[1];  convolution_backward_3 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_4: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_44, 0);  relu_44 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_4: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_4, full_default, getitem_117);  le_4 = getitem_117 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_10: f32[512] = torch.ops.aten.sum.dim_IntList(where_4, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_69: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_48, unsqueeze_262);  convolution_48 = unsqueeze_262 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_407: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_4, sub_69)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_11: f32[512] = torch.ops.aten.sum.dim_IntList(mul_407, [0, 2, 3]);  mul_407 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_408: f32[512] = torch.ops.aten.mul.Tensor(sum_10, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_263: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_408, 0);  mul_408 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_264: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_263, 2);  unsqueeze_263 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_265: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_264, 3);  unsqueeze_264 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_409: f32[512] = torch.ops.aten.mul.Tensor(sum_11, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_410: f32[512] = torch.ops.aten.mul.Tensor(squeeze_145, squeeze_145)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_411: f32[512] = torch.ops.aten.mul.Tensor(mul_409, mul_410);  mul_409 = mul_410 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_266: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_411, 0);  mul_411 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_267: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_266, 2);  unsqueeze_266 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_268: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_267, 3);  unsqueeze_267 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_412: f32[512] = torch.ops.aten.mul.Tensor(squeeze_145, primals_146);  primals_146 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_269: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_412, 0);  mul_412 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_270: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_269, 2);  unsqueeze_269 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_271: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_270, 3);  unsqueeze_270 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_413: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_69, unsqueeze_268);  sub_69 = unsqueeze_268 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_71: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_4, mul_413);  where_4 = mul_413 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_72: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_71, unsqueeze_265);  sub_71 = unsqueeze_265 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_414: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_72, unsqueeze_271);  sub_72 = unsqueeze_271 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_415: f32[512] = torch.ops.aten.mul.Tensor(sum_11, squeeze_145);  sum_11 = squeeze_145 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_4 = torch.ops.aten.convolution_backward.default(mul_414, relu_43, primals_145, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_414 = primals_145 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_120: f32[64, 512, 7, 7] = convolution_backward_4[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_121: f32[512, 512, 3, 3] = convolution_backward_4[1];  convolution_backward_4 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_5: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_43, 0);  relu_43 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_5: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_5, full_default, getitem_120);  le_5 = getitem_120 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_12: f32[512] = torch.ops.aten.sum.dim_IntList(where_5, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_73: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_47, unsqueeze_274);  convolution_47 = unsqueeze_274 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_416: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_5, sub_73)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_13: f32[512] = torch.ops.aten.sum.dim_IntList(mul_416, [0, 2, 3]);  mul_416 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_417: f32[512] = torch.ops.aten.mul.Tensor(sum_12, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_275: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_417, 0);  mul_417 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_276: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_275, 2);  unsqueeze_275 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_277: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_276, 3);  unsqueeze_276 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_418: f32[512] = torch.ops.aten.mul.Tensor(sum_13, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_419: f32[512] = torch.ops.aten.mul.Tensor(squeeze_142, squeeze_142)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_420: f32[512] = torch.ops.aten.mul.Tensor(mul_418, mul_419);  mul_418 = mul_419 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_278: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_420, 0);  mul_420 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_279: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_278, 2);  unsqueeze_278 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_280: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_279, 3);  unsqueeze_279 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_421: f32[512] = torch.ops.aten.mul.Tensor(squeeze_142, primals_143);  primals_143 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_281: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_421, 0);  mul_421 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_282: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_281, 2);  unsqueeze_281 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_283: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_282, 3);  unsqueeze_282 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_422: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_73, unsqueeze_280);  sub_73 = unsqueeze_280 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_75: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_5, mul_422);  where_5 = mul_422 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_76: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_75, unsqueeze_277);  sub_75 = unsqueeze_277 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_423: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_76, unsqueeze_283);  sub_76 = unsqueeze_283 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_424: f32[512] = torch.ops.aten.mul.Tensor(sum_13, squeeze_142);  sum_13 = squeeze_142 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_5 = torch.ops.aten.convolution_backward.default(mul_423, relu_42, primals_142, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_423 = primals_142 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_123: f32[64, 2048, 7, 7] = convolution_backward_5[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_124: f32[512, 2048, 1, 1] = convolution_backward_5[1];  convolution_backward_5 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_282: f32[64, 2048, 7, 7] = torch.ops.aten.add.Tensor(where_3, getitem_123);  where_3 = getitem_123 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_6: b8[64, 2048, 7, 7] = torch.ops.aten.le.Scalar(relu_42, 0);  relu_42 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_6: f32[64, 2048, 7, 7] = torch.ops.aten.where.self(le_6, full_default, add_282);  le_6 = add_282 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_14: f32[2048] = torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_77: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_46, unsqueeze_286);  convolution_46 = unsqueeze_286 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_425: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(where_6, sub_77)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_15: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_425, [0, 2, 3]);  mul_425 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_426: f32[2048] = torch.ops.aten.mul.Tensor(sum_14, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_287: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_426, 0);  mul_426 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_288: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_287, 2);  unsqueeze_287 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_289: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_288, 3);  unsqueeze_288 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_427: f32[2048] = torch.ops.aten.mul.Tensor(sum_15, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_428: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_139, squeeze_139)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_429: f32[2048] = torch.ops.aten.mul.Tensor(mul_427, mul_428);  mul_427 = mul_428 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_290: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_429, 0);  mul_429 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_291: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_290, 2);  unsqueeze_290 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_292: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_291, 3);  unsqueeze_291 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_430: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_139, primals_140);  primals_140 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_293: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_430, 0);  mul_430 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_294: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_293, 2);  unsqueeze_293 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_295: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_294, 3);  unsqueeze_294 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_431: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_77, unsqueeze_292);  sub_77 = unsqueeze_292 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_79: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(where_6, mul_431);  mul_431 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_80: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(sub_79, unsqueeze_289);  sub_79 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_432: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_80, unsqueeze_295);  sub_80 = unsqueeze_295 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_433: f32[2048] = torch.ops.aten.mul.Tensor(sum_15, squeeze_139);  sum_15 = squeeze_139 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_6 = torch.ops.aten.convolution_backward.default(mul_432, relu_39, primals_139, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_432 = primals_139 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_126: f32[64, 1024, 14, 14] = convolution_backward_6[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_127: f32[2048, 1024, 1, 1] = convolution_backward_6[1];  convolution_backward_6 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_81: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(convolution_45, unsqueeze_298);  convolution_45 = unsqueeze_298 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_434: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(where_6, sub_81)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_17: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_434, [0, 2, 3]);  mul_434 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_436: f32[2048] = torch.ops.aten.mul.Tensor(sum_17, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_437: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_136, squeeze_136)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_438: f32[2048] = torch.ops.aten.mul.Tensor(mul_436, mul_437);  mul_436 = mul_437 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_302: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_438, 0);  mul_438 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_303: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_302, 2);  unsqueeze_302 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_304: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_303, 3);  unsqueeze_303 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_439: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_136, primals_137);  primals_137 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_305: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_439, 0);  mul_439 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_306: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_305, 2);  unsqueeze_305 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_307: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_306, 3);  unsqueeze_306 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_440: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_81, unsqueeze_304);  sub_81 = unsqueeze_304 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_83: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(where_6, mul_440);  where_6 = mul_440 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_84: f32[64, 2048, 7, 7] = torch.ops.aten.sub.Tensor(sub_83, unsqueeze_289);  sub_83 = unsqueeze_289 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_441: f32[64, 2048, 7, 7] = torch.ops.aten.mul.Tensor(sub_84, unsqueeze_307);  sub_84 = unsqueeze_307 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_442: f32[2048] = torch.ops.aten.mul.Tensor(sum_17, squeeze_136);  sum_17 = squeeze_136 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_7 = torch.ops.aten.convolution_backward.default(mul_441, relu_41, primals_136, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_441 = primals_136 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_129: f32[64, 512, 7, 7] = convolution_backward_7[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_130: f32[2048, 512, 1, 1] = convolution_backward_7[1];  convolution_backward_7 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_7: b8[64, 512, 7, 7] = torch.ops.aten.le.Scalar(relu_41, 0);  relu_41 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_7: f32[64, 512, 7, 7] = torch.ops.aten.where.self(le_7, full_default, getitem_129);  le_7 = getitem_129 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_18: f32[512] = torch.ops.aten.sum.dim_IntList(where_7, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_85: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(convolution_44, unsqueeze_310);  convolution_44 = unsqueeze_310 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_443: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(where_7, sub_85)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_19: f32[512] = torch.ops.aten.sum.dim_IntList(mul_443, [0, 2, 3]);  mul_443 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_444: f32[512] = torch.ops.aten.mul.Tensor(sum_18, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_311: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_444, 0);  mul_444 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_312: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_311, 2);  unsqueeze_311 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_313: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_312, 3);  unsqueeze_312 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_445: f32[512] = torch.ops.aten.mul.Tensor(sum_19, 0.00031887755102040814)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_446: f32[512] = torch.ops.aten.mul.Tensor(squeeze_133, squeeze_133)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_447: f32[512] = torch.ops.aten.mul.Tensor(mul_445, mul_446);  mul_445 = mul_446 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_314: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_447, 0);  mul_447 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_315: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_314, 2);  unsqueeze_314 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_316: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_315, 3);  unsqueeze_315 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_448: f32[512] = torch.ops.aten.mul.Tensor(squeeze_133, primals_134);  primals_134 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_317: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_448, 0);  mul_448 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_318: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_317, 2);  unsqueeze_317 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_319: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_318, 3);  unsqueeze_318 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_449: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_85, unsqueeze_316);  sub_85 = unsqueeze_316 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_87: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(where_7, mul_449);  where_7 = mul_449 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_88: f32[64, 512, 7, 7] = torch.ops.aten.sub.Tensor(sub_87, unsqueeze_313);  sub_87 = unsqueeze_313 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_450: f32[64, 512, 7, 7] = torch.ops.aten.mul.Tensor(sub_88, unsqueeze_319);  sub_88 = unsqueeze_319 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_451: f32[512] = torch.ops.aten.mul.Tensor(sum_19, squeeze_133);  sum_19 = squeeze_133 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_8 = torch.ops.aten.convolution_backward.default(mul_450, relu_40, primals_133, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_450 = primals_133 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_132: f32[64, 512, 14, 14] = convolution_backward_8[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_133: f32[512, 512, 3, 3] = convolution_backward_8[1];  convolution_backward_8 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_8: b8[64, 512, 14, 14] = torch.ops.aten.le.Scalar(relu_40, 0);  relu_40 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_8: f32[64, 512, 14, 14] = torch.ops.aten.where.self(le_8, full_default, getitem_132);  le_8 = getitem_132 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_20: f32[512] = torch.ops.aten.sum.dim_IntList(where_8, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_89: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(convolution_43, unsqueeze_322);  convolution_43 = unsqueeze_322 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_452: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(where_8, sub_89)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_21: f32[512] = torch.ops.aten.sum.dim_IntList(mul_452, [0, 2, 3]);  mul_452 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_453: f32[512] = torch.ops.aten.mul.Tensor(sum_20, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_323: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_453, 0);  mul_453 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_324: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_323, 2);  unsqueeze_323 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_325: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_324, 3);  unsqueeze_324 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_454: f32[512] = torch.ops.aten.mul.Tensor(sum_21, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_455: f32[512] = torch.ops.aten.mul.Tensor(squeeze_130, squeeze_130)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_456: f32[512] = torch.ops.aten.mul.Tensor(mul_454, mul_455);  mul_454 = mul_455 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_326: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_456, 0);  mul_456 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_327: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_326, 2);  unsqueeze_326 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_328: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_327, 3);  unsqueeze_327 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_457: f32[512] = torch.ops.aten.mul.Tensor(squeeze_130, primals_131);  primals_131 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_329: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_457, 0);  mul_457 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_330: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_329, 2);  unsqueeze_329 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_331: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_330, 3);  unsqueeze_330 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_458: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(sub_89, unsqueeze_328);  sub_89 = unsqueeze_328 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_91: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(where_8, mul_458);  where_8 = mul_458 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_92: f32[64, 512, 14, 14] = torch.ops.aten.sub.Tensor(sub_91, unsqueeze_325);  sub_91 = unsqueeze_325 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_459: f32[64, 512, 14, 14] = torch.ops.aten.mul.Tensor(sub_92, unsqueeze_331);  sub_92 = unsqueeze_331 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_460: f32[512] = torch.ops.aten.mul.Tensor(sum_21, squeeze_130);  sum_21 = squeeze_130 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_9 = torch.ops.aten.convolution_backward.default(mul_459, relu_39, primals_130, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_459 = primals_130 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_135: f32[64, 1024, 14, 14] = convolution_backward_9[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_136: f32[512, 1024, 1, 1] = convolution_backward_9[1];  convolution_backward_9 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_283: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(getitem_126, getitem_135);  getitem_126 = getitem_135 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_9: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_39, 0);  relu_39 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_9: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_9, full_default, add_283);  le_9 = add_283 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_22: f32[1024] = torch.ops.aten.sum.dim_IntList(where_9, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_93: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_42, unsqueeze_334);  convolution_42 = unsqueeze_334 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_461: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_9, sub_93)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_23: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_461, [0, 2, 3]);  mul_461 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_462: f32[1024] = torch.ops.aten.mul.Tensor(sum_22, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_335: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_462, 0);  mul_462 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_336: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_335, 2);  unsqueeze_335 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_337: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_336, 3);  unsqueeze_336 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_463: f32[1024] = torch.ops.aten.mul.Tensor(sum_23, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_464: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_127, squeeze_127)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_465: f32[1024] = torch.ops.aten.mul.Tensor(mul_463, mul_464);  mul_463 = mul_464 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_338: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_465, 0);  mul_465 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_339: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_338, 2);  unsqueeze_338 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_340: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_339, 3);  unsqueeze_339 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_466: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_127, primals_128);  primals_128 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_341: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_466, 0);  mul_466 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_342: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_341, 2);  unsqueeze_341 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_343: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_342, 3);  unsqueeze_342 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_467: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_93, unsqueeze_340);  sub_93 = unsqueeze_340 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_95: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_9, mul_467);  mul_467 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_96: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_95, unsqueeze_337);  sub_95 = unsqueeze_337 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_468: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_96, unsqueeze_343);  sub_96 = unsqueeze_343 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_469: f32[1024] = torch.ops.aten.mul.Tensor(sum_23, squeeze_127);  sum_23 = squeeze_127 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_10 = torch.ops.aten.convolution_backward.default(mul_468, relu_38, primals_127, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_468 = primals_127 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_138: f32[64, 256, 14, 14] = convolution_backward_10[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_139: f32[1024, 256, 1, 1] = convolution_backward_10[1];  convolution_backward_10 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_10: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_38, 0);  relu_38 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_10: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_10, full_default, getitem_138);  le_10 = getitem_138 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_24: f32[256] = torch.ops.aten.sum.dim_IntList(where_10, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_97: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_41, unsqueeze_346);  convolution_41 = unsqueeze_346 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_470: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_10, sub_97)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_25: f32[256] = torch.ops.aten.sum.dim_IntList(mul_470, [0, 2, 3]);  mul_470 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_471: f32[256] = torch.ops.aten.mul.Tensor(sum_24, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_347: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_471, 0);  mul_471 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_348: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_347, 2);  unsqueeze_347 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_349: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_348, 3);  unsqueeze_348 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_472: f32[256] = torch.ops.aten.mul.Tensor(sum_25, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_473: f32[256] = torch.ops.aten.mul.Tensor(squeeze_124, squeeze_124)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_474: f32[256] = torch.ops.aten.mul.Tensor(mul_472, mul_473);  mul_472 = mul_473 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_350: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_474, 0);  mul_474 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_351: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_350, 2);  unsqueeze_350 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_352: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_351, 3);  unsqueeze_351 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_475: f32[256] = torch.ops.aten.mul.Tensor(squeeze_124, primals_125);  primals_125 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_353: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_475, 0);  mul_475 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_354: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_353, 2);  unsqueeze_353 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_355: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_354, 3);  unsqueeze_354 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_476: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_97, unsqueeze_352);  sub_97 = unsqueeze_352 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_99: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_10, mul_476);  where_10 = mul_476 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_100: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_99, unsqueeze_349);  sub_99 = unsqueeze_349 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_477: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_100, unsqueeze_355);  sub_100 = unsqueeze_355 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_478: f32[256] = torch.ops.aten.mul.Tensor(sum_25, squeeze_124);  sum_25 = squeeze_124 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_11 = torch.ops.aten.convolution_backward.default(mul_477, relu_37, primals_124, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_477 = primals_124 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_141: f32[64, 256, 14, 14] = convolution_backward_11[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_142: f32[256, 256, 3, 3] = convolution_backward_11[1];  convolution_backward_11 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_11: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_37, 0);  relu_37 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_11: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_11, full_default, getitem_141);  le_11 = getitem_141 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_26: f32[256] = torch.ops.aten.sum.dim_IntList(where_11, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_101: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_40, unsqueeze_358);  convolution_40 = unsqueeze_358 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_479: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_11, sub_101)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_27: f32[256] = torch.ops.aten.sum.dim_IntList(mul_479, [0, 2, 3]);  mul_479 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_480: f32[256] = torch.ops.aten.mul.Tensor(sum_26, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_359: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_480, 0);  mul_480 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_360: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_359, 2);  unsqueeze_359 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_361: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_360, 3);  unsqueeze_360 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_481: f32[256] = torch.ops.aten.mul.Tensor(sum_27, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_482: f32[256] = torch.ops.aten.mul.Tensor(squeeze_121, squeeze_121)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_483: f32[256] = torch.ops.aten.mul.Tensor(mul_481, mul_482);  mul_481 = mul_482 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_362: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_483, 0);  mul_483 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_363: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_362, 2);  unsqueeze_362 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_364: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_363, 3);  unsqueeze_363 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_484: f32[256] = torch.ops.aten.mul.Tensor(squeeze_121, primals_122);  primals_122 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_365: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_484, 0);  mul_484 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_366: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_365, 2);  unsqueeze_365 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_367: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_366, 3);  unsqueeze_366 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_485: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_101, unsqueeze_364);  sub_101 = unsqueeze_364 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_103: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_11, mul_485);  where_11 = mul_485 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_104: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_103, unsqueeze_361);  sub_103 = unsqueeze_361 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_486: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_104, unsqueeze_367);  sub_104 = unsqueeze_367 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_487: f32[256] = torch.ops.aten.mul.Tensor(sum_27, squeeze_121);  sum_27 = squeeze_121 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_12 = torch.ops.aten.convolution_backward.default(mul_486, relu_36, primals_121, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_486 = primals_121 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_144: f32[64, 1024, 14, 14] = convolution_backward_12[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_145: f32[256, 1024, 1, 1] = convolution_backward_12[1];  convolution_backward_12 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_284: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_9, getitem_144);  where_9 = getitem_144 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_12: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_36, 0);  relu_36 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_12: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_12, full_default, add_284);  le_12 = add_284 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_28: f32[1024] = torch.ops.aten.sum.dim_IntList(where_12, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_105: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_39, unsqueeze_370);  convolution_39 = unsqueeze_370 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_488: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_12, sub_105)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_29: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_488, [0, 2, 3]);  mul_488 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_489: f32[1024] = torch.ops.aten.mul.Tensor(sum_28, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_371: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_489, 0);  mul_489 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_372: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_371, 2);  unsqueeze_371 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_373: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_372, 3);  unsqueeze_372 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_490: f32[1024] = torch.ops.aten.mul.Tensor(sum_29, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_491: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_118, squeeze_118)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_492: f32[1024] = torch.ops.aten.mul.Tensor(mul_490, mul_491);  mul_490 = mul_491 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_374: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_492, 0);  mul_492 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_375: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_374, 2);  unsqueeze_374 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_376: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_375, 3);  unsqueeze_375 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_493: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_118, primals_119);  primals_119 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_377: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_493, 0);  mul_493 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_378: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_377, 2);  unsqueeze_377 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_379: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_378, 3);  unsqueeze_378 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_494: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_105, unsqueeze_376);  sub_105 = unsqueeze_376 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_107: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_12, mul_494);  mul_494 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_108: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_107, unsqueeze_373);  sub_107 = unsqueeze_373 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_495: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_108, unsqueeze_379);  sub_108 = unsqueeze_379 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_496: f32[1024] = torch.ops.aten.mul.Tensor(sum_29, squeeze_118);  sum_29 = squeeze_118 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_13 = torch.ops.aten.convolution_backward.default(mul_495, relu_35, primals_118, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_495 = primals_118 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_147: f32[64, 256, 14, 14] = convolution_backward_13[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_148: f32[1024, 256, 1, 1] = convolution_backward_13[1];  convolution_backward_13 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_13: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_35, 0);  relu_35 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_13: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_13, full_default, getitem_147);  le_13 = getitem_147 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_30: f32[256] = torch.ops.aten.sum.dim_IntList(where_13, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_109: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_38, unsqueeze_382);  convolution_38 = unsqueeze_382 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_497: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_13, sub_109)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_31: f32[256] = torch.ops.aten.sum.dim_IntList(mul_497, [0, 2, 3]);  mul_497 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_498: f32[256] = torch.ops.aten.mul.Tensor(sum_30, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_383: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_498, 0);  mul_498 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_384: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_383, 2);  unsqueeze_383 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_385: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_384, 3);  unsqueeze_384 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_499: f32[256] = torch.ops.aten.mul.Tensor(sum_31, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_500: f32[256] = torch.ops.aten.mul.Tensor(squeeze_115, squeeze_115)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_501: f32[256] = torch.ops.aten.mul.Tensor(mul_499, mul_500);  mul_499 = mul_500 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_386: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_501, 0);  mul_501 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_387: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_386, 2);  unsqueeze_386 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_388: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_387, 3);  unsqueeze_387 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_502: f32[256] = torch.ops.aten.mul.Tensor(squeeze_115, primals_116);  primals_116 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_389: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_502, 0);  mul_502 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_390: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_389, 2);  unsqueeze_389 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_391: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_390, 3);  unsqueeze_390 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_503: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_109, unsqueeze_388);  sub_109 = unsqueeze_388 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_111: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_13, mul_503);  where_13 = mul_503 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_112: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_111, unsqueeze_385);  sub_111 = unsqueeze_385 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_504: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_112, unsqueeze_391);  sub_112 = unsqueeze_391 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_505: f32[256] = torch.ops.aten.mul.Tensor(sum_31, squeeze_115);  sum_31 = squeeze_115 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_14 = torch.ops.aten.convolution_backward.default(mul_504, relu_34, primals_115, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_504 = primals_115 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_150: f32[64, 256, 14, 14] = convolution_backward_14[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_151: f32[256, 256, 3, 3] = convolution_backward_14[1];  convolution_backward_14 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_14: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_34, 0);  relu_34 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_14: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_14, full_default, getitem_150);  le_14 = getitem_150 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_32: f32[256] = torch.ops.aten.sum.dim_IntList(where_14, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_113: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_37, unsqueeze_394);  convolution_37 = unsqueeze_394 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_506: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_14, sub_113)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_33: f32[256] = torch.ops.aten.sum.dim_IntList(mul_506, [0, 2, 3]);  mul_506 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_507: f32[256] = torch.ops.aten.mul.Tensor(sum_32, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_395: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_507, 0);  mul_507 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_396: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_395, 2);  unsqueeze_395 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_397: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_396, 3);  unsqueeze_396 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_508: f32[256] = torch.ops.aten.mul.Tensor(sum_33, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_509: f32[256] = torch.ops.aten.mul.Tensor(squeeze_112, squeeze_112)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_510: f32[256] = torch.ops.aten.mul.Tensor(mul_508, mul_509);  mul_508 = mul_509 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_398: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_510, 0);  mul_510 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_399: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_398, 2);  unsqueeze_398 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_400: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_399, 3);  unsqueeze_399 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_511: f32[256] = torch.ops.aten.mul.Tensor(squeeze_112, primals_113);  primals_113 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_401: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_511, 0);  mul_511 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_402: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_401, 2);  unsqueeze_401 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_403: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_402, 3);  unsqueeze_402 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_512: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_113, unsqueeze_400);  sub_113 = unsqueeze_400 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_115: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_14, mul_512);  where_14 = mul_512 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_116: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_115, unsqueeze_397);  sub_115 = unsqueeze_397 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_513: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_116, unsqueeze_403);  sub_116 = unsqueeze_403 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_514: f32[256] = torch.ops.aten.mul.Tensor(sum_33, squeeze_112);  sum_33 = squeeze_112 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_15 = torch.ops.aten.convolution_backward.default(mul_513, relu_33, primals_112, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_513 = primals_112 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_153: f32[64, 1024, 14, 14] = convolution_backward_15[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_154: f32[256, 1024, 1, 1] = convolution_backward_15[1];  convolution_backward_15 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_285: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_12, getitem_153);  where_12 = getitem_153 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_15: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_33, 0);  relu_33 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_15: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_15, full_default, add_285);  le_15 = add_285 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_34: f32[1024] = torch.ops.aten.sum.dim_IntList(where_15, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_117: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_36, unsqueeze_406);  convolution_36 = unsqueeze_406 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_515: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_15, sub_117)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_35: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_515, [0, 2, 3]);  mul_515 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_516: f32[1024] = torch.ops.aten.mul.Tensor(sum_34, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_407: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_516, 0);  mul_516 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_408: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_407, 2);  unsqueeze_407 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_409: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_408, 3);  unsqueeze_408 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_517: f32[1024] = torch.ops.aten.mul.Tensor(sum_35, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_518: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_109, squeeze_109)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_519: f32[1024] = torch.ops.aten.mul.Tensor(mul_517, mul_518);  mul_517 = mul_518 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_410: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_519, 0);  mul_519 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_411: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_410, 2);  unsqueeze_410 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_412: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_411, 3);  unsqueeze_411 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_520: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_109, primals_110);  primals_110 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_413: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_520, 0);  mul_520 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_414: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_413, 2);  unsqueeze_413 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_415: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_414, 3);  unsqueeze_414 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_521: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_117, unsqueeze_412);  sub_117 = unsqueeze_412 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_119: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_15, mul_521);  mul_521 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_120: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_119, unsqueeze_409);  sub_119 = unsqueeze_409 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_522: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_120, unsqueeze_415);  sub_120 = unsqueeze_415 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_523: f32[1024] = torch.ops.aten.mul.Tensor(sum_35, squeeze_109);  sum_35 = squeeze_109 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_16 = torch.ops.aten.convolution_backward.default(mul_522, relu_32, primals_109, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_522 = primals_109 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_156: f32[64, 256, 14, 14] = convolution_backward_16[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_157: f32[1024, 256, 1, 1] = convolution_backward_16[1];  convolution_backward_16 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_16: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_32, 0);  relu_32 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_16: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_16, full_default, getitem_156);  le_16 = getitem_156 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_36: f32[256] = torch.ops.aten.sum.dim_IntList(where_16, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_121: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_35, unsqueeze_418);  convolution_35 = unsqueeze_418 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_524: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_16, sub_121)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_37: f32[256] = torch.ops.aten.sum.dim_IntList(mul_524, [0, 2, 3]);  mul_524 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_525: f32[256] = torch.ops.aten.mul.Tensor(sum_36, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_419: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_525, 0);  mul_525 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_420: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_419, 2);  unsqueeze_419 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_421: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_420, 3);  unsqueeze_420 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_526: f32[256] = torch.ops.aten.mul.Tensor(sum_37, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_527: f32[256] = torch.ops.aten.mul.Tensor(squeeze_106, squeeze_106)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_528: f32[256] = torch.ops.aten.mul.Tensor(mul_526, mul_527);  mul_526 = mul_527 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_422: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_528, 0);  mul_528 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_423: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_422, 2);  unsqueeze_422 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_424: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_423, 3);  unsqueeze_423 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_529: f32[256] = torch.ops.aten.mul.Tensor(squeeze_106, primals_107);  primals_107 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_425: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_529, 0);  mul_529 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_426: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_425, 2);  unsqueeze_425 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_427: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_426, 3);  unsqueeze_426 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_530: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_121, unsqueeze_424);  sub_121 = unsqueeze_424 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_123: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_16, mul_530);  where_16 = mul_530 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_124: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_123, unsqueeze_421);  sub_123 = unsqueeze_421 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_531: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_124, unsqueeze_427);  sub_124 = unsqueeze_427 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_532: f32[256] = torch.ops.aten.mul.Tensor(sum_37, squeeze_106);  sum_37 = squeeze_106 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_17 = torch.ops.aten.convolution_backward.default(mul_531, relu_31, primals_106, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_531 = primals_106 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_159: f32[64, 256, 14, 14] = convolution_backward_17[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_160: f32[256, 256, 3, 3] = convolution_backward_17[1];  convolution_backward_17 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_17: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_31, 0);  relu_31 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_17: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_17, full_default, getitem_159);  le_17 = getitem_159 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_38: f32[256] = torch.ops.aten.sum.dim_IntList(where_17, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_125: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_34, unsqueeze_430);  convolution_34 = unsqueeze_430 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_533: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_17, sub_125)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_39: f32[256] = torch.ops.aten.sum.dim_IntList(mul_533, [0, 2, 3]);  mul_533 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_534: f32[256] = torch.ops.aten.mul.Tensor(sum_38, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_431: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_534, 0);  mul_534 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_432: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_431, 2);  unsqueeze_431 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_433: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_432, 3);  unsqueeze_432 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_535: f32[256] = torch.ops.aten.mul.Tensor(sum_39, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_536: f32[256] = torch.ops.aten.mul.Tensor(squeeze_103, squeeze_103)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_537: f32[256] = torch.ops.aten.mul.Tensor(mul_535, mul_536);  mul_535 = mul_536 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_434: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_537, 0);  mul_537 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_435: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_434, 2);  unsqueeze_434 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_436: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_435, 3);  unsqueeze_435 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_538: f32[256] = torch.ops.aten.mul.Tensor(squeeze_103, primals_104);  primals_104 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_437: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_538, 0);  mul_538 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_438: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_437, 2);  unsqueeze_437 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_439: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_438, 3);  unsqueeze_438 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_539: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_125, unsqueeze_436);  sub_125 = unsqueeze_436 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_127: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_17, mul_539);  where_17 = mul_539 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_128: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_127, unsqueeze_433);  sub_127 = unsqueeze_433 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_540: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_128, unsqueeze_439);  sub_128 = unsqueeze_439 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_541: f32[256] = torch.ops.aten.mul.Tensor(sum_39, squeeze_103);  sum_39 = squeeze_103 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_18 = torch.ops.aten.convolution_backward.default(mul_540, relu_30, primals_103, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_540 = primals_103 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_162: f32[64, 1024, 14, 14] = convolution_backward_18[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_163: f32[256, 1024, 1, 1] = convolution_backward_18[1];  convolution_backward_18 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_286: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_15, getitem_162);  where_15 = getitem_162 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_18: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_30, 0);  relu_30 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_18: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_18, full_default, add_286);  le_18 = add_286 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_40: f32[1024] = torch.ops.aten.sum.dim_IntList(where_18, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_129: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_33, unsqueeze_442);  convolution_33 = unsqueeze_442 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_542: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_18, sub_129)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_41: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_542, [0, 2, 3]);  mul_542 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_543: f32[1024] = torch.ops.aten.mul.Tensor(sum_40, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_443: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_543, 0);  mul_543 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_444: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_443, 2);  unsqueeze_443 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_445: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_444, 3);  unsqueeze_444 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_544: f32[1024] = torch.ops.aten.mul.Tensor(sum_41, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_545: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_100, squeeze_100)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_546: f32[1024] = torch.ops.aten.mul.Tensor(mul_544, mul_545);  mul_544 = mul_545 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_446: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_546, 0);  mul_546 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_447: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_446, 2);  unsqueeze_446 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_448: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_447, 3);  unsqueeze_447 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_547: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_100, primals_101);  primals_101 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_449: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_547, 0);  mul_547 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_450: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_449, 2);  unsqueeze_449 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_451: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_450, 3);  unsqueeze_450 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_548: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_129, unsqueeze_448);  sub_129 = unsqueeze_448 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_131: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_18, mul_548);  mul_548 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_132: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_131, unsqueeze_445);  sub_131 = unsqueeze_445 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_549: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_132, unsqueeze_451);  sub_132 = unsqueeze_451 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_550: f32[1024] = torch.ops.aten.mul.Tensor(sum_41, squeeze_100);  sum_41 = squeeze_100 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_19 = torch.ops.aten.convolution_backward.default(mul_549, relu_29, primals_100, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_549 = primals_100 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_165: f32[64, 256, 14, 14] = convolution_backward_19[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_166: f32[1024, 256, 1, 1] = convolution_backward_19[1];  convolution_backward_19 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_19: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_29, 0);  relu_29 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_19: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_19, full_default, getitem_165);  le_19 = getitem_165 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_42: f32[256] = torch.ops.aten.sum.dim_IntList(where_19, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_133: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_32, unsqueeze_454);  convolution_32 = unsqueeze_454 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_551: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_19, sub_133)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_43: f32[256] = torch.ops.aten.sum.dim_IntList(mul_551, [0, 2, 3]);  mul_551 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_552: f32[256] = torch.ops.aten.mul.Tensor(sum_42, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_455: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_552, 0);  mul_552 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_456: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_455, 2);  unsqueeze_455 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_457: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_456, 3);  unsqueeze_456 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_553: f32[256] = torch.ops.aten.mul.Tensor(sum_43, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_554: f32[256] = torch.ops.aten.mul.Tensor(squeeze_97, squeeze_97)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_555: f32[256] = torch.ops.aten.mul.Tensor(mul_553, mul_554);  mul_553 = mul_554 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_458: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_555, 0);  mul_555 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_459: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_458, 2);  unsqueeze_458 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_460: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_459, 3);  unsqueeze_459 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_556: f32[256] = torch.ops.aten.mul.Tensor(squeeze_97, primals_98);  primals_98 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_461: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_556, 0);  mul_556 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_462: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_461, 2);  unsqueeze_461 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_463: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_462, 3);  unsqueeze_462 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_557: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_133, unsqueeze_460);  sub_133 = unsqueeze_460 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_135: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_19, mul_557);  where_19 = mul_557 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_136: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_135, unsqueeze_457);  sub_135 = unsqueeze_457 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_558: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_136, unsqueeze_463);  sub_136 = unsqueeze_463 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_559: f32[256] = torch.ops.aten.mul.Tensor(sum_43, squeeze_97);  sum_43 = squeeze_97 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_20 = torch.ops.aten.convolution_backward.default(mul_558, relu_28, primals_97, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_558 = primals_97 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_168: f32[64, 256, 14, 14] = convolution_backward_20[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_169: f32[256, 256, 3, 3] = convolution_backward_20[1];  convolution_backward_20 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_20: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_28, 0);  relu_28 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_20: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_20, full_default, getitem_168);  le_20 = getitem_168 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_44: f32[256] = torch.ops.aten.sum.dim_IntList(where_20, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_137: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_31, unsqueeze_466);  convolution_31 = unsqueeze_466 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_560: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_20, sub_137)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_45: f32[256] = torch.ops.aten.sum.dim_IntList(mul_560, [0, 2, 3]);  mul_560 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_561: f32[256] = torch.ops.aten.mul.Tensor(sum_44, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_467: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_561, 0);  mul_561 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_468: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_467, 2);  unsqueeze_467 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_469: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_468, 3);  unsqueeze_468 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_562: f32[256] = torch.ops.aten.mul.Tensor(sum_45, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_563: f32[256] = torch.ops.aten.mul.Tensor(squeeze_94, squeeze_94)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_564: f32[256] = torch.ops.aten.mul.Tensor(mul_562, mul_563);  mul_562 = mul_563 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_470: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_564, 0);  mul_564 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_471: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_470, 2);  unsqueeze_470 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_472: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_471, 3);  unsqueeze_471 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_565: f32[256] = torch.ops.aten.mul.Tensor(squeeze_94, primals_95);  primals_95 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_473: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_565, 0);  mul_565 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_474: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_473, 2);  unsqueeze_473 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_475: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_474, 3);  unsqueeze_474 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_566: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_137, unsqueeze_472);  sub_137 = unsqueeze_472 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_139: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_20, mul_566);  where_20 = mul_566 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_140: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_139, unsqueeze_469);  sub_139 = unsqueeze_469 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_567: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_140, unsqueeze_475);  sub_140 = unsqueeze_475 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_568: f32[256] = torch.ops.aten.mul.Tensor(sum_45, squeeze_94);  sum_45 = squeeze_94 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_21 = torch.ops.aten.convolution_backward.default(mul_567, relu_27, primals_94, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_567 = primals_94 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_171: f32[64, 1024, 14, 14] = convolution_backward_21[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_172: f32[256, 1024, 1, 1] = convolution_backward_21[1];  convolution_backward_21 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_287: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_18, getitem_171);  where_18 = getitem_171 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_21: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_27, 0);  relu_27 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_21: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_21, full_default, add_287);  le_21 = add_287 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_46: f32[1024] = torch.ops.aten.sum.dim_IntList(where_21, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_141: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_30, unsqueeze_478);  convolution_30 = unsqueeze_478 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_569: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_21, sub_141)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_47: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_569, [0, 2, 3]);  mul_569 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_570: f32[1024] = torch.ops.aten.mul.Tensor(sum_46, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_479: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_570, 0);  mul_570 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_480: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_479, 2);  unsqueeze_479 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_481: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_480, 3);  unsqueeze_480 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_571: f32[1024] = torch.ops.aten.mul.Tensor(sum_47, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_572: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_91, squeeze_91)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_573: f32[1024] = torch.ops.aten.mul.Tensor(mul_571, mul_572);  mul_571 = mul_572 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_482: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_573, 0);  mul_573 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_483: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_482, 2);  unsqueeze_482 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_484: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_483, 3);  unsqueeze_483 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_574: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_91, primals_92);  primals_92 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_485: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_574, 0);  mul_574 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_486: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_485, 2);  unsqueeze_485 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_487: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_486, 3);  unsqueeze_486 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_575: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_141, unsqueeze_484);  sub_141 = unsqueeze_484 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_143: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_21, mul_575);  mul_575 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_144: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_143, unsqueeze_481);  sub_143 = unsqueeze_481 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_576: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_144, unsqueeze_487);  sub_144 = unsqueeze_487 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_577: f32[1024] = torch.ops.aten.mul.Tensor(sum_47, squeeze_91);  sum_47 = squeeze_91 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_22 = torch.ops.aten.convolution_backward.default(mul_576, relu_26, primals_91, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_576 = primals_91 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_174: f32[64, 256, 14, 14] = convolution_backward_22[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_175: f32[1024, 256, 1, 1] = convolution_backward_22[1];  convolution_backward_22 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_22: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_26, 0);  relu_26 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_22: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_22, full_default, getitem_174);  le_22 = getitem_174 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_48: f32[256] = torch.ops.aten.sum.dim_IntList(where_22, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_145: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_29, unsqueeze_490);  convolution_29 = unsqueeze_490 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_578: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_22, sub_145)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_49: f32[256] = torch.ops.aten.sum.dim_IntList(mul_578, [0, 2, 3]);  mul_578 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_579: f32[256] = torch.ops.aten.mul.Tensor(sum_48, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_491: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_579, 0);  mul_579 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_492: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_491, 2);  unsqueeze_491 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_493: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_492, 3);  unsqueeze_492 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_580: f32[256] = torch.ops.aten.mul.Tensor(sum_49, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_581: f32[256] = torch.ops.aten.mul.Tensor(squeeze_88, squeeze_88)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_582: f32[256] = torch.ops.aten.mul.Tensor(mul_580, mul_581);  mul_580 = mul_581 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_494: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_582, 0);  mul_582 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_495: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_494, 2);  unsqueeze_494 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_496: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_495, 3);  unsqueeze_495 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_583: f32[256] = torch.ops.aten.mul.Tensor(squeeze_88, primals_89);  primals_89 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_497: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_583, 0);  mul_583 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_498: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_497, 2);  unsqueeze_497 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_499: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_498, 3);  unsqueeze_498 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_584: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_145, unsqueeze_496);  sub_145 = unsqueeze_496 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_147: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_22, mul_584);  where_22 = mul_584 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_148: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_147, unsqueeze_493);  sub_147 = unsqueeze_493 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_585: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_148, unsqueeze_499);  sub_148 = unsqueeze_499 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_586: f32[256] = torch.ops.aten.mul.Tensor(sum_49, squeeze_88);  sum_49 = squeeze_88 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_23 = torch.ops.aten.convolution_backward.default(mul_585, relu_25, primals_88, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_585 = primals_88 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_177: f32[64, 256, 14, 14] = convolution_backward_23[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_178: f32[256, 256, 3, 3] = convolution_backward_23[1];  convolution_backward_23 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_23: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_25, 0);  relu_25 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_23: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_23, full_default, getitem_177);  le_23 = getitem_177 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_50: f32[256] = torch.ops.aten.sum.dim_IntList(where_23, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_149: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_28, unsqueeze_502);  convolution_28 = unsqueeze_502 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_587: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_23, sub_149)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_51: f32[256] = torch.ops.aten.sum.dim_IntList(mul_587, [0, 2, 3]);  mul_587 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_588: f32[256] = torch.ops.aten.mul.Tensor(sum_50, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_503: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_588, 0);  mul_588 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_504: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_503, 2);  unsqueeze_503 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_505: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_504, 3);  unsqueeze_504 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_589: f32[256] = torch.ops.aten.mul.Tensor(sum_51, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_590: f32[256] = torch.ops.aten.mul.Tensor(squeeze_85, squeeze_85)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_591: f32[256] = torch.ops.aten.mul.Tensor(mul_589, mul_590);  mul_589 = mul_590 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_506: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_591, 0);  mul_591 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_507: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_506, 2);  unsqueeze_506 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_508: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_507, 3);  unsqueeze_507 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_592: f32[256] = torch.ops.aten.mul.Tensor(squeeze_85, primals_86);  primals_86 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_509: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_592, 0);  mul_592 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_510: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_509, 2);  unsqueeze_509 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_511: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_510, 3);  unsqueeze_510 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_593: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_149, unsqueeze_508);  sub_149 = unsqueeze_508 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_151: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_23, mul_593);  where_23 = mul_593 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_152: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_151, unsqueeze_505);  sub_151 = unsqueeze_505 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_594: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_152, unsqueeze_511);  sub_152 = unsqueeze_511 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_595: f32[256] = torch.ops.aten.mul.Tensor(sum_51, squeeze_85);  sum_51 = squeeze_85 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_24 = torch.ops.aten.convolution_backward.default(mul_594, relu_24, primals_85, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_594 = primals_85 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_180: f32[64, 1024, 14, 14] = convolution_backward_24[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_181: f32[256, 1024, 1, 1] = convolution_backward_24[1];  convolution_backward_24 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_288: f32[64, 1024, 14, 14] = torch.ops.aten.add.Tensor(where_21, getitem_180);  where_21 = getitem_180 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_24: b8[64, 1024, 14, 14] = torch.ops.aten.le.Scalar(relu_24, 0);  relu_24 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_24: f32[64, 1024, 14, 14] = torch.ops.aten.where.self(le_24, full_default, add_288);  le_24 = add_288 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_52: f32[1024] = torch.ops.aten.sum.dim_IntList(where_24, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_153: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_27, unsqueeze_514);  convolution_27 = unsqueeze_514 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_596: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_24, sub_153)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_53: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_596, [0, 2, 3]);  mul_596 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_597: f32[1024] = torch.ops.aten.mul.Tensor(sum_52, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_515: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_597, 0);  mul_597 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_516: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_515, 2);  unsqueeze_515 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_517: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_516, 3);  unsqueeze_516 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_598: f32[1024] = torch.ops.aten.mul.Tensor(sum_53, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_599: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_82, squeeze_82)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_600: f32[1024] = torch.ops.aten.mul.Tensor(mul_598, mul_599);  mul_598 = mul_599 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_518: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_600, 0);  mul_600 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_519: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_518, 2);  unsqueeze_518 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_520: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_519, 3);  unsqueeze_519 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_601: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_82, primals_83);  primals_83 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_521: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_601, 0);  mul_601 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_522: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_521, 2);  unsqueeze_521 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_523: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_522, 3);  unsqueeze_522 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_602: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_153, unsqueeze_520);  sub_153 = unsqueeze_520 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_155: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_24, mul_602);  mul_602 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_156: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_155, unsqueeze_517);  sub_155 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_603: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_156, unsqueeze_523);  sub_156 = unsqueeze_523 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_604: f32[1024] = torch.ops.aten.mul.Tensor(sum_53, squeeze_82);  sum_53 = squeeze_82 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_25 = torch.ops.aten.convolution_backward.default(mul_603, relu_21, primals_82, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_603 = primals_82 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_183: f32[64, 512, 28, 28] = convolution_backward_25[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_184: f32[1024, 512, 1, 1] = convolution_backward_25[1];  convolution_backward_25 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_157: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(convolution_26, unsqueeze_526);  convolution_26 = unsqueeze_526 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_605: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(where_24, sub_157)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_55: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_605, [0, 2, 3]);  mul_605 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_607: f32[1024] = torch.ops.aten.mul.Tensor(sum_55, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_608: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_79, squeeze_79)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_609: f32[1024] = torch.ops.aten.mul.Tensor(mul_607, mul_608);  mul_607 = mul_608 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_530: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_609, 0);  mul_609 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_531: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_530, 2);  unsqueeze_530 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_532: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_531, 3);  unsqueeze_531 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_610: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_79, primals_80);  primals_80 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_533: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_610, 0);  mul_610 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_534: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_533, 2);  unsqueeze_533 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_535: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_534, 3);  unsqueeze_534 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_611: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_157, unsqueeze_532);  sub_157 = unsqueeze_532 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_159: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(where_24, mul_611);  where_24 = mul_611 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_160: f32[64, 1024, 14, 14] = torch.ops.aten.sub.Tensor(sub_159, unsqueeze_517);  sub_159 = unsqueeze_517 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_612: f32[64, 1024, 14, 14] = torch.ops.aten.mul.Tensor(sub_160, unsqueeze_535);  sub_160 = unsqueeze_535 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_613: f32[1024] = torch.ops.aten.mul.Tensor(sum_55, squeeze_79);  sum_55 = squeeze_79 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_26 = torch.ops.aten.convolution_backward.default(mul_612, relu_23, primals_79, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_612 = primals_79 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_186: f32[64, 256, 14, 14] = convolution_backward_26[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_187: f32[1024, 256, 1, 1] = convolution_backward_26[1];  convolution_backward_26 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_25: b8[64, 256, 14, 14] = torch.ops.aten.le.Scalar(relu_23, 0);  relu_23 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_25: f32[64, 256, 14, 14] = torch.ops.aten.where.self(le_25, full_default, getitem_186);  le_25 = getitem_186 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_56: f32[256] = torch.ops.aten.sum.dim_IntList(where_25, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_161: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(convolution_25, unsqueeze_538);  convolution_25 = unsqueeze_538 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_614: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(where_25, sub_161)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_57: f32[256] = torch.ops.aten.sum.dim_IntList(mul_614, [0, 2, 3]);  mul_614 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_615: f32[256] = torch.ops.aten.mul.Tensor(sum_56, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_539: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_615, 0);  mul_615 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_540: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_539, 2);  unsqueeze_539 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_541: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_540, 3);  unsqueeze_540 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_616: f32[256] = torch.ops.aten.mul.Tensor(sum_57, 7.971938775510203e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_617: f32[256] = torch.ops.aten.mul.Tensor(squeeze_76, squeeze_76)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_618: f32[256] = torch.ops.aten.mul.Tensor(mul_616, mul_617);  mul_616 = mul_617 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_542: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_618, 0);  mul_618 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_543: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_542, 2);  unsqueeze_542 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_544: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_543, 3);  unsqueeze_543 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_619: f32[256] = torch.ops.aten.mul.Tensor(squeeze_76, primals_77);  primals_77 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_545: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_619, 0);  mul_619 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_546: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_545, 2);  unsqueeze_545 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_547: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_546, 3);  unsqueeze_546 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_620: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_161, unsqueeze_544);  sub_161 = unsqueeze_544 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_163: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(where_25, mul_620);  where_25 = mul_620 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_164: f32[64, 256, 14, 14] = torch.ops.aten.sub.Tensor(sub_163, unsqueeze_541);  sub_163 = unsqueeze_541 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_621: f32[64, 256, 14, 14] = torch.ops.aten.mul.Tensor(sub_164, unsqueeze_547);  sub_164 = unsqueeze_547 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_622: f32[256] = torch.ops.aten.mul.Tensor(sum_57, squeeze_76);  sum_57 = squeeze_76 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_27 = torch.ops.aten.convolution_backward.default(mul_621, relu_22, primals_76, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_621 = primals_76 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_189: f32[64, 256, 28, 28] = convolution_backward_27[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_190: f32[256, 256, 3, 3] = convolution_backward_27[1];  convolution_backward_27 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_26: b8[64, 256, 28, 28] = torch.ops.aten.le.Scalar(relu_22, 0);  relu_22 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_26: f32[64, 256, 28, 28] = torch.ops.aten.where.self(le_26, full_default, getitem_189);  le_26 = getitem_189 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_58: f32[256] = torch.ops.aten.sum.dim_IntList(where_26, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_165: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(convolution_24, unsqueeze_550);  convolution_24 = unsqueeze_550 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_623: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(where_26, sub_165)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_59: f32[256] = torch.ops.aten.sum.dim_IntList(mul_623, [0, 2, 3]);  mul_623 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_624: f32[256] = torch.ops.aten.mul.Tensor(sum_58, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_551: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_624, 0);  mul_624 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_552: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_551, 2);  unsqueeze_551 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_553: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_552, 3);  unsqueeze_552 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_625: f32[256] = torch.ops.aten.mul.Tensor(sum_59, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_626: f32[256] = torch.ops.aten.mul.Tensor(squeeze_73, squeeze_73)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_627: f32[256] = torch.ops.aten.mul.Tensor(mul_625, mul_626);  mul_625 = mul_626 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_554: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_627, 0);  mul_627 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_555: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_554, 2);  unsqueeze_554 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_556: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_555, 3);  unsqueeze_555 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_628: f32[256] = torch.ops.aten.mul.Tensor(squeeze_73, primals_74);  primals_74 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_557: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_628, 0);  mul_628 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_558: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_557, 2);  unsqueeze_557 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_559: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_558, 3);  unsqueeze_558 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_629: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(sub_165, unsqueeze_556);  sub_165 = unsqueeze_556 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_167: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(where_26, mul_629);  where_26 = mul_629 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_168: f32[64, 256, 28, 28] = torch.ops.aten.sub.Tensor(sub_167, unsqueeze_553);  sub_167 = unsqueeze_553 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_630: f32[64, 256, 28, 28] = torch.ops.aten.mul.Tensor(sub_168, unsqueeze_559);  sub_168 = unsqueeze_559 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_631: f32[256] = torch.ops.aten.mul.Tensor(sum_59, squeeze_73);  sum_59 = squeeze_73 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_28 = torch.ops.aten.convolution_backward.default(mul_630, relu_21, primals_73, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_630 = primals_73 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_192: f32[64, 512, 28, 28] = convolution_backward_28[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_193: f32[256, 512, 1, 1] = convolution_backward_28[1];  convolution_backward_28 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_289: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(getitem_183, getitem_192);  getitem_183 = getitem_192 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_27: b8[64, 512, 28, 28] = torch.ops.aten.le.Scalar(relu_21, 0);  relu_21 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_27: f32[64, 512, 28, 28] = torch.ops.aten.where.self(le_27, full_default, add_289);  le_27 = add_289 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_60: f32[512] = torch.ops.aten.sum.dim_IntList(where_27, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_169: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_23, unsqueeze_562);  convolution_23 = unsqueeze_562 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_632: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_27, sub_169)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_61: f32[512] = torch.ops.aten.sum.dim_IntList(mul_632, [0, 2, 3]);  mul_632 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_633: f32[512] = torch.ops.aten.mul.Tensor(sum_60, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_563: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_633, 0);  mul_633 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_564: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_563, 2);  unsqueeze_563 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_565: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_564, 3);  unsqueeze_564 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_634: f32[512] = torch.ops.aten.mul.Tensor(sum_61, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_635: f32[512] = torch.ops.aten.mul.Tensor(squeeze_70, squeeze_70)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_636: f32[512] = torch.ops.aten.mul.Tensor(mul_634, mul_635);  mul_634 = mul_635 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_566: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_636, 0);  mul_636 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_567: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_566, 2);  unsqueeze_566 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_568: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_567, 3);  unsqueeze_567 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_637: f32[512] = torch.ops.aten.mul.Tensor(squeeze_70, primals_71);  primals_71 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_569: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_637, 0);  mul_637 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_570: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_569, 2);  unsqueeze_569 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_571: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_570, 3);  unsqueeze_570 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_638: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_169, unsqueeze_568);  sub_169 = unsqueeze_568 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_171: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_27, mul_638);  mul_638 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_172: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_171, unsqueeze_565);  sub_171 = unsqueeze_565 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_639: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_172, unsqueeze_571);  sub_172 = unsqueeze_571 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_640: f32[512] = torch.ops.aten.mul.Tensor(sum_61, squeeze_70);  sum_61 = squeeze_70 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_29 = torch.ops.aten.convolution_backward.default(mul_639, relu_20, primals_70, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_639 = primals_70 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_195: f32[64, 128, 28, 28] = convolution_backward_29[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_196: f32[512, 128, 1, 1] = convolution_backward_29[1];  convolution_backward_29 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_28: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_20, 0);  relu_20 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_28: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_28, full_default, getitem_195);  le_28 = getitem_195 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_62: f32[128] = torch.ops.aten.sum.dim_IntList(where_28, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_173: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_22, unsqueeze_574);  convolution_22 = unsqueeze_574 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_641: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_28, sub_173)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_63: f32[128] = torch.ops.aten.sum.dim_IntList(mul_641, [0, 2, 3]);  mul_641 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_642: f32[128] = torch.ops.aten.mul.Tensor(sum_62, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_575: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_642, 0);  mul_642 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_576: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_575, 2);  unsqueeze_575 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_577: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_576, 3);  unsqueeze_576 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_643: f32[128] = torch.ops.aten.mul.Tensor(sum_63, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_644: f32[128] = torch.ops.aten.mul.Tensor(squeeze_67, squeeze_67)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_645: f32[128] = torch.ops.aten.mul.Tensor(mul_643, mul_644);  mul_643 = mul_644 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_578: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_645, 0);  mul_645 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_579: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_578, 2);  unsqueeze_578 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_580: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_579, 3);  unsqueeze_579 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_646: f32[128] = torch.ops.aten.mul.Tensor(squeeze_67, primals_68);  primals_68 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_581: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_646, 0);  mul_646 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_582: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_581, 2);  unsqueeze_581 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_583: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_582, 3);  unsqueeze_582 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_647: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_173, unsqueeze_580);  sub_173 = unsqueeze_580 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_175: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_28, mul_647);  where_28 = mul_647 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_176: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_175, unsqueeze_577);  sub_175 = unsqueeze_577 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_648: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_176, unsqueeze_583);  sub_176 = unsqueeze_583 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_649: f32[128] = torch.ops.aten.mul.Tensor(sum_63, squeeze_67);  sum_63 = squeeze_67 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_30 = torch.ops.aten.convolution_backward.default(mul_648, relu_19, primals_67, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_648 = primals_67 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_198: f32[64, 128, 28, 28] = convolution_backward_30[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_199: f32[128, 128, 3, 3] = convolution_backward_30[1];  convolution_backward_30 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_29: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_19, 0);  relu_19 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_29: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_29, full_default, getitem_198);  le_29 = getitem_198 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_64: f32[128] = torch.ops.aten.sum.dim_IntList(where_29, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_177: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_21, unsqueeze_586);  convolution_21 = unsqueeze_586 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_650: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_29, sub_177)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_65: f32[128] = torch.ops.aten.sum.dim_IntList(mul_650, [0, 2, 3]);  mul_650 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_651: f32[128] = torch.ops.aten.mul.Tensor(sum_64, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_587: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_651, 0);  mul_651 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_588: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_587, 2);  unsqueeze_587 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_589: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_588, 3);  unsqueeze_588 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_652: f32[128] = torch.ops.aten.mul.Tensor(sum_65, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_653: f32[128] = torch.ops.aten.mul.Tensor(squeeze_64, squeeze_64)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_654: f32[128] = torch.ops.aten.mul.Tensor(mul_652, mul_653);  mul_652 = mul_653 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_590: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_654, 0);  mul_654 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_591: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_590, 2);  unsqueeze_590 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_592: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_591, 3);  unsqueeze_591 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_655: f32[128] = torch.ops.aten.mul.Tensor(squeeze_64, primals_65);  primals_65 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_593: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_655, 0);  mul_655 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_594: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_593, 2);  unsqueeze_593 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_595: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_594, 3);  unsqueeze_594 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_656: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_177, unsqueeze_592);  sub_177 = unsqueeze_592 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_179: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_29, mul_656);  where_29 = mul_656 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_180: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_179, unsqueeze_589);  sub_179 = unsqueeze_589 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_657: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_180, unsqueeze_595);  sub_180 = unsqueeze_595 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_658: f32[128] = torch.ops.aten.mul.Tensor(sum_65, squeeze_64);  sum_65 = squeeze_64 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_31 = torch.ops.aten.convolution_backward.default(mul_657, relu_18, primals_64, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_657 = primals_64 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_201: f32[64, 512, 28, 28] = convolution_backward_31[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_202: f32[128, 512, 1, 1] = convolution_backward_31[1];  convolution_backward_31 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_290: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(where_27, getitem_201);  where_27 = getitem_201 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_30: b8[64, 512, 28, 28] = torch.ops.aten.le.Scalar(relu_18, 0);  relu_18 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_30: f32[64, 512, 28, 28] = torch.ops.aten.where.self(le_30, full_default, add_290);  le_30 = add_290 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_66: f32[512] = torch.ops.aten.sum.dim_IntList(where_30, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_181: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_20, unsqueeze_598);  convolution_20 = unsqueeze_598 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_659: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_30, sub_181)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_67: f32[512] = torch.ops.aten.sum.dim_IntList(mul_659, [0, 2, 3]);  mul_659 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_660: f32[512] = torch.ops.aten.mul.Tensor(sum_66, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_599: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_660, 0);  mul_660 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_600: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_599, 2);  unsqueeze_599 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_601: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_600, 3);  unsqueeze_600 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_661: f32[512] = torch.ops.aten.mul.Tensor(sum_67, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_662: f32[512] = torch.ops.aten.mul.Tensor(squeeze_61, squeeze_61)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_663: f32[512] = torch.ops.aten.mul.Tensor(mul_661, mul_662);  mul_661 = mul_662 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_602: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_663, 0);  mul_663 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_603: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_602, 2);  unsqueeze_602 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_604: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_603, 3);  unsqueeze_603 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_664: f32[512] = torch.ops.aten.mul.Tensor(squeeze_61, primals_62);  primals_62 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_605: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_664, 0);  mul_664 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_606: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_605, 2);  unsqueeze_605 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_607: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_606, 3);  unsqueeze_606 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_665: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_181, unsqueeze_604);  sub_181 = unsqueeze_604 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_183: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_30, mul_665);  mul_665 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_184: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_183, unsqueeze_601);  sub_183 = unsqueeze_601 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_666: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_184, unsqueeze_607);  sub_184 = unsqueeze_607 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_667: f32[512] = torch.ops.aten.mul.Tensor(sum_67, squeeze_61);  sum_67 = squeeze_61 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_32 = torch.ops.aten.convolution_backward.default(mul_666, relu_17, primals_61, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_666 = primals_61 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_204: f32[64, 128, 28, 28] = convolution_backward_32[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_205: f32[512, 128, 1, 1] = convolution_backward_32[1];  convolution_backward_32 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_31: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_17, 0);  relu_17 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_31: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_31, full_default, getitem_204);  le_31 = getitem_204 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_68: f32[128] = torch.ops.aten.sum.dim_IntList(where_31, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_185: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_610);  convolution_19 = unsqueeze_610 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_668: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_31, sub_185)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_69: f32[128] = torch.ops.aten.sum.dim_IntList(mul_668, [0, 2, 3]);  mul_668 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_669: f32[128] = torch.ops.aten.mul.Tensor(sum_68, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_611: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_669, 0);  mul_669 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_612: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_611, 2);  unsqueeze_611 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_613: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_612, 3);  unsqueeze_612 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_670: f32[128] = torch.ops.aten.mul.Tensor(sum_69, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_671: f32[128] = torch.ops.aten.mul.Tensor(squeeze_58, squeeze_58)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_672: f32[128] = torch.ops.aten.mul.Tensor(mul_670, mul_671);  mul_670 = mul_671 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_614: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_672, 0);  mul_672 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_615: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_614, 2);  unsqueeze_614 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_616: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_615, 3);  unsqueeze_615 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_673: f32[128] = torch.ops.aten.mul.Tensor(squeeze_58, primals_59);  primals_59 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_617: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_673, 0);  mul_673 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_618: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_617, 2);  unsqueeze_617 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_619: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_618, 3);  unsqueeze_618 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_674: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_185, unsqueeze_616);  sub_185 = unsqueeze_616 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_187: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_31, mul_674);  where_31 = mul_674 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_188: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_187, unsqueeze_613);  sub_187 = unsqueeze_613 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_675: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_188, unsqueeze_619);  sub_188 = unsqueeze_619 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_676: f32[128] = torch.ops.aten.mul.Tensor(sum_69, squeeze_58);  sum_69 = squeeze_58 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_33 = torch.ops.aten.convolution_backward.default(mul_675, relu_16, primals_58, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_675 = primals_58 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_207: f32[64, 128, 28, 28] = convolution_backward_33[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_208: f32[128, 128, 3, 3] = convolution_backward_33[1];  convolution_backward_33 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_32: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_16, 0);  relu_16 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_32: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_32, full_default, getitem_207);  le_32 = getitem_207 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_70: f32[128] = torch.ops.aten.sum.dim_IntList(where_32, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_189: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_622);  convolution_18 = unsqueeze_622 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_677: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_32, sub_189)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_71: f32[128] = torch.ops.aten.sum.dim_IntList(mul_677, [0, 2, 3]);  mul_677 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_678: f32[128] = torch.ops.aten.mul.Tensor(sum_70, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_623: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_678, 0);  mul_678 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_624: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_623, 2);  unsqueeze_623 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_625: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_624, 3);  unsqueeze_624 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_679: f32[128] = torch.ops.aten.mul.Tensor(sum_71, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_680: f32[128] = torch.ops.aten.mul.Tensor(squeeze_55, squeeze_55)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_681: f32[128] = torch.ops.aten.mul.Tensor(mul_679, mul_680);  mul_679 = mul_680 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_626: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_681, 0);  mul_681 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_627: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_626, 2);  unsqueeze_626 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_628: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_627, 3);  unsqueeze_627 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_682: f32[128] = torch.ops.aten.mul.Tensor(squeeze_55, primals_56);  primals_56 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_629: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_682, 0);  mul_682 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_630: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_629, 2);  unsqueeze_629 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_631: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_630, 3);  unsqueeze_630 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_683: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_189, unsqueeze_628);  sub_189 = unsqueeze_628 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_191: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_32, mul_683);  where_32 = mul_683 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_192: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_191, unsqueeze_625);  sub_191 = unsqueeze_625 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_684: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_192, unsqueeze_631);  sub_192 = unsqueeze_631 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_685: f32[128] = torch.ops.aten.mul.Tensor(sum_71, squeeze_55);  sum_71 = squeeze_55 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_34 = torch.ops.aten.convolution_backward.default(mul_684, relu_15, primals_55, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_684 = primals_55 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_210: f32[64, 512, 28, 28] = convolution_backward_34[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_211: f32[128, 512, 1, 1] = convolution_backward_34[1];  convolution_backward_34 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_291: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(where_30, getitem_210);  where_30 = getitem_210 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_33: b8[64, 512, 28, 28] = torch.ops.aten.le.Scalar(relu_15, 0);  relu_15 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_33: f32[64, 512, 28, 28] = torch.ops.aten.where.self(le_33, full_default, add_291);  le_33 = add_291 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_72: f32[512] = torch.ops.aten.sum.dim_IntList(where_33, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_193: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_634);  convolution_17 = unsqueeze_634 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_686: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_33, sub_193)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_73: f32[512] = torch.ops.aten.sum.dim_IntList(mul_686, [0, 2, 3]);  mul_686 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_687: f32[512] = torch.ops.aten.mul.Tensor(sum_72, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_635: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_687, 0);  mul_687 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_636: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_635, 2);  unsqueeze_635 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_637: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_636, 3);  unsqueeze_636 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_688: f32[512] = torch.ops.aten.mul.Tensor(sum_73, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_689: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, squeeze_52)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_690: f32[512] = torch.ops.aten.mul.Tensor(mul_688, mul_689);  mul_688 = mul_689 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_638: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_690, 0);  mul_690 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_639: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_638, 2);  unsqueeze_638 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_640: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_639, 3);  unsqueeze_639 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_691: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, primals_53);  primals_53 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_641: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_691, 0);  mul_691 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_642: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_641, 2);  unsqueeze_641 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_643: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_642, 3);  unsqueeze_642 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_692: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_193, unsqueeze_640);  sub_193 = unsqueeze_640 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_195: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_33, mul_692);  mul_692 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_196: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_195, unsqueeze_637);  sub_195 = unsqueeze_637 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_693: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_196, unsqueeze_643);  sub_196 = unsqueeze_643 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_694: f32[512] = torch.ops.aten.mul.Tensor(sum_73, squeeze_52);  sum_73 = squeeze_52 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_35 = torch.ops.aten.convolution_backward.default(mul_693, relu_14, primals_52, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_693 = primals_52 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_213: f32[64, 128, 28, 28] = convolution_backward_35[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_214: f32[512, 128, 1, 1] = convolution_backward_35[1];  convolution_backward_35 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_34: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_14, 0);  relu_14 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_34: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_34, full_default, getitem_213);  le_34 = getitem_213 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_74: f32[128] = torch.ops.aten.sum.dim_IntList(where_34, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_197: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_646);  convolution_16 = unsqueeze_646 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_695: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_34, sub_197)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_75: f32[128] = torch.ops.aten.sum.dim_IntList(mul_695, [0, 2, 3]);  mul_695 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_696: f32[128] = torch.ops.aten.mul.Tensor(sum_74, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_647: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_696, 0);  mul_696 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_648: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_647, 2);  unsqueeze_647 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_649: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_648, 3);  unsqueeze_648 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_697: f32[128] = torch.ops.aten.mul.Tensor(sum_75, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_698: f32[128] = torch.ops.aten.mul.Tensor(squeeze_49, squeeze_49)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_699: f32[128] = torch.ops.aten.mul.Tensor(mul_697, mul_698);  mul_697 = mul_698 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_650: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_699, 0);  mul_699 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_651: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_650, 2);  unsqueeze_650 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_652: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_651, 3);  unsqueeze_651 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_700: f32[128] = torch.ops.aten.mul.Tensor(squeeze_49, primals_50);  primals_50 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_653: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_700, 0);  mul_700 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_654: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_653, 2);  unsqueeze_653 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_655: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_654, 3);  unsqueeze_654 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_701: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_197, unsqueeze_652);  sub_197 = unsqueeze_652 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_199: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_34, mul_701);  where_34 = mul_701 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_200: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_199, unsqueeze_649);  sub_199 = unsqueeze_649 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_702: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_200, unsqueeze_655);  sub_200 = unsqueeze_655 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_703: f32[128] = torch.ops.aten.mul.Tensor(sum_75, squeeze_49);  sum_75 = squeeze_49 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_36 = torch.ops.aten.convolution_backward.default(mul_702, relu_13, primals_49, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_702 = primals_49 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_216: f32[64, 128, 28, 28] = convolution_backward_36[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_217: f32[128, 128, 3, 3] = convolution_backward_36[1];  convolution_backward_36 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_35: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_13, 0);  relu_13 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_35: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_35, full_default, getitem_216);  le_35 = getitem_216 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_76: f32[128] = torch.ops.aten.sum.dim_IntList(where_35, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_201: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_658);  convolution_15 = unsqueeze_658 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_704: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_35, sub_201)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_77: f32[128] = torch.ops.aten.sum.dim_IntList(mul_704, [0, 2, 3]);  mul_704 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_705: f32[128] = torch.ops.aten.mul.Tensor(sum_76, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_659: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_705, 0);  mul_705 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_660: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_659, 2);  unsqueeze_659 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_661: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_660, 3);  unsqueeze_660 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_706: f32[128] = torch.ops.aten.mul.Tensor(sum_77, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_707: f32[128] = torch.ops.aten.mul.Tensor(squeeze_46, squeeze_46)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_708: f32[128] = torch.ops.aten.mul.Tensor(mul_706, mul_707);  mul_706 = mul_707 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_662: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_708, 0);  mul_708 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_663: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_662, 2);  unsqueeze_662 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_664: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_663, 3);  unsqueeze_663 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_709: f32[128] = torch.ops.aten.mul.Tensor(squeeze_46, primals_47);  primals_47 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_665: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_709, 0);  mul_709 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_666: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_665, 2);  unsqueeze_665 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_667: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_666, 3);  unsqueeze_666 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_710: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_201, unsqueeze_664);  sub_201 = unsqueeze_664 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_203: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_35, mul_710);  where_35 = mul_710 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_204: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_203, unsqueeze_661);  sub_203 = unsqueeze_661 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_711: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_204, unsqueeze_667);  sub_204 = unsqueeze_667 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_712: f32[128] = torch.ops.aten.mul.Tensor(sum_77, squeeze_46);  sum_77 = squeeze_46 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_37 = torch.ops.aten.convolution_backward.default(mul_711, relu_12, primals_46, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_711 = primals_46 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_219: f32[64, 512, 28, 28] = convolution_backward_37[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_220: f32[128, 512, 1, 1] = convolution_backward_37[1];  convolution_backward_37 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_292: f32[64, 512, 28, 28] = torch.ops.aten.add.Tensor(where_33, getitem_219);  where_33 = getitem_219 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_36: b8[64, 512, 28, 28] = torch.ops.aten.le.Scalar(relu_12, 0);  relu_12 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_36: f32[64, 512, 28, 28] = torch.ops.aten.where.self(le_36, full_default, add_292);  le_36 = add_292 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_78: f32[512] = torch.ops.aten.sum.dim_IntList(where_36, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_205: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_670);  convolution_14 = unsqueeze_670 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_713: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_36, sub_205)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_79: f32[512] = torch.ops.aten.sum.dim_IntList(mul_713, [0, 2, 3]);  mul_713 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_714: f32[512] = torch.ops.aten.mul.Tensor(sum_78, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_671: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_714, 0);  mul_714 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_672: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_671, 2);  unsqueeze_671 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_673: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_672, 3);  unsqueeze_672 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_715: f32[512] = torch.ops.aten.mul.Tensor(sum_79, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_716: f32[512] = torch.ops.aten.mul.Tensor(squeeze_43, squeeze_43)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_717: f32[512] = torch.ops.aten.mul.Tensor(mul_715, mul_716);  mul_715 = mul_716 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_674: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_717, 0);  mul_717 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_675: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_674, 2);  unsqueeze_674 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_676: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_675, 3);  unsqueeze_675 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_718: f32[512] = torch.ops.aten.mul.Tensor(squeeze_43, primals_44);  primals_44 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_677: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_718, 0);  mul_718 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_678: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_677, 2);  unsqueeze_677 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_679: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_678, 3);  unsqueeze_678 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_719: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_205, unsqueeze_676);  sub_205 = unsqueeze_676 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_207: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_36, mul_719);  mul_719 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_208: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_207, unsqueeze_673);  sub_207 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_720: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_208, unsqueeze_679);  sub_208 = unsqueeze_679 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_721: f32[512] = torch.ops.aten.mul.Tensor(sum_79, squeeze_43);  sum_79 = squeeze_43 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_38 = torch.ops.aten.convolution_backward.default(mul_720, relu_9, primals_43, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_720 = primals_43 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_222: f32[64, 256, 56, 56] = convolution_backward_38[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_223: f32[512, 256, 1, 1] = convolution_backward_38[1];  convolution_backward_38 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_209: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_682);  convolution_13 = unsqueeze_682 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_722: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(where_36, sub_209)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_81: f32[512] = torch.ops.aten.sum.dim_IntList(mul_722, [0, 2, 3]);  mul_722 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_724: f32[512] = torch.ops.aten.mul.Tensor(sum_81, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_725: f32[512] = torch.ops.aten.mul.Tensor(squeeze_40, squeeze_40)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_726: f32[512] = torch.ops.aten.mul.Tensor(mul_724, mul_725);  mul_724 = mul_725 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_686: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_726, 0);  mul_726 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_687: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_686, 2);  unsqueeze_686 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_688: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_687, 3);  unsqueeze_687 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_727: f32[512] = torch.ops.aten.mul.Tensor(squeeze_40, primals_41);  primals_41 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_689: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_727, 0);  mul_727 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_690: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_689, 2);  unsqueeze_689 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_691: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_690, 3);  unsqueeze_690 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_728: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_209, unsqueeze_688);  sub_209 = unsqueeze_688 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_211: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(where_36, mul_728);  where_36 = mul_728 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_212: f32[64, 512, 28, 28] = torch.ops.aten.sub.Tensor(sub_211, unsqueeze_673);  sub_211 = unsqueeze_673 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_729: f32[64, 512, 28, 28] = torch.ops.aten.mul.Tensor(sub_212, unsqueeze_691);  sub_212 = unsqueeze_691 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_730: f32[512] = torch.ops.aten.mul.Tensor(sum_81, squeeze_40);  sum_81 = squeeze_40 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_39 = torch.ops.aten.convolution_backward.default(mul_729, relu_11, primals_40, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_729 = primals_40 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_225: f32[64, 128, 28, 28] = convolution_backward_39[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_226: f32[512, 128, 1, 1] = convolution_backward_39[1];  convolution_backward_39 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_37: b8[64, 128, 28, 28] = torch.ops.aten.le.Scalar(relu_11, 0);  relu_11 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_37: f32[64, 128, 28, 28] = torch.ops.aten.where.self(le_37, full_default, getitem_225);  le_37 = getitem_225 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_82: f32[128] = torch.ops.aten.sum.dim_IntList(where_37, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_213: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_694);  convolution_12 = unsqueeze_694 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_731: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(where_37, sub_213)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_83: f32[128] = torch.ops.aten.sum.dim_IntList(mul_731, [0, 2, 3]);  mul_731 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_732: f32[128] = torch.ops.aten.mul.Tensor(sum_82, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_695: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_732, 0);  mul_732 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_696: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_695, 2);  unsqueeze_695 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_697: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_696, 3);  unsqueeze_696 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_733: f32[128] = torch.ops.aten.mul.Tensor(sum_83, 1.992984693877551e-05)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_734: f32[128] = torch.ops.aten.mul.Tensor(squeeze_37, squeeze_37)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_735: f32[128] = torch.ops.aten.mul.Tensor(mul_733, mul_734);  mul_733 = mul_734 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_698: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_735, 0);  mul_735 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_699: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_698, 2);  unsqueeze_698 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_700: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_699, 3);  unsqueeze_699 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_736: f32[128] = torch.ops.aten.mul.Tensor(squeeze_37, primals_38);  primals_38 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_701: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_736, 0);  mul_736 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_702: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_701, 2);  unsqueeze_701 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_703: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_702, 3);  unsqueeze_702 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_737: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_213, unsqueeze_700);  sub_213 = unsqueeze_700 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_215: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(where_37, mul_737);  where_37 = mul_737 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_216: f32[64, 128, 28, 28] = torch.ops.aten.sub.Tensor(sub_215, unsqueeze_697);  sub_215 = unsqueeze_697 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_738: f32[64, 128, 28, 28] = torch.ops.aten.mul.Tensor(sub_216, unsqueeze_703);  sub_216 = unsqueeze_703 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_739: f32[128] = torch.ops.aten.mul.Tensor(sum_83, squeeze_37);  sum_83 = squeeze_37 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_40 = torch.ops.aten.convolution_backward.default(mul_738, relu_10, primals_37, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_738 = primals_37 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_228: f32[64, 128, 56, 56] = convolution_backward_40[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_229: f32[128, 128, 3, 3] = convolution_backward_40[1];  convolution_backward_40 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_38: b8[64, 128, 56, 56] = torch.ops.aten.le.Scalar(relu_10, 0);  relu_10 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_38: f32[64, 128, 56, 56] = torch.ops.aten.where.self(le_38, full_default, getitem_228);  le_38 = getitem_228 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_84: f32[128] = torch.ops.aten.sum.dim_IntList(where_38, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_217: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_706);  convolution_11 = unsqueeze_706 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_740: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(where_38, sub_217)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_85: f32[128] = torch.ops.aten.sum.dim_IntList(mul_740, [0, 2, 3]);  mul_740 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_741: f32[128] = torch.ops.aten.mul.Tensor(sum_84, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_707: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_741, 0);  mul_741 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_708: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_707, 2);  unsqueeze_707 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_709: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_708, 3);  unsqueeze_708 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_742: f32[128] = torch.ops.aten.mul.Tensor(sum_85, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_743: f32[128] = torch.ops.aten.mul.Tensor(squeeze_34, squeeze_34)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_744: f32[128] = torch.ops.aten.mul.Tensor(mul_742, mul_743);  mul_742 = mul_743 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_710: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_744, 0);  mul_744 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_711: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_710, 2);  unsqueeze_710 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_712: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_711, 3);  unsqueeze_711 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_745: f32[128] = torch.ops.aten.mul.Tensor(squeeze_34, primals_35);  primals_35 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_713: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_745, 0);  mul_745 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_714: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_713, 2);  unsqueeze_713 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_715: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_714, 3);  unsqueeze_714 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_746: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(sub_217, unsqueeze_712);  sub_217 = unsqueeze_712 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_219: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(where_38, mul_746);  where_38 = mul_746 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_220: f32[64, 128, 56, 56] = torch.ops.aten.sub.Tensor(sub_219, unsqueeze_709);  sub_219 = unsqueeze_709 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_747: f32[64, 128, 56, 56] = torch.ops.aten.mul.Tensor(sub_220, unsqueeze_715);  sub_220 = unsqueeze_715 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_748: f32[128] = torch.ops.aten.mul.Tensor(sum_85, squeeze_34);  sum_85 = squeeze_34 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_41 = torch.ops.aten.convolution_backward.default(mul_747, relu_9, primals_34, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_747 = primals_34 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_231: f32[64, 256, 56, 56] = convolution_backward_41[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_232: f32[128, 256, 1, 1] = convolution_backward_41[1];  convolution_backward_41 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_293: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(getitem_222, getitem_231);  getitem_222 = getitem_231 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_39: b8[64, 256, 56, 56] = torch.ops.aten.le.Scalar(relu_9, 0);  relu_9 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_39: f32[64, 256, 56, 56] = torch.ops.aten.where.self(le_39, full_default, add_293);  le_39 = add_293 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_86: f32[256] = torch.ops.aten.sum.dim_IntList(where_39, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_221: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_718);  convolution_10 = unsqueeze_718 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_749: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(where_39, sub_221)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_87: f32[256] = torch.ops.aten.sum.dim_IntList(mul_749, [0, 2, 3]);  mul_749 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_750: f32[256] = torch.ops.aten.mul.Tensor(sum_86, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_719: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_750, 0);  mul_750 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_720: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_719, 2);  unsqueeze_719 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_721: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_720, 3);  unsqueeze_720 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_751: f32[256] = torch.ops.aten.mul.Tensor(sum_87, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_752: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, squeeze_31)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_753: f32[256] = torch.ops.aten.mul.Tensor(mul_751, mul_752);  mul_751 = mul_752 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_722: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_753, 0);  mul_753 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_723: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_722, 2);  unsqueeze_722 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_724: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_723, 3);  unsqueeze_723 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_754: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, primals_32);  primals_32 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_725: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_754, 0);  mul_754 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_726: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_725, 2);  unsqueeze_725 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_727: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_726, 3);  unsqueeze_726 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_755: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_221, unsqueeze_724);  sub_221 = unsqueeze_724 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_223: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(where_39, mul_755);  mul_755 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_224: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(sub_223, unsqueeze_721);  sub_223 = unsqueeze_721 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_756: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_224, unsqueeze_727);  sub_224 = unsqueeze_727 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_757: f32[256] = torch.ops.aten.mul.Tensor(sum_87, squeeze_31);  sum_87 = squeeze_31 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_42 = torch.ops.aten.convolution_backward.default(mul_756, relu_8, primals_31, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_756 = primals_31 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_234: f32[64, 64, 56, 56] = convolution_backward_42[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_235: f32[256, 64, 1, 1] = convolution_backward_42[1];  convolution_backward_42 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_40: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_8, 0);  relu_8 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_40: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_40, full_default, getitem_234);  le_40 = getitem_234 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_88: f32[64] = torch.ops.aten.sum.dim_IntList(where_40, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_225: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_730);  convolution_9 = unsqueeze_730 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_758: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_40, sub_225)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_89: f32[64] = torch.ops.aten.sum.dim_IntList(mul_758, [0, 2, 3]);  mul_758 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_759: f32[64] = torch.ops.aten.mul.Tensor(sum_88, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_731: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_759, 0);  mul_759 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_732: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_731, 2);  unsqueeze_731 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_733: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_732, 3);  unsqueeze_732 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_760: f32[64] = torch.ops.aten.mul.Tensor(sum_89, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_761: f32[64] = torch.ops.aten.mul.Tensor(squeeze_28, squeeze_28)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_762: f32[64] = torch.ops.aten.mul.Tensor(mul_760, mul_761);  mul_760 = mul_761 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_734: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_762, 0);  mul_762 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_735: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_734, 2);  unsqueeze_734 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_736: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_735, 3);  unsqueeze_735 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_763: f32[64] = torch.ops.aten.mul.Tensor(squeeze_28, primals_29);  primals_29 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_737: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_763, 0);  mul_763 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_738: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_737, 2);  unsqueeze_737 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_739: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_738, 3);  unsqueeze_738 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_764: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_225, unsqueeze_736);  sub_225 = unsqueeze_736 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_227: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_40, mul_764);  where_40 = mul_764 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_228: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_227, unsqueeze_733);  sub_227 = unsqueeze_733 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_765: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_228, unsqueeze_739);  sub_228 = unsqueeze_739 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_766: f32[64] = torch.ops.aten.mul.Tensor(sum_89, squeeze_28);  sum_89 = squeeze_28 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_43 = torch.ops.aten.convolution_backward.default(mul_765, relu_7, primals_28, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_765 = primals_28 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_237: f32[64, 64, 56, 56] = convolution_backward_43[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_238: f32[64, 64, 3, 3] = convolution_backward_43[1];  convolution_backward_43 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_41: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_7, 0);  relu_7 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_41: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_41, full_default, getitem_237);  le_41 = getitem_237 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_90: f32[64] = torch.ops.aten.sum.dim_IntList(where_41, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_229: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_742);  convolution_8 = unsqueeze_742 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_767: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_41, sub_229)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_91: f32[64] = torch.ops.aten.sum.dim_IntList(mul_767, [0, 2, 3]);  mul_767 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_768: f32[64] = torch.ops.aten.mul.Tensor(sum_90, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_743: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_768, 0);  mul_768 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_744: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_743, 2);  unsqueeze_743 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_745: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_744, 3);  unsqueeze_744 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_769: f32[64] = torch.ops.aten.mul.Tensor(sum_91, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_770: f32[64] = torch.ops.aten.mul.Tensor(squeeze_25, squeeze_25)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_771: f32[64] = torch.ops.aten.mul.Tensor(mul_769, mul_770);  mul_769 = mul_770 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_746: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_771, 0);  mul_771 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_747: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_746, 2);  unsqueeze_746 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_748: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_747, 3);  unsqueeze_747 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_772: f32[64] = torch.ops.aten.mul.Tensor(squeeze_25, primals_26);  primals_26 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_749: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_772, 0);  mul_772 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_750: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_749, 2);  unsqueeze_749 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_751: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_750, 3);  unsqueeze_750 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_773: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_229, unsqueeze_748);  sub_229 = unsqueeze_748 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_231: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_41, mul_773);  where_41 = mul_773 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_232: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_231, unsqueeze_745);  sub_231 = unsqueeze_745 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_774: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_232, unsqueeze_751);  sub_232 = unsqueeze_751 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_775: f32[64] = torch.ops.aten.mul.Tensor(sum_91, squeeze_25);  sum_91 = squeeze_25 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_44 = torch.ops.aten.convolution_backward.default(mul_774, relu_6, primals_25, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_774 = primals_25 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_240: f32[64, 256, 56, 56] = convolution_backward_44[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_241: f32[64, 256, 1, 1] = convolution_backward_44[1];  convolution_backward_44 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_294: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(where_39, getitem_240);  where_39 = getitem_240 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_42: b8[64, 256, 56, 56] = torch.ops.aten.le.Scalar(relu_6, 0);  relu_6 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_42: f32[64, 256, 56, 56] = torch.ops.aten.where.self(le_42, full_default, add_294);  le_42 = add_294 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_92: f32[256] = torch.ops.aten.sum.dim_IntList(where_42, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_233: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_754);  convolution_7 = unsqueeze_754 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_776: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(where_42, sub_233)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_93: f32[256] = torch.ops.aten.sum.dim_IntList(mul_776, [0, 2, 3]);  mul_776 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_777: f32[256] = torch.ops.aten.mul.Tensor(sum_92, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_755: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_777, 0);  mul_777 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_756: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_755, 2);  unsqueeze_755 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_757: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_756, 3);  unsqueeze_756 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_778: f32[256] = torch.ops.aten.mul.Tensor(sum_93, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_779: f32[256] = torch.ops.aten.mul.Tensor(squeeze_22, squeeze_22)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_780: f32[256] = torch.ops.aten.mul.Tensor(mul_778, mul_779);  mul_778 = mul_779 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_758: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_780, 0);  mul_780 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_759: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_758, 2);  unsqueeze_758 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_760: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_759, 3);  unsqueeze_759 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_781: f32[256] = torch.ops.aten.mul.Tensor(squeeze_22, primals_23);  primals_23 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_761: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_781, 0);  mul_781 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_762: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_761, 2);  unsqueeze_761 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_763: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_762, 3);  unsqueeze_762 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_782: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_233, unsqueeze_760);  sub_233 = unsqueeze_760 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_235: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(where_42, mul_782);  mul_782 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_236: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(sub_235, unsqueeze_757);  sub_235 = unsqueeze_757 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_783: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_236, unsqueeze_763);  sub_236 = unsqueeze_763 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_784: f32[256] = torch.ops.aten.mul.Tensor(sum_93, squeeze_22);  sum_93 = squeeze_22 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_45 = torch.ops.aten.convolution_backward.default(mul_783, relu_5, primals_22, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_783 = primals_22 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_243: f32[64, 64, 56, 56] = convolution_backward_45[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_244: f32[256, 64, 1, 1] = convolution_backward_45[1];  convolution_backward_45 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_43: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_5, 0);  relu_5 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_43: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_43, full_default, getitem_243);  le_43 = getitem_243 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_94: f32[64] = torch.ops.aten.sum.dim_IntList(where_43, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_237: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_766);  convolution_6 = unsqueeze_766 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_785: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_43, sub_237)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_95: f32[64] = torch.ops.aten.sum.dim_IntList(mul_785, [0, 2, 3]);  mul_785 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_786: f32[64] = torch.ops.aten.mul.Tensor(sum_94, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_767: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_786, 0);  mul_786 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_768: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_767, 2);  unsqueeze_767 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_769: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_768, 3);  unsqueeze_768 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_787: f32[64] = torch.ops.aten.mul.Tensor(sum_95, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_788: f32[64] = torch.ops.aten.mul.Tensor(squeeze_19, squeeze_19)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_789: f32[64] = torch.ops.aten.mul.Tensor(mul_787, mul_788);  mul_787 = mul_788 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_770: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_789, 0);  mul_789 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_771: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_770, 2);  unsqueeze_770 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_772: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_771, 3);  unsqueeze_771 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_790: f32[64] = torch.ops.aten.mul.Tensor(squeeze_19, primals_20);  primals_20 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_773: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_790, 0);  mul_790 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_774: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_773, 2);  unsqueeze_773 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_775: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_774, 3);  unsqueeze_774 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_791: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_237, unsqueeze_772);  sub_237 = unsqueeze_772 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_239: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_43, mul_791);  where_43 = mul_791 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_240: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_239, unsqueeze_769);  sub_239 = unsqueeze_769 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_792: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_240, unsqueeze_775);  sub_240 = unsqueeze_775 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_793: f32[64] = torch.ops.aten.mul.Tensor(sum_95, squeeze_19);  sum_95 = squeeze_19 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_46 = torch.ops.aten.convolution_backward.default(mul_792, relu_4, primals_19, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_792 = primals_19 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_246: f32[64, 64, 56, 56] = convolution_backward_46[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_247: f32[64, 64, 3, 3] = convolution_backward_46[1];  convolution_backward_46 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_44: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_4, 0);  relu_4 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_44: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_44, full_default, getitem_246);  le_44 = getitem_246 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_96: f32[64] = torch.ops.aten.sum.dim_IntList(where_44, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_241: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_778);  convolution_5 = unsqueeze_778 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_794: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_44, sub_241)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_97: f32[64] = torch.ops.aten.sum.dim_IntList(mul_794, [0, 2, 3]);  mul_794 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_795: f32[64] = torch.ops.aten.mul.Tensor(sum_96, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_779: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_795, 0);  mul_795 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_780: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_779, 2);  unsqueeze_779 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_781: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_780, 3);  unsqueeze_780 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_796: f32[64] = torch.ops.aten.mul.Tensor(sum_97, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_797: f32[64] = torch.ops.aten.mul.Tensor(squeeze_16, squeeze_16)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_798: f32[64] = torch.ops.aten.mul.Tensor(mul_796, mul_797);  mul_796 = mul_797 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_782: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_798, 0);  mul_798 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_783: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_782, 2);  unsqueeze_782 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_784: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_783, 3);  unsqueeze_783 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_799: f32[64] = torch.ops.aten.mul.Tensor(squeeze_16, primals_17);  primals_17 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_785: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_799, 0);  mul_799 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_786: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_785, 2);  unsqueeze_785 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_787: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_786, 3);  unsqueeze_786 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_800: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_241, unsqueeze_784);  sub_241 = unsqueeze_784 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_243: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_44, mul_800);  where_44 = mul_800 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_244: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_243, unsqueeze_781);  sub_243 = unsqueeze_781 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_801: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_244, unsqueeze_787);  sub_244 = unsqueeze_787 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_802: f32[64] = torch.ops.aten.mul.Tensor(sum_97, squeeze_16);  sum_97 = squeeze_16 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_47 = torch.ops.aten.convolution_backward.default(mul_801, relu_3, primals_16, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_801 = primals_16 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_249: f32[64, 256, 56, 56] = convolution_backward_47[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_250: f32[64, 256, 1, 1] = convolution_backward_47[1];  convolution_backward_47 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_295: f32[64, 256, 56, 56] = torch.ops.aten.add.Tensor(where_42, getitem_249);  where_42 = getitem_249 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:161, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_45: b8[64, 256, 56, 56] = torch.ops.aten.le.Scalar(relu_3, 0);  relu_3 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_45: f32[64, 256, 56, 56] = torch.ops.aten.where.self(le_45, full_default, add_295);  le_45 = add_295 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:158, code: identity = self.downsample(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_98: f32[256] = torch.ops.aten.sum.dim_IntList(where_45, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_245: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_790);  convolution_4 = unsqueeze_790 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_803: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(where_45, sub_245)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_99: f32[256] = torch.ops.aten.sum.dim_IntList(mul_803, [0, 2, 3]);  mul_803 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_804: f32[256] = torch.ops.aten.mul.Tensor(sum_98, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_791: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_804, 0);  mul_804 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_792: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_791, 2);  unsqueeze_791 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_793: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_792, 3);  unsqueeze_792 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_805: f32[256] = torch.ops.aten.mul.Tensor(sum_99, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_806: f32[256] = torch.ops.aten.mul.Tensor(squeeze_13, squeeze_13)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_807: f32[256] = torch.ops.aten.mul.Tensor(mul_805, mul_806);  mul_805 = mul_806 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_794: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_807, 0);  mul_807 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_795: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_794, 2);  unsqueeze_794 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_796: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_795, 3);  unsqueeze_795 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_808: f32[256] = torch.ops.aten.mul.Tensor(squeeze_13, primals_14);  primals_14 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_797: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_808, 0);  mul_808 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_798: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_797, 2);  unsqueeze_797 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_799: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_798, 3);  unsqueeze_798 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_809: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_245, unsqueeze_796);  sub_245 = unsqueeze_796 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_247: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(where_45, mul_809);  mul_809 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_248: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(sub_247, unsqueeze_793);  sub_247 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_810: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_248, unsqueeze_799);  sub_248 = unsqueeze_799 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_811: f32[256] = torch.ops.aten.mul.Tensor(sum_99, squeeze_13);  sum_99 = squeeze_13 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_48 = torch.ops.aten.convolution_backward.default(mul_810, getitem_2, primals_13, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_810 = primals_13 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_252: f32[64, 64, 56, 56] = convolution_backward_48[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_253: f32[256, 64, 1, 1] = convolution_backward_48[1];  convolution_backward_48 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:155, code: out = self.bn3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_249: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_802);  convolution_3 = unsqueeze_802 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_812: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(where_45, sub_249)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_101: f32[256] = torch.ops.aten.sum.dim_IntList(mul_812, [0, 2, 3]);  mul_812 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_814: f32[256] = torch.ops.aten.mul.Tensor(sum_101, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_815: f32[256] = torch.ops.aten.mul.Tensor(squeeze_10, squeeze_10)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_816: f32[256] = torch.ops.aten.mul.Tensor(mul_814, mul_815);  mul_814 = mul_815 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_806: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_816, 0);  mul_816 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_807: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_806, 2);  unsqueeze_806 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_808: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_807, 3);  unsqueeze_807 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_817: f32[256] = torch.ops.aten.mul.Tensor(squeeze_10, primals_11);  primals_11 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_809: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_817, 0);  mul_817 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_810: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_809, 2);  unsqueeze_809 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_811: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_810, 3);  unsqueeze_810 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_818: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_249, unsqueeze_808);  sub_249 = unsqueeze_808 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_251: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(where_45, mul_818);  where_45 = mul_818 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_252: f32[64, 256, 56, 56] = torch.ops.aten.sub.Tensor(sub_251, unsqueeze_793);  sub_251 = unsqueeze_793 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_819: f32[64, 256, 56, 56] = torch.ops.aten.mul.Tensor(sub_252, unsqueeze_811);  sub_252 = unsqueeze_811 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_820: f32[256] = torch.ops.aten.mul.Tensor(sum_101, squeeze_10);  sum_101 = squeeze_10 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:154, code: out = self.conv3(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_49 = torch.ops.aten.convolution_backward.default(mul_819, relu_2, primals_10, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_819 = primals_10 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_255: f32[64, 64, 56, 56] = convolution_backward_49[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_256: f32[256, 64, 1, 1] = convolution_backward_49[1];  convolution_backward_49 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:152, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_46: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_2, 0);  relu_2 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_46: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_46, full_default, getitem_255);  le_46 = getitem_255 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:151, code: out = self.bn2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_102: f32[64] = torch.ops.aten.sum.dim_IntList(where_46, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_253: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_814);  convolution_2 = unsqueeze_814 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_821: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_46, sub_253)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_103: f32[64] = torch.ops.aten.sum.dim_IntList(mul_821, [0, 2, 3]);  mul_821 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_822: f32[64] = torch.ops.aten.mul.Tensor(sum_102, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_815: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_822, 0);  mul_822 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_816: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_815, 2);  unsqueeze_815 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_817: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_816, 3);  unsqueeze_816 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_823: f32[64] = torch.ops.aten.mul.Tensor(sum_103, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_824: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, squeeze_7)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_825: f32[64] = torch.ops.aten.mul.Tensor(mul_823, mul_824);  mul_823 = mul_824 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_818: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_825, 0);  mul_825 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_819: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_818, 2);  unsqueeze_818 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_820: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_819, 3);  unsqueeze_819 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_826: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, primals_8);  primals_8 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_821: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_826, 0);  mul_826 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_822: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_821, 2);  unsqueeze_821 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_823: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_822, 3);  unsqueeze_822 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_827: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_253, unsqueeze_820);  sub_253 = unsqueeze_820 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_255: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_46, mul_827);  where_46 = mul_827 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_256: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_255, unsqueeze_817);  sub_255 = unsqueeze_817 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_828: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_256, unsqueeze_823);  sub_256 = unsqueeze_823 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_829: f32[64] = torch.ops.aten.mul.Tensor(sum_103, squeeze_7);  sum_103 = squeeze_7 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:150, code: out = self.conv2(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_50 = torch.ops.aten.convolution_backward.default(mul_828, relu_1, primals_7, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_828 = primals_7 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_258: f32[64, 64, 56, 56] = convolution_backward_50[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_259: f32[64, 64, 3, 3] = convolution_backward_50[1];  convolution_backward_50 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:148, code: out = self.relu(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_47: b8[64, 64, 56, 56] = torch.ops.aten.le.Scalar(relu_1, 0);  relu_1 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_47: f32[64, 64, 56, 56] = torch.ops.aten.where.self(le_47, full_default, getitem_258);  le_47 = getitem_258 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:147, code: out = self.bn1(out)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_104: f32[64] = torch.ops.aten.sum.dim_IntList(where_47, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_257: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_826);  convolution_1 = unsqueeze_826 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_830: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(where_47, sub_257)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_105: f32[64] = torch.ops.aten.sum.dim_IntList(mul_830, [0, 2, 3]);  mul_830 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_831: f32[64] = torch.ops.aten.mul.Tensor(sum_104, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_827: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_831, 0);  mul_831 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_828: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_827, 2);  unsqueeze_827 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_829: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_828, 3);  unsqueeze_828 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_832: f32[64] = torch.ops.aten.mul.Tensor(sum_105, 4.982461734693877e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_833: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, squeeze_4)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_834: f32[64] = torch.ops.aten.mul.Tensor(mul_832, mul_833);  mul_832 = mul_833 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_830: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_834, 0);  mul_834 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_831: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_830, 2);  unsqueeze_830 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_832: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_831, 3);  unsqueeze_831 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_835: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, primals_5);  primals_5 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_833: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_835, 0);  mul_835 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_834: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_833, 2);  unsqueeze_833 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_835: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_834, 3);  unsqueeze_834 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_836: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_257, unsqueeze_832);  sub_257 = unsqueeze_832 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_259: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(where_47, mul_836);  where_47 = mul_836 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_260: f32[64, 64, 56, 56] = torch.ops.aten.sub.Tensor(sub_259, unsqueeze_829);  sub_259 = unsqueeze_829 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_837: f32[64, 64, 56, 56] = torch.ops.aten.mul.Tensor(sub_260, unsqueeze_835);  sub_260 = unsqueeze_835 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_838: f32[64] = torch.ops.aten.mul.Tensor(sum_105, squeeze_4);  sum_105 = squeeze_4 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_51 = torch.ops.aten.convolution_backward.default(mul_837, getitem_2, primals_4, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_837 = getitem_2 = primals_4 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_261: f32[64, 64, 56, 56] = convolution_backward_51[0]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_262: f32[64, 64, 1, 1] = convolution_backward_51[1];  convolution_backward_51 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:146, code: out = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_296: f32[64, 64, 56, 56] = torch.ops.aten.add.Tensor(getitem_252, getitem_261);  getitem_252 = getitem_261 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:271, code: x = self.maxpool(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         max_pool2d_with_indices_backward: f32[64, 64, 112, 112] = torch.ops.aten.max_pool2d_with_indices_backward.default(add_296, relu, [3, 3], [2, 2], [1, 1], [1, 1], False, getitem_3);  add_296 = getitem_3 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:270, code: x = self.relu(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_48: b8[64, 64, 112, 112] = torch.ops.aten.le.Scalar(relu, 0);  relu = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_48: f32[64, 64, 112, 112] = torch.ops.aten.where.self(le_48, full_default, max_pool2d_with_indices_backward);  le_48 = full_default = max_pool2d_with_indices_backward = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:269, code: x = self.bn1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_106: f32[64] = torch.ops.aten.sum.dim_IntList(where_48, [0, 2, 3])
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_261: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(convolution, unsqueeze_838);  convolution = unsqueeze_838 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_839: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(where_48, sub_261)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_107: f32[64] = torch.ops.aten.sum.dim_IntList(mul_839, [0, 2, 3]);  mul_839 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_840: f32[64] = torch.ops.aten.mul.Tensor(sum_106, 1.2456154336734693e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_839: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_840, 0);  mul_840 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_840: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_839, 2);  unsqueeze_839 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_841: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_840, 3);  unsqueeze_840 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_841: f32[64] = torch.ops.aten.mul.Tensor(sum_107, 1.2456154336734693e-06)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_842: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, squeeze_1)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_843: f32[64] = torch.ops.aten.mul.Tensor(mul_841, mul_842);  mul_841 = mul_842 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_842: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_843, 0);  mul_843 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_843: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_842, 2);  unsqueeze_842 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_844: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_843, 3);  unsqueeze_843 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_844: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, primals_2);  primals_2 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_845: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_844, 0);  mul_844 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_846: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_845, 2);  unsqueeze_845 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_847: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_846, 3);  unsqueeze_846 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_845: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(sub_261, unsqueeze_844);  sub_261 = unsqueeze_844 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_263: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(where_48, mul_845);  where_48 = mul_845 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_264: f32[64, 64, 112, 112] = torch.ops.aten.sub.Tensor(sub_263, unsqueeze_841);  sub_263 = unsqueeze_841 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_846: f32[64, 64, 112, 112] = torch.ops.aten.mul.Tensor(sub_264, unsqueeze_847);  sub_264 = unsqueeze_847 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_847: f32[64] = torch.ops.aten.mul.Tensor(sum_107, squeeze_1);  sum_107 = squeeze_1 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torchvision/models/resnet.py:268, code: x = self.conv1(x)
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_52 = torch.ops.aten.convolution_backward.default(mul_846, primals_321, primals_1, [0], [2, 2], [3, 3], [1, 1], False, [0, 0], 1, [False, True, False]);  mul_846 = primals_321 = primals_1 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_265: f32[64, 3, 7, 7] = convolution_backward_52[1];  convolution_backward_52 = None
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         return [getitem_265, mul_847, sum_106, getitem_262, mul_838, sum_104, getitem_259, mul_829, sum_102, getitem_256, mul_820, sum_98, getitem_253, mul_811, sum_98, getitem_250, mul_802, sum_96, getitem_247, mul_793, sum_94, getitem_244, mul_784, sum_92, getitem_241, mul_775, sum_90, getitem_238, mul_766, sum_88, getitem_235, mul_757, sum_86, getitem_232, mul_748, sum_84, getitem_229, mul_739, sum_82, getitem_226, mul_730, sum_78, getitem_223, mul_721, sum_78, getitem_220, mul_712, sum_76, getitem_217, mul_703, sum_74, getitem_214, mul_694, sum_72, getitem_211, mul_685, sum_70, getitem_208, mul_676, sum_68, getitem_205, mul_667, sum_66, getitem_202, mul_658, sum_64, getitem_199, mul_649, sum_62, getitem_196, mul_640, sum_60, getitem_193, mul_631, sum_58, getitem_190, mul_622, sum_56, getitem_187, mul_613, sum_52, getitem_184, mul_604, sum_52, getitem_181, mul_595, sum_50, getitem_178, mul_586, sum_48, getitem_175, mul_577, sum_46, getitem_172, mul_568, sum_44, getitem_169, mul_559, sum_42, getitem_166, mul_550, sum_40, getitem_163, mul_541, sum_38, getitem_160, mul_532, sum_36, getitem_157, mul_523, sum_34, getitem_154, mul_514, sum_32, getitem_151, mul_505, sum_30, getitem_148, mul_496, sum_28, getitem_145, mul_487, sum_26, getitem_142, mul_478, sum_24, getitem_139, mul_469, sum_22, getitem_136, mul_460, sum_20, getitem_133, mul_451, sum_18, getitem_130, mul_442, sum_14, getitem_127, mul_433, sum_14, getitem_124, mul_424, sum_12, getitem_121, mul_415, sum_10, getitem_118, mul_406, sum_8, getitem_115, mul_397, sum_6, getitem_112, mul_388, sum_4, getitem_109, mul_379, sum_2, permute_4, view_1, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         
[2023-12-28 21:23:00,009] [0/0] torch._functorch.aot_autograd.__aot_graphs: [INFO] 
[2023-12-28 21:23:00,125] [0/0] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0
[2023-12-28 21:23:06,076] [0/0] torch._inductor.graph: [DEBUG] Force channels last inputs for 20 conv for the current graph with id 0
[2023-12-28 21:23:09,132] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf27
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf43
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf57
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf71
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf84
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf99
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf113
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf127
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf141
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf155
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf169
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf183
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf197
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf211
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf224
[2023-12-28 21:23:09,133] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf239
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf253
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf267
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf281
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf295
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf309
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf323
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf337
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf351
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf365
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf376
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf387
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf397
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf409
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf420
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf431
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf442
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf453
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf464
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf475
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf486
[2023-12-28 21:23:09,134] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf497
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf508
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf519
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf530
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf541
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf552
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf563
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf574
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf585
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf596
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf606
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf618
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf629
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf640
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf651
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf662
[2023-12-28 21:23:09,135] [0/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf673
[2023-12-28 21:23:09,321] [0/0] torch._inductor.scheduler: [INFO] Number of scheduler nodes after fusion 307
[2023-12-28 21:23:12,360] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,360] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, YBLOCK: 32, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,371] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,371] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, YBLOCK: 64, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,377] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,377] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, YBLOCK: 64, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,384] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,384] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, YBLOCK: 64, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,390] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,390] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, YBLOCK: 64, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,396] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,396] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, YBLOCK: 32, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,404] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,404] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 64, RBLOCK: 64, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,413] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,413] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,422] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,422] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 64, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,430] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,430] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,441] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,441] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 512, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,451] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,451] [0/0] torch._inductor.triton_heuristics: [DEBUG] num_warps: 8, num_stages: 3
[2023-12-28 21:23:12,459] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,459] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 64, RBLOCK: 4, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,468] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,468] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 64, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,476] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,476] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,484] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,484] [0/0] torch._inductor.triton_heuristics: [DEBUG] num_warps: 4, num_stages: 3
[2023-12-28 21:23:12,493] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,494] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 128, RBLOCK: 8, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,502] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,502] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,511] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,511] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 128, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,520] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,520] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,528] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,528] [0/0] torch._inductor.triton_heuristics: [DEBUG] num_warps: 4, num_stages: 3
[2023-12-28 21:23:12,537] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,537] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,545] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,545] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 64, RBLOCK: 4, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,553] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,553] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,562] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,562] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 64, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,570] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,570] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,578] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,578] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,587] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,587] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,596] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,596] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 128, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,604] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,604] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,611] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,611] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 64, RBLOCK: 4, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,620] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,620] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,629] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,629] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 256, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,639] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,639] [0/0] torch._inductor.triton_heuristics: [DEBUG] num_warps: 8, num_stages: 2
[2023-12-28 21:23:12,650] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,650] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,658] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,658] [0/0] torch._inductor.triton_heuristics: [DEBUG] num_warps: 4, num_stages: 3
[2023-12-28 21:23:12,667] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,667] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,674] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,674] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,683] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,683] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,692] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,692] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 128, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,700] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,700] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,708] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,708] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,717] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,717] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 4, RBLOCK: 128, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,726] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,726] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,733] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,733] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,742] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,742] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,752] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,752] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 512, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,759] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,759] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 512, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,767] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,767] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,776] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,776] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,785] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,785] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 512, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,793] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,793] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,802] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,802] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 16, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,811] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,811] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1024, num_warps: 4, num_stages: 1
[2023-12-28 21:23:12,819] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,819] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, RBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,828] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,828] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 128, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,837] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,837] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 512, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,845] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,845] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 512, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,852] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,852] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 512, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,859] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,859] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 32, num_warps: 8, num_stages: 1
[2023-12-28 21:23:12,865] [0/0] torch._inductor.triton_heuristics: [DEBUG] CachingAutotuner gets 1 configs
[2023-12-28 21:23:12,865] [0/0] torch._inductor.triton_heuristics: [DEBUG] XBLOCK: 1, num_warps: 1, num_stages: 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [INFO] Output code written to: /tmp/torchinductor_fjr38/mh/cmhdwebll3lcq56l3kcmrdsej5mlwuihrdwwrtir4cpsfshtiet3.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph: [DEBUG] Output code written to: /tmp/torchinductor_fjr38/mh/cmhdwebll3lcq56l3kcmrdsej5mlwuihrdwwrtir4cpsfshtiet3.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] Output code: 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from ctypes import c_void_p, c_long
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import torch
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import math
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import random
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import os
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import tempfile
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from math import inf, nan
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.hooks import run_intermediate_hooks
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import maybe_profile
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch import empty_strided, device
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.codecache import AsyncCompile
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.select_algorithm import extern_kernels
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] aten = torch.ops.aten
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] async_compile = AsyncCompile()
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/sy/csy4pmse4puptclk7z2xiyyi4zbmpcmg5hmjoflfywzjtvq3cuww.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_0 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[256, 64], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 192
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 49
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 3)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (49*y3)), xmask & ymask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (3*x2) + (147*y1)), tmp0, xmask & ymask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import grid, start_graph, end_graph
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._C import _cuda_getCurrentRawStream as get_cuda_stream
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/ol/colrzzexyhjdujnvcfmofznluxqvsmcb7x56ttirnena5enimaul.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_1 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[4096, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 4096
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (64*x2) + (576*y1)), tmp0, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/7j/c7jq4ltoopy6njmxtkvyoy4gy4advmx35xqtqxma632smhepxjtg.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_2 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16384, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_2', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 16384
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 128)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (128*x2) + (1152*y1)), tmp0, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/cb/ccbcjudge7cw4dvqd435xnwszasmx533jndtrpksskpltc2malds.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_3 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[65536, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_3', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 65536
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 256)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (256*x2) + (2304*y1)), tmp0, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/n2/cn2ntxb3sgq4ahu626iyrmwql3yddwegett7doe4xkkpcpwpstrk.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_4 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[262144, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_4', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 262144
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 512)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (512*x2) + (4608*y1)), tmp0, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/h3/ch3e5xbuevrfrpemfovkmijgvbue4nmwmpehov2nkwphobdlcogq.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_5 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[256, 65536], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_5', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2, 3))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 192
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 50176
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 3)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (50176*y3)), xmask & ymask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (3*x2) + (150528*y1)), tmp0, xmask & ymask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/dc/cdcgfp7k3fx3ywyiraybltyt2iquydnajepe3mo5nickyf6qmz7u.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => var_mean
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_6 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[65536, 1024],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_6', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 57344
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 896
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (57344*x1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/br/cbr6zpnm3uzwjg4azuw6yy2q2piiepmh4rnvodaylpemayf67zg7.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => var_mean
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_7 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[512, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_7', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6, 7))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 448
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 7
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x1 + (64*r2) + (8192*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x1 + (64*r2) + (8192*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x1 + (64*r2) + (8192*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x1 + (64*x0)), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x1 + (64*x0)), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x1 + (64*x0)), tmp8, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/xc/cxcuwl37tu6qd4oa3jfjdf3aekhkr6tmwfs2q25f5syqjszsa5i3.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => add_1, add_2, add_3, mul_1, mul_2, mul_3, mul_4, mul_5, rsqrt, squeeze_1, var_mean
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_8 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[64, 8],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_8', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 7
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 802816.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0000012456169853
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/gw/cgwtc5pmwxd3u6plm4a64lwyhawnjmxrirpknnb2ruxoamvsc6jy.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___bn1, l__self___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => add_1, add_4, mul, mul_6, rsqrt, sub, var_mean
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___relu => relu
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_9 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[67108864], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_9', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 51380224
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 802816.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/kl/cklz7sgagaxrdiokmouz4o2oxcxvcka6juyqy5h3mkft4gaq2sa4.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___maxpool], Original ATen: [aten.max_pool2d_with_indices]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___maxpool => getitem_2, getitem_3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_max_pool2d_with_indices_10 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16777216], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_10', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 12845056
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = (xindex // 3584) % 56
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 64) % 56
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x5 = (xindex // 3584)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x6 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = (-1) + (2*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.full([1], 0, tl.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 >= tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.full([1], 112, tl.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp0 < tmp3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp2 & tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = (-1) + (2*x1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp6 >= tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp6 < tmp3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp7 & tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tmp5 & tmp9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tl.load(in_ptr0 + ((-7232) + x0 + (128*x1) + (14336*x5)), tmp10, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.where(tmp10, tmp11, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = 2*x1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp13 >= tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 < tmp3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 & tmp15
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp5 & tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tl.load(in_ptr0 + ((-7168) + x0 + (128*x1) + (14336*x5)), tmp17, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tl.where(tmp17, tmp18, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = triton_helpers.maximum(tmp19, tmp12)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1 + (2*x1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp21 >= tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 < tmp3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 & tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp5 & tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tl.load(in_ptr0 + ((-7104) + x0 + (128*x1) + (14336*x5)), tmp25, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tl.where(tmp25, tmp26, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = triton_helpers.maximum(tmp27, tmp20)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = 2*x2
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tmp29 >= tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp29 < tmp3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp30 & tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp33 = tmp32 & tmp9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp34 = tl.load(in_ptr0 + ((-64) + x0 + (128*x1) + (14336*x5)), tmp33, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp35 = tl.where(tmp33, tmp34, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp36 = triton_helpers.maximum(tmp35, tmp28)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp37 = tmp32 & tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp38 = tl.load(in_ptr0 + (x0 + (128*x1) + (14336*x5)), tmp37, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp39 = tl.where(tmp37, tmp38, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp40 = triton_helpers.maximum(tmp39, tmp36)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp41 = tmp32 & tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp42 = tl.load(in_ptr0 + (64 + x0 + (128*x1) + (14336*x5)), tmp41, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp43 = tl.where(tmp41, tmp42, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp44 = triton_helpers.maximum(tmp43, tmp40)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp45 = 1 + (2*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp46 = tmp45 >= tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp47 = tmp45 < tmp3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp48 = tmp46 & tmp47
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp49 = tmp48 & tmp9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp50 = tl.load(in_ptr0 + (7104 + x0 + (128*x1) + (14336*x5)), tmp49, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp51 = tl.where(tmp49, tmp50, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp52 = triton_helpers.maximum(tmp51, tmp44)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp53 = tmp48 & tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp54 = tl.load(in_ptr0 + (7168 + x0 + (128*x1) + (14336*x5)), tmp53, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp55 = tl.where(tmp53, tmp54, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp56 = triton_helpers.maximum(tmp55, tmp52)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp57 = tmp48 & tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp58 = tl.load(in_ptr0 + (7232 + x0 + (128*x1) + (14336*x5)), tmp57, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp59 = tl.where(tmp57, tmp58, float("-inf"))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp60 = triton_helpers.maximum(tmp59, tmp56)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp61 = tmp19 > tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp62 = (-112) + (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp63 = (-113) + (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp64 = tl.where(tmp61, tmp62, tmp63)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp65 = tmp27 > tmp20
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp66 = (-111) + (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp67 = tl.where(tmp65, tmp66, tmp64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp68 = tmp35 > tmp28
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp69 = (-1) + (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp70 = tl.where(tmp68, tmp69, tmp67)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp71 = tmp39 > tmp36
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp72 = (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp73 = tl.where(tmp71, tmp72, tmp70)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp74 = tmp43 > tmp40
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp75 = 1 + (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp76 = tl.where(tmp74, tmp75, tmp73)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp77 = tmp51 > tmp44
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp78 = 111 + (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp79 = tl.where(tmp77, tmp78, tmp76)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp80 = tmp55 > tmp52
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp81 = 112 + (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp82 = tl.where(tmp80, tmp81, tmp79)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp83 = tmp59 > tmp56
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp84 = 113 + (2*x1) + (224*x2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp85 = tl.where(tmp83, tmp84, tmp82)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x6), tmp60, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x6), tmp85, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/oy/coyl7wt2qmw2p63lssue2myltk73qdlp4hjfxh4bjlm7sxezq36l.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___conv1 => convolution_1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_unk_fused_convolution_11 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import template
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @template(num_stages=3, num_warps=8, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(arg_A, arg_B, out_ptr0):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     GROUP_M : tl.constexpr = 8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     EVEN_K : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ALLOW_TF32 : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ACC_TYPE : tl.constexpr = tl.float32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B_PROLOGUE_CAST_TYPE : tl.constexpr = None
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_M : tl.constexpr = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_N : tl.constexpr = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_K : tl.constexpr = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     A = arg_A
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B = arg_B
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     M = 200704
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     N = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     K = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     if M * N == 0:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # early exit due to zero-size input(s)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         return
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_am = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_ak = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_bk = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_bn = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # based on triton.ops.matmul
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid = tl.program_id(0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     grid_m = (M + BLOCK_M - 1) // BLOCK_M
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     grid_n = (N + BLOCK_N - 1) // BLOCK_N
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # re-order program ID for better L2 performance
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     width = GROUP_M * grid_n
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group_id = pid // width
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group_size = min(grid_m - group_id * GROUP_M, GROUP_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid_m = group_id * GROUP_M + (pid % group_size)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid_n = (pid % width) // (group_size)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rk = tl.arange(0, BLOCK_K)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=ACC_TYPE)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for k in range(K, 0, -BLOCK_K):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         if EVEN_K:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             a = tl.load(A)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = tl.load(B)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         else:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             a = tl.load(A, mask=rk[None, :] < k, other=0.)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = tl.load(B, mask=rk[:, None] < k, other=0.)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         if B_PROLOGUE_CAST_TYPE is not None:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = b.to(B_PROLOGUE_CAST_TYPE)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         acc += tl.dot(a, b, allow_tf32=ALLOW_TF32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         A += BLOCK_K * stride_ak
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         B += BLOCK_K * stride_bk
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # rematerialize rm and rn to save registers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_m = rm[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_n = rn[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     mask = (idx_m < M) & (idx_n < N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # inductor generates a suffix
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = idx_n + (64*idx_m)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (tl.broadcast_to(xindex, mask.shape)), acc, mask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import torch._inductor.kernel.mm_common
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] meta0 = {'GROUP_M': 8, 'EVEN_K': True, 'ALLOW_TF32': True, 'ACC_TYPE': 'tl.float32', 'B_PROLOGUE_CAST_TYPE': None, 'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/c5/cc5n5ufb6c5imfwvcgonaa66hhwp27g62e2qxg2l4yoclu25burc.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn1 => var_mean_1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_12 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[65536, 256],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_12', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 57344
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 224
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (14336*x1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/ql/cqle5ojvcyza4z6u72orjymzj3rrmzwu7nzxgpsywsy6qdialza2.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn1 => add_6, add_7, add_8, mul_10, mul_11, mul_12, mul_8, mul_9, rsqrt_1, squeeze_4, var_mean_1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_13 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[64, 8],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_13', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 7
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 200704.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0000049824865598
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/xu/cxuxrnzmm2fanv7llmgm3e6oiyppwn7aqlizvibneg2hslhwxg7e.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn1, getattr_l__self___layer1___0___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn1 => add_6, add_9, mul_13, mul_7, rsqrt_1, sub_1, var_mean_1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___relu => relu_1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_14 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16777216], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_14', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 12845056
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 200704.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/ta/ctayldz2y2b3m4ehjo3mhykdjvsmqga5llzath6igzm25ssg5jcm.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___conv3 => convolution_3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_unk_fused_convolution_15 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import template
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @template(num_stages=3, num_warps=4, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(arg_A, arg_B, out_ptr0):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     GROUP_M : tl.constexpr = 8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     EVEN_K : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ALLOW_TF32 : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ACC_TYPE : tl.constexpr = tl.float32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B_PROLOGUE_CAST_TYPE : tl.constexpr = None
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_M : tl.constexpr = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_N : tl.constexpr = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_K : tl.constexpr = 32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     A = arg_A
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B = arg_B
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     M = 200704
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     N = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     K = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     if M * N == 0:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # early exit due to zero-size input(s)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         return
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_am = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_ak = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_bk = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_bn = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # based on triton.ops.matmul
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid = tl.program_id(0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     grid_m = (M + BLOCK_M - 1) // BLOCK_M
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     grid_n = (N + BLOCK_N - 1) // BLOCK_N
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # re-order program ID for better L2 performance
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     width = GROUP_M * grid_n
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group_id = pid // width
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group_size = min(grid_m - group_id * GROUP_M, GROUP_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid_m = group_id * GROUP_M + (pid % group_size)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid_n = (pid % width) // (group_size)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rk = tl.arange(0, BLOCK_K)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=ACC_TYPE)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for k in range(K, 0, -BLOCK_K):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         if EVEN_K:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             a = tl.load(A)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = tl.load(B)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         else:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             a = tl.load(A, mask=rk[None, :] < k, other=0.)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = tl.load(B, mask=rk[:, None] < k, other=0.)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         if B_PROLOGUE_CAST_TYPE is not None:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = b.to(B_PROLOGUE_CAST_TYPE)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         acc += tl.dot(a, b, allow_tf32=ALLOW_TF32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         A += BLOCK_K * stride_ak
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         B += BLOCK_K * stride_bk
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # rematerialize rm and rn to save registers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_m = rm[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_n = rn[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     mask = (idx_m < M) & (idx_n < N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # inductor generates a suffix
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = idx_n + (256*idx_m)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (tl.broadcast_to(xindex, mask.shape)), acc, mask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] meta1 = {'GROUP_M': 8, 'EVEN_K': True, 'ALLOW_TF32': True, 'ACC_TYPE': 'tl.float32', 'B_PROLOGUE_CAST_TYPE': None, 'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 32}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/tz/ctzsv2kynow5hitf5vbnxgkvbkuq4k2ejemknjlevo4ff7cogw55.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn3 => var_mean_3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_16 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[131072, 512],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_16', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 114688
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 448
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 256)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (114688*x1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/4a/c4aamscwuhdpk6ux2vk3sbizh4pmiwldl4wk56otamrxvgqt5tom.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn3 => var_mean_3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_17 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[1024, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_17', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6, 7))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 1024
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 112
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 4)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x1 + (256*r2) + (28672*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x1 + (256*r2) + (28672*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x1 + (256*r2) + (28672*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x1 + (256*x0)), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x1 + (256*x0)), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x1 + (256*x0)), tmp8, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/nk/cnkj4qxw3zlpkguaomjnxb6pa72cl4ffhqmog3dem4nme6asqruu.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn3 => add_16, add_17, add_18, mul_22, mul_23, mul_24, mul_25, mul_26, rsqrt_3, squeeze_10, var_mean_3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_18 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[256, 4],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_18', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 200704.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0000049824865598
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/x3/cx3nics7gcrse3gg3dysjaqytsa464ojc3adnyewl4jh27mreo4a.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn3, getattr_l__self___layer1___0___downsample_1, getattr_l__self___layer1___0___relu_2, iadd], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn3 => add_16, add_19, mul_21, mul_27, rsqrt_3, sub_3, var_mean_3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___downsample_1 => add_21, add_24, mul_28, mul_34, rsqrt_4, sub_4, var_mean_4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___relu_2 => relu_3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd => add_25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_19 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[67108864], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': ['in_out_ptr0'], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_19', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 51380224
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 200704.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 - tmp15
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp17 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp18 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp16 * tmp20
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 * tmp22
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 + tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tmp13 + tmp25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = triton_helpers.maximum(0, tmp26)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(in_out_ptr0 + (x2), tmp27, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/dk/cdkiqd7scrhdkxsbowc3acjujf3k3btra7rtygw2omtnjmwpdtgk.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___1___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___1___conv1 => convolution_5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_unk_fused_convolution_20 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import template
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @template(num_stages=3, num_warps=4, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(arg_A, arg_B, out_ptr0):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     GROUP_M : tl.constexpr = 8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     EVEN_K : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ALLOW_TF32 : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ACC_TYPE : tl.constexpr = tl.float32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B_PROLOGUE_CAST_TYPE : tl.constexpr = None
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_M : tl.constexpr = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_N : tl.constexpr = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_K : tl.constexpr = 32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     A = arg_A
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B = arg_B
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     M = 200704
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     N = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     K = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     if M * N == 0:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # early exit due to zero-size input(s)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         return
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_am = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_ak = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_bk = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_bn = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # based on triton.ops.matmul
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid = tl.program_id(0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     grid_m = (M + BLOCK_M - 1) // BLOCK_M
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     grid_n = (N + BLOCK_N - 1) // BLOCK_N
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # re-order program ID for better L2 performance
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     width = GROUP_M * grid_n
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group_id = pid // width
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group_size = min(grid_m - group_id * GROUP_M, GROUP_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid_m = group_id * GROUP_M + (pid % group_size)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid_n = (pid % width) // (group_size)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rk = tl.arange(0, BLOCK_K)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=ACC_TYPE)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for k in range(K, 0, -BLOCK_K):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         if EVEN_K:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             a = tl.load(A)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = tl.load(B)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         else:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             a = tl.load(A, mask=rk[None, :] < k, other=0.)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = tl.load(B, mask=rk[:, None] < k, other=0.)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         if B_PROLOGUE_CAST_TYPE is not None:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = b.to(B_PROLOGUE_CAST_TYPE)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         acc += tl.dot(a, b, allow_tf32=ALLOW_TF32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         A += BLOCK_K * stride_ak
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         B += BLOCK_K * stride_bk
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # rematerialize rm and rn to save registers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_m = rm[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_n = rn[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     mask = (idx_m < M) & (idx_n < N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # inductor generates a suffix
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = idx_n + (64*idx_m)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (tl.broadcast_to(xindex, mask.shape)), acc, mask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] meta2 = {'GROUP_M': 8, 'EVEN_K': True, 'ALLOW_TF32': True, 'ACC_TYPE': 'tl.float32', 'B_PROLOGUE_CAST_TYPE': None, 'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 32}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/eo/ceoiusqnl4lbxgwqyaiil62r4nvmdbnegmcjlxmln23uvbxf6bdy.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___1___bn3, getattr_l__self___layer1___1___relu_2, iadd_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___1___bn3 => add_37, add_40, mul_49, mul_55, rsqrt_7, sub_7, var_mean_7
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___1___relu_2 => relu_6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_1 => add_41
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_21 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[67108864], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_21', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 51380224
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 200704.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp16, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/ya/cyazwk7wxmuf3gs43afl5zbmxa35e4bhfjfnjvoy6loauq2flmri.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn1 => var_mean_11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_22 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[131072, 256],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_22', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 114688
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 224
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 128)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (28672*x1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/wj/cwjrbyaba35on5xhietphkzcjjoxn3ltvsn77ty3ao4ajfpufscz.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn1 => var_mean_11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_23 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[1024, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_23', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6, 7))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 896
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 7
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x1 + (128*r2) + (16384*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x1 + (128*r2) + (16384*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x1 + (128*r2) + (16384*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x1 + (128*x0)), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x1 + (128*x0)), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x1 + (128*x0)), tmp8, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/tf/ctfr23ptchblzrvhnuwynymabiobvne5knbnxyt3jp4hpektjthm.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn1 => add_59, add_60, add_61, mul_78, mul_79, mul_80, mul_81, mul_82, rsqrt_11, squeeze_34, var_mean_11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_24 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[128, 8],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_24', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 7
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 200704.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0000049824865598
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/7h/c7hbkf6uwllb6xbjek2qiv47zsftvwwhnxx7p7iwyt6bgvqhasyp.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn1, getattr_l__self___layer2___0___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn1 => add_59, add_62, mul_77, mul_83, rsqrt_11, sub_11, var_mean_11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___relu => relu_10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_25 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[33554432], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_25', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 25690112
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 200704.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/gj/cgjrcnwzoqvgsh5brjzbj4ivhwv6aac7xhgfg6rk25zdwyb25gxz.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn2 => var_mean_12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_26 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[65536, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_26', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 50176
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 128)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (128*r2) + (16384*x1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/2q/c2q4gfhk3e4wfs7vy6rssy6wjt4bbir5m4uaz7tomr44lrfvktrx.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn2 => var_mean_12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_27 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[512, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_27', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 98
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 4)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x1 + (128*r2) + (12544*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x1 + (128*r2) + (12544*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x1 + (128*r2) + (12544*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x1 + (128*x0)), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x1 + (128*x0)), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x1 + (128*x0)), tmp8, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/dp/cdpfglrvuy3uorvjvc7kdg43sdov52migcyhethsftrxywlvgwg3.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn2 => add_64, add_65, add_66, mul_85, mul_86, mul_87, mul_88, mul_89, rsqrt_12, squeeze_37, var_mean_12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_28 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[128, 4],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_28', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (128*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (128*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 50176.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0000199302441455
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/jy/cjyjmqx3vdhihiwb4dnf2leu7sslly4z5ar5ht4qqqwihet3i6am.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn2, getattr_l__self___layer2___0___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn2 => add_64, add_67, mul_84, mul_90, rsqrt_12, sub_12, var_mean_12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___relu_1 => relu_11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_29 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8388608], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_29', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 6422528
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 50176.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/j7/cj7mqtsakhu7emc44toiqyhnzuehqogxej46vvcdgo4sunyexaeo.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn3 => var_mean_13
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_30 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[131072, 256],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_30', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 114688
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 224
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 512)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (512*r2) + (114688*x1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/7k/c7ktwrsws6mwmzqugzcqemcroqhjb744xiphlb3fog53xvkuymi3.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn3 => var_mean_13
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_31 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[1024, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_31', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6, 7))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 1024
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 112
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 2
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x1 + (512*r2) + (57344*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x1 + (512*r2) + (57344*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x1 + (512*r2) + (57344*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x1 + (512*x0)), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x1 + (512*x0)), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x1 + (512*x0)), tmp8, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/m7/cm7yt7bes6eva4ef3ixxay4iufhq3pw5zmbbeh6nqtsgnvcio2nt.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn3 => add_69, add_70, add_71, mul_92, mul_93, mul_94, mul_95, mul_96, rsqrt_13, squeeze_40, var_mean_13
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_32 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[512, 2],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_32', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 2
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 2
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 50176.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0000199302441455
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/7t/c7tod7dlkktci5pdksoiv4z5uylt2eihbei3joyhuoqxtzcncmpx.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___downsample_0], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___downsample_0 => convolution_14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_unk_fused_convolution_33 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import template
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @template(num_stages=2, num_warps=8, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(arg_X, arg_W, out_ptr0):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     KERNEL_H : tl.constexpr = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     KERNEL_W : tl.constexpr = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     STRIDE_H : tl.constexpr = 2
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     STRIDE_W : tl.constexpr = 2
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     PADDING_H : tl.constexpr = 0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     PADDING_W : tl.constexpr = 0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     GROUPS : tl.constexpr = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     UNROLL : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ALLOW_TF32 : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_M : tl.constexpr = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_N : tl.constexpr = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_K : tl.constexpr = 32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     X = arg_X
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     W = arg_W
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # Tensor dimensions
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BATCH = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     IN_C = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     IN_H = 56
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     IN_W = 56
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     OUT_C = 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     OUT_H = 28
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     OUT_W = 28
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # Strides:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_xn = 802816
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_xc = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_xh = 14336
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_xw = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_wc_out = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_wc_in = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_wh = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_ww = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     nhw = tl.program_id(0) * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_y_w = nhw % OUT_W
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     nh = nhw // OUT_W
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_y_h = nh % OUT_H
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_n = nh // OUT_H
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_y_c = tl.program_id(1) * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group = 0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     GROUP_IN_C = IN_C
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     GROUP_OUT_C = OUT_C
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x_base = X + (group * stride_xc * GROUP_IN_C + idx_n * stride_xn)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     w_base = (
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         W + (group * stride_wc_out * GROUP_OUT_C + idx_y_c * stride_wc_out)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     i = 0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     j = 0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for k in range(0, GROUP_IN_C, BLOCK_K):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         idx_x_h = i - PADDING_H + idx_y_h * STRIDE_H
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         idx_x_w = j - PADDING_W + idx_y_w * STRIDE_W
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         idx_x_c = tl.arange(0, BLOCK_K) + k
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         x_ptrs = x_base + (
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             (idx_x_h * stride_xh)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             + (idx_x_w * stride_xw)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             + (idx_x_c * stride_xc)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         mask_x = (
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             (idx_n < BATCH)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             & (idx_x_h >= 0)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             & (idx_x_h < IN_H)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             & (idx_x_w >= 0)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             & (idx_x_w < IN_W)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             & (idx_x_c < GROUP_IN_C)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         matrix_x = tl.load(x_ptrs, mask=mask_x, other=0.0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         w_ptrs = w_base + (
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             (idx_x_c * stride_wc_in)[:, None] + (i * stride_wh) + (j * stride_ww)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         mask_w = (idx_x_c[:, None] < GROUP_IN_C) & (idx_y_c[None, :] < GROUP_OUT_C)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         matrix_w = tl.load(w_ptrs, mask=mask_w, other=0.0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         acc += tl.dot(matrix_x, matrix_w, allow_tf32=ALLOW_TF32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     mask = (
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         (idx_n < BATCH)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         & (idx_y_h < OUT_H)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         & (idx_y_w < OUT_W)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         & (idx_y_c < GROUP_OUT_C)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_n = idx_n[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_c = idx_y_c[None, :] + group * GROUP_OUT_C
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_h = idx_y_h[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_w = idx_y_w[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # inductor generates a suffix
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = idx_w + (28*idx_h) + (784*idx_c) + (401408*idx_n)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (tl.broadcast_to(idx_c + (512*idx_w) + (14336*idx_h) + (401408*idx_n), mask.shape)), acc, mask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import torch._inductor.kernel.conv
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] meta3 = {'KERNEL_H': 1, 'KERNEL_W': 1, 'STRIDE_H': 2, 'STRIDE_W': 2, 'PADDING_H': 0, 'PADDING_W': 0, 'GROUPS': 1, 'UNROLL': True, 'ALLOW_TF32': True, 'BLOCK_M': 64, 'BLOCK_N': 256, 'BLOCK_K': 32}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/dh/cdhzf46h23uyc5jd6cy23mkbdttcucezt3c24hd5rx6utsxwlen5.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn3, getattr_l__self___layer2___0___downsample_1, getattr_l__self___layer2___0___relu_2, iadd_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn3 => add_69, add_72, mul_91, mul_97, rsqrt_13, sub_13, var_mean_13
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___downsample_1 => add_74, add_77, mul_104, mul_98, rsqrt_14, sub_14, var_mean_14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___relu_2 => relu_12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_3 => add_78
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_34 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[33554432], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': ['in_out_ptr0'], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_34', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 25690112
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 50176.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 - tmp15
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp17 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp18 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp16 * tmp20
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 * tmp22
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 + tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tmp13 + tmp25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = triton_helpers.maximum(0, tmp26)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(in_out_ptr0 + (x2), tmp27, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/ac/caczvcer5utwk77meso747capf4ruyyywefcnjy47m3bwn2xlyvh.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___1___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___1___conv1 => convolution_15
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_unk_fused_convolution_35 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import template
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @template(num_stages=3, num_warps=4, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(arg_A, arg_B, out_ptr0):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     GROUP_M : tl.constexpr = 8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     EVEN_K : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ALLOW_TF32 : tl.constexpr = True
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ACC_TYPE : tl.constexpr = tl.float32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B_PROLOGUE_CAST_TYPE : tl.constexpr = None
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_M : tl.constexpr = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_N : tl.constexpr = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     BLOCK_K : tl.constexpr = 32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     A = arg_A
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B = arg_B
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     M = 50176
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     N = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     K = 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     if M * N == 0:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # early exit due to zero-size input(s)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         return
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_am = 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_ak = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_bk = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     stride_bn = 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # based on triton.ops.matmul
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid = tl.program_id(0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     grid_m = (M + BLOCK_M - 1) // BLOCK_M
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     grid_n = (N + BLOCK_N - 1) // BLOCK_N
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # re-order program ID for better L2 performance
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     width = GROUP_M * grid_n
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group_id = pid // width
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     group_size = min(grid_m - group_id * GROUP_M, GROUP_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid_m = group_id * GROUP_M + (pid % group_size)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     pid_n = (pid % width) // (group_size)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rk = tl.arange(0, BLOCK_K)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=ACC_TYPE)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for k in range(K, 0, -BLOCK_K):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         if EVEN_K:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             a = tl.load(A)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = tl.load(B)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         else:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             a = tl.load(A, mask=rk[None, :] < k, other=0.)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = tl.load(B, mask=rk[:, None] < k, other=0.)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         if B_PROLOGUE_CAST_TYPE is not None:
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             b = b.to(B_PROLOGUE_CAST_TYPE)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         acc += tl.dot(a, b, allow_tf32=ALLOW_TF32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         A += BLOCK_K * stride_ak
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         B += BLOCK_K * stride_bk
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # rematerialize rm and rn to save registers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_m = rm[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     idx_n = rn[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     mask = (idx_m < M) & (idx_n < N)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     # inductor generates a suffix
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = idx_n + (128*idx_m)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (tl.broadcast_to(xindex, mask.shape)), acc, mask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/fg/cfghsj5gmlooid7g6imxmxyktzy3aastflfqmsgoydoxaordxki6.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___1___bn3, getattr_l__self___layer2___1___relu_2, iadd_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___1___bn3 => add_90, add_93, mul_119, mul_125, rsqrt_17, sub_17, var_mean_17
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___1___relu_2 => relu_15
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_4 => add_94
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_36 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[33554432], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_36', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 25690112
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 50176.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp16, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/7p/c7pldcghywj5pnexfgsmffmlw3ikwsbj32agq27255ha7xia5nzo.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn1 => var_mean_24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_37 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[131072, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_37', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 100352
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 256)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/qn/cqncbifz7zant7t3qeaoxw2c7g6i76hkkadphdcmkskmrwhrhwim.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn1 => var_mean_24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_38 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[1024, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_38', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 1024
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 98
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 4)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x1 + (256*r2) + (25088*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x1 + (256*r2) + (25088*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x1 + (256*r2) + (25088*x0)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x1 + (256*x0)), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x1 + (256*x0)), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x1 + (256*x0)), tmp8, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/bz/cbz2plhgnltcenlkbrgyyffyctldsb3kzmtdpqn6y2mztbwbdw4t.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn1 => add_128, add_129, add_130, mul_169, mul_170, mul_171, mul_172, mul_173, rsqrt_24, squeeze_73, var_mean_24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_39 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[256, 4],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_39', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 50176.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0000199302441455
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/gy/cgymgnrj3tfg27pe2boa65pqlhfayu2kpfom7wikofhs374czitr.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn1, getattr_l__self___layer3___0___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn1 => add_128, add_131, mul_168, mul_174, rsqrt_24, sub_24, var_mean_24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___relu => relu_22
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_40 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16777216], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_40', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 12845056
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 50176.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/xq/cxqnnwbjdfbyow24pjyrockslwp6y3dchkjvnhczimmr4ksbljd4.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn2 => var_mean_25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_41 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[32768, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_41', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 25088
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 256)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (256*r2) + (32768*x1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/zi/czi22uq5zn6yrb375yl4nexyscn4zxrq4g2kkfsimv3xqh2oybmj.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn2 => add_133, add_134, add_135, mul_176, mul_177, mul_178, mul_179, mul_180, rsqrt_25, squeeze_76, var_mean_25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_42 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[256, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_42', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 98
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x0 + (256*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = 12544.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tmp7 / tmp9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tmp10 + tmp11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tl.math.rsqrt(tmp12)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = 1.0000797257434426
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp10 * tmp14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp15 * tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tmp18 * tmp19
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp17 + tmp20
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp6 * tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp23 * tmp19
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp22 + tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp21, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp25, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/3t/c3trvyyuh6eimzic6oq7mladnphvqp3clnfhexqu3usmm4c4yeu3.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn2, getattr_l__self___layer3___0___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn2 => add_133, add_136, mul_175, mul_181, rsqrt_25, sub_25, var_mean_25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___relu_1 => relu_23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_43 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[4194304], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_43', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 3211264
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 12544.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/s4/cs4xxznfsew5v5f6lg2adxgynd6j6vucfcbnj7e7azxe75xm5el7.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn3 => var_mean_26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_44 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[131072, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_44', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 100352
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 1024
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 1024)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (1024*r2) + (131072*x1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/iq/ciqp5vxg4xtlbwpy7amttg6ibhss3xmmao6zvviftraqolpibkr4.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn3 => add_138, add_139, add_140, mul_183, mul_184, mul_185, mul_186, mul_187, rsqrt_26, squeeze_79, var_mean_26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_45 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[1024, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_45', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 1024
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 98
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (1024*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x0 + (1024*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x0 + (1024*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = 12544.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tmp7 / tmp9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tmp10 + tmp11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tl.math.rsqrt(tmp12)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = 1.0000797257434426
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp10 * tmp14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp15 * tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tmp18 * tmp19
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp17 + tmp20
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp6 * tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp23 * tmp19
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp22 + tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp21, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp25, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/co/ccobqdq4j6bmd2yz6rstu3tm3aiky4dxmunsmoafsgaxpruzmuzy.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn3, getattr_l__self___layer3___0___downsample_1, getattr_l__self___layer3___0___relu_2, iadd_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn3 => add_138, add_141, mul_182, mul_188, rsqrt_26, sub_26, var_mean_26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___downsample_1 => add_143, add_146, mul_189, mul_195, rsqrt_27, sub_27, var_mean_27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___relu_2 => relu_24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_7 => add_147
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_46 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16777216], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': ['in_out_ptr0'], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_46', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 12845056
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 1024
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 12544.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 - tmp15
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp17 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp18 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp16 * tmp20
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 * tmp22
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 + tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tmp13 + tmp25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = triton_helpers.maximum(0, tmp26)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(in_out_ptr0 + (x2), tmp27, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/ms/cmsqwbsjlxz6scczjzmuejphmlyjodywe33niaf3nhdy2t5zv37x.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___1___bn3, getattr_l__self___layer3___1___relu_2, iadd_8], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___1___bn3 => add_159, add_162, mul_210, mul_216, rsqrt_30, sub_30, var_mean_30
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___1___relu_2 => relu_27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_8 => add_163
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_47 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16777216], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_47', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 12845056
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 1024
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 12544.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp16, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/3s/c3seyg3cyqkb4wnzy5ni4h4lpuz4t7mtor4lpvxpvqht2y7oppku.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn1 => var_mean_43
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_48 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[65536, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_48', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 50176
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 512)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (512*r2) + (65536*x1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/t2/ct2tdddlqalkow3l4j5t7vq2lfymterxzrfvpwaglrwr7cf5wixm.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn1 => add_229, add_230, add_231, mul_302, mul_303, mul_304, mul_305, mul_306, rsqrt_43, squeeze_130, var_mean_43
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_49 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[512, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_49', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 98
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean_next, tmp6_m2_next, tmp6_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp6_mean, tmp6_m2, tmp6_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp3, tmp4, tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean = tl.where(rmask & xmask, tmp6_mean_next, tmp6_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_m2 = tl.where(rmask & xmask, tmp6_m2_next, tmp6_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_weight = tl.where(rmask & xmask, tmp6_weight_next, tmp6_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6_tmp, tmp7_tmp, tmp8_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6_mean, tmp6_m2, tmp6_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp6_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp7_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp8_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp6, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp7, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = 12544.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tmp7 / tmp9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tmp10 + tmp11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tl.math.rsqrt(tmp12)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = 1.0000797257434426
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp10 * tmp14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp15 * tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tmp18 * tmp19
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp17 + tmp20
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp6 * tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp23 * tmp19
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp22 + tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp21, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp25, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/q5/cq5wvzrvhjrindk777q4x4l3i645m2mcizezvaswl33kvwgh3tvy.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn1, getattr_l__self___layer4___0___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn1 => add_229, add_232, mul_301, mul_307, rsqrt_43, sub_43, var_mean_43
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___relu => relu_40
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_50 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8388608], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_50', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 6422528
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 12544.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/gv/cgvcig5niq46n4ck6rhxajmxtmjs4qdtkm2mqqnpejum3qb5qz2j.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn2 => var_mean_44
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_51 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[16384, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_51', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 12800
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 126
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 512)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = r2 + (126*x1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.full([1, 1], 3136, tl.int32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tmp0 < tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.load(in_ptr0 + (x0 + (512*(r2 % 7)) + (3584*(((r2 + (126*x1)) // 7) % 448))), rmask & tmp2 & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.where(tmp2, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = 0.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6 = tl.where(tmp2, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp7 = 1.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp8 = tl.where(tmp2, tmp7, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp9 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp10 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp11 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_mean_next, tmp12_m2_next, tmp12_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp12_mean, tmp12_m2, tmp12_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp9, tmp10, tmp11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_mean = tl.where(rmask & xmask, tmp12_mean_next, tmp12_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_m2 = tl.where(rmask & xmask, tmp12_m2_next, tmp12_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_weight = tl.where(rmask & xmask, tmp12_weight_next, tmp12_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12_tmp, tmp13_tmp, tmp14_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_mean, tmp12_m2, tmp12_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tmp12_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp13_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp14_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp12, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/3o/c3oz3tygxoewt4na7cessxj4zg6kr6vzwlkbyww5omql5scy4mug.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn2 => add_234, add_235, add_236, mul_309, mul_310, mul_311, mul_312, mul_313, rsqrt_44, squeeze_133, var_mean_44
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_52 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[512, 32],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_52', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (512*r1)), rmask & xmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 3136.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0003189792663476
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/m5/cm5f2j4sauuhzndjlhgj26wtcejyxqyq3qvsodx27buviowqf5i4.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn2, getattr_l__self___layer4___0___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn2 => add_234, add_237, mul_308, mul_314, rsqrt_44, sub_44, var_mean_44
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___relu_1 => relu_41
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_53 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[2097152], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_53', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 1605632
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 3136.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/2w/c2wyy3vnzp27erlvur3dp3ajqp7siimwlnezvqkyqqjobuayumqf.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn3 => var_mean_45
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_54 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[65536, 128],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_54', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 51200
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 126
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 2048)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 2048
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = r2 + (126*x1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.full([1, 1], 3136, tl.int32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2 = tmp0 < tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp3 = tl.load(in_ptr0 + (x0 + (2048*(r2 % 7)) + (14336*(((r2 + (126*x1)) // 7) % 448))), rmask & tmp2, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp4 = tl.where(tmp2, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp5 = 0.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp6 = tl.where(tmp2, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp7 = 1.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp8 = tl.where(tmp2, tmp7, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp9 = tl.broadcast_to(tmp4, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp10 = tl.broadcast_to(tmp6, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp11 = tl.broadcast_to(tmp8, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_mean_next, tmp12_m2_next, tmp12_weight_next = triton_helpers.welford_combine(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp12_mean, tmp12_m2, tmp12_weight,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]             tmp9, tmp10, tmp11
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_mean = tl.where(rmask, tmp12_mean_next, tmp12_mean)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_m2 = tl.where(rmask, tmp12_m2_next, tmp12_m2)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_weight = tl.where(rmask, tmp12_weight_next, tmp12_weight)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12_tmp, tmp13_tmp, tmp14_tmp = triton_helpers.welford(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         tmp12_mean, tmp12_m2, tmp12_weight, 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tmp12_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp13_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp14_tmp[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp12, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp13, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/sb/csbmyyejlp5gelisc3a2ketduk6yykhmig26xi6egfuebnnqejus.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn3 => add_239, add_240, add_241, mul_316, mul_317, mul_318, mul_319, mul_320, rsqrt_45, squeeze_136, var_mean_45
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_55 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[2048, 32],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_55', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 2048
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 32
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (2048*r1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (2048*r1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (2048*r1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask, tmp3, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask, tmp4, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask, tmp5, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 3136.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0003189792663476
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/3c/c3cpwm2ki5ejmkydor2kgxxedabjzf6rbrt4u5v56rqkwbldpghs.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn3, getattr_l__self___layer4___0___downsample_1, getattr_l__self___layer4___0___relu_2, iadd_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn3 => add_239, add_242, mul_315, mul_321, rsqrt_45, sub_45, var_mean_45
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___downsample_1 => add_244, add_247, mul_322, mul_328, rsqrt_46, sub_46, var_mean_46
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___relu_2 => relu_42
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_13 => add_248
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_56 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8388608], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': ['in_out_ptr0'], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_56', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 6422528
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 2048
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 3136.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 - tmp15
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp17 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp18 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp16 * tmp20
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 * tmp22
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 + tmp24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tmp13 + tmp25
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = triton_helpers.maximum(0, tmp26)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(in_out_ptr0 + (x2), tmp27, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/mc/cmcy6d4gkagwwr2ovihvnddlpd7ybttecsaher7nnkjsp4hggm2g.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___1___bn3, getattr_l__self___layer4___1___relu_2, iadd_14], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___1___bn3 => add_260, add_263, mul_343, mul_349, rsqrt_49, sub_49, var_mean_49
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___1___relu_2 => relu_45
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_14 => add_264
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_57 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8388608], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_57', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 6422528
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 2048
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 3136.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp16, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/ea/ceawx5jbvcfi5xkxeokqv3y7xwf3jsou4n2huy7icsxygkc5qsyw.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___2___bn3, getattr_l__self___layer4___2___relu_2, iadd_15], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu, aten.threshold_backward]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___2___bn3 => add_276, add_279, mul_364, mul_370, rsqrt_52, sub_52, var_mean_52
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___2___relu_2 => relu_48
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_15 => add_280
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_58 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8388608], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i1', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_58', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 6422528
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 2048
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 3136.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = 0.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp16 <= tmp17
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp16, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x2), tmp18, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/7x/c7x5k2uvux5y4tu3bxrzxzgvazucv2ytdtdxhtkh4ud2pqkmfzsd.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [flatten, l__self___avgpool], Original ATen: [aten.mean, aten.view]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # flatten => view
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___avgpool => mean
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused_mean_view_59 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[131072, 64],
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.DEFAULT,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': ['in_out_ptr0'], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused_mean_view_59', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]}
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_out_ptr0, in_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 131072
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 49
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 64
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     r2 = rindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 2048
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 2048)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (2048*r2) + (100352*x1)), rmask, other=0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.where(rmask, tmp1, 0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.sum(tmp3, 1)[:, None]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = 49.0
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tmp4 / tmp5
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.debug_barrier()
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(in_out_ptr0 + (x3), tmp6, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_fjr38/qd/cqdebqvltjn6alpvw4crxngcj7gujyxcwz2z4stpvthwgwrwc4z4.py
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => add
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_add_60 = async_compile.triton('triton_', '''
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[1], filename=__file__, meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_60', 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]})
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (0))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK])
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.full([1], 1, tl.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp1 + tmp2
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] ''')
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] async_compile.wait(globals())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] del async_compile
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def call(args):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321 = args
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     args.clear()
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_1, (64, 3, 7, 7), (147, 49, 7, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_2, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_3, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_4, (64, 64, 1, 1), (64, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_5, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_6, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_7, (64, 64, 3, 3), (576, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_8, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_9, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_10, (256, 64, 1, 1), (64, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_11, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_12, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_13, (256, 64, 1, 1), (64, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_14, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_15, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_16, (64, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_17, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_18, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_19, (64, 64, 3, 3), (576, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_20, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_21, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_22, (256, 64, 1, 1), (64, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_23, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_24, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_25, (64, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_26, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_27, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_28, (64, 64, 3, 3), (576, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_29, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_30, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_31, (256, 64, 1, 1), (64, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_32, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_33, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_34, (128, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_35, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_36, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_37, (128, 128, 3, 3), (1152, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_38, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_39, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_40, (512, 128, 1, 1), (128, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_41, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_42, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_43, (512, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_44, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_45, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_46, (128, 512, 1, 1), (512, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_47, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_48, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_49, (128, 128, 3, 3), (1152, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_50, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_51, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_52, (512, 128, 1, 1), (128, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_53, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_54, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_55, (128, 512, 1, 1), (512, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_56, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_57, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_58, (128, 128, 3, 3), (1152, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_59, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_60, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_61, (512, 128, 1, 1), (128, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_62, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_63, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_64, (128, 512, 1, 1), (512, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_65, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_66, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_67, (128, 128, 3, 3), (1152, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_68, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_69, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_70, (512, 128, 1, 1), (128, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_71, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_72, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_73, (256, 512, 1, 1), (512, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_74, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_75, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_76, (256, 256, 3, 3), (2304, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_77, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_78, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_79, (1024, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_80, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_81, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_82, (1024, 512, 1, 1), (512, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_83, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_84, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_85, (256, 1024, 1, 1), (1024, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_86, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_87, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_88, (256, 256, 3, 3), (2304, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_89, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_90, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_91, (1024, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_92, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_93, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_94, (256, 1024, 1, 1), (1024, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_95, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_96, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_97, (256, 256, 3, 3), (2304, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_98, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_99, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_100, (1024, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_101, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_102, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_103, (256, 1024, 1, 1), (1024, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_104, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_105, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_106, (256, 256, 3, 3), (2304, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_107, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_108, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_109, (1024, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_110, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_111, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_112, (256, 1024, 1, 1), (1024, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_113, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_114, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_115, (256, 256, 3, 3), (2304, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_116, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_117, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_118, (1024, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_119, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_120, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_121, (256, 1024, 1, 1), (1024, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_122, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_123, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_124, (256, 256, 3, 3), (2304, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_125, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_126, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_127, (1024, 256, 1, 1), (256, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_128, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_129, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_130, (512, 1024, 1, 1), (1024, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_131, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_132, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_133, (512, 512, 3, 3), (4608, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_134, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_135, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_136, (2048, 512, 1, 1), (512, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_137, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_138, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_139, (2048, 1024, 1, 1), (1024, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_140, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_141, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_142, (512, 2048, 1, 1), (2048, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_143, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_144, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_145, (512, 512, 3, 3), (4608, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_146, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_147, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_148, (2048, 512, 1, 1), (512, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_149, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_150, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_151, (512, 2048, 1, 1), (2048, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_152, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_153, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_154, (512, 512, 3, 3), (4608, 9, 3, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_155, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_156, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_157, (2048, 512, 1, 1), (512, 1, 1, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_158, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_159, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_160, (1000, 2048), (2048, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_161, (1000, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_162, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_163, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_164, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_165, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_166, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_167, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_168, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_169, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_170, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_171, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_172, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_173, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_174, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_175, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_176, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_177, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_178, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_179, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_180, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_181, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_182, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_183, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_184, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_185, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_186, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_187, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_188, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_189, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_190, (64, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_191, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_192, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_193, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_194, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_195, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_196, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_197, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_198, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_199, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_200, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_201, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_202, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_203, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_204, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_205, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_206, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_207, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_208, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_209, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_210, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_211, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_212, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_213, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_214, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_215, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_216, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_217, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_218, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_219, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_220, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_221, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_222, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_223, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_224, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_225, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_226, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_227, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_228, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_229, (128, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_230, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_231, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_232, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_233, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_234, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_235, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_236, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_237, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_238, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_239, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_240, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_241, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_242, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_243, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_244, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_245, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_246, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_247, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_248, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_249, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_250, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_251, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_252, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_253, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_254, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_255, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_256, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_257, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_258, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_259, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_260, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_261, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_262, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_263, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_264, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_265, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_266, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_267, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_268, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_269, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_270, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_271, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_272, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_273, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_274, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_275, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_276, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_277, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_278, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_279, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_280, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_281, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_282, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_283, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_284, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_285, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_286, (256, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_287, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_288, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_289, (1024, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_290, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_291, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_292, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_293, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_294, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_295, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_296, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_297, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_298, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_299, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_300, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_301, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_302, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_303, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_304, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_305, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_306, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_307, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_308, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_309, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_310, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_311, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_312, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_313, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_314, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_315, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_316, (512, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_317, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_318, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_319, (2048, ), (1, ))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_320, (), ())
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_321, (64, 3, 224, 224), (150528, 50176, 224, 1))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     with torch.cuda._DeviceGuard(0):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         torch.cuda.set_device(0) # no-op to ensure context
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf0 = empty_strided((64, 3, 7, 7), (147, 1, 21, 3), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         stream0 = get_cuda_stream(0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_0.run(primals_1, buf0, 192, 49, grid=grid(192, 49), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_1
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf1 = empty_strided((64, 64, 3, 3), (576, 1, 192, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_1.run(primals_7, buf1, 4096, 9, grid=grid(4096, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_7
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf2 = empty_strided((64, 64, 3, 3), (576, 1, 192, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_1.run(primals_19, buf2, 4096, 9, grid=grid(4096, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_19
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf3 = empty_strided((64, 64, 3, 3), (576, 1, 192, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_1.run(primals_28, buf3, 4096, 9, grid=grid(4096, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_28
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf4 = empty_strided((128, 128, 3, 3), (1152, 1, 384, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_2.run(primals_37, buf4, 16384, 9, grid=grid(16384, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_37
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf5 = empty_strided((128, 128, 3, 3), (1152, 1, 384, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_2.run(primals_49, buf5, 16384, 9, grid=grid(16384, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_49
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf6 = empty_strided((128, 128, 3, 3), (1152, 1, 384, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_2.run(primals_58, buf6, 16384, 9, grid=grid(16384, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_58
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf7 = empty_strided((128, 128, 3, 3), (1152, 1, 384, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_2.run(primals_67, buf7, 16384, 9, grid=grid(16384, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_67
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf8 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_76, buf8, 65536, 9, grid=grid(65536, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_76
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf9 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_88, buf9, 65536, 9, grid=grid(65536, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_88
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf10 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_97, buf10, 65536, 9, grid=grid(65536, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_97
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf11 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_106, buf11, 65536, 9, grid=grid(65536, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_106
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf12 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_115, buf12, 65536, 9, grid=grid(65536, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_115
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf13 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_124, buf13, 65536, 9, grid=grid(65536, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_124
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf14 = empty_strided((512, 512, 3, 3), (4608, 1, 1536, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_4.run(primals_133, buf14, 262144, 9, grid=grid(262144, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_133
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf15 = empty_strided((512, 512, 3, 3), (4608, 1, 1536, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_4.run(primals_145, buf15, 262144, 9, grid=grid(262144, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_145
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf16 = empty_strided((512, 512, 3, 3), (4608, 1, 1536, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_4.run(primals_154, buf16, 262144, 9, grid=grid(262144, 9), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_154
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf17 = empty_strided((64, 3, 224, 224), (150528, 1, 672, 3), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_5.run(primals_321, buf17, 192, 50176, grid=grid(192, 50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_321
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf18 = extern_kernels.convolution(buf17, buf0, stride=(2, 2), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf18, (64, 64, 112, 112), (802816, 1, 7168, 64))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf19 = empty_strided((1, 64, 1, 1, 896), (57344, 1, 57344, 57344, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf20 = empty_strided((1, 64, 1, 1, 896), (57344, 1, 57344, 57344, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf21 = empty_strided((1, 64, 1, 1, 896), (57344, 1, 57344, 57344, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_6.run(buf18, buf19, buf20, buf21, 57344, 896, grid=grid(57344), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf22 = empty_strided((1, 64, 1, 1, 7), (448, 1, 448, 448, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf23 = empty_strided((1, 64, 1, 1, 7), (448, 1, 448, 448, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf24 = empty_strided((1, 64, 1, 1, 7), (448, 1, 448, 448, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_7.run(buf19, buf20, buf21, buf22, buf23, buf24, 448, 128, grid=grid(448), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf25 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf26 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf28 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf30 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf29 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_8.run(buf22, buf23, buf24, primals_163, primals_162, buf25, buf26, buf28, buf30, buf29, 64, 7, grid=grid(64), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_162
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_163
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf31 = empty_strided((64, 64, 112, 112), (802816, 1, 7168, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___bn1, l__self___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_9.run(buf18, buf25, buf26, primals_2, primals_3, buf31, 51380224, grid=grid(51380224), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_3
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf32 = empty_strided((64, 64, 56, 56), (200704, 1, 3584, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf33 = empty_strided((64, 64, 56, 56), (200704, 1, 3584, 64), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___maxpool], Original ATen: [aten.max_pool2d_with_indices]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_max_pool2d_with_indices_10.run(buf31, buf32, buf33, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf34 = empty_strided((200704, 64), (64, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_11.run(buf32, primals_4, buf34, grid=torch._inductor.kernel.mm_common.mm_grid(200704, 64, meta0), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf35 = buf21; del buf21  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf36 = buf20; del buf20  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf37 = buf19; del buf19  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf34, buf35, buf36, buf37, 57344, 224, grid=grid(57344), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf38 = buf24; del buf24  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf39 = buf23; del buf23  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf40 = buf22; del buf22  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_7.run(buf35, buf36, buf37, buf38, buf39, buf40, 448, 128, grid=grid(448), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf41 = buf26; del buf26  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf42 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf44 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf46 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf45 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf38, buf39, buf40, primals_166, primals_165, buf41, buf42, buf44, buf46, buf45, 64, 7, grid=grid(64), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_165
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_166
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf47 = empty_strided((64, 64, 56, 56), (200704, 1, 3584, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn1, getattr_l__self___layer1___0___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_14.run(buf34, buf41, buf42, primals_5, primals_6, buf47, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_6
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf48 = extern_kernels.convolution(buf47, buf1, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf48, (64, 64, 56, 56), (200704, 1, 3584, 64))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf49 = buf37; del buf37  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf50 = buf36; del buf36  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf51 = buf35; del buf35  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf48, buf49, buf50, buf51, 57344, 224, grid=grid(57344), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf52 = buf40; del buf40  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf53 = buf39; del buf39  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf54 = buf38; del buf38  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_7.run(buf49, buf50, buf51, buf52, buf53, buf54, 448, 128, grid=grid(448), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf55 = buf42; del buf42  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf56 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf58 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf60 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf59 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf52, buf53, buf54, primals_169, primals_168, buf55, buf56, buf58, buf60, buf59, 64, 7, grid=grid(64), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_168
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_169
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf61 = empty_strided((64, 64, 56, 56), (200704, 1, 3584, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn2, getattr_l__self___layer1___0___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_14.run(buf48, buf55, buf56, primals_8, primals_9, buf61, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_9
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf62 = empty_strided((200704, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_15.run(buf61, primals_10, buf62, grid=torch._inductor.kernel.mm_common.mm_grid(200704, 256, meta1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf63 = empty_strided((1, 256, 1, 1, 448), (114688, 1, 114688, 114688, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf64 = empty_strided((1, 256, 1, 1, 448), (114688, 1, 114688, 114688, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf65 = empty_strided((1, 256, 1, 1, 448), (114688, 1, 114688, 114688, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_16.run(buf62, buf63, buf64, buf65, 114688, 448, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf66 = empty_strided((1, 256, 1, 1, 4), (1024, 1, 1024, 1024, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf67 = empty_strided((1, 256, 1, 1, 4), (1024, 1, 1024, 1024, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf68 = empty_strided((1, 256, 1, 1, 4), (1024, 1, 1024, 1024, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_17.run(buf63, buf64, buf65, buf66, buf67, buf68, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf69 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf70 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf72 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf74 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf73 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_18.run(buf66, buf67, buf68, primals_172, primals_171, buf69, buf70, buf72, buf74, buf73, 256, 4, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_171
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_172
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf75 = empty_strided((200704, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___downsample_0], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_15.run(buf32, primals_13, buf75, grid=torch._inductor.kernel.mm_common.mm_grid(200704, 256, meta1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf76 = buf65; del buf65  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf77 = buf64; del buf64  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf78 = buf63; del buf63  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_16.run(buf75, buf76, buf77, buf78, 114688, 448, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf79 = buf68; del buf68  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf80 = buf67; del buf67  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf81 = buf66; del buf66  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_17.run(buf76, buf77, buf78, buf79, buf80, buf81, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf82 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf83 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf85 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf87 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf86 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_18.run(buf79, buf80, buf81, primals_175, primals_174, buf82, buf83, buf85, buf87, buf86, 256, 4, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_174
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_175
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf88 = empty_strided((64, 256, 56, 56), (802816, 1, 14336, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf89 = buf88; del buf88  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn3, getattr_l__self___layer1___0___downsample_1, getattr_l__self___layer1___0___relu_2, iadd], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_19.run(buf89, buf62, buf69, buf70, primals_11, primals_12, buf75, buf82, buf83, primals_14, primals_15, 51380224, grid=grid(51380224), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_12
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_15
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf90 = empty_strided((200704, 64), (64, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_20.run(buf89, primals_16, buf90, grid=torch._inductor.kernel.mm_common.mm_grid(200704, 64, meta2), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf91 = buf51; del buf51  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf92 = buf50; del buf50  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf93 = buf49; del buf49  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf90, buf91, buf92, buf93, 57344, 224, grid=grid(57344), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf94 = buf54; del buf54  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf95 = buf53; del buf53  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf96 = buf52; del buf52  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_7.run(buf91, buf92, buf93, buf94, buf95, buf96, 448, 128, grid=grid(448), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf97 = buf56; del buf56  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf98 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf100 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf102 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf101 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf94, buf95, buf96, primals_178, primals_177, buf97, buf98, buf100, buf102, buf101, 64, 7, grid=grid(64), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_177
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_178
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf103 = empty_strided((64, 64, 56, 56), (200704, 1, 3584, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn1, getattr_l__self___layer1___1___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_14.run(buf90, buf97, buf98, primals_17, primals_18, buf103, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_18
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf104 = extern_kernels.convolution(buf103, buf2, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf104, (64, 64, 56, 56), (200704, 1, 3584, 64))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf105 = buf93; del buf93  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf106 = buf92; del buf92  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf107 = buf91; del buf91  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf104, buf105, buf106, buf107, 57344, 224, grid=grid(57344), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf108 = buf96; del buf96  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf109 = buf95; del buf95  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf110 = buf94; del buf94  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_7.run(buf105, buf106, buf107, buf108, buf109, buf110, 448, 128, grid=grid(448), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf111 = buf98; del buf98  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf112 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf114 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf116 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf115 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf108, buf109, buf110, primals_181, primals_180, buf111, buf112, buf114, buf116, buf115, 64, 7, grid=grid(64), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_180
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_181
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf117 = empty_strided((64, 64, 56, 56), (200704, 1, 3584, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn2, getattr_l__self___layer1___1___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_14.run(buf104, buf111, buf112, primals_20, primals_21, buf117, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_21
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf118 = empty_strided((200704, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_15.run(buf117, primals_22, buf118, grid=torch._inductor.kernel.mm_common.mm_grid(200704, 256, meta1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf119 = buf78; del buf78  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf120 = buf77; del buf77  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf121 = buf76; del buf76  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_16.run(buf118, buf119, buf120, buf121, 114688, 448, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf122 = buf81; del buf81  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf123 = buf80; del buf80  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf124 = buf79; del buf79  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_17.run(buf119, buf120, buf121, buf122, buf123, buf124, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf125 = buf83; del buf83  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf126 = buf70; del buf70  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf128 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf130 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf129 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_18.run(buf122, buf123, buf124, primals_184, primals_183, buf125, buf126, buf128, buf130, buf129, 256, 4, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_183
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_184
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf131 = empty_strided((64, 256, 56, 56), (802816, 1, 14336, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn3, getattr_l__self___layer1___1___relu_2, iadd_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf118, buf125, buf126, primals_23, primals_24, buf89, buf131, 51380224, grid=grid(51380224), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_24
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf132 = empty_strided((200704, 64), (64, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_20.run(buf131, primals_25, buf132, grid=torch._inductor.kernel.mm_common.mm_grid(200704, 64, meta2), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf133 = buf107; del buf107  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf134 = buf106; del buf106  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf135 = buf105; del buf105  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf132, buf133, buf134, buf135, 57344, 224, grid=grid(57344), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf136 = buf110; del buf110  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf137 = buf109; del buf109  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf138 = buf108; del buf108  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_7.run(buf133, buf134, buf135, buf136, buf137, buf138, 448, 128, grid=grid(448), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf139 = buf112; del buf112  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf140 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf142 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf144 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf143 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf136, buf137, buf138, primals_187, primals_186, buf139, buf140, buf142, buf144, buf143, 64, 7, grid=grid(64), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_186
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_187
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf145 = empty_strided((64, 64, 56, 56), (200704, 1, 3584, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn1, getattr_l__self___layer1___2___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_14.run(buf132, buf139, buf140, primals_26, primals_27, buf145, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_27
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf146 = extern_kernels.convolution(buf145, buf3, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf146, (64, 64, 56, 56), (200704, 1, 3584, 64))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf147 = buf135; del buf135  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf148 = buf134; del buf134  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf149 = buf133; del buf133  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf146, buf147, buf148, buf149, 57344, 224, grid=grid(57344), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf150 = buf138; del buf138  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf151 = buf137; del buf137  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf152 = buf136; del buf136  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_7.run(buf147, buf148, buf149, buf150, buf151, buf152, 448, 128, grid=grid(448), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf147
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf148
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf149
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf153 = buf140; del buf140  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf154 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf156 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf158 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf157 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf150, buf151, buf152, primals_190, primals_189, buf153, buf154, buf156, buf158, buf157, 64, 7, grid=grid(64), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf150
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf151
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf152
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_189
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_190
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf159 = empty_strided((64, 64, 56, 56), (200704, 1, 3584, 64), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn2, getattr_l__self___layer1___2___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_14.run(buf146, buf153, buf154, primals_29, primals_30, buf159, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf154
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_30
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf160 = empty_strided((200704, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_15.run(buf159, primals_31, buf160, grid=torch._inductor.kernel.mm_common.mm_grid(200704, 256, meta1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf161 = buf121; del buf121  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf162 = buf120; del buf120  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf163 = buf119; del buf119  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_16.run(buf160, buf161, buf162, buf163, 114688, 448, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf164 = buf124; del buf124  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf165 = buf123; del buf123  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf166 = buf122; del buf122  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_17.run(buf161, buf162, buf163, buf164, buf165, buf166, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf167 = buf126; del buf126  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf168 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf170 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf172 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf171 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_18.run(buf164, buf165, buf166, primals_193, primals_192, buf167, buf168, buf170, buf172, buf171, 256, 4, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_192
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_193
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf173 = empty_strided((64, 256, 56, 56), (802816, 1, 14336, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn3, getattr_l__self___layer1___2___relu_2, iadd_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_21.run(buf160, buf167, buf168, primals_32, primals_33, buf131, buf173, 51380224, grid=grid(51380224), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_33
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf174 = empty_strided((200704, 128), (128, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf173, (200704, 256), (256, 1), 0), reinterpret_tensor(primals_34, (256, 128), (1, 256), 0), out=buf174)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf175 = reinterpret_tensor(buf163, (1, 128, 1, 1, 896), (114688, 1, 114688, 114688, 128)); del buf163  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf176 = reinterpret_tensor(buf162, (1, 128, 1, 1, 896), (114688, 1, 114688, 114688, 128)); del buf162  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf177 = reinterpret_tensor(buf161, (1, 128, 1, 1, 896), (114688, 1, 114688, 114688, 128)); del buf161  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_22.run(buf174, buf175, buf176, buf177, 114688, 224, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf178 = empty_strided((1, 128, 1, 1, 7), (896, 1, 896, 896, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf179 = empty_strided((1, 128, 1, 1, 7), (896, 1, 896, 896, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf180 = empty_strided((1, 128, 1, 1, 7), (896, 1, 896, 896, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_23.run(buf175, buf176, buf177, buf178, buf179, buf180, 896, 128, grid=grid(896), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf181 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf182 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf184 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf186 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf185 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_24.run(buf178, buf179, buf180, primals_196, primals_195, buf181, buf182, buf184, buf186, buf185, 128, 7, grid=grid(128), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf178
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf179
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf180
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_195
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_196
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf187 = empty_strided((64, 128, 56, 56), (401408, 1, 7168, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn1, getattr_l__self___layer2___0___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_25.run(buf174, buf181, buf182, primals_35, primals_36, buf187, 25690112, grid=grid(25690112), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_36
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf188 = extern_kernels.convolution(buf187, buf4, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf188, (64, 128, 28, 28), (100352, 1, 3584, 128))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf189 = empty_strided((1, 128, 1, 1, 392), (50176, 1, 50176, 50176, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf190 = empty_strided((1, 128, 1, 1, 392), (50176, 1, 50176, 50176, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf191 = empty_strided((1, 128, 1, 1, 392), (50176, 1, 50176, 50176, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_26.run(buf188, buf189, buf190, buf191, 50176, 128, grid=grid(50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf192 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf193 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf194 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_27.run(buf189, buf190, buf191, buf192, buf193, buf194, 512, 98, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf195 = buf182; del buf182  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf196 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf198 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf200 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf199 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_28.run(buf192, buf193, buf194, primals_199, primals_198, buf195, buf196, buf198, buf200, buf199, 128, 4, grid=grid(128), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_198
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_199
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf201 = empty_strided((64, 128, 28, 28), (100352, 1, 3584, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn2, getattr_l__self___layer2___0___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_29.run(buf188, buf195, buf196, primals_38, primals_39, buf201, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_39
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf202 = empty_strided((50176, 512), (512, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf201, (50176, 128), (128, 1), 0), reinterpret_tensor(primals_40, (128, 512), (1, 128), 0), out=buf202)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf203 = reinterpret_tensor(buf177, (1, 512, 1, 1, 224), (114688, 1, 114688, 114688, 512)); del buf177  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf204 = reinterpret_tensor(buf176, (1, 512, 1, 1, 224), (114688, 1, 114688, 114688, 512)); del buf176  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf205 = reinterpret_tensor(buf175, (1, 512, 1, 1, 224), (114688, 1, 114688, 114688, 512)); del buf175  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_30.run(buf202, buf203, buf204, buf205, 114688, 224, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf206 = reinterpret_tensor(buf166, (1, 512, 1, 1, 2), (1024, 1, 1024, 1024, 512)); del buf166  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf207 = reinterpret_tensor(buf165, (1, 512, 1, 1, 2), (1024, 1, 1024, 1024, 512)); del buf165  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf208 = reinterpret_tensor(buf164, (1, 512, 1, 1, 2), (1024, 1, 1024, 1024, 512)); del buf164  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_31.run(buf203, buf204, buf205, buf206, buf207, buf208, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf209 = reinterpret_tensor(buf194, (1, 512, 1, 1), (512, 1, 512, 512)); del buf194  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf210 = reinterpret_tensor(buf193, (1, 512, 1, 1), (512, 1, 512, 512)); del buf193  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf212 = reinterpret_tensor(buf192, (512, ), (1, )); del buf192  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf214 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf213 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_32.run(buf206, buf207, buf208, primals_202, primals_201, buf209, buf210, buf212, buf214, buf213, 512, 2, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_201
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_202
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf215 = empty_strided((64, 512, 28, 28), (401408, 1, 14336, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___downsample_0], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_33.run(buf173, primals_43, buf215, grid=torch._inductor.kernel.conv.conv_grid(64, 512, 28, 28, meta3), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf216 = buf205; del buf205  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf217 = buf204; del buf204  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf218 = buf203; del buf203  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_30.run(buf215, buf216, buf217, buf218, 114688, 224, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf219 = buf208; del buf208  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf220 = buf207; del buf207  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf221 = buf206; del buf206  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_31.run(buf216, buf217, buf218, buf219, buf220, buf221, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf222 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf223 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf225 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf227 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf226 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_32.run(buf219, buf220, buf221, primals_205, primals_204, buf222, buf223, buf225, buf227, buf226, 512, 2, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_204
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_205
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf228 = empty_strided((64, 512, 28, 28), (401408, 1, 14336, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf229 = buf228; del buf228  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn3, getattr_l__self___layer2___0___downsample_1, getattr_l__self___layer2___0___relu_2, iadd_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_34.run(buf229, buf202, buf209, buf210, primals_41, primals_42, buf215, buf222, buf223, primals_44, primals_45, 25690112, grid=grid(25690112), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_42
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_45
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf230 = empty_strided((50176, 128), (128, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_35.run(buf229, primals_46, buf230, grid=torch._inductor.kernel.mm_common.mm_grid(50176, 128, meta1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf231 = buf191; del buf191  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf232 = buf190; del buf190  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf233 = buf189; del buf189  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_26.run(buf230, buf231, buf232, buf233, 50176, 128, grid=grid(50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf234 = reinterpret_tensor(buf223, (1, 128, 1, 1, 4), (512, 1, 512, 512, 128)); del buf223  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf235 = reinterpret_tensor(buf210, (1, 128, 1, 1, 4), (512, 1, 512, 512, 128)); del buf210  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf236 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_27.run(buf231, buf232, buf233, buf234, buf235, buf236, 512, 98, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf237 = buf196; del buf196  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf238 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf240 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf242 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf241 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_28.run(buf234, buf235, buf236, primals_208, primals_207, buf237, buf238, buf240, buf242, buf241, 128, 4, grid=grid(128), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_207
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_208
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf243 = empty_strided((64, 128, 28, 28), (100352, 1, 3584, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn1, getattr_l__self___layer2___1___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_29.run(buf230, buf237, buf238, primals_47, primals_48, buf243, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_48
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf244 = extern_kernels.convolution(buf243, buf5, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf244, (64, 128, 28, 28), (100352, 1, 3584, 128))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf245 = buf233; del buf233  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf246 = buf232; del buf232  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf247 = buf231; del buf231  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_26.run(buf244, buf245, buf246, buf247, 50176, 128, grid=grid(50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf248 = buf236; del buf236  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf249 = buf235; del buf235  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf250 = buf234; del buf234  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_27.run(buf245, buf246, buf247, buf248, buf249, buf250, 512, 98, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf251 = buf238; del buf238  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf252 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf254 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf256 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf255 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_28.run(buf248, buf249, buf250, primals_211, primals_210, buf251, buf252, buf254, buf256, buf255, 128, 4, grid=grid(128), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_210
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_211
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf257 = empty_strided((64, 128, 28, 28), (100352, 1, 3584, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn2, getattr_l__self___layer2___1___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_29.run(buf244, buf251, buf252, primals_50, primals_51, buf257, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_51
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf258 = empty_strided((50176, 512), (512, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf257, (50176, 128), (128, 1), 0), reinterpret_tensor(primals_52, (128, 512), (1, 128), 0), out=buf258)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf259 = buf218; del buf218  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf260 = buf217; del buf217  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf261 = buf216; del buf216  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_30.run(buf258, buf259, buf260, buf261, 114688, 224, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf262 = buf221; del buf221  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf263 = buf220; del buf220  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf264 = buf219; del buf219  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_31.run(buf259, buf260, buf261, buf262, buf263, buf264, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf265 = reinterpret_tensor(buf250, (1, 512, 1, 1), (512, 1, 512, 512)); del buf250  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf266 = reinterpret_tensor(buf249, (1, 512, 1, 1), (512, 1, 512, 512)); del buf249  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf268 = reinterpret_tensor(buf248, (512, ), (1, )); del buf248  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf270 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf269 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_32.run(buf262, buf263, buf264, primals_214, primals_213, buf265, buf266, buf268, buf270, buf269, 512, 2, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_213
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_214
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf271 = empty_strided((64, 512, 28, 28), (401408, 1, 14336, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn3, getattr_l__self___layer2___1___relu_2, iadd_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_36.run(buf258, buf265, buf266, primals_53, primals_54, buf229, buf271, 25690112, grid=grid(25690112), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_54
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf272 = empty_strided((50176, 128), (128, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_35.run(buf271, primals_55, buf272, grid=torch._inductor.kernel.mm_common.mm_grid(50176, 128, meta1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf273 = buf247; del buf247  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf274 = buf246; del buf246  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf275 = buf245; del buf245  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_26.run(buf272, buf273, buf274, buf275, 50176, 128, grid=grid(50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf276 = reinterpret_tensor(buf266, (1, 128, 1, 1, 4), (512, 1, 512, 512, 128)); del buf266  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf277 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf278 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_27.run(buf273, buf274, buf275, buf276, buf277, buf278, 512, 98, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf279 = buf252; del buf252  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf280 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf282 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf284 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf283 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_28.run(buf276, buf277, buf278, primals_217, primals_216, buf279, buf280, buf282, buf284, buf283, 128, 4, grid=grid(128), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_216
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_217
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf285 = empty_strided((64, 128, 28, 28), (100352, 1, 3584, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn1, getattr_l__self___layer2___2___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_29.run(buf272, buf279, buf280, primals_56, primals_57, buf285, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_57
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf286 = extern_kernels.convolution(buf285, buf6, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf286, (64, 128, 28, 28), (100352, 1, 3584, 128))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf287 = buf275; del buf275  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf288 = buf274; del buf274  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf289 = buf273; del buf273  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_26.run(buf286, buf287, buf288, buf289, 50176, 128, grid=grid(50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf290 = buf278; del buf278  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf291 = buf277; del buf277  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf292 = buf276; del buf276  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_27.run(buf287, buf288, buf289, buf290, buf291, buf292, 512, 98, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf293 = buf280; del buf280  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf294 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf296 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf298 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf297 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_28.run(buf290, buf291, buf292, primals_220, primals_219, buf293, buf294, buf296, buf298, buf297, 128, 4, grid=grid(128), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_219
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_220
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf299 = empty_strided((64, 128, 28, 28), (100352, 1, 3584, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn2, getattr_l__self___layer2___2___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_29.run(buf286, buf293, buf294, primals_59, primals_60, buf299, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_60
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf300 = empty_strided((50176, 512), (512, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf299, (50176, 128), (128, 1), 0), reinterpret_tensor(primals_61, (128, 512), (1, 128), 0), out=buf300)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf301 = buf261; del buf261  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf302 = buf260; del buf260  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf303 = buf259; del buf259  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_30.run(buf300, buf301, buf302, buf303, 114688, 224, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf304 = buf264; del buf264  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf305 = buf263; del buf263  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf306 = buf262; del buf262  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_31.run(buf301, buf302, buf303, buf304, buf305, buf306, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf307 = reinterpret_tensor(buf292, (1, 512, 1, 1), (512, 1, 512, 512)); del buf292  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf308 = reinterpret_tensor(buf291, (1, 512, 1, 1), (512, 1, 512, 512)); del buf291  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf310 = reinterpret_tensor(buf290, (512, ), (1, )); del buf290  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf312 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf311 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_32.run(buf304, buf305, buf306, primals_223, primals_222, buf307, buf308, buf310, buf312, buf311, 512, 2, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_222
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_223
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf313 = empty_strided((64, 512, 28, 28), (401408, 1, 14336, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn3, getattr_l__self___layer2___2___relu_2, iadd_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_36.run(buf300, buf307, buf308, primals_62, primals_63, buf271, buf313, 25690112, grid=grid(25690112), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_63
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf314 = empty_strided((50176, 128), (128, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_unk_fused_convolution_35.run(buf313, primals_64, buf314, grid=torch._inductor.kernel.mm_common.mm_grid(50176, 128, meta1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf315 = buf289; del buf289  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf316 = buf288; del buf288  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf317 = buf287; del buf287  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_26.run(buf314, buf315, buf316, buf317, 50176, 128, grid=grid(50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf318 = reinterpret_tensor(buf308, (1, 128, 1, 1, 4), (512, 1, 512, 512, 128)); del buf308  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf319 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf320 = empty_strided((1, 128, 1, 1, 4), (512, 1, 512, 512, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_27.run(buf315, buf316, buf317, buf318, buf319, buf320, 512, 98, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf321 = buf294; del buf294  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf322 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf324 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf326 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf325 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_28.run(buf318, buf319, buf320, primals_226, primals_225, buf321, buf322, buf324, buf326, buf325, 128, 4, grid=grid(128), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_225
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_226
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf327 = empty_strided((64, 128, 28, 28), (100352, 1, 3584, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn1, getattr_l__self___layer2___3___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_29.run(buf314, buf321, buf322, primals_65, primals_66, buf327, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_66
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf328 = extern_kernels.convolution(buf327, buf7, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf328, (64, 128, 28, 28), (100352, 1, 3584, 128))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf329 = buf317; del buf317  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf330 = buf316; del buf316  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf331 = buf315; del buf315  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_26.run(buf328, buf329, buf330, buf331, 50176, 128, grid=grid(50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf332 = buf320; del buf320  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf333 = buf319; del buf319  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf334 = buf318; del buf318  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_27.run(buf329, buf330, buf331, buf332, buf333, buf334, 512, 98, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf335 = buf322; del buf322  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf336 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf338 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf340 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf339 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_28.run(buf332, buf333, buf334, primals_229, primals_228, buf335, buf336, buf338, buf340, buf339, 128, 4, grid=grid(128), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_228
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_229
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf341 = empty_strided((64, 128, 28, 28), (100352, 1, 3584, 128), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn2, getattr_l__self___layer2___3___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_29.run(buf328, buf335, buf336, primals_68, primals_69, buf341, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf336
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_69
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf342 = empty_strided((50176, 512), (512, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf341, (50176, 128), (128, 1), 0), reinterpret_tensor(primals_70, (128, 512), (1, 128), 0), out=buf342)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf343 = buf303; del buf303  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf344 = buf302; del buf302  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf345 = buf301; del buf301  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_30.run(buf342, buf343, buf344, buf345, 114688, 224, grid=grid(114688), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf346 = buf306; del buf306  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf347 = buf305; del buf305  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf348 = buf304; del buf304  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_31.run(buf343, buf344, buf345, buf346, buf347, buf348, 1024, 112, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf343
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf344
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf345
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf349 = reinterpret_tensor(buf334, (1, 512, 1, 1), (512, 1, 512, 512)); del buf334  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf350 = reinterpret_tensor(buf333, (1, 512, 1, 1), (512, 1, 512, 512)); del buf333  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf352 = reinterpret_tensor(buf332, (512, ), (1, )); del buf332  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf354 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf353 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_32.run(buf346, buf347, buf348, primals_232, primals_231, buf349, buf350, buf352, buf354, buf353, 512, 2, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_231
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_232
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf355 = empty_strided((64, 512, 28, 28), (401408, 1, 14336, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn3, getattr_l__self___layer2___3___relu_2, iadd_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_36.run(buf342, buf349, buf350, primals_71, primals_72, buf313, buf355, 25690112, grid=grid(25690112), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_72
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf356 = empty_strided((50176, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf355, (50176, 512), (512, 1), 0), reinterpret_tensor(primals_73, (512, 256), (1, 512), 0), out=buf356)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf357 = empty_strided((1, 256, 1, 1, 392), (100352, 1, 100352, 100352, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf358 = empty_strided((1, 256, 1, 1, 392), (100352, 1, 100352, 100352, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf359 = empty_strided((1, 256, 1, 1, 392), (100352, 1, 100352, 100352, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_37.run(buf356, buf357, buf358, buf359, 100352, 128, grid=grid(100352), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf360 = reinterpret_tensor(buf348, (1, 256, 1, 1, 4), (1024, 1, 1024, 1024, 256)); del buf348  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf361 = reinterpret_tensor(buf347, (1, 256, 1, 1, 4), (1024, 1, 1024, 1024, 256)); del buf347  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf362 = reinterpret_tensor(buf346, (1, 256, 1, 1, 4), (1024, 1, 1024, 1024, 256)); del buf346  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_38.run(buf357, buf358, buf359, buf360, buf361, buf362, 1024, 98, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf363 = buf168; del buf168  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf364 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf366 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf368 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf367 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_39.run(buf360, buf361, buf362, primals_235, primals_234, buf363, buf364, buf366, buf368, buf367, 256, 4, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_234
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_235
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf369 = empty_strided((64, 256, 28, 28), (200704, 1, 7168, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn1, getattr_l__self___layer3___0___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_40.run(buf356, buf363, buf364, primals_74, primals_75, buf369, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_75
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf370 = extern_kernels.convolution(buf369, buf8, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf370, (64, 256, 14, 14), (50176, 1, 3584, 256))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf371 = empty_strided((1, 256, 1, 1, 98), (25088, 1, 25088, 25088, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf372 = empty_strided((1, 256, 1, 1, 98), (25088, 1, 25088, 25088, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf373 = empty_strided((1, 256, 1, 1, 98), (25088, 1, 25088, 25088, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf370, buf371, buf372, buf373, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf374 = buf364; del buf364  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf375 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf377 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf379 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf378 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf371, buf372, buf373, primals_238, primals_237, buf374, buf375, buf377, buf379, buf378, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_237
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_238
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf380 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn2, getattr_l__self___layer3___0___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf370, buf374, buf375, primals_77, primals_78, buf380, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_78
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf381 = empty_strided((12544, 1024), (1024, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf380, (12544, 256), (256, 1), 0), reinterpret_tensor(primals_79, (256, 1024), (1, 256), 0), out=buf381)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf382 = reinterpret_tensor(buf359, (1, 1024, 1, 1, 98), (100352, 1, 100352, 100352, 1024)); del buf359  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf383 = reinterpret_tensor(buf358, (1, 1024, 1, 1, 98), (100352, 1, 100352, 100352, 1024)); del buf358  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf384 = reinterpret_tensor(buf357, (1, 1024, 1, 1, 98), (100352, 1, 100352, 100352, 1024)); del buf357  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_44.run(buf381, buf382, buf383, buf384, 100352, 128, grid=grid(100352), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf385 = reinterpret_tensor(buf362, (1, 1024, 1, 1), (1024, 1, 1024, 1024)); del buf362  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf386 = reinterpret_tensor(buf361, (1, 1024, 1, 1), (1024, 1, 1024, 1024)); del buf361  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf388 = reinterpret_tensor(buf360, (1024, ), (1, )); del buf360  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf390 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf389 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_45.run(buf382, buf383, buf384, primals_241, primals_240, buf385, buf386, buf388, buf390, buf389, 1024, 98, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_240
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_241
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___downsample_0], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf391 = extern_kernels.convolution(buf355, primals_82, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf391, (64, 1024, 14, 14), (200704, 1, 14336, 1024))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf392 = buf384; del buf384  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf393 = buf383; del buf383  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf394 = buf382; del buf382  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_44.run(buf391, buf392, buf393, buf394, 100352, 128, grid=grid(100352), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf395 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf396 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf398 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf400 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf399 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_45.run(buf392, buf393, buf394, primals_244, primals_243, buf395, buf396, buf398, buf400, buf399, 1024, 98, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_243
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_244
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf401 = empty_strided((64, 1024, 14, 14), (200704, 1, 14336, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf402 = buf401; del buf401  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn3, getattr_l__self___layer3___0___downsample_1, getattr_l__self___layer3___0___relu_2, iadd_7], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_46.run(buf402, buf381, buf385, buf386, primals_80, primals_81, buf391, buf395, buf396, primals_83, primals_84, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_81
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_84
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf403 = empty_strided((12544, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf402, (12544, 1024), (1024, 1), 0), reinterpret_tensor(primals_85, (1024, 256), (1, 1024), 0), out=buf403)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf404 = buf373; del buf373  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf405 = buf372; del buf372  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf406 = buf371; del buf371  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf403, buf404, buf405, buf406, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf407 = buf375; del buf375  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf408 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf410 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf412 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf411 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf404, buf405, buf406, primals_247, primals_246, buf407, buf408, buf410, buf412, buf411, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_246
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_247
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf413 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn1, getattr_l__self___layer3___1___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf403, buf407, buf408, primals_86, primals_87, buf413, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_87
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf414 = extern_kernels.convolution(buf413, buf9, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf414, (64, 256, 14, 14), (50176, 1, 3584, 256))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf415 = buf406; del buf406  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf416 = buf405; del buf405  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf417 = buf404; del buf404  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf414, buf415, buf416, buf417, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf418 = buf408; del buf408  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf419 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf421 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf423 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf422 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf415, buf416, buf417, primals_250, primals_249, buf418, buf419, buf421, buf423, buf422, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_249
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_250
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf424 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn2, getattr_l__self___layer3___1___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf414, buf418, buf419, primals_89, primals_90, buf424, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_90
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf425 = empty_strided((12544, 1024), (1024, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf424, (12544, 256), (256, 1), 0), reinterpret_tensor(primals_91, (256, 1024), (1, 256), 0), out=buf425)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf426 = buf394; del buf394  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf427 = buf393; del buf393  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf428 = buf392; del buf392  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_44.run(buf425, buf426, buf427, buf428, 100352, 128, grid=grid(100352), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf429 = buf396; del buf396  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf430 = buf386; del buf386  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf432 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf434 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf433 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_45.run(buf426, buf427, buf428, primals_253, primals_252, buf429, buf430, buf432, buf434, buf433, 1024, 98, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_252
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_253
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf435 = empty_strided((64, 1024, 14, 14), (200704, 1, 14336, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn3, getattr_l__self___layer3___1___relu_2, iadd_8], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_47.run(buf425, buf429, buf430, primals_92, primals_93, buf402, buf435, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_93
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf436 = empty_strided((12544, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf435, (12544, 1024), (1024, 1), 0), reinterpret_tensor(primals_94, (1024, 256), (1, 1024), 0), out=buf436)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf437 = buf417; del buf417  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf438 = buf416; del buf416  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf439 = buf415; del buf415  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf436, buf437, buf438, buf439, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf440 = buf419; del buf419  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf441 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf443 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf445 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf444 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf437, buf438, buf439, primals_256, primals_255, buf440, buf441, buf443, buf445, buf444, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_255
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_256
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf446 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn1, getattr_l__self___layer3___2___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf436, buf440, buf441, primals_95, primals_96, buf446, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_96
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf447 = extern_kernels.convolution(buf446, buf10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf447, (64, 256, 14, 14), (50176, 1, 3584, 256))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf448 = buf439; del buf439  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf449 = buf438; del buf438  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf450 = buf437; del buf437  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf447, buf448, buf449, buf450, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf451 = buf441; del buf441  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf452 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf454 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf456 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf455 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf448, buf449, buf450, primals_259, primals_258, buf451, buf452, buf454, buf456, buf455, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_258
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_259
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf457 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn2, getattr_l__self___layer3___2___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf447, buf451, buf452, primals_98, primals_99, buf457, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_99
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf458 = empty_strided((12544, 1024), (1024, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf457, (12544, 256), (256, 1), 0), reinterpret_tensor(primals_100, (256, 1024), (1, 256), 0), out=buf458)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf459 = buf428; del buf428  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf460 = buf427; del buf427  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf461 = buf426; del buf426  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_44.run(buf458, buf459, buf460, buf461, 100352, 128, grid=grid(100352), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf462 = buf430; del buf430  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf463 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf465 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf467 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf466 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_45.run(buf459, buf460, buf461, primals_262, primals_261, buf462, buf463, buf465, buf467, buf466, 1024, 98, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_261
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_262
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf468 = empty_strided((64, 1024, 14, 14), (200704, 1, 14336, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn3, getattr_l__self___layer3___2___relu_2, iadd_9], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_47.run(buf458, buf462, buf463, primals_101, primals_102, buf435, buf468, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_102
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf469 = empty_strided((12544, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf468, (12544, 1024), (1024, 1), 0), reinterpret_tensor(primals_103, (1024, 256), (1, 1024), 0), out=buf469)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf470 = buf450; del buf450  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf471 = buf449; del buf449  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf472 = buf448; del buf448  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf469, buf470, buf471, buf472, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf473 = buf452; del buf452  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf474 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf476 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf478 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf477 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf470, buf471, buf472, primals_265, primals_264, buf473, buf474, buf476, buf478, buf477, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_264
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_265
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf479 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn1, getattr_l__self___layer3___3___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf469, buf473, buf474, primals_104, primals_105, buf479, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_105
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf480 = extern_kernels.convolution(buf479, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf480, (64, 256, 14, 14), (50176, 1, 3584, 256))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf481 = buf472; del buf472  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf482 = buf471; del buf471  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf483 = buf470; del buf470  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf480, buf481, buf482, buf483, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf484 = buf474; del buf474  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf485 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf487 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf489 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf488 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf481, buf482, buf483, primals_268, primals_267, buf484, buf485, buf487, buf489, buf488, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_267
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_268
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf490 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn2, getattr_l__self___layer3___3___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf480, buf484, buf485, primals_107, primals_108, buf490, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_108
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf491 = empty_strided((12544, 1024), (1024, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf490, (12544, 256), (256, 1), 0), reinterpret_tensor(primals_109, (256, 1024), (1, 256), 0), out=buf491)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf492 = buf461; del buf461  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf493 = buf460; del buf460  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf494 = buf459; del buf459  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_44.run(buf491, buf492, buf493, buf494, 100352, 128, grid=grid(100352), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf495 = buf463; del buf463  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf496 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf498 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf500 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf499 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_45.run(buf492, buf493, buf494, primals_271, primals_270, buf495, buf496, buf498, buf500, buf499, 1024, 98, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_270
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_271
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf501 = empty_strided((64, 1024, 14, 14), (200704, 1, 14336, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn3, getattr_l__self___layer3___3___relu_2, iadd_10], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_47.run(buf491, buf495, buf496, primals_110, primals_111, buf468, buf501, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_111
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf502 = empty_strided((12544, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf501, (12544, 1024), (1024, 1), 0), reinterpret_tensor(primals_112, (1024, 256), (1, 1024), 0), out=buf502)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf503 = buf483; del buf483  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf504 = buf482; del buf482  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf505 = buf481; del buf481  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf502, buf503, buf504, buf505, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf506 = buf485; del buf485  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf507 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf509 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf511 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf510 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf503, buf504, buf505, primals_274, primals_273, buf506, buf507, buf509, buf511, buf510, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_273
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_274
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf512 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn1, getattr_l__self___layer3___4___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf502, buf506, buf507, primals_113, primals_114, buf512, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_114
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf513 = extern_kernels.convolution(buf512, buf12, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf513, (64, 256, 14, 14), (50176, 1, 3584, 256))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf514 = buf505; del buf505  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf515 = buf504; del buf504  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf516 = buf503; del buf503  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf513, buf514, buf515, buf516, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf517 = buf507; del buf507  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf518 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf520 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf522 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf521 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf514, buf515, buf516, primals_277, primals_276, buf517, buf518, buf520, buf522, buf521, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_276
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_277
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf523 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn2, getattr_l__self___layer3___4___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf513, buf517, buf518, primals_116, primals_117, buf523, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_117
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf524 = empty_strided((12544, 1024), (1024, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf523, (12544, 256), (256, 1), 0), reinterpret_tensor(primals_118, (256, 1024), (1, 256), 0), out=buf524)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf525 = buf494; del buf494  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf526 = buf493; del buf493  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf527 = buf492; del buf492  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_44.run(buf524, buf525, buf526, buf527, 100352, 128, grid=grid(100352), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf528 = buf496; del buf496  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf529 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf531 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf533 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf532 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_45.run(buf525, buf526, buf527, primals_280, primals_279, buf528, buf529, buf531, buf533, buf532, 1024, 98, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_279
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_280
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf534 = empty_strided((64, 1024, 14, 14), (200704, 1, 14336, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn3, getattr_l__self___layer3___4___relu_2, iadd_11], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_47.run(buf524, buf528, buf529, primals_119, primals_120, buf501, buf534, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_120
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf535 = empty_strided((12544, 256), (256, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf534, (12544, 1024), (1024, 1), 0), reinterpret_tensor(primals_121, (1024, 256), (1, 1024), 0), out=buf535)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf536 = buf516; del buf516  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf537 = buf515; del buf515  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf538 = buf514; del buf514  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf535, buf536, buf537, buf538, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf539 = buf518; del buf518  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf540 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf542 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf544 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf543 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf536, buf537, buf538, primals_283, primals_282, buf539, buf540, buf542, buf544, buf543, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_282
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_283
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf545 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn1, getattr_l__self___layer3___5___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf535, buf539, buf540, primals_122, primals_123, buf545, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_123
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf546 = extern_kernels.convolution(buf545, buf13, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf546, (64, 256, 14, 14), (50176, 1, 3584, 256))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf547 = buf538; del buf538  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf548 = buf537; del buf537  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf549 = buf536; del buf536  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_41.run(buf546, buf547, buf548, buf549, 25088, 128, grid=grid(25088), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf550 = buf540; del buf540  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf551 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf553 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf555 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf554 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_42.run(buf547, buf548, buf549, primals_286, primals_285, buf550, buf551, buf553, buf555, buf554, 256, 98, grid=grid(256), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf547
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf548
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf549
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_285
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_286
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf556 = empty_strided((64, 256, 14, 14), (50176, 1, 3584, 256), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn2, getattr_l__self___layer3___5___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_43.run(buf546, buf550, buf551, primals_125, primals_126, buf556, 3211264, grid=grid(3211264), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf551
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_126
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf557 = empty_strided((12544, 1024), (1024, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf556, (12544, 256), (256, 1), 0), reinterpret_tensor(primals_127, (256, 1024), (1, 256), 0), out=buf557)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf558 = buf527; del buf527  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf559 = buf526; del buf526  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf560 = buf525; del buf525  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_44.run(buf557, buf558, buf559, buf560, 100352, 128, grid=grid(100352), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf561 = buf529; del buf529  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf562 = empty_strided((1, 1024, 1, 1), (1024, 1, 1024, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf564 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf566 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf565 = empty_strided((1024, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_45.run(buf558, buf559, buf560, primals_289, primals_288, buf561, buf562, buf564, buf566, buf565, 1024, 98, grid=grid(1024), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf558
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf559
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf560
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_288
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_289
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf567 = empty_strided((64, 1024, 14, 14), (200704, 1, 14336, 1024), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn3, getattr_l__self___layer3___5___relu_2, iadd_12], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_47.run(buf557, buf561, buf562, primals_128, primals_129, buf534, buf567, 12845056, grid=grid(12845056), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf562
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_129
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf568 = empty_strided((12544, 512), (512, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf567, (12544, 1024), (1024, 1), 0), reinterpret_tensor(primals_130, (1024, 512), (1, 1024), 0), out=buf568)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf569 = reinterpret_tensor(buf331, (1, 512, 1, 1, 98), (50176, 1, 50176, 50176, 512)); del buf331  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf570 = reinterpret_tensor(buf330, (1, 512, 1, 1, 98), (50176, 1, 50176, 50176, 512)); del buf330  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf571 = reinterpret_tensor(buf329, (1, 512, 1, 1, 98), (50176, 1, 50176, 50176, 512)); del buf329  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_48.run(buf568, buf569, buf570, buf571, 50176, 128, grid=grid(50176), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf572 = buf350; del buf350  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf573 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf575 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf577 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf576 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_49.run(buf569, buf570, buf571, primals_292, primals_291, buf572, buf573, buf575, buf577, buf576, 512, 98, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf569
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf570
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf571
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_291
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_292
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf578 = empty_strided((64, 512, 14, 14), (100352, 1, 7168, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn1, getattr_l__self___layer4___0___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_50.run(buf568, buf572, buf573, primals_131, primals_132, buf578, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_132
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf579 = extern_kernels.convolution(buf578, buf14, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf579, (64, 512, 7, 7), (25088, 1, 3584, 512))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf580 = empty_strided((1, 512, 1, 1, 25), (12800, 1, 12800, 12800, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf581 = empty_strided((1, 512, 1, 1, 25), (12800, 1, 12800, 12800, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf582 = empty_strided((1, 512, 1, 1, 25), (12800, 1, 12800, 12800, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_51.run(buf579, buf580, buf581, buf582, 12800, 126, grid=grid(12800), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf583 = buf573; del buf573  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf584 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf586 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf588 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf587 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_52.run(buf580, buf581, buf582, primals_295, primals_294, buf583, buf584, buf586, buf588, buf587, 512, 25, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_294
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_295
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf589 = empty_strided((64, 512, 7, 7), (25088, 1, 3584, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn2, getattr_l__self___layer4___0___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_53.run(buf579, buf583, buf584, primals_134, primals_135, buf589, 1605632, grid=grid(1605632), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_135
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf590 = empty_strided((3136, 2048), (2048, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf589, (3136, 512), (512, 1), 0), reinterpret_tensor(primals_136, (512, 2048), (1, 512), 0), out=buf590)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf591 = empty_strided((1, 2048, 1, 1, 25), (51200, 1, 51200, 51200, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf592 = empty_strided((1, 2048, 1, 1, 25), (51200, 1, 51200, 51200, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf593 = empty_strided((1, 2048, 1, 1, 25), (51200, 1, 51200, 51200, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_54.run(buf590, buf591, buf592, buf593, 51200, 126, grid=grid(51200), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf594 = empty_strided((1, 2048, 1, 1), (2048, 1, 2048, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf595 = empty_strided((1, 2048, 1, 1), (2048, 1, 2048, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf597 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf599 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf598 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_55.run(buf591, buf592, buf593, primals_298, primals_297, buf594, buf595, buf597, buf599, buf598, 2048, 25, grid=grid(2048), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_297
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_298
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___downsample_0], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf600 = extern_kernels.convolution(buf567, primals_139, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf600, (64, 2048, 7, 7), (100352, 1, 14336, 2048))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf601 = buf593; del buf593  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf602 = buf592; del buf592  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf603 = buf591; del buf591  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_54.run(buf600, buf601, buf602, buf603, 51200, 126, grid=grid(51200), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf604 = empty_strided((1, 2048, 1, 1), (2048, 1, 2048, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf605 = empty_strided((1, 2048, 1, 1), (2048, 1, 2048, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf607 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf609 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf608 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_55.run(buf601, buf602, buf603, primals_301, primals_300, buf604, buf605, buf607, buf609, buf608, 2048, 25, grid=grid(2048), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_300
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_301
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf610 = empty_strided((64, 2048, 7, 7), (100352, 1, 14336, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf611 = buf610; del buf610  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn3, getattr_l__self___layer4___0___downsample_1, getattr_l__self___layer4___0___relu_2, iadd_13], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_56.run(buf611, buf590, buf594, buf595, primals_137, primals_138, buf600, buf604, buf605, primals_140, primals_141, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_138
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_141
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf612 = empty_strided((3136, 512), (512, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf611, (3136, 2048), (2048, 1), 0), reinterpret_tensor(primals_142, (2048, 512), (1, 2048), 0), out=buf612)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf613 = buf582; del buf582  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf614 = buf581; del buf581  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf615 = buf580; del buf580  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_51.run(buf612, buf613, buf614, buf615, 12800, 126, grid=grid(12800), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf616 = buf584; del buf584  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf617 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf619 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf621 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf620 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_52.run(buf613, buf614, buf615, primals_304, primals_303, buf616, buf617, buf619, buf621, buf620, 512, 25, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_303
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_304
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf622 = empty_strided((64, 512, 7, 7), (25088, 1, 3584, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn1, getattr_l__self___layer4___1___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_53.run(buf612, buf616, buf617, primals_143, primals_144, buf622, 1605632, grid=grid(1605632), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_144
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf623 = extern_kernels.convolution(buf622, buf15, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf623, (64, 512, 7, 7), (25088, 1, 3584, 512))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf624 = buf615; del buf615  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf625 = buf614; del buf614  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf626 = buf613; del buf613  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_51.run(buf623, buf624, buf625, buf626, 12800, 126, grid=grid(12800), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf627 = buf617; del buf617  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf628 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf630 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf632 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf631 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_52.run(buf624, buf625, buf626, primals_307, primals_306, buf627, buf628, buf630, buf632, buf631, 512, 25, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_306
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_307
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf633 = empty_strided((64, 512, 7, 7), (25088, 1, 3584, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn2, getattr_l__self___layer4___1___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_53.run(buf623, buf627, buf628, primals_146, primals_147, buf633, 1605632, grid=grid(1605632), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_147
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf634 = empty_strided((3136, 2048), (2048, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf633, (3136, 512), (512, 1), 0), reinterpret_tensor(primals_148, (512, 2048), (1, 512), 0), out=buf634)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf635 = buf603; del buf603  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf636 = buf602; del buf602  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf637 = buf601; del buf601  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_54.run(buf634, buf635, buf636, buf637, 51200, 126, grid=grid(51200), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf638 = buf605; del buf605  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf639 = buf595; del buf595  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf641 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf643 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf642 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_55.run(buf635, buf636, buf637, primals_310, primals_309, buf638, buf639, buf641, buf643, buf642, 2048, 25, grid=grid(2048), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_309
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_310
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf644 = empty_strided((64, 2048, 7, 7), (100352, 1, 14336, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn3, getattr_l__self___layer4___1___relu_2, iadd_14], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_57.run(buf634, buf638, buf639, primals_149, primals_150, buf611, buf644, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_150
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf645 = empty_strided((3136, 512), (512, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___conv1], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf644, (3136, 2048), (2048, 1), 0), reinterpret_tensor(primals_151, (2048, 512), (1, 2048), 0), out=buf645)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf646 = buf626; del buf626  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf647 = buf625; del buf625  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf648 = buf624; del buf624  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_51.run(buf645, buf646, buf647, buf648, 12800, 126, grid=grid(12800), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf649 = buf628; del buf628  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf650 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf652 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf654 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf653 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn1], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_52.run(buf646, buf647, buf648, primals_313, primals_312, buf649, buf650, buf652, buf654, buf653, 512, 25, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_312
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_313
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf655 = empty_strided((64, 512, 7, 7), (25088, 1, 3584, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn1, getattr_l__self___layer4___2___relu], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_53.run(buf645, buf649, buf650, primals_152, primals_153, buf655, 1605632, grid=grid(1605632), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_153
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___conv2], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf656 = extern_kernels.convolution(buf655, buf16, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf656, (64, 512, 7, 7), (25088, 1, 3584, 512))
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf657 = buf648; del buf648  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf658 = buf647; del buf647  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf659 = buf646; del buf646  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_51.run(buf656, buf657, buf658, buf659, 12800, 126, grid=grid(12800), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf660 = buf650; del buf650  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf661 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf663 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf665 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf664 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn2], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_52.run(buf657, buf658, buf659, primals_316, primals_315, buf660, buf661, buf663, buf665, buf664, 512, 25, grid=grid(512), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf657
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf658
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf659
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_315
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_316
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf666 = empty_strided((64, 512, 7, 7), (25088, 1, 3584, 512), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn2, getattr_l__self___layer4___2___relu_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_53.run(buf656, buf660, buf661, primals_155, primals_156, buf666, 1605632, grid=grid(1605632), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf661
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_156
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf667 = empty_strided((3136, 2048), (2048, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___conv3], Original ATen: [aten.convolution]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.mm(reinterpret_tensor(buf666, (3136, 512), (512, 1), 0), reinterpret_tensor(primals_157, (512, 2048), (1, 512), 0), out=buf667)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf668 = buf637; del buf637  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf669 = buf636; del buf636  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf670 = buf635; del buf635  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_54.run(buf667, buf668, buf669, buf670, 51200, 126, grid=grid(51200), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf671 = buf639; del buf639  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf672 = empty_strided((1, 2048, 1, 1), (2048, 1, 2048, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf674 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf676 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf675 = empty_strided((2048, ), (1, ), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn3], Original ATen: [aten._native_batch_norm_legit_functional]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_55.run(buf668, buf669, buf670, primals_319, primals_318, buf671, buf672, buf674, buf676, buf675, 2048, 25, grid=grid(2048), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf668
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf669
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf670
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_318
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_319
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf677 = empty_strided((64, 2048, 7, 7), (100352, 1, 14336, 2048), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf681 = empty_strided((64, 2048, 7, 7), (100352, 1, 14336, 2048), device='cuda', dtype=torch.bool)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn3, getattr_l__self___layer4___2___relu_2, iadd_15], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu, aten.threshold_backward]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_threshold_backward_58.run(buf667, buf671, buf672, primals_158, primals_159, buf644, buf677, buf681, 6422528, grid=grid(6422528), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf672
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_159
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf678 = empty_strided((64, 2048, 1, 1), (2048, 1, 131072, 131072), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf679 = reinterpret_tensor(buf678, (64, 2048), (2048, 1)); del buf678  # reuse
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [flatten, l__self___avgpool], Original ATen: [aten.mean, aten.view]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused_mean_view_59.run(buf679, buf677, 131072, 49, grid=grid(131072), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del buf677
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf680 = empty_strided((64, 1000), (1000, 1), device='cuda', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___fc], Original ATen: [aten.addmm]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.addmm(reinterpret_tensor(primals_161, (64, 1000), (0, 1), 0), buf679, reinterpret_tensor(primals_160, (2048, 1000), (1, 2048), 0), alpha=1, beta=1, out=buf680)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_161
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf682 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_164, buf682, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_164
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf683 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_167, buf683, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_167
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf684 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_170, buf684, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_170
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf685 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_173, buf685, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_173
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf686 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___downsample_1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_176, buf686, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_176
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf687 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_179, buf687, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_179
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf688 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_182, buf688, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_182
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf689 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_185, buf689, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_185
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf690 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_188, buf690, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_188
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf691 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_191, buf691, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_191
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf692 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___2___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_194, buf692, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_194
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf693 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_197, buf693, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_197
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf694 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_200, buf694, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_200
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf695 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_203, buf695, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_203
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf696 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___downsample_1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_206, buf696, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_206
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf697 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_209, buf697, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_209
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf698 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_212, buf698, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_212
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf699 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_215, buf699, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_215
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf700 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_218, buf700, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_218
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf701 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_221, buf701, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_221
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf702 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___2___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_224, buf702, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_224
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf703 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_227, buf703, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_227
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf704 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_230, buf704, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_230
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf705 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___3___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_233, buf705, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_233
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf706 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_236, buf706, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_236
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf707 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_239, buf707, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_239
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf708 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_242, buf708, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_242
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf709 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___downsample_1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_245, buf709, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_245
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf710 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_248, buf710, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_248
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf711 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_251, buf711, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_251
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf712 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_254, buf712, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_254
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf713 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_257, buf713, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_257
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf714 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_260, buf714, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_260
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf715 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___2___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_263, buf715, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_263
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf716 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_266, buf716, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_266
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf717 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_269, buf717, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_269
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf718 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___3___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_272, buf718, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_272
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf719 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_275, buf719, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_275
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf720 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_278, buf720, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_278
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf721 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___4___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_281, buf721, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_281
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf722 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_284, buf722, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_284
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf723 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_287, buf723, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_287
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf724 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___5___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_290, buf724, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_290
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf725 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_293, buf725, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_293
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf726 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_296, buf726, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_296
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf727 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_299, buf727, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_299
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf728 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___downsample_1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_302, buf728, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_302
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf729 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_305, buf729, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_305
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf730 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_308, buf730, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_308
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf731 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_311, buf731, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_311
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf732 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn1], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_314, buf732, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_314
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf733 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn2], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_317, buf733, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_317
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         buf734 = empty_strided((), (), device='cuda', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___2___bn3], Original ATen: [aten.add]
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_60.run(primals_320, buf734, 1, grid=grid(1), stream=stream0)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_320
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]         return (buf29, buf30, buf682, buf45, buf46, buf683, buf59, buf60, buf684, buf73, buf74, buf685, buf86, buf87, buf686, buf101, buf102, buf687, buf115, buf116, buf688, buf129, buf130, buf689, buf143, buf144, buf690, buf157, buf158, buf691, buf171, buf172, buf692, buf185, buf186, buf693, buf199, buf200, buf694, buf213, buf214, buf695, buf226, buf227, buf696, buf241, buf242, buf697, buf255, buf256, buf698, buf269, buf270, buf699, buf283, buf284, buf700, buf297, buf298, buf701, buf311, buf312, buf702, buf325, buf326, buf703, buf339, buf340, buf704, buf353, buf354, buf705, buf367, buf368, buf706, buf378, buf379, buf707, buf389, buf390, buf708, buf399, buf400, buf709, buf411, buf412, buf710, buf422, buf423, buf711, buf433, buf434, buf712, buf444, buf445, buf713, buf455, buf456, buf714, buf466, buf467, buf715, buf477, buf478, buf716, buf488, buf489, buf717, buf499, buf500, buf718, buf510, buf511, buf719, buf521, buf522, buf720, buf532, buf533, buf721, buf543, buf544, buf722, buf554, buf555, buf723, buf565, buf566, buf724, buf576, buf577, buf725, buf587, buf588, buf726, buf598, buf599, buf727, buf608, buf609, buf728, buf620, buf621, buf729, buf631, buf632, buf730, buf642, buf643, buf731, buf653, buf654, buf732, buf664, buf665, buf733, buf675, buf676, buf734, buf680, buf0, primals_2, primals_4, primals_5, buf1, primals_8, primals_10, primals_11, primals_13, primals_14, primals_16, primals_17, buf2, primals_20, primals_22, primals_23, primals_25, primals_26, buf3, primals_29, primals_31, primals_32, primals_34, primals_35, buf4, primals_38, primals_40, primals_41, primals_43, primals_44, primals_46, primals_47, buf5, primals_50, primals_52, primals_53, primals_55, primals_56, buf6, primals_59, primals_61, primals_62, primals_64, primals_65, buf7, primals_68, primals_70, primals_71, primals_73, primals_74, buf8, primals_77, primals_79, primals_80, primals_82, primals_83, primals_85, primals_86, buf9, primals_89, primals_91, primals_92, primals_94, primals_95, buf10, primals_98, primals_100, primals_101, primals_103, primals_104, buf11, primals_107, primals_109, primals_110, primals_112, primals_113, buf12, primals_116, primals_118, primals_119, primals_121, primals_122, buf13, primals_125, primals_127, primals_128, primals_130, primals_131, buf14, primals_134, primals_136, primals_137, primals_139, primals_140, primals_142, primals_143, buf15, primals_146, primals_148, primals_149, primals_151, primals_152, buf16, primals_155, primals_157, primals_158, buf17, buf18, buf28, buf31, buf32, buf33, reinterpret_tensor(buf34, (64, 64, 56, 56), (200704, 1, 3584, 64), 0), buf44, buf47, buf48, buf58, buf61, reinterpret_tensor(buf62, (64, 256, 56, 56), (802816, 1, 14336, 256), 0), buf72, reinterpret_tensor(buf75, (64, 256, 56, 56), (802816, 1, 14336, 256), 0), buf85, buf89, reinterpret_tensor(buf90, (64, 64, 56, 56), (200704, 1, 3584, 64), 0), buf100, buf103, buf104, buf114, buf117, reinterpret_tensor(buf118, (64, 256, 56, 56), (802816, 1, 14336, 256), 0), buf128, buf131, reinterpret_tensor(buf132, (64, 64, 56, 56), (200704, 1, 3584, 64), 0), buf142, buf145, buf146, buf156, buf159, reinterpret_tensor(buf160, (64, 256, 56, 56), (802816, 1, 14336, 256), 0), buf170, buf173, reinterpret_tensor(buf174, (64, 128, 56, 56), (401408, 1, 7168, 128), 0), buf184, buf187, buf188, buf198, buf201, reinterpret_tensor(buf202, (64, 512, 28, 28), (401408, 1, 14336, 512), 0), buf212, buf215, buf225, buf229, reinterpret_tensor(buf230, (64, 128, 28, 28), (100352, 1, 3584, 128), 0), buf240, buf243, buf244, buf254, buf257, reinterpret_tensor(buf258, (64, 512, 28, 28), (401408, 1, 14336, 512), 0), buf268, buf271, reinterpret_tensor(buf272, (64, 128, 28, 28), (100352, 1, 3584, 128), 0), buf282, buf285, buf286, buf296, buf299, reinterpret_tensor(buf300, (64, 512, 28, 28), (401408, 1, 14336, 512), 0), buf310, buf313, reinterpret_tensor(buf314, (64, 128, 28, 28), (100352, 1, 3584, 128), 0), buf324, buf327, buf328, buf338, buf341, reinterpret_tensor(buf342, (64, 512, 28, 28), (401408, 1, 14336, 512), 0), buf352, buf355, reinterpret_tensor(buf356, (64, 256, 28, 28), (200704, 1, 7168, 256), 0), buf366, buf369, buf370, buf377, buf380, reinterpret_tensor(buf381, (64, 1024, 14, 14), (200704, 1, 14336, 1024), 0), buf388, buf391, buf398, buf402, reinterpret_tensor(buf403, (64, 256, 14, 14), (50176, 1, 3584, 256), 0), buf410, buf413, buf414, buf421, buf424, reinterpret_tensor(buf425, (64, 1024, 14, 14), (200704, 1, 14336, 1024), 0), buf432, buf435, reinterpret_tensor(buf436, (64, 256, 14, 14), (50176, 1, 3584, 256), 0), buf443, buf446, buf447, buf454, buf457, reinterpret_tensor(buf458, (64, 1024, 14, 14), (200704, 1, 14336, 1024), 0), buf465, buf468, reinterpret_tensor(buf469, (64, 256, 14, 14), (50176, 1, 3584, 256), 0), buf476, buf479, buf480, buf487, buf490, reinterpret_tensor(buf491, (64, 1024, 14, 14), (200704, 1, 14336, 1024), 0), buf498, buf501, reinterpret_tensor(buf502, (64, 256, 14, 14), (50176, 1, 3584, 256), 0), buf509, buf512, buf513, buf520, buf523, reinterpret_tensor(buf524, (64, 1024, 14, 14), (200704, 1, 14336, 1024), 0), buf531, buf534, reinterpret_tensor(buf535, (64, 256, 14, 14), (50176, 1, 3584, 256), 0), buf542, buf545, buf546, buf553, buf556, reinterpret_tensor(buf557, (64, 1024, 14, 14), (200704, 1, 14336, 1024), 0), buf564, buf567, reinterpret_tensor(buf568, (64, 512, 14, 14), (100352, 1, 7168, 512), 0), buf575, buf578, buf579, buf586, buf589, reinterpret_tensor(buf590, (64, 2048, 7, 7), (100352, 1, 14336, 2048), 0), buf597, buf600, buf607, buf611, reinterpret_tensor(buf612, (64, 512, 7, 7), (25088, 1, 3584, 512), 0), buf619, buf622, buf623, buf630, buf633, reinterpret_tensor(buf634, (64, 2048, 7, 7), (100352, 1, 14336, 2048), 0), buf641, buf644, reinterpret_tensor(buf645, (64, 512, 7, 7), (25088, 1, 3584, 512), 0), buf652, buf655, buf656, buf663, buf666, reinterpret_tensor(buf667, (64, 2048, 7, 7), (100352, 1, 14336, 2048), 0), buf674, buf679, reinterpret_tensor(primals_160, (1000, 2048), (2048, 1), 0), buf681, reinterpret_tensor(buf671, (1, 2048, 1, 1), (2048, 1, 1, 1), 0), reinterpret_tensor(buf660, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf649, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf638, (1, 2048, 1, 1), (2048, 1, 1, 1), 0), reinterpret_tensor(buf627, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf616, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf604, (1, 2048, 1, 1), (2048, 1, 1, 1), 0), reinterpret_tensor(buf594, (1, 2048, 1, 1), (2048, 1, 1, 1), 0), reinterpret_tensor(buf583, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf572, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf561, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf550, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf539, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf528, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf517, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf506, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf495, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf484, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf473, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf462, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf451, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf440, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf429, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf418, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf407, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf395, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf385, (1, 1024, 1, 1), (1024, 1, 1, 1), 0), reinterpret_tensor(buf374, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf363, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf349, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf335, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf321, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf307, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf293, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf279, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf265, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf251, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf237, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf222, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf209, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf195, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf181, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf167, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf153, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf139, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf125, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf111, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf97, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf82, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf69, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf55, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf41, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf25, (1, 64, 1, 1), (64, 1, 1, 1), 0), )
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] def benchmark_compiled_module(times=10, repeat=10):
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     from torch._dynamo.testing import rand_strided
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     from torch._inductor.utils import print_performance
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_1 = rand_strided((64, 3, 7, 7), (147, 49, 7, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_2 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_3 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_4 = rand_strided((64, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_5 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_6 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_7 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_10 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_11 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_12 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_13 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_14 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_15 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_16 = rand_strided((64, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_17 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_18 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_19 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_20 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_21 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_22 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_23 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_24 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_25 = rand_strided((64, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_26 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_27 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_28 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_29 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_30 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_31 = rand_strided((256, 64, 1, 1), (64, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_32 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_33 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_34 = rand_strided((128, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_35 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_36 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_37 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_38 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_39 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_40 = rand_strided((512, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_41 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_42 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_43 = rand_strided((512, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_44 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_45 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_46 = rand_strided((128, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_47 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_48 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_49 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_50 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_51 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_52 = rand_strided((512, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_53 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_54 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_55 = rand_strided((128, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_56 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_57 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_58 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_59 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_60 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_61 = rand_strided((512, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_62 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_63 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_64 = rand_strided((128, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_65 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_66 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_67 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_68 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_69 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_70 = rand_strided((512, 128, 1, 1), (128, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_71 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_72 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_73 = rand_strided((256, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_74 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_75 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_76 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_77 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_78 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_79 = rand_strided((1024, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_80 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_81 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_82 = rand_strided((1024, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_83 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_84 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_85 = rand_strided((256, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_86 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_87 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_88 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_89 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_90 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_91 = rand_strided((1024, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_92 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_93 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_94 = rand_strided((256, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_95 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_96 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_97 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_98 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_99 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_100 = rand_strided((1024, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_101 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_102 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_103 = rand_strided((256, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_104 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_105 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_106 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_107 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_108 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_109 = rand_strided((1024, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_110 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_111 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_112 = rand_strided((256, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_113 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_114 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_115 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_116 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_117 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_118 = rand_strided((1024, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_119 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_120 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_121 = rand_strided((256, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_122 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_123 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_124 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_125 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_126 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_127 = rand_strided((1024, 256, 1, 1), (256, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_128 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_129 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_130 = rand_strided((512, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_131 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_132 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_133 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_134 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_135 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_136 = rand_strided((2048, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_137 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_138 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_139 = rand_strided((2048, 1024, 1, 1), (1024, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_140 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_141 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_142 = rand_strided((512, 2048, 1, 1), (2048, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_143 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_144 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_145 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_146 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_147 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_148 = rand_strided((2048, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_149 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_150 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_151 = rand_strided((512, 2048, 1, 1), (2048, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_152 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_153 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_154 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_155 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_156 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_157 = rand_strided((2048, 512, 1, 1), (512, 1, 1, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_158 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_159 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_160 = rand_strided((1000, 2048), (2048, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_161 = rand_strided((1000, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_162 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_163 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_164 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_165 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_166 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_167 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_168 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_169 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_170 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_171 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_172 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_173 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_174 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_175 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_176 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_177 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_178 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_179 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_180 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_181 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_182 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_183 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_184 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_185 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_186 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_187 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_188 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_189 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_190 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_191 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_192 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_193 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_194 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_195 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_196 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_197 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_198 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_199 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_200 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_201 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_202 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_203 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_204 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_205 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_206 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_207 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_208 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_209 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_210 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_211 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_212 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_213 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_214 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_215 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_216 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_217 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_218 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_219 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_220 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_221 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_222 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_223 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_224 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_225 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_226 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_227 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_228 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_229 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_230 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_231 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_232 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_233 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_234 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_235 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_236 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_237 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_238 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_239 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_240 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_241 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_242 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_243 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_244 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_245 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_246 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_247 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_248 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_249 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_250 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_251 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_252 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_253 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_254 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_255 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_256 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_257 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_258 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_259 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_260 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_261 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_262 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_263 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_264 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_265 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_266 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_267 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_268 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_269 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_270 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_271 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_272 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_273 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_274 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_275 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_276 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_277 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_278 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_279 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_280 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_281 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_282 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_283 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_284 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_285 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_286 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_287 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_288 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_289 = rand_strided((1024, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_290 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_291 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_292 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_293 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_294 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_295 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_296 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_297 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_298 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_299 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_300 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_301 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_302 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_303 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_304 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_305 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_306 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_307 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_308 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_309 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_310 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_311 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_312 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_313 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_314 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_315 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_316 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_317 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_318 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_319 = rand_strided((2048, ), (1, ), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_320 = rand_strided((), (), device='cuda:0', dtype=torch.int64)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     primals_321 = rand_strided((64, 3, 224, 224), (150528, 50176, 224, 1), device='cuda:0', dtype=torch.float32)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     return print_performance(lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321]), times=times, repeat=repeat)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] if __name__ == "__main__":
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     from torch._inductor.wrapper_benchmark import compiled_module_main
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG]     compiled_module_main('None', benchmark_compiled_module)
[2023-12-28 21:23:12,869] [0/0] torch._inductor.graph.__output_code: [DEBUG] 
[2023-12-28 21:23:12,884] [0/0] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0
[2023-12-28 21:23:12,927] [0/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor
[2023-12-28 21:23:13,005] [0/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:
[2023-12-28 21:23:13,006] [0/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1248 in wrap_fx_proxy_cls
[2023-12-28 21:23:13,006] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 140327618489120)                   # x = self.conv1(x)  # torchvision/models/resnet.py:268 in _forward_impl
[2023-12-28 21:23:13,007] [0/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # x = self.conv1(x)  # torchvision/models/resnet.py:268 in _forward_impl
[2023-12-28 21:23:13,007] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards
[2023-12-28 21:23:13,007] [0/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards
[2023-12-28 21:23:13,008] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards
[2023-12-28 21:23:13,008] [0/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards
[2023-12-28 21:23:13,008] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 94204099156960)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl
[2023-12-28 21:23:13,008] [0/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl
[2023-12-28 21:23:13,008] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 94204099156960)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl
[2023-12-28 21:23:13,009] [0/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl
[2023-12-28 21:23:13,009] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 94204099156960)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl
[2023-12-28 21:23:13,009] [0/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl
[2023-12-28 21:23:13,010] [0/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 94204099156960)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl
[2023-12-28 21:23:13,010] [0/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl
[2023-12-28 21:23:13,010] [0/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=False, size=[64, 3, 224, 224], stride=[150528, 50176, 224, 1])  # _dynamo/variables/builder.py:1248 in wrap_fx_proxy_cls
[2023-12-28 21:23:13,011] torch._dynamo.eval_frame: [DEBUG] skipping _fn /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py
[2023-12-28 21:23:13,012] torch._dynamo.eval_frame: [DEBUG] skipping nothing /home/fjr38/.conda/envs/triton/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py
[2023-12-28 21:23:13,012] torch._inductor.cudagraph_trees: [INFO] recording cudagraph tree for None
[2023-12-28 21:23:13,341] torch._inductor.cudagraph_trees: [DEBUG] Running warmup of function 0
[2023-12-28 21:23:14,087] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/fjr38/.conda/envs/triton/lib/python3.8/contextlib.py
[2023-12-28 21:23:14,087] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /home/fjr38/.conda/envs/triton/lib/python3.8/contextlib.py
[2023-12-28 21:23:14,103] torch._inductor.cudagraph_trees: [DEBUG] Recording function 0 of graph recording id 0
STAGE:2023-12-28 21:24:08 2086747:2086747 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2023-12-28 21:24:08 2086747:2086747 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2023-12-28 21:24:08 2086747:2086747 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
STAGE:2023-12-28 21:24:08 2086747:2086747 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2023-12-28 21:24:08 2086747:2086747 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2023-12-28 21:24:08 2086747:2086747 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Unoptimized Model:
30.49424903869629 ms
30.700718097686767 ms
30.677831649780273 ms
30.550968322753906 ms
30.689198188781738 ms
30.69917179107666 ms
30.723604412078856 ms
30.48652811050415 ms
30.703349628448485 ms
30.525143089294435 ms

Optimized Model
23.166566429138182 ms
22.612203540802003 ms
23.25231605529785 ms
23.091077041625976 ms
22.912972736358643 ms
22.825410461425783 ms
22.805657653808595 ms
23.196426258087158 ms
23.0367130279541 ms
22.89543170928955 ms
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                        cudaMemcpyAsync        37.05%      12.816ms        37.05%      12.816ms      12.816ms       0.000us         0.00%       0.000us       0.000us             1  
                                  cudaDeviceSynchronize        23.59%       8.160ms        23.59%       8.160ms       8.160ms       0.000us         0.00%       0.000us       0.000us             1  
                                 aten::cudnn_batch_norm        11.48%       3.969ms        16.46%       5.692ms     107.396us       7.982ms        20.18%       8.884ms     167.623us            53  
                                aten::cudnn_convolution         5.31%       1.835ms         6.87%       2.375ms      44.811us       9.967ms        25.20%       9.967ms     188.057us            53  
                                       cudaLaunchKernel         3.87%       1.340ms         3.87%       1.340ms       4.981us       0.000us         0.00%       0.000us       0.000us           269  
                                            aten::relu_         2.38%     824.000us         3.88%       1.342ms      27.388us     258.000us         0.65%       3.090ms      63.061us            49  
                                            aten::empty         2.25%     779.000us         2.25%     779.000us       2.940us     531.000us         1.34%     531.000us       2.004us           265  
                                      aten::convolution         1.99%     689.000us        10.68%       3.694ms      69.698us     304.000us         0.77%      10.554ms     199.132us            53  
                                             aten::add_         1.89%     654.000us         2.75%     951.000us      13.783us       2.682ms         6.78%       2.682ms      38.870us            69  
                                     aten::_convolution         1.82%     630.000us         8.69%       3.005ms      56.698us     283.000us         0.72%      10.250ms     193.396us            53  
                           aten::_batch_norm_impl_index         1.66%     573.000us        18.11%       6.265ms     118.208us     280.000us         0.71%       9.164ms     172.906us            53  
                                       aten::empty_like         1.38%     477.000us         2.16%     748.000us      14.113us     265.000us         0.67%     371.000us       7.000us            53  
                                           aten::conv2d         1.28%     444.000us        11.96%       4.138ms      78.075us     287.000us         0.73%      10.841ms     204.547us            53  
                                       aten::batch_norm         1.23%     426.000us        19.34%       6.691ms     126.245us     279.000us         0.71%       9.443ms     178.170us            53  
                                       aten::clamp_min_         0.93%     320.000us         1.50%     518.000us      10.571us       2.832ms         7.16%       2.832ms      57.796us            49  
                                  cudaStreamSynchronize         0.22%      76.000us         0.22%      76.000us      76.000us       0.000us         0.00%       0.000us       0.000us             1  
                                            aten::addmm         0.21%      72.000us         0.23%      80.000us      80.000us      32.000us         0.08%      32.000us      32.000us             1  
                                             aten::view         0.20%      70.000us         0.20%      70.000us       1.296us     108.000us         0.27%     108.000us       2.000us            54  
                                    cudaLaunchKernelExC         0.17%      59.000us         0.17%      59.000us       3.688us       0.000us         0.00%       0.000us       0.000us            16  
                                         aten::_to_copy         0.16%      57.000us        37.65%      13.022ms      13.022ms      51.000us         0.13%      13.024ms      13.024ms             1  
                                            aten::copy_         0.11%      38.000us        37.38%      12.930ms      12.930ms      12.934ms        32.70%      12.934ms      12.934ms             1  
                                    aten::empty_strided         0.10%      35.000us         0.10%      35.000us      35.000us      39.000us         0.10%      39.000us      39.000us             1  
cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.09%      32.000us         0.09%      32.000us       1.067us       0.000us         0.00%       0.000us       0.000us            30  
                                             aten::mean         0.09%      30.000us         0.11%      37.000us      37.000us      50.000us         0.13%      50.000us      50.000us             1  
                          aten::max_pool2d_with_indices         0.08%      29.000us         0.10%      35.000us      35.000us     327.000us         0.83%     327.000us     327.000us             1  
                                   cudaFuncSetAttribute         0.08%      27.000us         0.08%      27.000us       0.276us       0.000us         0.00%       0.000us       0.000us            98  
                                        aten::transpose         0.07%      25.000us         0.08%      29.000us      29.000us       5.000us         0.01%       7.000us       7.000us             1  
                                           aten::linear         0.07%      23.000us         0.42%     145.000us     145.000us       8.000us         0.02%      53.000us      53.000us             1  
                                               aten::to         0.06%      20.000us        37.71%      13.042ms      13.042ms      22.000us         0.06%      13.046ms      13.046ms             1  
                              aten::adaptive_avg_pool2d         0.05%      19.000us         0.16%      56.000us      56.000us       5.000us         0.01%      55.000us      55.000us             1  
                                                aten::t         0.04%      13.000us         0.12%      42.000us      42.000us       6.000us         0.02%      13.000us      13.000us             1  
                                       aten::max_pool2d         0.03%      11.000us         0.13%      46.000us      46.000us       5.000us         0.01%     332.000us     332.000us             1  
                                          aten::flatten         0.03%      10.000us         0.05%      17.000us      17.000us       5.000us         0.01%       7.000us       7.000us             1  
                                       aten::as_strided         0.01%       4.000us         0.01%       4.000us       4.000us       2.000us         0.01%       2.000us       2.000us             1  
                                  cudaStreamIsCapturing         0.00%       1.000us         0.00%       1.000us       0.009us       0.000us         0.00%       0.000us       0.000us           106  
                                  cudaStreamGetPriority         0.00%       1.000us         0.00%       1.000us       0.009us       0.000us         0.00%       0.000us       0.000us           106  
                       cudaDeviceGetStreamPriorityRange         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           106  
                                        cudaMemsetAsync         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             1  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 34.588ms
Self CUDA time total: 39.549ms

----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                        Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  
----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
             cudaMemcpyAsync        44.77%      12.854ms        44.77%      12.854ms      79.839us       0.000us         0.00%       0.000us       0.000us           161  
       cudaDeviceSynchronize        42.79%      12.285ms        42.79%      12.285ms      12.285ms       0.000us         0.00%       0.000us       0.000us             1  
            CompiledFunction         4.58%       1.316ms         5.81%       1.669ms       1.669ms      15.118ms        49.75%      15.218ms      15.218ms             1  
                aten::detach         3.96%       1.138ms         4.06%       1.165ms       7.281us       1.166ms         3.84%       1.755ms      10.969us           160  
                 aten::copy_         1.71%     492.000us        46.75%      13.422ms      83.366us      13.291ms        43.74%      13.291ms      82.553us           161  
             cudaGraphLaunch         1.02%     293.000us         1.02%     293.000us     293.000us       0.000us         0.00%       0.000us       0.000us             1  
    TorchDynamo Cache Lookup         0.54%     156.000us         0.54%     156.000us     156.000us     163.000us         0.54%     163.000us     163.000us             1  
       cudaStreamSynchronize         0.26%      76.000us         0.26%      76.000us      76.000us       0.000us         0.00%       0.000us       0.000us             1  
                      detach         0.09%      27.000us         0.09%      27.000us       0.169us     589.000us         1.94%     589.000us       3.681us           160  
              aten::_to_copy         0.08%      24.000us        43.34%      12.442ms      12.442ms      18.000us         0.06%      12.444ms      12.444ms             1  
                 aten::fill_         0.05%      15.000us         0.09%      27.000us      13.500us      18.000us         0.06%      18.000us       9.000us             2  
            cudaLaunchKernel         0.04%      12.000us         0.04%      12.000us       6.000us       0.000us         0.00%       0.000us       0.000us             2  
                    aten::to         0.04%      11.000us        43.38%      12.453ms      12.453ms      11.000us         0.04%      12.455ms      12.455ms             1  
         aten::empty_strided         0.03%       9.000us         0.03%       9.000us       9.000us      14.000us         0.05%      14.000us      14.000us             1  
       cudaStreamIsCapturing         0.00%       1.000us         0.00%       1.000us       0.500us       0.000us         0.00%       0.000us       0.000us             2  
        cudaDriverGetVersion         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             1  
----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 28.709ms
Self CUDA time total: 30.388ms


Compile time: 24577.58203125
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] TorchDynamo compilation metrics:
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] Function, Runtimes (s)
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] _compile.<locals>.compile_inner, 23.4781
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] OutputGraph.call_user_compiler, 22.0322
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] create_aot_dispatcher_function, 23.3993
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] compile_fx.<locals>.fw_compiler_base, 12.7951
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] GraphLowering.run, 3.8677
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] GraphLowering.compile_to_module, 6.7949
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] Scheduler.__init__, 3.2249
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] Scheduler.codegen, 1.9957
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] WrapperCodeGen.generate, 0.1878
[2023-12-28 21:24:08,560] torch._dynamo.utils: [INFO] cudagraphify, 0.0029
