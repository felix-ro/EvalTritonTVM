2023-12-19 14:10:19 [INFO] [task_scheduler.cc:160] Initializing Task #2: "fused_nn_contrib_conv2d_NCHWc_add_1"
2023-12-19 14:10:19 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64), T.int64(512), T.int64(1), T.int64(1)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
2023-12-19 14:10:19 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2023-12-19 14:10:19 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)):
                with T.block("T_add"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 4, 2])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[32, 16])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v62 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v62)
2023-12-19 14:10:19 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(8)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(2) + oc_chunk_1 + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), oh_1 + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 4, 2])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[32, 16])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-12-19 14:10:19 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(1), T.int64(2), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(16)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(2) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(16) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 4, 2])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[32, 16])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-12-19 14:11:40 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-12-19 14:11:40 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-12-19 14:11:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1360eb18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xca70db8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbd9c268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x12e27f28)]: 0 failure(s)
2023-12-19 14:11:44 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2023-12-19 14:11:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1360eb18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xca70db8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbd9c268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x12e27f28)]: 0 failure(s)
2023-12-19 14:11:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1360eb18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xca70db8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbd9c268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x12e27f28)]: 0 failure(s)
2023-12-19 14:11:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1360eb18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xca70db8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbd9c268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x12e27f28)]: 0 failure(s)
2023-12-19 14:12:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x1360eb18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xca70db8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xbd9c268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x12e27f28)]: 0 failure(s)
2023-12-19 14:12:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9998  0.9985  0.9983  0.9982  0.9971  0.9968  0.9968  0.9960  0.9958  0.9958  0.9955  0.9951  0.9950  0.9945  0.9942  0.9940
[17 : 32]:	0.9939  0.9937  0.9934  0.9930  0.9929  0.9925  0.9924  0.9924  0.9917  0.9911  0.9895  0.9895  0.9889  0.9885  0.9869  0.9858
[33 : 48]:	0.9852  0.9842  0.9837  0.9824  0.9821  0.9820  0.9816  0.9815  0.9814  0.9813  0.9810  0.9792  0.9791  0.9782  0.9782  0.9779
[49 : 64]:	0.9766  0.9764  0.9762  0.9760  0.9755  0.9752  0.9752  0.9749  0.9747  0.9745  0.9742  0.9738  0.9737  0.9731  0.9728  0.9725
2023-12-19 14:12:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-12-19 14:12:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #1: GFLOPs: 22.0957. Time: 9310.4974 us. Best GFLOPs: 22.0957
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #2: GFLOPs: 20.8454. Time: 9868.9287 us. Best GFLOPs: 22.0957
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #3: GFLOPs: 14.7783. Time: 13920.5455 us. Best GFLOPs: 22.0957
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #4: GFLOPs: 8.0267. Time: 25629.5362 us. Best GFLOPs: 22.0957
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #5: GFLOPs: 12.9511. Time: 15884.4961 us. Best GFLOPs: 22.0957
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #6: GFLOPs: 12.0372. Time: 17090.5373 us. Best GFLOPs: 22.0957
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #7: GFLOPs: 23.4519. Time: 8772.0620 us. Best GFLOPs: 23.4519
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #8: GFLOPs: 20.1342. Time: 10217.4983 us. Best GFLOPs: 23.4519
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #9: GFLOPs: 33.9186. Time: 6065.1526 us. Best GFLOPs: 33.9186
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #10: GFLOPs: 12.8073. Time: 16062.8074 us. Best GFLOPs: 33.9186
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #11: GFLOPs: 32.8644. Time: 6259.7099 us. Best GFLOPs: 33.9186
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #12: GFLOPs: 8.8879. Time: 23146.2992 us. Best GFLOPs: 33.9186
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #13: GFLOPs: 25.1732. Time: 8172.2341 us. Best GFLOPs: 33.9186
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #14: GFLOPs: 77.3774. Time: 2658.6790 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #15: GFLOPs: 29.1363. Time: 7060.6669 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #16: GFLOPs: 32.0301. Time: 6422.7596 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #17: GFLOPs: 33.9426. Time: 6060.8596 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #18: GFLOPs: 70.9813. Time: 2898.2500 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #19: GFLOPs: 14.3576. Time: 14328.4350 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #20: GFLOPs: 38.4042. Time: 5356.7469 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #21: GFLOPs: 39.7792. Time: 5171.5921 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #22: GFLOPs: 25.2189. Time: 8157.4403 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #23: GFLOPs: 33.1749. Time: 6201.1198 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #24: GFLOPs: 8.0381. Time: 25593.1838 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #25: GFLOPs: 21.5605. Time: 9541.6041 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #26: GFLOPs: 24.0028. Time: 8570.7465 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #27: GFLOPs: 21.5422. Time: 9549.6972 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #28: GFLOPs: 11.2463. Time: 18292.4102 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #29: GFLOPs: 19.4917. Time: 10554.3019 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #30: GFLOPs: 47.6380. Time: 4318.4384 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #31: GFLOPs: 31.3099. Time: 6570.5004 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #32: GFLOPs: 50.7820. Time: 4051.0695 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #33: GFLOPs: 24.9705. Time: 8238.5692 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #34: GFLOPs: 27.1053. Time: 7589.7171 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #35: GFLOPs: 12.2263. Time: 16826.1591 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #36: GFLOPs: 6.8731. Time: 29931.4705 us. Best GFLOPs: 77.3774
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #37: GFLOPs: 153.8537. Time: 1337.1248 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #38: GFLOPs: 15.0060. Time: 13709.3019 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #39: GFLOPs: 46.7543. Time: 4400.0526 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #40: GFLOPs: 11.3207. Time: 18172.1736 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #41: GFLOPs: 20.7820. Time: 9899.0221 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #42: GFLOPs: 29.9810. Time: 6861.7339 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #43: GFLOPs: 43.6554. Time: 4712.3968 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #44: GFLOPs: 14.2533. Time: 14433.3009 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #45: GFLOPs: 30.1398. Time: 6825.5778 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #46: GFLOPs: 23.6038. Time: 8715.6245 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #47: GFLOPs: 11.6683. Time: 17630.8699 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #48: GFLOPs: 20.9896. Time: 9801.1063 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #49: GFLOPs: 21.2216. Time: 9693.9692 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #50: GFLOPs: 12.8680. Time: 15987.0719 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #51: GFLOPs: 16.8341. Time: 12220.5166 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #52: GFLOPs: 64.3471. Time: 3197.0625 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #53: GFLOPs: 39.0000. Time: 5274.9110 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #54: GFLOPs: 8.0409. Time: 25584.3305 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #55: GFLOPs: 15.4443. Time: 13320.2615 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #56: GFLOPs: 129.9518. Time: 1583.0612 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #57: GFLOPs: 13.8903. Time: 14810.4556 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #58: GFLOPs: 23.7491. Time: 8662.2927 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #59: GFLOPs: 19.6753. Time: 10455.8107 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #60: GFLOPs: 4.6216. Time: 44513.1833 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #61: GFLOPs: 26.3521. Time: 7806.6429 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #62: GFLOPs: 8.0192. Time: 25653.7123 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #63: GFLOPs: 27.0659. Time: 7600.7555 us. Best GFLOPs: 153.8537
2023-12-19 14:15:57 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #64: GFLOPs: 16.1734. Time: 12719.7750 us. Best GFLOPs: 153.8537
2023-12-20 15:07:31 [INFO] [task_scheduler.cc:160] Initializing Task #2: "fused_nn_contrib_conv2d_NCHWc_add_1"
2023-12-20 15:07:31 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64), T.int64(512), T.int64(1), T.int64(1)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
2023-12-20 15:07:31 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2023-12-20 15:07:31 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(8), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(4) + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)):
                with T.block("T_add"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 4])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[128, 4])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v62 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v62)
2023-12-20 15:07:31 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(8), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(4) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 4])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[128, 4])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-12-20 15:07:31 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(8), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(4) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(2), T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 4])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[128, 4])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-12-20 15:08:44 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-12-20 15:08:44 [INFO] [evolutionary_search.cc:715] Picked top 64 candidate(s) from database
2023-12-20 15:08:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xf630c78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x138182c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc46c0e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x153dae58)]: 0 failure(s)
2023-12-20 15:08:49 [INFO] [evolutionary_search.cc:723] Sampled 448 candidate(s)
2023-12-20 15:08:54 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xf630c78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x138182c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc46c0e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x153dae58)]: 0 failure(s)
2023-12-20 15:09:00 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xf630c78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x138182c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc46c0e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x153dae58)]: 0 failure(s)
2023-12-20 15:09:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xf630c78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x138182c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc46c0e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x153dae58)]: 0 failure(s)
2023-12-20 15:09:11 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xf630c78)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x138182c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc46c0e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x153dae58)]: 0 failure(s)
2023-12-20 15:09:12 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9995  0.9993  0.9989  0.9989  0.9987  0.9972  0.9972  0.9970  0.9959  0.9956  0.9950  0.9940  0.9933  0.9933  0.9923  0.9913
[17 : 32]:	0.9913  0.9912  0.9912  0.9911  0.9904  0.9886  0.9885  0.9882  0.9868  0.9863  0.9846  0.9840  0.9831  0.9824  0.9821  0.9818
[33 : 48]:	0.9814  0.9812  0.9802  0.9780  0.9776  0.9762  0.9760  0.9758  0.9758  0.9758  0.9751  0.9740  0.9740  0.9738  0.9737  0.9734
[49 : 64]:	0.9728  0.9726  0.9726  0.9725  0.9724  0.9721  0.9715  0.9712  0.9698  0.9692  0.9692  0.9692  0.9691  0.9684  0.9675  0.9673
2023-12-20 15:09:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-12-20 15:09:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #1: GFLOPs: 274.8454. Time: 748.4994 us. Best GFLOPs: 274.8454
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #2: GFLOPs: 33.2345. Time: 6190.0046 us. Best GFLOPs: 274.8454
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #3: GFLOPs: 69.5659. Time: 2957.2179 us. Best GFLOPs: 274.8454
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #4: GFLOPs: 84.2180. Time: 2442.7271 us. Best GFLOPs: 274.8454
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #5: GFLOPs: 122.1510. Time: 1684.1588 us. Best GFLOPs: 274.8454
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #6: GFLOPs: 126.4675. Time: 1626.6754 us. Best GFLOPs: 274.8454
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #7: GFLOPs: 302.1947. Time: 680.7585 us. Best GFLOPs: 302.1947
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #8: GFLOPs: 347.8095. Time: 591.4777 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #9: GFLOPs: 39.8308. Time: 5164.8823 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #10: GFLOPs: 61.2501. Time: 3358.7123 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #11: GFLOPs: 45.1495. Time: 4556.4516 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #12: GFLOPs: 54.1711. Time: 3797.6250 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #13: GFLOPs: 32.1724. Time: 6394.3489 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #14: GFLOPs: 234.8495. Time: 875.9720 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #15: GFLOPs: 50.9096. Time: 4040.9212 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #16: GFLOPs: 220.5041. Time: 932.9606 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #17: GFLOPs: 37.6180. Time: 5468.7059 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #18: GFLOPs: 95.8923. Time: 2145.3404 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #19: GFLOPs: 6.3916. Time: 32185.9968 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #20: GFLOPs: 12.1992. Time: 16863.4756 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #21: GFLOPs: 81.2281. Time: 2532.6398 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #22: GFLOPs: 54.8536. Time: 3750.3768 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #23: GFLOPs: 150.1404. Time: 1370.1951 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #24: GFLOPs: 18.4502. Time: 11150.1133 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #25: GFLOPs: 50.3313. Time: 4087.3494 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #26: GFLOPs: 15.5036. Time: 13269.2551 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #27: GFLOPs: 84.2103. Time: 2442.9513 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #28: GFLOPs: 57.5646. Time: 3573.7514 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #29: GFLOPs: 44.7831. Time: 4593.7282 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #30: GFLOPs: 64.2237. Time: 3203.2029 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #31: GFLOPs: 17.0801. Time: 12044.4939 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #32: GFLOPs: 81.2064. Time: 2533.3174 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #33: GFLOPs: 174.5328. Time: 1178.6990 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #34: GFLOPs: 69.2858. Time: 2969.1725 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #35: GFLOPs: 69.3074. Time: 2968.2479 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #36: GFLOPs: 33.4970. Time: 6141.4888 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #37: GFLOPs: 62.9031. Time: 3270.4507 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #38: GFLOPs: 224.6907. Time: 915.5766 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #39: GFLOPs: 67.6186. Time: 3042.3816 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #40: GFLOPs: 70.9094. Time: 2901.1901 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #41: GFLOPs: 118.8594. Time: 1730.7978 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #42: GFLOPs: 45.6831. Time: 4503.2312 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #43: GFLOPs: 1.5464. Time: 133031.5817 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #44: GFLOPs: 42.4114. Time: 4850.6173 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #45: GFLOPs: 101.4539. Time: 2027.7350 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #46: GFLOPs: 180.3657. Time: 1140.5802 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #47: GFLOPs: 70.8488. Time: 2903.6689 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #48: GFLOPs: 43.6639. Time: 4711.4776 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #49: GFLOPs: 40.6553. Time: 5060.1375 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #50: GFLOPs: 139.9295. Time: 1470.1801 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #51: GFLOPs: 11.2108. Time: 18350.3422 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #52: GFLOPs: 12.9842. Time: 15843.9969 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #53: GFLOPs: 29.9193. Time: 6875.8847 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #54: GFLOPs: 24.2893. Time: 8469.6528 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #55: GFLOPs: 47.3184. Time: 4347.5990 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #56: GFLOPs: 37.1899. Time: 5531.6499 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #57: GFLOPs: 209.1758. Time: 983.4868 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #58: GFLOPs: 56.1975. Time: 3660.6922 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #59: GFLOPs: 50.8719. Time: 4043.9154 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #60: GFLOPs: 214.4662. Time: 959.2260 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #61: GFLOPs: 65.9598. Time: 3118.8951 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #62: GFLOPs: 153.9218. Time: 1336.5335 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #63: GFLOPs: 63.4582. Time: 3241.8427 us. Best GFLOPs: 347.8095
2023-12-20 15:12:16 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #64: GFLOPs: 12.2926. Time: 16735.4388 us. Best GFLOPs: 347.8095
2023-12-20 15:27:19 [INFO] [task_scheduler.cc:160] Initializing Task #2: "fused_nn_contrib_conv2d_NCHWc_add_1"
2023-12-20 15:27:19 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64), T.int64(512), T.int64(1), T.int64(1)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
2023-12-20 15:27:19 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2023-12-20 15:27:19 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(7), T.int64(2)):
                with T.block("conv2d_NCHWc"):
                    v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                    T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    with T.init():
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)):
                with T.block("T_add"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 4, 2])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[32, 16])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v62 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v62)
2023-12-20 15:27:19 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(7), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(7), T.int64(8)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 4, 2])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[32, 16])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-12-20 15:27:19 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(28), T.int64(28), T.int64(512)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(512), T.int64(64)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(64)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 256, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(64)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(7), T.int64(2)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(512), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(1), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)], p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + p0[v_n, v_ic // T.int64(512), v_oh * T.int64(2) + v_kh, v_ow * T.int64(2) + v_kw, v_ic % T.int64(512)] * p1[v_oc_chunk, v_ic // T.int64(512), v_kh, v_kw, v_ic % T.int64(512), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(14), T.int64(32)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(64), oc_block_0 * T.int64(32) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l2, l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b0)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l2, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l22, l23, l24, l25 = sch.split(loop=l3, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l30, l31, l32, l33 = sch.split(loop=l4, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l38, l39, l40, l41 = sch.split(loop=l5, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 4, 4, 2])
l46, l47, l48, l49 = sch.split(loop=l6, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[32, 16])
l52, l53 = sch.split(loop=l7, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])
l56, l57 = sch.split(loop=l8, factors=[v54, v55], preserve_unit_iters=True)
v58, v59 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])
l60, l61 = sch.split(loop=l9, factors=[v58, v59], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l60, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49)
b62, = sch.get_consumers(block=b0)
sch.reverse_compute_at(block=b62, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=256)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v63 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v63)
2023-12-20 15:28:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-12-20 15:28:28 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-12-20 15:28:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x197d29c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xfc84c38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1c9eafe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x13eb9888)]: 0 failure(s)
2023-12-20 15:28:32 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2023-12-20 15:28:37 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x197d29c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xfc84c38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1c9eafe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x13eb9888)]: 0 failure(s)
2023-12-20 15:28:42 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x197d29c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xfc84c38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1c9eafe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x13eb9888)]: 0 failure(s)
2023-12-20 15:28:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x197d29c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xfc84c38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1c9eafe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x13eb9888)]: 0 failure(s)
2023-12-20 15:28:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x197d29c8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xfc84c38)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x1c9eafe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x13eb9888)]: 0 failure(s)
2023-12-20 15:28:54 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9998  0.9993  0.9989  0.9980  0.9976  0.9974  0.9953  0.9947  0.9941  0.9938  0.9938  0.9935  0.9934  0.9917  0.9917  0.9912
[17 : 32]:	0.9908  0.9908  0.9904  0.9894  0.9890  0.9887  0.9886  0.9882  0.9851  0.9847  0.9846  0.9845  0.9832  0.9827  0.9822  0.9809
[33 : 48]:	0.9807  0.9801  0.9800  0.9799  0.9782  0.9773  0.9769  0.9769  0.9766  0.9762  0.9757  0.9756  0.9748  0.9742  0.9742  0.9737
[49 : 64]:	0.9736  0.9736  0.9732  0.9721  0.9719  0.9713  0.9713  0.9710  0.9701  0.9697  0.9692  0.9688  0.9687  0.9684  0.9682  0.9678
2023-12-20 15:28:55 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-12-20 15:28:55 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #1: GFLOPs: 80.7525. Time: 2547.5585 us. Best GFLOPs: 80.7525
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #2: GFLOPs: 103.5851. Time: 1986.0154 us. Best GFLOPs: 103.5851
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #3: GFLOPs: 118.6733. Time: 1733.5127 us. Best GFLOPs: 118.6733
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #4: GFLOPs: 61.4189. Time: 3349.4819 us. Best GFLOPs: 118.6733
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #5: GFLOPs: 0.6129. Time: 335651.9173 us. Best GFLOPs: 118.6733
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #6: GFLOPs: 26.2713. Time: 7830.6546 us. Best GFLOPs: 118.6733
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #7: GFLOPs: 194.0006. Time: 1060.4173 us. Best GFLOPs: 194.0006
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #8: GFLOPs: 200.7966. Time: 1024.5276 us. Best GFLOPs: 200.7966
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #9: GFLOPs: 85.3086. Time: 2411.4980 us. Best GFLOPs: 200.7966
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #10: GFLOPs: 29.7366. Time: 6918.1334 us. Best GFLOPs: 200.7966
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #11: GFLOPs: 24.3327. Time: 8454.5473 us. Best GFLOPs: 200.7966
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #12: GFLOPs: 23.6347. Time: 8704.2306 us. Best GFLOPs: 200.7966
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #13: GFLOPs: 103.5593. Time: 1986.5100 us. Best GFLOPs: 200.7966
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #14: GFLOPs: 6.5462. Time: 31426.0763 us. Best GFLOPs: 200.7966
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #15: GFLOPs: 1.6368. Time: 125688.7390 us. Best GFLOPs: 200.7966
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #16: GFLOPs: 221.3153. Time: 929.5407 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #17: GFLOPs: 50.5489. Time: 4069.7536 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #18: GFLOPs: 18.2933. Time: 11245.7108 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #19: GFLOPs: 171.8386. Time: 1197.1789 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #20: GFLOPs: 110.1609. Time: 1867.4654 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #21: GFLOPs: 83.3721. Time: 2467.5103 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #22: GFLOPs: 78.0288. Time: 2636.4835 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #23: GFLOPs: 113.8899. Time: 1806.3200 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #24: GFLOPs: 74.3703. Time: 2766.1813 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #25: GFLOPs: 107.6020. Time: 1911.8751 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #26: GFLOPs: 0.4439. Time: 463440.5150 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #27: GFLOPs: 43.5976. Time: 4718.6403 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #28: GFLOPs: 85.7579. Time: 2398.8644 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #29: GFLOPs: 33.4045. Time: 6158.4935 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #30: GFLOPs: 97.7115. Time: 2105.3972 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #31: GFLOPs: 33.9351. Time: 6062.1998 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #32: GFLOPs: 42.9303. Time: 4791.9919 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #33: GFLOPs: 3.4679. Time: 59321.9680 us. Best GFLOPs: 221.3153
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #34: GFLOPs: 232.6783. Time: 884.1461 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #35: GFLOPs: 71.4389. Time: 2879.6854 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #36: GFLOPs: 45.3201. Time: 4539.3015 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #37: GFLOPs: 41.8589. Time: 4914.6478 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #38: GFLOPs: 53.0895. Time: 3874.9984 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #39: GFLOPs: 71.3727. Time: 2882.3568 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #40: GFLOPs: 11.4683. Time: 17938.2625 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #41: GFLOPs: 46.7986. Time: 4395.8969 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #42: GFLOPs: 23.2723. Time: 8839.7509 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #43: GFLOPs: 24.3008. Time: 8465.6349 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #44: GFLOPs: 83.6140. Time: 2460.3731 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #45: GFLOPs: 7.9578. Time: 25851.4132 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #46: GFLOPs: 70.7171. Time: 2909.0798 us. Best GFLOPs: 232.6783
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #47: GFLOPs: 282.8995. Time: 727.1898 us. Best GFLOPs: 282.8995
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #48: GFLOPs: 50.2666. Time: 4092.6116 us. Best GFLOPs: 282.8995
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #49: GFLOPs: 334.9309. Time: 614.2210 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #50: GFLOPs: 49.7380. Time: 4136.1032 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #51: GFLOPs: 60.9776. Time: 3373.7230 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #52: GFLOPs: 81.0826. Time: 2537.1848 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #53: GFLOPs: 89.6966. Time: 2293.5268 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #54: GFLOPs: 33.6178. Time: 6119.4324 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #55: GFLOPs: 89.9265. Time: 2287.6630 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #56: GFLOPs: 55.3528. Time: 3716.5510 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #57: GFLOPs: 29.2895. Time: 7023.7247 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #58: GFLOPs: 58.8267. Time: 3497.0802 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #59: GFLOPs: 114.0309. Time: 1804.0862 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #60: GFLOPs: 32.2451. Time: 6379.9265 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #61: GFLOPs: 73.2708. Time: 2807.6886 us. Best GFLOPs: 334.9309
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #62: GFLOPs: 481.3765. Time: 427.3611 us. Best GFLOPs: 481.3765
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #63: GFLOPs: 25.9523. Time: 7926.9267 us. Best GFLOPs: 481.3765
2023-12-20 15:31:43 [INFO] [task_scheduler.cc:131] [Task #2: fused_nn_contrib_conv2d_NCHWc_add_1] Trial #64: GFLOPs: 73.2371. Time: 2808.9815 us. Best GFLOPs: 481.3765
