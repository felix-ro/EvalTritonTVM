[aot_autograd.py:2815 INFO] TRACED GRAPH
 ===== Joint graph 28 =====
 <eval_with_key>.299 from /usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py:477 in wrapped class joint_helper(torch.nn.Module):
    def forward(self, primals, tangents):
        primals_1: f32[64, 3, 7, 7], primals_2: f32[64], primals_3: f32[64], primals_4: f32[64, 64, 1, 1], primals_5: f32[64], primals_6: f32[64], primals_7: f32[64, 64, 3, 3], primals_8: f32[64], primals_9: f32[64], primals_10: f32[256, 64, 1, 1], primals_11: f32[256], primals_12: f32[256], primals_13: f32[256, 64, 1, 1], primals_14: f32[256], primals_15: f32[256], primals_16: f32[64, 256, 1, 1], primals_17: f32[64], primals_18: f32[64], primals_19: f32[64, 64, 3, 3], primals_20: f32[64], primals_21: f32[64], primals_22: f32[256, 64, 1, 1], primals_23: f32[256], primals_24: f32[256], primals_25: f32[64, 256, 1, 1], primals_26: f32[64], primals_27: f32[64], primals_28: f32[64, 64, 3, 3], primals_29: f32[64], primals_30: f32[64], primals_31: f32[256, 64, 1, 1], primals_32: f32[256], primals_33: f32[256], primals_34: f32[128, 256, 1, 1], primals_35: f32[128], primals_36: f32[128], primals_37: f32[128, 128, 3, 3], primals_38: f32[128], primals_39: f32[128], primals_40: f32[512, 128, 1, 1], primals_41: f32[512], primals_42: f32[512], primals_43: f32[512, 256, 1, 1], primals_44: f32[512], primals_45: f32[512], primals_46: f32[128, 512, 1, 1], primals_47: f32[128], primals_48: f32[128], primals_49: f32[128, 128, 3, 3], primals_50: f32[128], primals_51: f32[128], primals_52: f32[512, 128, 1, 1], primals_53: f32[512], primals_54: f32[512], primals_55: f32[128, 512, 1, 1], primals_56: f32[128], primals_57: f32[128], primals_58: f32[128, 128, 3, 3], primals_59: f32[128], primals_60: f32[128], primals_61: f32[512, 128, 1, 1], primals_62: f32[512], primals_63: f32[512], primals_64: f32[128, 512, 1, 1], primals_65: f32[128], primals_66: f32[128], primals_67: f32[128, 128, 3, 3], primals_68: f32[128], primals_69: f32[128], primals_70: f32[512, 128, 1, 1], primals_71: f32[512], primals_72: f32[512], primals_73: f32[256, 512, 1, 1], primals_74: f32[256], primals_75: f32[256], primals_76: f32[256, 256, 3, 3], primals_77: f32[256], primals_78: f32[256], primals_79: f32[1024, 256, 1, 1], primals_80: f32[1024], primals_81: f32[1024], primals_82: f32[1024, 512, 1, 1], primals_83: f32[1024], primals_84: f32[1024], primals_85: f32[256, 1024, 1, 1], primals_86: f32[256], primals_87: f32[256], primals_88: f32[256, 256, 3, 3], primals_89: f32[256], primals_90: f32[256], primals_91: f32[1024, 256, 1, 1], primals_92: f32[1024], primals_93: f32[1024], primals_94: f32[256, 1024, 1, 1], primals_95: f32[256], primals_96: f32[256], primals_97: f32[256, 256, 3, 3], primals_98: f32[256], primals_99: f32[256], primals_100: f32[1024, 256, 1, 1], primals_101: f32[1024], primals_102: f32[1024], primals_103: f32[256, 1024, 1, 1], primals_104: f32[256], primals_105: f32[256], primals_106: f32[256, 256, 3, 3], primals_107: f32[256], primals_108: f32[256], primals_109: f32[1024, 256, 1, 1], primals_110: f32[1024], primals_111: f32[1024], primals_112: f32[256, 1024, 1, 1], primals_113: f32[256], primals_114: f32[256], primals_115: f32[256, 256, 3, 3], primals_116: f32[256], primals_117: f32[256], primals_118: f32[1024, 256, 1, 1], primals_119: f32[1024], primals_120: f32[1024], primals_121: f32[256, 1024, 1, 1], primals_122: f32[256], primals_123: f32[256], primals_124: f32[256, 256, 3, 3], primals_125: f32[256], primals_126: f32[256], primals_127: f32[1024, 256, 1, 1], primals_128: f32[1024], primals_129: f32[1024], primals_130: f32[512, 1024, 1, 1], primals_131: f32[512], primals_132: f32[512], primals_133: f32[512, 512, 3, 3], primals_134: f32[512], primals_135: f32[512], primals_136: f32[2048, 512, 1, 1], primals_137: f32[2048], primals_138: f32[2048], primals_139: f32[2048, 1024, 1, 1], primals_140: f32[2048], primals_141: f32[2048], primals_142: f32[512, 2048, 1, 1], primals_143: f32[512], primals_144: f32[512], primals_145: f32[512, 512, 3, 3], primals_146: f32[512], primals_147: f32[512], primals_148: f32[2048, 512, 1, 1], primals_149: f32[2048], primals_150: f32[2048], primals_151: f32[512, 2048, 1, 1], primals_152: f32[512], primals_153: f32[512], primals_154: f32[512, 512, 3, 3], primals_155: f32[512], primals_156: f32[512], primals_157: f32[2048, 512, 1, 1], primals_158: f32[2048], primals_159: f32[2048], primals_160: f32[1000, 2048], primals_161: f32[1000], primals_162: f32[64], primals_163: f32[64], primals_164: i64[], primals_165: f32[64], primals_166: f32[64], primals_167: i64[], primals_168: f32[64], primals_169: f32[64], primals_170: i64[], primals_171: f32[256], primals_172: f32[256], primals_173: i64[], primals_174: f32[256], primals_175: f32[256], primals_176: i64[], primals_177: f32[64], primals_178: f32[64], primals_179: i64[], primals_180: f32[64], primals_181: f32[64], primals_182: i64[], primals_183: f32[256], primals_184: f32[256], primals_185: i64[], primals_186: f32[64], primals_187: f32[64], primals_188: i64[], primals_189: f32[64], primals_190: f32[64], primals_191: i64[], primals_192: f32[256], primals_193: f32[256], primals_194: i64[], primals_195: f32[128], primals_196: f32[128], primals_197: i64[], primals_198: f32[128], primals_199: f32[128], primals_200: i64[], primals_201: f32[512], primals_202: f32[512], primals_203: i64[], primals_204: f32[512], primals_205: f32[512], primals_206: i64[], primals_207: f32[128], primals_208: f32[128], primals_209: i64[], primals_210: f32[128], primals_211: f32[128], primals_212: i64[], primals_213: f32[512], primals_214: f32[512], primals_215: i64[], primals_216: f32[128], primals_217: f32[128], primals_218: i64[], primals_219: f32[128], primals_220: f32[128], primals_221: i64[], primals_222: f32[512], primals_223: f32[512], primals_224: i64[], primals_225: f32[128], primals_226: f32[128], primals_227: i64[], primals_228: f32[128], primals_229: f32[128], primals_230: i64[], primals_231: f32[512], primals_232: f32[512], primals_233: i64[], primals_234: f32[256], primals_235: f32[256], primals_236: i64[], primals_237: f32[256], primals_238: f32[256], primals_239: i64[], primals_240: f32[1024], primals_241: f32[1024], primals_242: i64[], primals_243: f32[1024], primals_244: f32[1024], primals_245: i64[], primals_246: f32[256], primals_247: f32[256], primals_248: i64[], primals_249: f32[256], primals_250: f32[256], primals_251: i64[], primals_252: f32[1024], primals_253: f32[1024], primals_254: i64[], primals_255: f32[256], primals_256: f32[256], primals_257: i64[], primals_258: f32[256], primals_259: f32[256], primals_260: i64[], primals_261: f32[1024], primals_262: f32[1024], primals_263: i64[], primals_264: f32[256], primals_265: f32[256], primals_266: i64[], primals_267: f32[256], primals_268: f32[256], primals_269: i64[], primals_270: f32[1024], primals_271: f32[1024], primals_272: i64[], primals_273: f32[256], primals_274: f32[256], primals_275: i64[], primals_276: f32[256], primals_277: f32[256], primals_278: i64[], primals_279: f32[1024], primals_280: f32[1024], primals_281: i64[], primals_282: f32[256], primals_283: f32[256], primals_284: i64[], primals_285: f32[256], primals_286: f32[256], primals_287: i64[], primals_288: f32[1024], primals_289: f32[1024], primals_290: i64[], primals_291: f32[512], primals_292: f32[512], primals_293: i64[], primals_294: f32[512], primals_295: f32[512], primals_296: i64[], primals_297: f32[2048], primals_298: f32[2048], primals_299: i64[], primals_300: f32[2048], primals_301: f32[2048], primals_302: i64[], primals_303: f32[512], primals_304: f32[512], primals_305: i64[], primals_306: f32[512], primals_307: f32[512], primals_308: i64[], primals_309: f32[2048], primals_310: f32[2048], primals_311: i64[], primals_312: f32[512], primals_313: f32[512], primals_314: i64[], primals_315: f32[512], primals_316: f32[512], primals_317: i64[], primals_318: f32[2048], primals_319: f32[2048], primals_320: i64[], primals_321: f32[1, 3, 64, 64], tangents_1: f32[64], tangents_2: f32[64], tangents_3: i64[], tangents_4: f32[64], tangents_5: f32[64], tangents_6: i64[], tangents_7: f32[64], tangents_8: f32[64], tangents_9: i64[], tangents_10: f32[256], tangents_11: f32[256], tangents_12: i64[], tangents_13: f32[256], tangents_14: f32[256], tangents_15: i64[], tangents_16: f32[64], tangents_17: f32[64], tangents_18: i64[], tangents_19: f32[64], tangents_20: f32[64], tangents_21: i64[], tangents_22: f32[256], tangents_23: f32[256], tangents_24: i64[], tangents_25: f32[64], tangents_26: f32[64], tangents_27: i64[], tangents_28: f32[64], tangents_29: f32[64], tangents_30: i64[], tangents_31: f32[256], tangents_32: f32[256], tangents_33: i64[], tangents_34: f32[128], tangents_35: f32[128], tangents_36: i64[], tangents_37: f32[128], tangents_38: f32[128], tangents_39: i64[], tangents_40: f32[512], tangents_41: f32[512], tangents_42: i64[], tangents_43: f32[512], tangents_44: f32[512], tangents_45: i64[], tangents_46: f32[128], tangents_47: f32[128], tangents_48: i64[], tangents_49: f32[128], tangents_50: f32[128], tangents_51: i64[], tangents_52: f32[512], tangents_53: f32[512], tangents_54: i64[], tangents_55: f32[128], tangents_56: f32[128], tangents_57: i64[], tangents_58: f32[128], tangents_59: f32[128], tangents_60: i64[], tangents_61: f32[512], tangents_62: f32[512], tangents_63: i64[], tangents_64: f32[128], tangents_65: f32[128], tangents_66: i64[], tangents_67: f32[128], tangents_68: f32[128], tangents_69: i64[], tangents_70: f32[512], tangents_71: f32[512], tangents_72: i64[], tangents_73: f32[256], tangents_74: f32[256], tangents_75: i64[], tangents_76: f32[256], tangents_77: f32[256], tangents_78: i64[], tangents_79: f32[1024], tangents_80: f32[1024], tangents_81: i64[], tangents_82: f32[1024], tangents_83: f32[1024], tangents_84: i64[], tangents_85: f32[256], tangents_86: f32[256], tangents_87: i64[], tangents_88: f32[256], tangents_89: f32[256], tangents_90: i64[], tangents_91: f32[1024], tangents_92: f32[1024], tangents_93: i64[], tangents_94: f32[256], tangents_95: f32[256], tangents_96: i64[], tangents_97: f32[256], tangents_98: f32[256], tangents_99: i64[], tangents_100: f32[1024], tangents_101: f32[1024], tangents_102: i64[], tangents_103: f32[256], tangents_104: f32[256], tangents_105: i64[], tangents_106: f32[256], tangents_107: f32[256], tangents_108: i64[], tangents_109: f32[1024], tangents_110: f32[1024], tangents_111: i64[], tangents_112: f32[256], tangents_113: f32[256], tangents_114: i64[], tangents_115: f32[256], tangents_116: f32[256], tangents_117: i64[], tangents_118: f32[1024], tangents_119: f32[1024], tangents_120: i64[], tangents_121: f32[256], tangents_122: f32[256], tangents_123: i64[], tangents_124: f32[256], tangents_125: f32[256], tangents_126: i64[], tangents_127: f32[1024], tangents_128: f32[1024], tangents_129: i64[], tangents_130: f32[512], tangents_131: f32[512], tangents_132: i64[], tangents_133: f32[512], tangents_134: f32[512], tangents_135: i64[], tangents_136: f32[2048], tangents_137: f32[2048], tangents_138: i64[], tangents_139: f32[2048], tangents_140: f32[2048], tangents_141: i64[], tangents_142: f32[512], tangents_143: f32[512], tangents_144: i64[], tangents_145: f32[512], tangents_146: f32[512], tangents_147: i64[], tangents_148: f32[2048], tangents_149: f32[2048], tangents_150: i64[], tangents_151: f32[512], tangents_152: f32[512], tangents_153: i64[], tangents_154: f32[512], tangents_155: f32[512], tangents_156: i64[], tangents_157: f32[2048], tangents_158: f32[2048], tangents_159: i64[], tangents_160: f32[1, 1000], = fx_pytree.tree_flatten_spec([primals, tangents], self._in_spec)
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:232, code: x = self.conv1(x)
        convolution: f32[1, 64, 32, 32] = torch.ops.aten.convolution.default(primals_321, primals_1, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:233, code: x = self.bn1(x)
        add: i64[] = torch.ops.aten.add.Tensor(primals_164, 1);  primals_164 = None
        var_mean = torch.ops.aten.var_mean.correction(convolution, [0, 2, 3], correction = 0, keepdim = True)
        getitem: f32[1, 64, 1, 1] = var_mean[0]
        getitem_1: f32[1, 64, 1, 1] = var_mean[1];  var_mean = None
        add_1: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem, 1e-05)
        rsqrt: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
        sub: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(convolution, getitem_1)
        mul: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
        squeeze: f32[64] = torch.ops.aten.squeeze.dims(getitem_1, [0, 2, 3]);  getitem_1 = None
        squeeze_1: f32[64] = torch.ops.aten.squeeze.dims(rsqrt, [0, 2, 3]);  rsqrt = None
        mul_1: f32[64] = torch.ops.aten.mul.Tensor(squeeze, 0.1)
        mul_2: f32[64] = torch.ops.aten.mul.Tensor(primals_162, 0.9);  primals_162 = None
        add_2: f32[64] = torch.ops.aten.add.Tensor(mul_1, mul_2);  mul_1 = mul_2 = None
        squeeze_2: f32[64] = torch.ops.aten.squeeze.dims(getitem, [0, 2, 3]);  getitem = None
        mul_3: f32[64] = torch.ops.aten.mul.Tensor(squeeze_2, 1.0009775171065494);  squeeze_2 = None
        mul_4: f32[64] = torch.ops.aten.mul.Tensor(mul_3, 0.1);  mul_3 = None
        mul_5: f32[64] = torch.ops.aten.mul.Tensor(primals_163, 0.9);  primals_163 = None
        add_3: f32[64] = torch.ops.aten.add.Tensor(mul_4, mul_5);  mul_4 = mul_5 = None
        unsqueeze: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_2, -1)
        unsqueeze_1: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze, -1);  unsqueeze = None
        mul_6: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(mul, unsqueeze_1);  mul = unsqueeze_1 = None
        unsqueeze_2: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_3, -1);  primals_3 = None
        unsqueeze_3: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_2, -1);  unsqueeze_2 = None
        add_4: f32[1, 64, 32, 32] = torch.ops.aten.add.Tensor(mul_6, unsqueeze_3);  mul_6 = unsqueeze_3 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:234, code: x = self.relu(x)
        relu: f32[1, 64, 32, 32] = torch.ops.aten.relu.default(add_4);  add_4 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:235, code: x = self.maxpool(x)
        max_pool2d_with_indices = torch.ops.aten.max_pool2d_with_indices.default(relu, [3, 3], [2, 2], [1, 1])
        getitem_2: f32[1, 64, 16, 16] = max_pool2d_with_indices[0]
        getitem_3: i64[1, 64, 16, 16] = max_pool2d_with_indices[1];  max_pool2d_with_indices = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_1: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(getitem_2, primals_4, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_5: i64[] = torch.ops.aten.add.Tensor(primals_167, 1);  primals_167 = None
        var_mean_1 = torch.ops.aten.var_mean.correction(convolution_1, [0, 2, 3], correction = 0, keepdim = True)
        getitem_4: f32[1, 64, 1, 1] = var_mean_1[0]
        getitem_5: f32[1, 64, 1, 1] = var_mean_1[1];  var_mean_1 = None
        add_6: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_4, 1e-05)
        rsqrt_1: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_6);  add_6 = None
        sub_1: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_1, getitem_5)
        mul_7: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_1, rsqrt_1);  sub_1 = None
        squeeze_3: f32[64] = torch.ops.aten.squeeze.dims(getitem_5, [0, 2, 3]);  getitem_5 = None
        squeeze_4: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_1, [0, 2, 3]);  rsqrt_1 = None
        mul_8: f32[64] = torch.ops.aten.mul.Tensor(squeeze_3, 0.1)
        mul_9: f32[64] = torch.ops.aten.mul.Tensor(primals_165, 0.9);  primals_165 = None
        add_7: f32[64] = torch.ops.aten.add.Tensor(mul_8, mul_9);  mul_8 = mul_9 = None
        squeeze_5: f32[64] = torch.ops.aten.squeeze.dims(getitem_4, [0, 2, 3]);  getitem_4 = None
        mul_10: f32[64] = torch.ops.aten.mul.Tensor(squeeze_5, 1.003921568627451);  squeeze_5 = None
        mul_11: f32[64] = torch.ops.aten.mul.Tensor(mul_10, 0.1);  mul_10 = None
        mul_12: f32[64] = torch.ops.aten.mul.Tensor(primals_166, 0.9);  primals_166 = None
        add_8: f32[64] = torch.ops.aten.add.Tensor(mul_11, mul_12);  mul_11 = mul_12 = None
        unsqueeze_4: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_5, -1)
        unsqueeze_5: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_4, -1);  unsqueeze_4 = None
        mul_13: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_7, unsqueeze_5);  mul_7 = unsqueeze_5 = None
        unsqueeze_6: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_6, -1);  primals_6 = None
        unsqueeze_7: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_6, -1);  unsqueeze_6 = None
        add_9: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_13, unsqueeze_7);  mul_13 = unsqueeze_7 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_1: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_9);  add_9 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_2: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_1, primals_7, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_10: i64[] = torch.ops.aten.add.Tensor(primals_170, 1);  primals_170 = None
        var_mean_2 = torch.ops.aten.var_mean.correction(convolution_2, [0, 2, 3], correction = 0, keepdim = True)
        getitem_6: f32[1, 64, 1, 1] = var_mean_2[0]
        getitem_7: f32[1, 64, 1, 1] = var_mean_2[1];  var_mean_2 = None
        add_11: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_6, 1e-05)
        rsqrt_2: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_11);  add_11 = None
        sub_2: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_2, getitem_7)
        mul_14: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_2, rsqrt_2);  sub_2 = None
        squeeze_6: f32[64] = torch.ops.aten.squeeze.dims(getitem_7, [0, 2, 3]);  getitem_7 = None
        squeeze_7: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_2, [0, 2, 3]);  rsqrt_2 = None
        mul_15: f32[64] = torch.ops.aten.mul.Tensor(squeeze_6, 0.1)
        mul_16: f32[64] = torch.ops.aten.mul.Tensor(primals_168, 0.9);  primals_168 = None
        add_12: f32[64] = torch.ops.aten.add.Tensor(mul_15, mul_16);  mul_15 = mul_16 = None
        squeeze_8: f32[64] = torch.ops.aten.squeeze.dims(getitem_6, [0, 2, 3]);  getitem_6 = None
        mul_17: f32[64] = torch.ops.aten.mul.Tensor(squeeze_8, 1.003921568627451);  squeeze_8 = None
        mul_18: f32[64] = torch.ops.aten.mul.Tensor(mul_17, 0.1);  mul_17 = None
        mul_19: f32[64] = torch.ops.aten.mul.Tensor(primals_169, 0.9);  primals_169 = None
        add_13: f32[64] = torch.ops.aten.add.Tensor(mul_18, mul_19);  mul_18 = mul_19 = None
        unsqueeze_8: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_8, -1)
        unsqueeze_9: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_8, -1);  unsqueeze_8 = None
        mul_20: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_14, unsqueeze_9);  mul_14 = unsqueeze_9 = None
        unsqueeze_10: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_9, -1);  primals_9 = None
        unsqueeze_11: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_10, -1);  unsqueeze_10 = None
        add_14: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_20, unsqueeze_11);  mul_20 = unsqueeze_11 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_2: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_14);  add_14 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_3: f32[1, 256, 16, 16] = torch.ops.aten.convolution.default(relu_2, primals_10, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_15: i64[] = torch.ops.aten.add.Tensor(primals_173, 1);  primals_173 = None
        var_mean_3 = torch.ops.aten.var_mean.correction(convolution_3, [0, 2, 3], correction = 0, keepdim = True)
        getitem_8: f32[1, 256, 1, 1] = var_mean_3[0]
        getitem_9: f32[1, 256, 1, 1] = var_mean_3[1];  var_mean_3 = None
        add_16: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_8, 1e-05)
        rsqrt_3: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
        sub_3: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_3, getitem_9)
        mul_21: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_3, rsqrt_3);  sub_3 = None
        squeeze_9: f32[256] = torch.ops.aten.squeeze.dims(getitem_9, [0, 2, 3]);  getitem_9 = None
        squeeze_10: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_3, [0, 2, 3]);  rsqrt_3 = None
        mul_22: f32[256] = torch.ops.aten.mul.Tensor(squeeze_9, 0.1)
        mul_23: f32[256] = torch.ops.aten.mul.Tensor(primals_171, 0.9);  primals_171 = None
        add_17: f32[256] = torch.ops.aten.add.Tensor(mul_22, mul_23);  mul_22 = mul_23 = None
        squeeze_11: f32[256] = torch.ops.aten.squeeze.dims(getitem_8, [0, 2, 3]);  getitem_8 = None
        mul_24: f32[256] = torch.ops.aten.mul.Tensor(squeeze_11, 1.003921568627451);  squeeze_11 = None
        mul_25: f32[256] = torch.ops.aten.mul.Tensor(mul_24, 0.1);  mul_24 = None
        mul_26: f32[256] = torch.ops.aten.mul.Tensor(primals_172, 0.9);  primals_172 = None
        add_18: f32[256] = torch.ops.aten.add.Tensor(mul_25, mul_26);  mul_25 = mul_26 = None
        unsqueeze_12: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_11, -1)
        unsqueeze_13: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_12, -1);  unsqueeze_12 = None
        mul_27: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(mul_21, unsqueeze_13);  mul_21 = unsqueeze_13 = None
        unsqueeze_14: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_12, -1);  primals_12 = None
        unsqueeze_15: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_14, -1);  unsqueeze_14 = None
        add_19: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(mul_27, unsqueeze_15);  mul_27 = unsqueeze_15 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        convolution_4: f32[1, 256, 16, 16] = torch.ops.aten.convolution.default(getitem_2, primals_13, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        add_20: i64[] = torch.ops.aten.add.Tensor(primals_176, 1);  primals_176 = None
        var_mean_4 = torch.ops.aten.var_mean.correction(convolution_4, [0, 2, 3], correction = 0, keepdim = True)
        getitem_10: f32[1, 256, 1, 1] = var_mean_4[0]
        getitem_11: f32[1, 256, 1, 1] = var_mean_4[1];  var_mean_4 = None
        add_21: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_10, 1e-05)
        rsqrt_4: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_21);  add_21 = None
        sub_4: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_4, getitem_11)
        mul_28: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_4, rsqrt_4);  sub_4 = None
        squeeze_12: f32[256] = torch.ops.aten.squeeze.dims(getitem_11, [0, 2, 3]);  getitem_11 = None
        squeeze_13: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_4, [0, 2, 3]);  rsqrt_4 = None
        mul_29: f32[256] = torch.ops.aten.mul.Tensor(squeeze_12, 0.1)
        mul_30: f32[256] = torch.ops.aten.mul.Tensor(primals_174, 0.9);  primals_174 = None
        add_22: f32[256] = torch.ops.aten.add.Tensor(mul_29, mul_30);  mul_29 = mul_30 = None
        squeeze_14: f32[256] = torch.ops.aten.squeeze.dims(getitem_10, [0, 2, 3]);  getitem_10 = None
        mul_31: f32[256] = torch.ops.aten.mul.Tensor(squeeze_14, 1.003921568627451);  squeeze_14 = None
        mul_32: f32[256] = torch.ops.aten.mul.Tensor(mul_31, 0.1);  mul_31 = None
        mul_33: f32[256] = torch.ops.aten.mul.Tensor(primals_175, 0.9);  primals_175 = None
        add_23: f32[256] = torch.ops.aten.add.Tensor(mul_32, mul_33);  mul_32 = mul_33 = None
        unsqueeze_16: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_14, -1)
        unsqueeze_17: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_16, -1);  unsqueeze_16 = None
        mul_34: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(mul_28, unsqueeze_17);  mul_28 = unsqueeze_17 = None
        unsqueeze_18: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_15, -1);  primals_15 = None
        unsqueeze_19: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_18, -1);  unsqueeze_18 = None
        add_24: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(mul_34, unsqueeze_19);  mul_34 = unsqueeze_19 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_25: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(add_19, add_24);  add_19 = add_24 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_3: f32[1, 256, 16, 16] = torch.ops.aten.relu.default(add_25);  add_25 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_5: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_3, primals_16, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_26: i64[] = torch.ops.aten.add.Tensor(primals_179, 1);  primals_179 = None
        var_mean_5 = torch.ops.aten.var_mean.correction(convolution_5, [0, 2, 3], correction = 0, keepdim = True)
        getitem_12: f32[1, 64, 1, 1] = var_mean_5[0]
        getitem_13: f32[1, 64, 1, 1] = var_mean_5[1];  var_mean_5 = None
        add_27: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_12, 1e-05)
        rsqrt_5: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_27);  add_27 = None
        sub_5: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_5, getitem_13)
        mul_35: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_5, rsqrt_5);  sub_5 = None
        squeeze_15: f32[64] = torch.ops.aten.squeeze.dims(getitem_13, [0, 2, 3]);  getitem_13 = None
        squeeze_16: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_5, [0, 2, 3]);  rsqrt_5 = None
        mul_36: f32[64] = torch.ops.aten.mul.Tensor(squeeze_15, 0.1)
        mul_37: f32[64] = torch.ops.aten.mul.Tensor(primals_177, 0.9);  primals_177 = None
        add_28: f32[64] = torch.ops.aten.add.Tensor(mul_36, mul_37);  mul_36 = mul_37 = None
        squeeze_17: f32[64] = torch.ops.aten.squeeze.dims(getitem_12, [0, 2, 3]);  getitem_12 = None
        mul_38: f32[64] = torch.ops.aten.mul.Tensor(squeeze_17, 1.003921568627451);  squeeze_17 = None
        mul_39: f32[64] = torch.ops.aten.mul.Tensor(mul_38, 0.1);  mul_38 = None
        mul_40: f32[64] = torch.ops.aten.mul.Tensor(primals_178, 0.9);  primals_178 = None
        add_29: f32[64] = torch.ops.aten.add.Tensor(mul_39, mul_40);  mul_39 = mul_40 = None
        unsqueeze_20: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_17, -1)
        unsqueeze_21: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_20, -1);  unsqueeze_20 = None
        mul_41: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_35, unsqueeze_21);  mul_35 = unsqueeze_21 = None
        unsqueeze_22: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_18, -1);  primals_18 = None
        unsqueeze_23: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_22, -1);  unsqueeze_22 = None
        add_30: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_41, unsqueeze_23);  mul_41 = unsqueeze_23 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_4: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_30);  add_30 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_6: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_4, primals_19, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_31: i64[] = torch.ops.aten.add.Tensor(primals_182, 1);  primals_182 = None
        var_mean_6 = torch.ops.aten.var_mean.correction(convolution_6, [0, 2, 3], correction = 0, keepdim = True)
        getitem_14: f32[1, 64, 1, 1] = var_mean_6[0]
        getitem_15: f32[1, 64, 1, 1] = var_mean_6[1];  var_mean_6 = None
        add_32: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_14, 1e-05)
        rsqrt_6: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_32);  add_32 = None
        sub_6: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_6, getitem_15)
        mul_42: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_6, rsqrt_6);  sub_6 = None
        squeeze_18: f32[64] = torch.ops.aten.squeeze.dims(getitem_15, [0, 2, 3]);  getitem_15 = None
        squeeze_19: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_6, [0, 2, 3]);  rsqrt_6 = None
        mul_43: f32[64] = torch.ops.aten.mul.Tensor(squeeze_18, 0.1)
        mul_44: f32[64] = torch.ops.aten.mul.Tensor(primals_180, 0.9);  primals_180 = None
        add_33: f32[64] = torch.ops.aten.add.Tensor(mul_43, mul_44);  mul_43 = mul_44 = None
        squeeze_20: f32[64] = torch.ops.aten.squeeze.dims(getitem_14, [0, 2, 3]);  getitem_14 = None
        mul_45: f32[64] = torch.ops.aten.mul.Tensor(squeeze_20, 1.003921568627451);  squeeze_20 = None
        mul_46: f32[64] = torch.ops.aten.mul.Tensor(mul_45, 0.1);  mul_45 = None
        mul_47: f32[64] = torch.ops.aten.mul.Tensor(primals_181, 0.9);  primals_181 = None
        add_34: f32[64] = torch.ops.aten.add.Tensor(mul_46, mul_47);  mul_46 = mul_47 = None
        unsqueeze_24: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_20, -1)
        unsqueeze_25: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_24, -1);  unsqueeze_24 = None
        mul_48: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_42, unsqueeze_25);  mul_42 = unsqueeze_25 = None
        unsqueeze_26: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_21, -1);  primals_21 = None
        unsqueeze_27: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_26, -1);  unsqueeze_26 = None
        add_35: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_48, unsqueeze_27);  mul_48 = unsqueeze_27 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_5: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_35);  add_35 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_7: f32[1, 256, 16, 16] = torch.ops.aten.convolution.default(relu_5, primals_22, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_36: i64[] = torch.ops.aten.add.Tensor(primals_185, 1);  primals_185 = None
        var_mean_7 = torch.ops.aten.var_mean.correction(convolution_7, [0, 2, 3], correction = 0, keepdim = True)
        getitem_16: f32[1, 256, 1, 1] = var_mean_7[0]
        getitem_17: f32[1, 256, 1, 1] = var_mean_7[1];  var_mean_7 = None
        add_37: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_16, 1e-05)
        rsqrt_7: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_37);  add_37 = None
        sub_7: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_7, getitem_17)
        mul_49: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_7, rsqrt_7);  sub_7 = None
        squeeze_21: f32[256] = torch.ops.aten.squeeze.dims(getitem_17, [0, 2, 3]);  getitem_17 = None
        squeeze_22: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_7, [0, 2, 3]);  rsqrt_7 = None
        mul_50: f32[256] = torch.ops.aten.mul.Tensor(squeeze_21, 0.1)
        mul_51: f32[256] = torch.ops.aten.mul.Tensor(primals_183, 0.9);  primals_183 = None
        add_38: f32[256] = torch.ops.aten.add.Tensor(mul_50, mul_51);  mul_50 = mul_51 = None
        squeeze_23: f32[256] = torch.ops.aten.squeeze.dims(getitem_16, [0, 2, 3]);  getitem_16 = None
        mul_52: f32[256] = torch.ops.aten.mul.Tensor(squeeze_23, 1.003921568627451);  squeeze_23 = None
        mul_53: f32[256] = torch.ops.aten.mul.Tensor(mul_52, 0.1);  mul_52 = None
        mul_54: f32[256] = torch.ops.aten.mul.Tensor(primals_184, 0.9);  primals_184 = None
        add_39: f32[256] = torch.ops.aten.add.Tensor(mul_53, mul_54);  mul_53 = mul_54 = None
        unsqueeze_28: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_23, -1)
        unsqueeze_29: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_28, -1);  unsqueeze_28 = None
        mul_55: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(mul_49, unsqueeze_29);  mul_49 = unsqueeze_29 = None
        unsqueeze_30: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_24, -1);  primals_24 = None
        unsqueeze_31: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_30, -1);  unsqueeze_30 = None
        add_40: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(mul_55, unsqueeze_31);  mul_55 = unsqueeze_31 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_41: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(add_40, relu_3);  add_40 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_6: f32[1, 256, 16, 16] = torch.ops.aten.relu.default(add_41);  add_41 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_8: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_6, primals_25, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_42: i64[] = torch.ops.aten.add.Tensor(primals_188, 1);  primals_188 = None
        var_mean_8 = torch.ops.aten.var_mean.correction(convolution_8, [0, 2, 3], correction = 0, keepdim = True)
        getitem_18: f32[1, 64, 1, 1] = var_mean_8[0]
        getitem_19: f32[1, 64, 1, 1] = var_mean_8[1];  var_mean_8 = None
        add_43: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_18, 1e-05)
        rsqrt_8: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_43);  add_43 = None
        sub_8: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_8, getitem_19)
        mul_56: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_8, rsqrt_8);  sub_8 = None
        squeeze_24: f32[64] = torch.ops.aten.squeeze.dims(getitem_19, [0, 2, 3]);  getitem_19 = None
        squeeze_25: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_8, [0, 2, 3]);  rsqrt_8 = None
        mul_57: f32[64] = torch.ops.aten.mul.Tensor(squeeze_24, 0.1)
        mul_58: f32[64] = torch.ops.aten.mul.Tensor(primals_186, 0.9);  primals_186 = None
        add_44: f32[64] = torch.ops.aten.add.Tensor(mul_57, mul_58);  mul_57 = mul_58 = None
        squeeze_26: f32[64] = torch.ops.aten.squeeze.dims(getitem_18, [0, 2, 3]);  getitem_18 = None
        mul_59: f32[64] = torch.ops.aten.mul.Tensor(squeeze_26, 1.003921568627451);  squeeze_26 = None
        mul_60: f32[64] = torch.ops.aten.mul.Tensor(mul_59, 0.1);  mul_59 = None
        mul_61: f32[64] = torch.ops.aten.mul.Tensor(primals_187, 0.9);  primals_187 = None
        add_45: f32[64] = torch.ops.aten.add.Tensor(mul_60, mul_61);  mul_60 = mul_61 = None
        unsqueeze_32: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_26, -1)
        unsqueeze_33: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_32, -1);  unsqueeze_32 = None
        mul_62: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_56, unsqueeze_33);  mul_56 = unsqueeze_33 = None
        unsqueeze_34: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_27, -1);  primals_27 = None
        unsqueeze_35: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_34, -1);  unsqueeze_34 = None
        add_46: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_62, unsqueeze_35);  mul_62 = unsqueeze_35 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_7: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_46);  add_46 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_9: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_7, primals_28, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_47: i64[] = torch.ops.aten.add.Tensor(primals_191, 1);  primals_191 = None
        var_mean_9 = torch.ops.aten.var_mean.correction(convolution_9, [0, 2, 3], correction = 0, keepdim = True)
        getitem_20: f32[1, 64, 1, 1] = var_mean_9[0]
        getitem_21: f32[1, 64, 1, 1] = var_mean_9[1];  var_mean_9 = None
        add_48: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_20, 1e-05)
        rsqrt_9: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_48);  add_48 = None
        sub_9: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_9, getitem_21)
        mul_63: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_9, rsqrt_9);  sub_9 = None
        squeeze_27: f32[64] = torch.ops.aten.squeeze.dims(getitem_21, [0, 2, 3]);  getitem_21 = None
        squeeze_28: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_9, [0, 2, 3]);  rsqrt_9 = None
        mul_64: f32[64] = torch.ops.aten.mul.Tensor(squeeze_27, 0.1)
        mul_65: f32[64] = torch.ops.aten.mul.Tensor(primals_189, 0.9);  primals_189 = None
        add_49: f32[64] = torch.ops.aten.add.Tensor(mul_64, mul_65);  mul_64 = mul_65 = None
        squeeze_29: f32[64] = torch.ops.aten.squeeze.dims(getitem_20, [0, 2, 3]);  getitem_20 = None
        mul_66: f32[64] = torch.ops.aten.mul.Tensor(squeeze_29, 1.003921568627451);  squeeze_29 = None
        mul_67: f32[64] = torch.ops.aten.mul.Tensor(mul_66, 0.1);  mul_66 = None
        mul_68: f32[64] = torch.ops.aten.mul.Tensor(primals_190, 0.9);  primals_190 = None
        add_50: f32[64] = torch.ops.aten.add.Tensor(mul_67, mul_68);  mul_67 = mul_68 = None
        unsqueeze_36: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_29, -1)
        unsqueeze_37: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_36, -1);  unsqueeze_36 = None
        mul_69: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_63, unsqueeze_37);  mul_63 = unsqueeze_37 = None
        unsqueeze_38: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_30, -1);  primals_30 = None
        unsqueeze_39: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_38, -1);  unsqueeze_38 = None
        add_51: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_69, unsqueeze_39);  mul_69 = unsqueeze_39 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_8: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_51);  add_51 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_10: f32[1, 256, 16, 16] = torch.ops.aten.convolution.default(relu_8, primals_31, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_52: i64[] = torch.ops.aten.add.Tensor(primals_194, 1);  primals_194 = None
        var_mean_10 = torch.ops.aten.var_mean.correction(convolution_10, [0, 2, 3], correction = 0, keepdim = True)
        getitem_22: f32[1, 256, 1, 1] = var_mean_10[0]
        getitem_23: f32[1, 256, 1, 1] = var_mean_10[1];  var_mean_10 = None
        add_53: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_22, 1e-05)
        rsqrt_10: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_53);  add_53 = None
        sub_10: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_10, getitem_23)
        mul_70: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_10, rsqrt_10);  sub_10 = None
        squeeze_30: f32[256] = torch.ops.aten.squeeze.dims(getitem_23, [0, 2, 3]);  getitem_23 = None
        squeeze_31: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_10, [0, 2, 3]);  rsqrt_10 = None
        mul_71: f32[256] = torch.ops.aten.mul.Tensor(squeeze_30, 0.1)
        mul_72: f32[256] = torch.ops.aten.mul.Tensor(primals_192, 0.9);  primals_192 = None
        add_54: f32[256] = torch.ops.aten.add.Tensor(mul_71, mul_72);  mul_71 = mul_72 = None
        squeeze_32: f32[256] = torch.ops.aten.squeeze.dims(getitem_22, [0, 2, 3]);  getitem_22 = None
        mul_73: f32[256] = torch.ops.aten.mul.Tensor(squeeze_32, 1.003921568627451);  squeeze_32 = None
        mul_74: f32[256] = torch.ops.aten.mul.Tensor(mul_73, 0.1);  mul_73 = None
        mul_75: f32[256] = torch.ops.aten.mul.Tensor(primals_193, 0.9);  primals_193 = None
        add_55: f32[256] = torch.ops.aten.add.Tensor(mul_74, mul_75);  mul_74 = mul_75 = None
        unsqueeze_40: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_32, -1)
        unsqueeze_41: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_40, -1);  unsqueeze_40 = None
        mul_76: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(mul_70, unsqueeze_41);  mul_70 = unsqueeze_41 = None
        unsqueeze_42: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_33, -1);  primals_33 = None
        unsqueeze_43: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_42, -1);  unsqueeze_42 = None
        add_56: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(mul_76, unsqueeze_43);  mul_76 = unsqueeze_43 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_57: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(add_56, relu_6);  add_56 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_9: f32[1, 256, 16, 16] = torch.ops.aten.relu.default(add_57);  add_57 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_11: f32[1, 128, 16, 16] = torch.ops.aten.convolution.default(relu_9, primals_34, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_58: i64[] = torch.ops.aten.add.Tensor(primals_197, 1);  primals_197 = None
        var_mean_11 = torch.ops.aten.var_mean.correction(convolution_11, [0, 2, 3], correction = 0, keepdim = True)
        getitem_24: f32[1, 128, 1, 1] = var_mean_11[0]
        getitem_25: f32[1, 128, 1, 1] = var_mean_11[1];  var_mean_11 = None
        add_59: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_24, 1e-05)
        rsqrt_11: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_59);  add_59 = None
        sub_11: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(convolution_11, getitem_25)
        mul_77: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(sub_11, rsqrt_11);  sub_11 = None
        squeeze_33: f32[128] = torch.ops.aten.squeeze.dims(getitem_25, [0, 2, 3]);  getitem_25 = None
        squeeze_34: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_11, [0, 2, 3]);  rsqrt_11 = None
        mul_78: f32[128] = torch.ops.aten.mul.Tensor(squeeze_33, 0.1)
        mul_79: f32[128] = torch.ops.aten.mul.Tensor(primals_195, 0.9);  primals_195 = None
        add_60: f32[128] = torch.ops.aten.add.Tensor(mul_78, mul_79);  mul_78 = mul_79 = None
        squeeze_35: f32[128] = torch.ops.aten.squeeze.dims(getitem_24, [0, 2, 3]);  getitem_24 = None
        mul_80: f32[128] = torch.ops.aten.mul.Tensor(squeeze_35, 1.003921568627451);  squeeze_35 = None
        mul_81: f32[128] = torch.ops.aten.mul.Tensor(mul_80, 0.1);  mul_80 = None
        mul_82: f32[128] = torch.ops.aten.mul.Tensor(primals_196, 0.9);  primals_196 = None
        add_61: f32[128] = torch.ops.aten.add.Tensor(mul_81, mul_82);  mul_81 = mul_82 = None
        unsqueeze_44: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_35, -1)
        unsqueeze_45: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_44, -1);  unsqueeze_44 = None
        mul_83: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(mul_77, unsqueeze_45);  mul_77 = unsqueeze_45 = None
        unsqueeze_46: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_36, -1);  primals_36 = None
        unsqueeze_47: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_46, -1);  unsqueeze_46 = None
        add_62: f32[1, 128, 16, 16] = torch.ops.aten.add.Tensor(mul_83, unsqueeze_47);  mul_83 = unsqueeze_47 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_10: f32[1, 128, 16, 16] = torch.ops.aten.relu.default(add_62);  add_62 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_12: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_10, primals_37, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_63: i64[] = torch.ops.aten.add.Tensor(primals_200, 1);  primals_200 = None
        var_mean_12 = torch.ops.aten.var_mean.correction(convolution_12, [0, 2, 3], correction = 0, keepdim = True)
        getitem_26: f32[1, 128, 1, 1] = var_mean_12[0]
        getitem_27: f32[1, 128, 1, 1] = var_mean_12[1];  var_mean_12 = None
        add_64: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_26, 1e-05)
        rsqrt_12: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_64);  add_64 = None
        sub_12: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_12, getitem_27)
        mul_84: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_12, rsqrt_12);  sub_12 = None
        squeeze_36: f32[128] = torch.ops.aten.squeeze.dims(getitem_27, [0, 2, 3]);  getitem_27 = None
        squeeze_37: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_12, [0, 2, 3]);  rsqrt_12 = None
        mul_85: f32[128] = torch.ops.aten.mul.Tensor(squeeze_36, 0.1)
        mul_86: f32[128] = torch.ops.aten.mul.Tensor(primals_198, 0.9);  primals_198 = None
        add_65: f32[128] = torch.ops.aten.add.Tensor(mul_85, mul_86);  mul_85 = mul_86 = None
        squeeze_38: f32[128] = torch.ops.aten.squeeze.dims(getitem_26, [0, 2, 3]);  getitem_26 = None
        mul_87: f32[128] = torch.ops.aten.mul.Tensor(squeeze_38, 1.0158730158730158);  squeeze_38 = None
        mul_88: f32[128] = torch.ops.aten.mul.Tensor(mul_87, 0.1);  mul_87 = None
        mul_89: f32[128] = torch.ops.aten.mul.Tensor(primals_199, 0.9);  primals_199 = None
        add_66: f32[128] = torch.ops.aten.add.Tensor(mul_88, mul_89);  mul_88 = mul_89 = None
        unsqueeze_48: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_38, -1)
        unsqueeze_49: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_48, -1);  unsqueeze_48 = None
        mul_90: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_84, unsqueeze_49);  mul_84 = unsqueeze_49 = None
        unsqueeze_50: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_39, -1);  primals_39 = None
        unsqueeze_51: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_50, -1);  unsqueeze_50 = None
        add_67: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_90, unsqueeze_51);  mul_90 = unsqueeze_51 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_11: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_67);  add_67 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_13: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_11, primals_40, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_68: i64[] = torch.ops.aten.add.Tensor(primals_203, 1);  primals_203 = None
        var_mean_13 = torch.ops.aten.var_mean.correction(convolution_13, [0, 2, 3], correction = 0, keepdim = True)
        getitem_28: f32[1, 512, 1, 1] = var_mean_13[0]
        getitem_29: f32[1, 512, 1, 1] = var_mean_13[1];  var_mean_13 = None
        add_69: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_28, 1e-05)
        rsqrt_13: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_69);  add_69 = None
        sub_13: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_13, getitem_29)
        mul_91: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_13, rsqrt_13);  sub_13 = None
        squeeze_39: f32[512] = torch.ops.aten.squeeze.dims(getitem_29, [0, 2, 3]);  getitem_29 = None
        squeeze_40: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_13, [0, 2, 3]);  rsqrt_13 = None
        mul_92: f32[512] = torch.ops.aten.mul.Tensor(squeeze_39, 0.1)
        mul_93: f32[512] = torch.ops.aten.mul.Tensor(primals_201, 0.9);  primals_201 = None
        add_70: f32[512] = torch.ops.aten.add.Tensor(mul_92, mul_93);  mul_92 = mul_93 = None
        squeeze_41: f32[512] = torch.ops.aten.squeeze.dims(getitem_28, [0, 2, 3]);  getitem_28 = None
        mul_94: f32[512] = torch.ops.aten.mul.Tensor(squeeze_41, 1.0158730158730158);  squeeze_41 = None
        mul_95: f32[512] = torch.ops.aten.mul.Tensor(mul_94, 0.1);  mul_94 = None
        mul_96: f32[512] = torch.ops.aten.mul.Tensor(primals_202, 0.9);  primals_202 = None
        add_71: f32[512] = torch.ops.aten.add.Tensor(mul_95, mul_96);  mul_95 = mul_96 = None
        unsqueeze_52: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_41, -1)
        unsqueeze_53: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_52, -1);  unsqueeze_52 = None
        mul_97: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_91, unsqueeze_53);  mul_91 = unsqueeze_53 = None
        unsqueeze_54: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_42, -1);  primals_42 = None
        unsqueeze_55: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_54, -1);  unsqueeze_54 = None
        add_72: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_97, unsqueeze_55);  mul_97 = unsqueeze_55 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        convolution_14: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_9, primals_43, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
        add_73: i64[] = torch.ops.aten.add.Tensor(primals_206, 1);  primals_206 = None
        var_mean_14 = torch.ops.aten.var_mean.correction(convolution_14, [0, 2, 3], correction = 0, keepdim = True)
        getitem_30: f32[1, 512, 1, 1] = var_mean_14[0]
        getitem_31: f32[1, 512, 1, 1] = var_mean_14[1];  var_mean_14 = None
        add_74: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_30, 1e-05)
        rsqrt_14: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_74);  add_74 = None
        sub_14: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_14, getitem_31)
        mul_98: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_14, rsqrt_14);  sub_14 = None
        squeeze_42: f32[512] = torch.ops.aten.squeeze.dims(getitem_31, [0, 2, 3]);  getitem_31 = None
        squeeze_43: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_14, [0, 2, 3]);  rsqrt_14 = None
        mul_99: f32[512] = torch.ops.aten.mul.Tensor(squeeze_42, 0.1)
        mul_100: f32[512] = torch.ops.aten.mul.Tensor(primals_204, 0.9);  primals_204 = None
        add_75: f32[512] = torch.ops.aten.add.Tensor(mul_99, mul_100);  mul_99 = mul_100 = None
        squeeze_44: f32[512] = torch.ops.aten.squeeze.dims(getitem_30, [0, 2, 3]);  getitem_30 = None
        mul_101: f32[512] = torch.ops.aten.mul.Tensor(squeeze_44, 1.0158730158730158);  squeeze_44 = None
        mul_102: f32[512] = torch.ops.aten.mul.Tensor(mul_101, 0.1);  mul_101 = None
        mul_103: f32[512] = torch.ops.aten.mul.Tensor(primals_205, 0.9);  primals_205 = None
        add_76: f32[512] = torch.ops.aten.add.Tensor(mul_102, mul_103);  mul_102 = mul_103 = None
        unsqueeze_56: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_44, -1)
        unsqueeze_57: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_56, -1);  unsqueeze_56 = None
        mul_104: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_98, unsqueeze_57);  mul_98 = unsqueeze_57 = None
        unsqueeze_58: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_45, -1);  primals_45 = None
        unsqueeze_59: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_58, -1);  unsqueeze_58 = None
        add_77: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_104, unsqueeze_59);  mul_104 = unsqueeze_59 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_78: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(add_72, add_77);  add_72 = add_77 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_12: f32[1, 512, 8, 8] = torch.ops.aten.relu.default(add_78);  add_78 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_15: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_12, primals_46, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_79: i64[] = torch.ops.aten.add.Tensor(primals_209, 1);  primals_209 = None
        var_mean_15 = torch.ops.aten.var_mean.correction(convolution_15, [0, 2, 3], correction = 0, keepdim = True)
        getitem_32: f32[1, 128, 1, 1] = var_mean_15[0]
        getitem_33: f32[1, 128, 1, 1] = var_mean_15[1];  var_mean_15 = None
        add_80: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_32, 1e-05)
        rsqrt_15: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_80);  add_80 = None
        sub_15: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_15, getitem_33)
        mul_105: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_15, rsqrt_15);  sub_15 = None
        squeeze_45: f32[128] = torch.ops.aten.squeeze.dims(getitem_33, [0, 2, 3]);  getitem_33 = None
        squeeze_46: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_15, [0, 2, 3]);  rsqrt_15 = None
        mul_106: f32[128] = torch.ops.aten.mul.Tensor(squeeze_45, 0.1)
        mul_107: f32[128] = torch.ops.aten.mul.Tensor(primals_207, 0.9);  primals_207 = None
        add_81: f32[128] = torch.ops.aten.add.Tensor(mul_106, mul_107);  mul_106 = mul_107 = None
        squeeze_47: f32[128] = torch.ops.aten.squeeze.dims(getitem_32, [0, 2, 3]);  getitem_32 = None
        mul_108: f32[128] = torch.ops.aten.mul.Tensor(squeeze_47, 1.0158730158730158);  squeeze_47 = None
        mul_109: f32[128] = torch.ops.aten.mul.Tensor(mul_108, 0.1);  mul_108 = None
        mul_110: f32[128] = torch.ops.aten.mul.Tensor(primals_208, 0.9);  primals_208 = None
        add_82: f32[128] = torch.ops.aten.add.Tensor(mul_109, mul_110);  mul_109 = mul_110 = None
        unsqueeze_60: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_47, -1)
        unsqueeze_61: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_60, -1);  unsqueeze_60 = None
        mul_111: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_105, unsqueeze_61);  mul_105 = unsqueeze_61 = None
        unsqueeze_62: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_48, -1);  primals_48 = None
        unsqueeze_63: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_62, -1);  unsqueeze_62 = None
        add_83: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_111, unsqueeze_63);  mul_111 = unsqueeze_63 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_13: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_83);  add_83 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_16: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_13, primals_49, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_84: i64[] = torch.ops.aten.add.Tensor(primals_212, 1);  primals_212 = None
        var_mean_16 = torch.ops.aten.var_mean.correction(convolution_16, [0, 2, 3], correction = 0, keepdim = True)
        getitem_34: f32[1, 128, 1, 1] = var_mean_16[0]
        getitem_35: f32[1, 128, 1, 1] = var_mean_16[1];  var_mean_16 = None
        add_85: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_34, 1e-05)
        rsqrt_16: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_85);  add_85 = None
        sub_16: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_16, getitem_35)
        mul_112: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_16, rsqrt_16);  sub_16 = None
        squeeze_48: f32[128] = torch.ops.aten.squeeze.dims(getitem_35, [0, 2, 3]);  getitem_35 = None
        squeeze_49: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_16, [0, 2, 3]);  rsqrt_16 = None
        mul_113: f32[128] = torch.ops.aten.mul.Tensor(squeeze_48, 0.1)
        mul_114: f32[128] = torch.ops.aten.mul.Tensor(primals_210, 0.9);  primals_210 = None
        add_86: f32[128] = torch.ops.aten.add.Tensor(mul_113, mul_114);  mul_113 = mul_114 = None
        squeeze_50: f32[128] = torch.ops.aten.squeeze.dims(getitem_34, [0, 2, 3]);  getitem_34 = None
        mul_115: f32[128] = torch.ops.aten.mul.Tensor(squeeze_50, 1.0158730158730158);  squeeze_50 = None
        mul_116: f32[128] = torch.ops.aten.mul.Tensor(mul_115, 0.1);  mul_115 = None
        mul_117: f32[128] = torch.ops.aten.mul.Tensor(primals_211, 0.9);  primals_211 = None
        add_87: f32[128] = torch.ops.aten.add.Tensor(mul_116, mul_117);  mul_116 = mul_117 = None
        unsqueeze_64: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_50, -1)
        unsqueeze_65: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_64, -1);  unsqueeze_64 = None
        mul_118: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_112, unsqueeze_65);  mul_112 = unsqueeze_65 = None
        unsqueeze_66: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_51, -1);  primals_51 = None
        unsqueeze_67: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_66, -1);  unsqueeze_66 = None
        add_88: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_118, unsqueeze_67);  mul_118 = unsqueeze_67 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_14: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_88);  add_88 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_17: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_14, primals_52, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_89: i64[] = torch.ops.aten.add.Tensor(primals_215, 1);  primals_215 = None
        var_mean_17 = torch.ops.aten.var_mean.correction(convolution_17, [0, 2, 3], correction = 0, keepdim = True)
        getitem_36: f32[1, 512, 1, 1] = var_mean_17[0]
        getitem_37: f32[1, 512, 1, 1] = var_mean_17[1];  var_mean_17 = None
        add_90: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_36, 1e-05)
        rsqrt_17: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_90);  add_90 = None
        sub_17: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_17, getitem_37)
        mul_119: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_17, rsqrt_17);  sub_17 = None
        squeeze_51: f32[512] = torch.ops.aten.squeeze.dims(getitem_37, [0, 2, 3]);  getitem_37 = None
        squeeze_52: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_17, [0, 2, 3]);  rsqrt_17 = None
        mul_120: f32[512] = torch.ops.aten.mul.Tensor(squeeze_51, 0.1)
        mul_121: f32[512] = torch.ops.aten.mul.Tensor(primals_213, 0.9);  primals_213 = None
        add_91: f32[512] = torch.ops.aten.add.Tensor(mul_120, mul_121);  mul_120 = mul_121 = None
        squeeze_53: f32[512] = torch.ops.aten.squeeze.dims(getitem_36, [0, 2, 3]);  getitem_36 = None
        mul_122: f32[512] = torch.ops.aten.mul.Tensor(squeeze_53, 1.0158730158730158);  squeeze_53 = None
        mul_123: f32[512] = torch.ops.aten.mul.Tensor(mul_122, 0.1);  mul_122 = None
        mul_124: f32[512] = torch.ops.aten.mul.Tensor(primals_214, 0.9);  primals_214 = None
        add_92: f32[512] = torch.ops.aten.add.Tensor(mul_123, mul_124);  mul_123 = mul_124 = None
        unsqueeze_68: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_53, -1)
        unsqueeze_69: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_68, -1);  unsqueeze_68 = None
        mul_125: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_119, unsqueeze_69);  mul_119 = unsqueeze_69 = None
        unsqueeze_70: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_54, -1);  primals_54 = None
        unsqueeze_71: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_70, -1);  unsqueeze_70 = None
        add_93: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_125, unsqueeze_71);  mul_125 = unsqueeze_71 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_94: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(add_93, relu_12);  add_93 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_15: f32[1, 512, 8, 8] = torch.ops.aten.relu.default(add_94);  add_94 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_18: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_15, primals_55, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_95: i64[] = torch.ops.aten.add.Tensor(primals_218, 1);  primals_218 = None
        var_mean_18 = torch.ops.aten.var_mean.correction(convolution_18, [0, 2, 3], correction = 0, keepdim = True)
        getitem_38: f32[1, 128, 1, 1] = var_mean_18[0]
        getitem_39: f32[1, 128, 1, 1] = var_mean_18[1];  var_mean_18 = None
        add_96: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_38, 1e-05)
        rsqrt_18: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_96);  add_96 = None
        sub_18: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_18, getitem_39)
        mul_126: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_18, rsqrt_18);  sub_18 = None
        squeeze_54: f32[128] = torch.ops.aten.squeeze.dims(getitem_39, [0, 2, 3]);  getitem_39 = None
        squeeze_55: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_18, [0, 2, 3]);  rsqrt_18 = None
        mul_127: f32[128] = torch.ops.aten.mul.Tensor(squeeze_54, 0.1)
        mul_128: f32[128] = torch.ops.aten.mul.Tensor(primals_216, 0.9);  primals_216 = None
        add_97: f32[128] = torch.ops.aten.add.Tensor(mul_127, mul_128);  mul_127 = mul_128 = None
        squeeze_56: f32[128] = torch.ops.aten.squeeze.dims(getitem_38, [0, 2, 3]);  getitem_38 = None
        mul_129: f32[128] = torch.ops.aten.mul.Tensor(squeeze_56, 1.0158730158730158);  squeeze_56 = None
        mul_130: f32[128] = torch.ops.aten.mul.Tensor(mul_129, 0.1);  mul_129 = None
        mul_131: f32[128] = torch.ops.aten.mul.Tensor(primals_217, 0.9);  primals_217 = None
        add_98: f32[128] = torch.ops.aten.add.Tensor(mul_130, mul_131);  mul_130 = mul_131 = None
        unsqueeze_72: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_56, -1)
        unsqueeze_73: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_72, -1);  unsqueeze_72 = None
        mul_132: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_126, unsqueeze_73);  mul_126 = unsqueeze_73 = None
        unsqueeze_74: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_57, -1);  primals_57 = None
        unsqueeze_75: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_74, -1);  unsqueeze_74 = None
        add_99: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_132, unsqueeze_75);  mul_132 = unsqueeze_75 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_16: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_99);  add_99 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_19: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_16, primals_58, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_100: i64[] = torch.ops.aten.add.Tensor(primals_221, 1);  primals_221 = None
        var_mean_19 = torch.ops.aten.var_mean.correction(convolution_19, [0, 2, 3], correction = 0, keepdim = True)
        getitem_40: f32[1, 128, 1, 1] = var_mean_19[0]
        getitem_41: f32[1, 128, 1, 1] = var_mean_19[1];  var_mean_19 = None
        add_101: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_40, 1e-05)
        rsqrt_19: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_101);  add_101 = None
        sub_19: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_19, getitem_41)
        mul_133: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_19, rsqrt_19);  sub_19 = None
        squeeze_57: f32[128] = torch.ops.aten.squeeze.dims(getitem_41, [0, 2, 3]);  getitem_41 = None
        squeeze_58: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_19, [0, 2, 3]);  rsqrt_19 = None
        mul_134: f32[128] = torch.ops.aten.mul.Tensor(squeeze_57, 0.1)
        mul_135: f32[128] = torch.ops.aten.mul.Tensor(primals_219, 0.9);  primals_219 = None
        add_102: f32[128] = torch.ops.aten.add.Tensor(mul_134, mul_135);  mul_134 = mul_135 = None
        squeeze_59: f32[128] = torch.ops.aten.squeeze.dims(getitem_40, [0, 2, 3]);  getitem_40 = None
        mul_136: f32[128] = torch.ops.aten.mul.Tensor(squeeze_59, 1.0158730158730158);  squeeze_59 = None
        mul_137: f32[128] = torch.ops.aten.mul.Tensor(mul_136, 0.1);  mul_136 = None
        mul_138: f32[128] = torch.ops.aten.mul.Tensor(primals_220, 0.9);  primals_220 = None
        add_103: f32[128] = torch.ops.aten.add.Tensor(mul_137, mul_138);  mul_137 = mul_138 = None
        unsqueeze_76: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_59, -1)
        unsqueeze_77: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_76, -1);  unsqueeze_76 = None
        mul_139: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_133, unsqueeze_77);  mul_133 = unsqueeze_77 = None
        unsqueeze_78: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_60, -1);  primals_60 = None
        unsqueeze_79: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_78, -1);  unsqueeze_78 = None
        add_104: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_139, unsqueeze_79);  mul_139 = unsqueeze_79 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_17: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_104);  add_104 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_20: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_17, primals_61, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_105: i64[] = torch.ops.aten.add.Tensor(primals_224, 1);  primals_224 = None
        var_mean_20 = torch.ops.aten.var_mean.correction(convolution_20, [0, 2, 3], correction = 0, keepdim = True)
        getitem_42: f32[1, 512, 1, 1] = var_mean_20[0]
        getitem_43: f32[1, 512, 1, 1] = var_mean_20[1];  var_mean_20 = None
        add_106: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_42, 1e-05)
        rsqrt_20: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_106);  add_106 = None
        sub_20: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_20, getitem_43)
        mul_140: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_20, rsqrt_20);  sub_20 = None
        squeeze_60: f32[512] = torch.ops.aten.squeeze.dims(getitem_43, [0, 2, 3]);  getitem_43 = None
        squeeze_61: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_20, [0, 2, 3]);  rsqrt_20 = None
        mul_141: f32[512] = torch.ops.aten.mul.Tensor(squeeze_60, 0.1)
        mul_142: f32[512] = torch.ops.aten.mul.Tensor(primals_222, 0.9);  primals_222 = None
        add_107: f32[512] = torch.ops.aten.add.Tensor(mul_141, mul_142);  mul_141 = mul_142 = None
        squeeze_62: f32[512] = torch.ops.aten.squeeze.dims(getitem_42, [0, 2, 3]);  getitem_42 = None
        mul_143: f32[512] = torch.ops.aten.mul.Tensor(squeeze_62, 1.0158730158730158);  squeeze_62 = None
        mul_144: f32[512] = torch.ops.aten.mul.Tensor(mul_143, 0.1);  mul_143 = None
        mul_145: f32[512] = torch.ops.aten.mul.Tensor(primals_223, 0.9);  primals_223 = None
        add_108: f32[512] = torch.ops.aten.add.Tensor(mul_144, mul_145);  mul_144 = mul_145 = None
        unsqueeze_80: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_62, -1)
        unsqueeze_81: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_80, -1);  unsqueeze_80 = None
        mul_146: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_140, unsqueeze_81);  mul_140 = unsqueeze_81 = None
        unsqueeze_82: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_63, -1);  primals_63 = None
        unsqueeze_83: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_82, -1);  unsqueeze_82 = None
        add_109: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_146, unsqueeze_83);  mul_146 = unsqueeze_83 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_110: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(add_109, relu_15);  add_109 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_18: f32[1, 512, 8, 8] = torch.ops.aten.relu.default(add_110);  add_110 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_21: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_18, primals_64, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_111: i64[] = torch.ops.aten.add.Tensor(primals_227, 1);  primals_227 = None
        var_mean_21 = torch.ops.aten.var_mean.correction(convolution_21, [0, 2, 3], correction = 0, keepdim = True)
        getitem_44: f32[1, 128, 1, 1] = var_mean_21[0]
        getitem_45: f32[1, 128, 1, 1] = var_mean_21[1];  var_mean_21 = None
        add_112: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_44, 1e-05)
        rsqrt_21: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_112);  add_112 = None
        sub_21: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_21, getitem_45)
        mul_147: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_21, rsqrt_21);  sub_21 = None
        squeeze_63: f32[128] = torch.ops.aten.squeeze.dims(getitem_45, [0, 2, 3]);  getitem_45 = None
        squeeze_64: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_21, [0, 2, 3]);  rsqrt_21 = None
        mul_148: f32[128] = torch.ops.aten.mul.Tensor(squeeze_63, 0.1)
        mul_149: f32[128] = torch.ops.aten.mul.Tensor(primals_225, 0.9);  primals_225 = None
        add_113: f32[128] = torch.ops.aten.add.Tensor(mul_148, mul_149);  mul_148 = mul_149 = None
        squeeze_65: f32[128] = torch.ops.aten.squeeze.dims(getitem_44, [0, 2, 3]);  getitem_44 = None
        mul_150: f32[128] = torch.ops.aten.mul.Tensor(squeeze_65, 1.0158730158730158);  squeeze_65 = None
        mul_151: f32[128] = torch.ops.aten.mul.Tensor(mul_150, 0.1);  mul_150 = None
        mul_152: f32[128] = torch.ops.aten.mul.Tensor(primals_226, 0.9);  primals_226 = None
        add_114: f32[128] = torch.ops.aten.add.Tensor(mul_151, mul_152);  mul_151 = mul_152 = None
        unsqueeze_84: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_65, -1)
        unsqueeze_85: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_84, -1);  unsqueeze_84 = None
        mul_153: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_147, unsqueeze_85);  mul_147 = unsqueeze_85 = None
        unsqueeze_86: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_66, -1);  primals_66 = None
        unsqueeze_87: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_86, -1);  unsqueeze_86 = None
        add_115: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_153, unsqueeze_87);  mul_153 = unsqueeze_87 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_19: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_115);  add_115 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_22: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_19, primals_67, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_116: i64[] = torch.ops.aten.add.Tensor(primals_230, 1);  primals_230 = None
        var_mean_22 = torch.ops.aten.var_mean.correction(convolution_22, [0, 2, 3], correction = 0, keepdim = True)
        getitem_46: f32[1, 128, 1, 1] = var_mean_22[0]
        getitem_47: f32[1, 128, 1, 1] = var_mean_22[1];  var_mean_22 = None
        add_117: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_46, 1e-05)
        rsqrt_22: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_117);  add_117 = None
        sub_22: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_22, getitem_47)
        mul_154: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_22, rsqrt_22);  sub_22 = None
        squeeze_66: f32[128] = torch.ops.aten.squeeze.dims(getitem_47, [0, 2, 3]);  getitem_47 = None
        squeeze_67: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_22, [0, 2, 3]);  rsqrt_22 = None
        mul_155: f32[128] = torch.ops.aten.mul.Tensor(squeeze_66, 0.1)
        mul_156: f32[128] = torch.ops.aten.mul.Tensor(primals_228, 0.9);  primals_228 = None
        add_118: f32[128] = torch.ops.aten.add.Tensor(mul_155, mul_156);  mul_155 = mul_156 = None
        squeeze_68: f32[128] = torch.ops.aten.squeeze.dims(getitem_46, [0, 2, 3]);  getitem_46 = None
        mul_157: f32[128] = torch.ops.aten.mul.Tensor(squeeze_68, 1.0158730158730158);  squeeze_68 = None
        mul_158: f32[128] = torch.ops.aten.mul.Tensor(mul_157, 0.1);  mul_157 = None
        mul_159: f32[128] = torch.ops.aten.mul.Tensor(primals_229, 0.9);  primals_229 = None
        add_119: f32[128] = torch.ops.aten.add.Tensor(mul_158, mul_159);  mul_158 = mul_159 = None
        unsqueeze_88: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_68, -1)
        unsqueeze_89: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_88, -1);  unsqueeze_88 = None
        mul_160: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_154, unsqueeze_89);  mul_154 = unsqueeze_89 = None
        unsqueeze_90: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_69, -1);  primals_69 = None
        unsqueeze_91: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_90, -1);  unsqueeze_90 = None
        add_120: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_160, unsqueeze_91);  mul_160 = unsqueeze_91 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_20: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_120);  add_120 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_23: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_20, primals_70, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_121: i64[] = torch.ops.aten.add.Tensor(primals_233, 1);  primals_233 = None
        var_mean_23 = torch.ops.aten.var_mean.correction(convolution_23, [0, 2, 3], correction = 0, keepdim = True)
        getitem_48: f32[1, 512, 1, 1] = var_mean_23[0]
        getitem_49: f32[1, 512, 1, 1] = var_mean_23[1];  var_mean_23 = None
        add_122: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_48, 1e-05)
        rsqrt_23: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_122);  add_122 = None
        sub_23: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_23, getitem_49)
        mul_161: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_23, rsqrt_23);  sub_23 = None
        squeeze_69: f32[512] = torch.ops.aten.squeeze.dims(getitem_49, [0, 2, 3]);  getitem_49 = None
        squeeze_70: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_23, [0, 2, 3]);  rsqrt_23 = None
        mul_162: f32[512] = torch.ops.aten.mul.Tensor(squeeze_69, 0.1)
        mul_163: f32[512] = torch.ops.aten.mul.Tensor(primals_231, 0.9);  primals_231 = None
        add_123: f32[512] = torch.ops.aten.add.Tensor(mul_162, mul_163);  mul_162 = mul_163 = None
        squeeze_71: f32[512] = torch.ops.aten.squeeze.dims(getitem_48, [0, 2, 3]);  getitem_48 = None
        mul_164: f32[512] = torch.ops.aten.mul.Tensor(squeeze_71, 1.0158730158730158);  squeeze_71 = None
        mul_165: f32[512] = torch.ops.aten.mul.Tensor(mul_164, 0.1);  mul_164 = None
        mul_166: f32[512] = torch.ops.aten.mul.Tensor(primals_232, 0.9);  primals_232 = None
        add_124: f32[512] = torch.ops.aten.add.Tensor(mul_165, mul_166);  mul_165 = mul_166 = None
        unsqueeze_92: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_71, -1)
        unsqueeze_93: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_92, -1);  unsqueeze_92 = None
        mul_167: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_161, unsqueeze_93);  mul_161 = unsqueeze_93 = None
        unsqueeze_94: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_72, -1);  primals_72 = None
        unsqueeze_95: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_94, -1);  unsqueeze_94 = None
        add_125: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_167, unsqueeze_95);  mul_167 = unsqueeze_95 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_126: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(add_125, relu_18);  add_125 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_21: f32[1, 512, 8, 8] = torch.ops.aten.relu.default(add_126);  add_126 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_24: f32[1, 256, 8, 8] = torch.ops.aten.convolution.default(relu_21, primals_73, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_127: i64[] = torch.ops.aten.add.Tensor(primals_236, 1);  primals_236 = None
        var_mean_24 = torch.ops.aten.var_mean.correction(convolution_24, [0, 2, 3], correction = 0, keepdim = True)
        getitem_50: f32[1, 256, 1, 1] = var_mean_24[0]
        getitem_51: f32[1, 256, 1, 1] = var_mean_24[1];  var_mean_24 = None
        add_128: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_50, 1e-05)
        rsqrt_24: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_128);  add_128 = None
        sub_24: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(convolution_24, getitem_51)
        mul_168: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(sub_24, rsqrt_24);  sub_24 = None
        squeeze_72: f32[256] = torch.ops.aten.squeeze.dims(getitem_51, [0, 2, 3]);  getitem_51 = None
        squeeze_73: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_24, [0, 2, 3]);  rsqrt_24 = None
        mul_169: f32[256] = torch.ops.aten.mul.Tensor(squeeze_72, 0.1)
        mul_170: f32[256] = torch.ops.aten.mul.Tensor(primals_234, 0.9);  primals_234 = None
        add_129: f32[256] = torch.ops.aten.add.Tensor(mul_169, mul_170);  mul_169 = mul_170 = None
        squeeze_74: f32[256] = torch.ops.aten.squeeze.dims(getitem_50, [0, 2, 3]);  getitem_50 = None
        mul_171: f32[256] = torch.ops.aten.mul.Tensor(squeeze_74, 1.0158730158730158);  squeeze_74 = None
        mul_172: f32[256] = torch.ops.aten.mul.Tensor(mul_171, 0.1);  mul_171 = None
        mul_173: f32[256] = torch.ops.aten.mul.Tensor(primals_235, 0.9);  primals_235 = None
        add_130: f32[256] = torch.ops.aten.add.Tensor(mul_172, mul_173);  mul_172 = mul_173 = None
        unsqueeze_96: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_74, -1)
        unsqueeze_97: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_96, -1);  unsqueeze_96 = None
        mul_174: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(mul_168, unsqueeze_97);  mul_168 = unsqueeze_97 = None
        unsqueeze_98: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_75, -1);  primals_75 = None
        unsqueeze_99: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_98, -1);  unsqueeze_98 = None
        add_131: f32[1, 256, 8, 8] = torch.ops.aten.add.Tensor(mul_174, unsqueeze_99);  mul_174 = unsqueeze_99 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_22: f32[1, 256, 8, 8] = torch.ops.aten.relu.default(add_131);  add_131 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_25: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_22, primals_76, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_132: i64[] = torch.ops.aten.add.Tensor(primals_239, 1);  primals_239 = None
        var_mean_25 = torch.ops.aten.var_mean.correction(convolution_25, [0, 2, 3], correction = 0, keepdim = True)
        getitem_52: f32[1, 256, 1, 1] = var_mean_25[0]
        getitem_53: f32[1, 256, 1, 1] = var_mean_25[1];  var_mean_25 = None
        add_133: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_52, 1e-05)
        rsqrt_25: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_133);  add_133 = None
        sub_25: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_25, getitem_53)
        mul_175: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_25, rsqrt_25);  sub_25 = None
        squeeze_75: f32[256] = torch.ops.aten.squeeze.dims(getitem_53, [0, 2, 3]);  getitem_53 = None
        squeeze_76: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_25, [0, 2, 3]);  rsqrt_25 = None
        mul_176: f32[256] = torch.ops.aten.mul.Tensor(squeeze_75, 0.1)
        mul_177: f32[256] = torch.ops.aten.mul.Tensor(primals_237, 0.9);  primals_237 = None
        add_134: f32[256] = torch.ops.aten.add.Tensor(mul_176, mul_177);  mul_176 = mul_177 = None
        squeeze_77: f32[256] = torch.ops.aten.squeeze.dims(getitem_52, [0, 2, 3]);  getitem_52 = None
        mul_178: f32[256] = torch.ops.aten.mul.Tensor(squeeze_77, 1.0666666666666667);  squeeze_77 = None
        mul_179: f32[256] = torch.ops.aten.mul.Tensor(mul_178, 0.1);  mul_178 = None
        mul_180: f32[256] = torch.ops.aten.mul.Tensor(primals_238, 0.9);  primals_238 = None
        add_135: f32[256] = torch.ops.aten.add.Tensor(mul_179, mul_180);  mul_179 = mul_180 = None
        unsqueeze_100: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_77, -1)
        unsqueeze_101: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_100, -1);  unsqueeze_100 = None
        mul_181: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_175, unsqueeze_101);  mul_175 = unsqueeze_101 = None
        unsqueeze_102: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_78, -1);  primals_78 = None
        unsqueeze_103: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_102, -1);  unsqueeze_102 = None
        add_136: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_181, unsqueeze_103);  mul_181 = unsqueeze_103 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_23: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_136);  add_136 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_26: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_23, primals_79, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_137: i64[] = torch.ops.aten.add.Tensor(primals_242, 1);  primals_242 = None
        var_mean_26 = torch.ops.aten.var_mean.correction(convolution_26, [0, 2, 3], correction = 0, keepdim = True)
        getitem_54: f32[1, 1024, 1, 1] = var_mean_26[0]
        getitem_55: f32[1, 1024, 1, 1] = var_mean_26[1];  var_mean_26 = None
        add_138: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_54, 1e-05)
        rsqrt_26: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_138);  add_138 = None
        sub_26: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_26, getitem_55)
        mul_182: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_26, rsqrt_26);  sub_26 = None
        squeeze_78: f32[1024] = torch.ops.aten.squeeze.dims(getitem_55, [0, 2, 3]);  getitem_55 = None
        squeeze_79: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_26, [0, 2, 3]);  rsqrt_26 = None
        mul_183: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_78, 0.1)
        mul_184: f32[1024] = torch.ops.aten.mul.Tensor(primals_240, 0.9);  primals_240 = None
        add_139: f32[1024] = torch.ops.aten.add.Tensor(mul_183, mul_184);  mul_183 = mul_184 = None
        squeeze_80: f32[1024] = torch.ops.aten.squeeze.dims(getitem_54, [0, 2, 3]);  getitem_54 = None
        mul_185: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_80, 1.0666666666666667);  squeeze_80 = None
        mul_186: f32[1024] = torch.ops.aten.mul.Tensor(mul_185, 0.1);  mul_185 = None
        mul_187: f32[1024] = torch.ops.aten.mul.Tensor(primals_241, 0.9);  primals_241 = None
        add_140: f32[1024] = torch.ops.aten.add.Tensor(mul_186, mul_187);  mul_186 = mul_187 = None
        unsqueeze_104: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_80, -1)
        unsqueeze_105: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_104, -1);  unsqueeze_104 = None
        mul_188: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_182, unsqueeze_105);  mul_182 = unsqueeze_105 = None
        unsqueeze_106: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_81, -1);  primals_81 = None
        unsqueeze_107: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_106, -1);  unsqueeze_106 = None
        add_141: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_188, unsqueeze_107);  mul_188 = unsqueeze_107 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        convolution_27: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_21, primals_82, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
        add_142: i64[] = torch.ops.aten.add.Tensor(primals_245, 1);  primals_245 = None
        var_mean_27 = torch.ops.aten.var_mean.correction(convolution_27, [0, 2, 3], correction = 0, keepdim = True)
        getitem_56: f32[1, 1024, 1, 1] = var_mean_27[0]
        getitem_57: f32[1, 1024, 1, 1] = var_mean_27[1];  var_mean_27 = None
        add_143: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_56, 1e-05)
        rsqrt_27: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_143);  add_143 = None
        sub_27: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_27, getitem_57)
        mul_189: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_27, rsqrt_27);  sub_27 = None
        squeeze_81: f32[1024] = torch.ops.aten.squeeze.dims(getitem_57, [0, 2, 3]);  getitem_57 = None
        squeeze_82: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_27, [0, 2, 3]);  rsqrt_27 = None
        mul_190: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_81, 0.1)
        mul_191: f32[1024] = torch.ops.aten.mul.Tensor(primals_243, 0.9);  primals_243 = None
        add_144: f32[1024] = torch.ops.aten.add.Tensor(mul_190, mul_191);  mul_190 = mul_191 = None
        squeeze_83: f32[1024] = torch.ops.aten.squeeze.dims(getitem_56, [0, 2, 3]);  getitem_56 = None
        mul_192: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_83, 1.0666666666666667);  squeeze_83 = None
        mul_193: f32[1024] = torch.ops.aten.mul.Tensor(mul_192, 0.1);  mul_192 = None
        mul_194: f32[1024] = torch.ops.aten.mul.Tensor(primals_244, 0.9);  primals_244 = None
        add_145: f32[1024] = torch.ops.aten.add.Tensor(mul_193, mul_194);  mul_193 = mul_194 = None
        unsqueeze_108: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_83, -1)
        unsqueeze_109: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_108, -1);  unsqueeze_108 = None
        mul_195: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_189, unsqueeze_109);  mul_189 = unsqueeze_109 = None
        unsqueeze_110: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_84, -1);  primals_84 = None
        unsqueeze_111: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_110, -1);  unsqueeze_110 = None
        add_146: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_195, unsqueeze_111);  mul_195 = unsqueeze_111 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_147: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_141, add_146);  add_141 = add_146 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_24: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_147);  add_147 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_28: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_24, primals_85, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_148: i64[] = torch.ops.aten.add.Tensor(primals_248, 1);  primals_248 = None
        var_mean_28 = torch.ops.aten.var_mean.correction(convolution_28, [0, 2, 3], correction = 0, keepdim = True)
        getitem_58: f32[1, 256, 1, 1] = var_mean_28[0]
        getitem_59: f32[1, 256, 1, 1] = var_mean_28[1];  var_mean_28 = None
        add_149: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_58, 1e-05)
        rsqrt_28: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_149);  add_149 = None
        sub_28: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_28, getitem_59)
        mul_196: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_28, rsqrt_28);  sub_28 = None
        squeeze_84: f32[256] = torch.ops.aten.squeeze.dims(getitem_59, [0, 2, 3]);  getitem_59 = None
        squeeze_85: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_28, [0, 2, 3]);  rsqrt_28 = None
        mul_197: f32[256] = torch.ops.aten.mul.Tensor(squeeze_84, 0.1)
        mul_198: f32[256] = torch.ops.aten.mul.Tensor(primals_246, 0.9);  primals_246 = None
        add_150: f32[256] = torch.ops.aten.add.Tensor(mul_197, mul_198);  mul_197 = mul_198 = None
        squeeze_86: f32[256] = torch.ops.aten.squeeze.dims(getitem_58, [0, 2, 3]);  getitem_58 = None
        mul_199: f32[256] = torch.ops.aten.mul.Tensor(squeeze_86, 1.0666666666666667);  squeeze_86 = None
        mul_200: f32[256] = torch.ops.aten.mul.Tensor(mul_199, 0.1);  mul_199 = None
        mul_201: f32[256] = torch.ops.aten.mul.Tensor(primals_247, 0.9);  primals_247 = None
        add_151: f32[256] = torch.ops.aten.add.Tensor(mul_200, mul_201);  mul_200 = mul_201 = None
        unsqueeze_112: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_86, -1)
        unsqueeze_113: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_112, -1);  unsqueeze_112 = None
        mul_202: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_196, unsqueeze_113);  mul_196 = unsqueeze_113 = None
        unsqueeze_114: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_87, -1);  primals_87 = None
        unsqueeze_115: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_114, -1);  unsqueeze_114 = None
        add_152: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_202, unsqueeze_115);  mul_202 = unsqueeze_115 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_25: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_152);  add_152 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_29: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_25, primals_88, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_153: i64[] = torch.ops.aten.add.Tensor(primals_251, 1);  primals_251 = None
        var_mean_29 = torch.ops.aten.var_mean.correction(convolution_29, [0, 2, 3], correction = 0, keepdim = True)
        getitem_60: f32[1, 256, 1, 1] = var_mean_29[0]
        getitem_61: f32[1, 256, 1, 1] = var_mean_29[1];  var_mean_29 = None
        add_154: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_60, 1e-05)
        rsqrt_29: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_154);  add_154 = None
        sub_29: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_29, getitem_61)
        mul_203: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_29, rsqrt_29);  sub_29 = None
        squeeze_87: f32[256] = torch.ops.aten.squeeze.dims(getitem_61, [0, 2, 3]);  getitem_61 = None
        squeeze_88: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_29, [0, 2, 3]);  rsqrt_29 = None
        mul_204: f32[256] = torch.ops.aten.mul.Tensor(squeeze_87, 0.1)
        mul_205: f32[256] = torch.ops.aten.mul.Tensor(primals_249, 0.9);  primals_249 = None
        add_155: f32[256] = torch.ops.aten.add.Tensor(mul_204, mul_205);  mul_204 = mul_205 = None
        squeeze_89: f32[256] = torch.ops.aten.squeeze.dims(getitem_60, [0, 2, 3]);  getitem_60 = None
        mul_206: f32[256] = torch.ops.aten.mul.Tensor(squeeze_89, 1.0666666666666667);  squeeze_89 = None
        mul_207: f32[256] = torch.ops.aten.mul.Tensor(mul_206, 0.1);  mul_206 = None
        mul_208: f32[256] = torch.ops.aten.mul.Tensor(primals_250, 0.9);  primals_250 = None
        add_156: f32[256] = torch.ops.aten.add.Tensor(mul_207, mul_208);  mul_207 = mul_208 = None
        unsqueeze_116: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_89, -1)
        unsqueeze_117: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_116, -1);  unsqueeze_116 = None
        mul_209: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_203, unsqueeze_117);  mul_203 = unsqueeze_117 = None
        unsqueeze_118: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_90, -1);  primals_90 = None
        unsqueeze_119: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_118, -1);  unsqueeze_118 = None
        add_157: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_209, unsqueeze_119);  mul_209 = unsqueeze_119 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_26: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_157);  add_157 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_30: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_26, primals_91, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_158: i64[] = torch.ops.aten.add.Tensor(primals_254, 1);  primals_254 = None
        var_mean_30 = torch.ops.aten.var_mean.correction(convolution_30, [0, 2, 3], correction = 0, keepdim = True)
        getitem_62: f32[1, 1024, 1, 1] = var_mean_30[0]
        getitem_63: f32[1, 1024, 1, 1] = var_mean_30[1];  var_mean_30 = None
        add_159: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_62, 1e-05)
        rsqrt_30: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_159);  add_159 = None
        sub_30: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_30, getitem_63)
        mul_210: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_30, rsqrt_30);  sub_30 = None
        squeeze_90: f32[1024] = torch.ops.aten.squeeze.dims(getitem_63, [0, 2, 3]);  getitem_63 = None
        squeeze_91: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_30, [0, 2, 3]);  rsqrt_30 = None
        mul_211: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_90, 0.1)
        mul_212: f32[1024] = torch.ops.aten.mul.Tensor(primals_252, 0.9);  primals_252 = None
        add_160: f32[1024] = torch.ops.aten.add.Tensor(mul_211, mul_212);  mul_211 = mul_212 = None
        squeeze_92: f32[1024] = torch.ops.aten.squeeze.dims(getitem_62, [0, 2, 3]);  getitem_62 = None
        mul_213: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_92, 1.0666666666666667);  squeeze_92 = None
        mul_214: f32[1024] = torch.ops.aten.mul.Tensor(mul_213, 0.1);  mul_213 = None
        mul_215: f32[1024] = torch.ops.aten.mul.Tensor(primals_253, 0.9);  primals_253 = None
        add_161: f32[1024] = torch.ops.aten.add.Tensor(mul_214, mul_215);  mul_214 = mul_215 = None
        unsqueeze_120: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_92, -1)
        unsqueeze_121: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_120, -1);  unsqueeze_120 = None
        mul_216: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_210, unsqueeze_121);  mul_210 = unsqueeze_121 = None
        unsqueeze_122: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_93, -1);  primals_93 = None
        unsqueeze_123: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_122, -1);  unsqueeze_122 = None
        add_162: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_216, unsqueeze_123);  mul_216 = unsqueeze_123 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_163: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_162, relu_24);  add_162 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_27: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_163);  add_163 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_31: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_27, primals_94, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_164: i64[] = torch.ops.aten.add.Tensor(primals_257, 1);  primals_257 = None
        var_mean_31 = torch.ops.aten.var_mean.correction(convolution_31, [0, 2, 3], correction = 0, keepdim = True)
        getitem_64: f32[1, 256, 1, 1] = var_mean_31[0]
        getitem_65: f32[1, 256, 1, 1] = var_mean_31[1];  var_mean_31 = None
        add_165: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_64, 1e-05)
        rsqrt_31: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_165);  add_165 = None
        sub_31: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_31, getitem_65)
        mul_217: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_31, rsqrt_31);  sub_31 = None
        squeeze_93: f32[256] = torch.ops.aten.squeeze.dims(getitem_65, [0, 2, 3]);  getitem_65 = None
        squeeze_94: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_31, [0, 2, 3]);  rsqrt_31 = None
        mul_218: f32[256] = torch.ops.aten.mul.Tensor(squeeze_93, 0.1)
        mul_219: f32[256] = torch.ops.aten.mul.Tensor(primals_255, 0.9);  primals_255 = None
        add_166: f32[256] = torch.ops.aten.add.Tensor(mul_218, mul_219);  mul_218 = mul_219 = None
        squeeze_95: f32[256] = torch.ops.aten.squeeze.dims(getitem_64, [0, 2, 3]);  getitem_64 = None
        mul_220: f32[256] = torch.ops.aten.mul.Tensor(squeeze_95, 1.0666666666666667);  squeeze_95 = None
        mul_221: f32[256] = torch.ops.aten.mul.Tensor(mul_220, 0.1);  mul_220 = None
        mul_222: f32[256] = torch.ops.aten.mul.Tensor(primals_256, 0.9);  primals_256 = None
        add_167: f32[256] = torch.ops.aten.add.Tensor(mul_221, mul_222);  mul_221 = mul_222 = None
        unsqueeze_124: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_95, -1)
        unsqueeze_125: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_124, -1);  unsqueeze_124 = None
        mul_223: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_217, unsqueeze_125);  mul_217 = unsqueeze_125 = None
        unsqueeze_126: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_96, -1);  primals_96 = None
        unsqueeze_127: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_126, -1);  unsqueeze_126 = None
        add_168: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_223, unsqueeze_127);  mul_223 = unsqueeze_127 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_28: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_168);  add_168 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_32: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_28, primals_97, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_169: i64[] = torch.ops.aten.add.Tensor(primals_260, 1);  primals_260 = None
        var_mean_32 = torch.ops.aten.var_mean.correction(convolution_32, [0, 2, 3], correction = 0, keepdim = True)
        getitem_66: f32[1, 256, 1, 1] = var_mean_32[0]
        getitem_67: f32[1, 256, 1, 1] = var_mean_32[1];  var_mean_32 = None
        add_170: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_66, 1e-05)
        rsqrt_32: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_170);  add_170 = None
        sub_32: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_32, getitem_67)
        mul_224: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_32, rsqrt_32);  sub_32 = None
        squeeze_96: f32[256] = torch.ops.aten.squeeze.dims(getitem_67, [0, 2, 3]);  getitem_67 = None
        squeeze_97: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_32, [0, 2, 3]);  rsqrt_32 = None
        mul_225: f32[256] = torch.ops.aten.mul.Tensor(squeeze_96, 0.1)
        mul_226: f32[256] = torch.ops.aten.mul.Tensor(primals_258, 0.9);  primals_258 = None
        add_171: f32[256] = torch.ops.aten.add.Tensor(mul_225, mul_226);  mul_225 = mul_226 = None
        squeeze_98: f32[256] = torch.ops.aten.squeeze.dims(getitem_66, [0, 2, 3]);  getitem_66 = None
        mul_227: f32[256] = torch.ops.aten.mul.Tensor(squeeze_98, 1.0666666666666667);  squeeze_98 = None
        mul_228: f32[256] = torch.ops.aten.mul.Tensor(mul_227, 0.1);  mul_227 = None
        mul_229: f32[256] = torch.ops.aten.mul.Tensor(primals_259, 0.9);  primals_259 = None
        add_172: f32[256] = torch.ops.aten.add.Tensor(mul_228, mul_229);  mul_228 = mul_229 = None
        unsqueeze_128: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_98, -1)
        unsqueeze_129: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_128, -1);  unsqueeze_128 = None
        mul_230: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_224, unsqueeze_129);  mul_224 = unsqueeze_129 = None
        unsqueeze_130: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_99, -1);  primals_99 = None
        unsqueeze_131: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_130, -1);  unsqueeze_130 = None
        add_173: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_230, unsqueeze_131);  mul_230 = unsqueeze_131 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_29: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_173);  add_173 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_33: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_29, primals_100, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_174: i64[] = torch.ops.aten.add.Tensor(primals_263, 1);  primals_263 = None
        var_mean_33 = torch.ops.aten.var_mean.correction(convolution_33, [0, 2, 3], correction = 0, keepdim = True)
        getitem_68: f32[1, 1024, 1, 1] = var_mean_33[0]
        getitem_69: f32[1, 1024, 1, 1] = var_mean_33[1];  var_mean_33 = None
        add_175: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_68, 1e-05)
        rsqrt_33: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_175);  add_175 = None
        sub_33: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_33, getitem_69)
        mul_231: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_33, rsqrt_33);  sub_33 = None
        squeeze_99: f32[1024] = torch.ops.aten.squeeze.dims(getitem_69, [0, 2, 3]);  getitem_69 = None
        squeeze_100: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_33, [0, 2, 3]);  rsqrt_33 = None
        mul_232: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_99, 0.1)
        mul_233: f32[1024] = torch.ops.aten.mul.Tensor(primals_261, 0.9);  primals_261 = None
        add_176: f32[1024] = torch.ops.aten.add.Tensor(mul_232, mul_233);  mul_232 = mul_233 = None
        squeeze_101: f32[1024] = torch.ops.aten.squeeze.dims(getitem_68, [0, 2, 3]);  getitem_68 = None
        mul_234: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_101, 1.0666666666666667);  squeeze_101 = None
        mul_235: f32[1024] = torch.ops.aten.mul.Tensor(mul_234, 0.1);  mul_234 = None
        mul_236: f32[1024] = torch.ops.aten.mul.Tensor(primals_262, 0.9);  primals_262 = None
        add_177: f32[1024] = torch.ops.aten.add.Tensor(mul_235, mul_236);  mul_235 = mul_236 = None
        unsqueeze_132: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_101, -1)
        unsqueeze_133: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_132, -1);  unsqueeze_132 = None
        mul_237: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_231, unsqueeze_133);  mul_231 = unsqueeze_133 = None
        unsqueeze_134: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_102, -1);  primals_102 = None
        unsqueeze_135: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_134, -1);  unsqueeze_134 = None
        add_178: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_237, unsqueeze_135);  mul_237 = unsqueeze_135 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_179: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_178, relu_27);  add_178 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_30: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_179);  add_179 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_34: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_30, primals_103, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_180: i64[] = torch.ops.aten.add.Tensor(primals_266, 1);  primals_266 = None
        var_mean_34 = torch.ops.aten.var_mean.correction(convolution_34, [0, 2, 3], correction = 0, keepdim = True)
        getitem_70: f32[1, 256, 1, 1] = var_mean_34[0]
        getitem_71: f32[1, 256, 1, 1] = var_mean_34[1];  var_mean_34 = None
        add_181: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_70, 1e-05)
        rsqrt_34: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_181);  add_181 = None
        sub_34: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_34, getitem_71)
        mul_238: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_34, rsqrt_34);  sub_34 = None
        squeeze_102: f32[256] = torch.ops.aten.squeeze.dims(getitem_71, [0, 2, 3]);  getitem_71 = None
        squeeze_103: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_34, [0, 2, 3]);  rsqrt_34 = None
        mul_239: f32[256] = torch.ops.aten.mul.Tensor(squeeze_102, 0.1)
        mul_240: f32[256] = torch.ops.aten.mul.Tensor(primals_264, 0.9);  primals_264 = None
        add_182: f32[256] = torch.ops.aten.add.Tensor(mul_239, mul_240);  mul_239 = mul_240 = None
        squeeze_104: f32[256] = torch.ops.aten.squeeze.dims(getitem_70, [0, 2, 3]);  getitem_70 = None
        mul_241: f32[256] = torch.ops.aten.mul.Tensor(squeeze_104, 1.0666666666666667);  squeeze_104 = None
        mul_242: f32[256] = torch.ops.aten.mul.Tensor(mul_241, 0.1);  mul_241 = None
        mul_243: f32[256] = torch.ops.aten.mul.Tensor(primals_265, 0.9);  primals_265 = None
        add_183: f32[256] = torch.ops.aten.add.Tensor(mul_242, mul_243);  mul_242 = mul_243 = None
        unsqueeze_136: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_104, -1)
        unsqueeze_137: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_136, -1);  unsqueeze_136 = None
        mul_244: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_238, unsqueeze_137);  mul_238 = unsqueeze_137 = None
        unsqueeze_138: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_105, -1);  primals_105 = None
        unsqueeze_139: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_138, -1);  unsqueeze_138 = None
        add_184: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_244, unsqueeze_139);  mul_244 = unsqueeze_139 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_31: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_184);  add_184 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_35: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_31, primals_106, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_185: i64[] = torch.ops.aten.add.Tensor(primals_269, 1);  primals_269 = None
        var_mean_35 = torch.ops.aten.var_mean.correction(convolution_35, [0, 2, 3], correction = 0, keepdim = True)
        getitem_72: f32[1, 256, 1, 1] = var_mean_35[0]
        getitem_73: f32[1, 256, 1, 1] = var_mean_35[1];  var_mean_35 = None
        add_186: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_72, 1e-05)
        rsqrt_35: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_186);  add_186 = None
        sub_35: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_35, getitem_73)
        mul_245: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_35, rsqrt_35);  sub_35 = None
        squeeze_105: f32[256] = torch.ops.aten.squeeze.dims(getitem_73, [0, 2, 3]);  getitem_73 = None
        squeeze_106: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_35, [0, 2, 3]);  rsqrt_35 = None
        mul_246: f32[256] = torch.ops.aten.mul.Tensor(squeeze_105, 0.1)
        mul_247: f32[256] = torch.ops.aten.mul.Tensor(primals_267, 0.9);  primals_267 = None
        add_187: f32[256] = torch.ops.aten.add.Tensor(mul_246, mul_247);  mul_246 = mul_247 = None
        squeeze_107: f32[256] = torch.ops.aten.squeeze.dims(getitem_72, [0, 2, 3]);  getitem_72 = None
        mul_248: f32[256] = torch.ops.aten.mul.Tensor(squeeze_107, 1.0666666666666667);  squeeze_107 = None
        mul_249: f32[256] = torch.ops.aten.mul.Tensor(mul_248, 0.1);  mul_248 = None
        mul_250: f32[256] = torch.ops.aten.mul.Tensor(primals_268, 0.9);  primals_268 = None
        add_188: f32[256] = torch.ops.aten.add.Tensor(mul_249, mul_250);  mul_249 = mul_250 = None
        unsqueeze_140: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_107, -1)
        unsqueeze_141: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_140, -1);  unsqueeze_140 = None
        mul_251: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_245, unsqueeze_141);  mul_245 = unsqueeze_141 = None
        unsqueeze_142: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_108, -1);  primals_108 = None
        unsqueeze_143: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_142, -1);  unsqueeze_142 = None
        add_189: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_251, unsqueeze_143);  mul_251 = unsqueeze_143 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_32: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_189);  add_189 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_36: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_32, primals_109, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_190: i64[] = torch.ops.aten.add.Tensor(primals_272, 1);  primals_272 = None
        var_mean_36 = torch.ops.aten.var_mean.correction(convolution_36, [0, 2, 3], correction = 0, keepdim = True)
        getitem_74: f32[1, 1024, 1, 1] = var_mean_36[0]
        getitem_75: f32[1, 1024, 1, 1] = var_mean_36[1];  var_mean_36 = None
        add_191: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_74, 1e-05)
        rsqrt_36: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_191);  add_191 = None
        sub_36: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_36, getitem_75)
        mul_252: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_36, rsqrt_36);  sub_36 = None
        squeeze_108: f32[1024] = torch.ops.aten.squeeze.dims(getitem_75, [0, 2, 3]);  getitem_75 = None
        squeeze_109: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_36, [0, 2, 3]);  rsqrt_36 = None
        mul_253: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_108, 0.1)
        mul_254: f32[1024] = torch.ops.aten.mul.Tensor(primals_270, 0.9);  primals_270 = None
        add_192: f32[1024] = torch.ops.aten.add.Tensor(mul_253, mul_254);  mul_253 = mul_254 = None
        squeeze_110: f32[1024] = torch.ops.aten.squeeze.dims(getitem_74, [0, 2, 3]);  getitem_74 = None
        mul_255: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_110, 1.0666666666666667);  squeeze_110 = None
        mul_256: f32[1024] = torch.ops.aten.mul.Tensor(mul_255, 0.1);  mul_255 = None
        mul_257: f32[1024] = torch.ops.aten.mul.Tensor(primals_271, 0.9);  primals_271 = None
        add_193: f32[1024] = torch.ops.aten.add.Tensor(mul_256, mul_257);  mul_256 = mul_257 = None
        unsqueeze_144: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_110, -1)
        unsqueeze_145: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_144, -1);  unsqueeze_144 = None
        mul_258: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_252, unsqueeze_145);  mul_252 = unsqueeze_145 = None
        unsqueeze_146: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_111, -1);  primals_111 = None
        unsqueeze_147: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_146, -1);  unsqueeze_146 = None
        add_194: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_258, unsqueeze_147);  mul_258 = unsqueeze_147 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_195: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_194, relu_30);  add_194 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_33: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_195);  add_195 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_37: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_33, primals_112, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_196: i64[] = torch.ops.aten.add.Tensor(primals_275, 1);  primals_275 = None
        var_mean_37 = torch.ops.aten.var_mean.correction(convolution_37, [0, 2, 3], correction = 0, keepdim = True)
        getitem_76: f32[1, 256, 1, 1] = var_mean_37[0]
        getitem_77: f32[1, 256, 1, 1] = var_mean_37[1];  var_mean_37 = None
        add_197: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_76, 1e-05)
        rsqrt_37: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_197);  add_197 = None
        sub_37: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_37, getitem_77)
        mul_259: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_37, rsqrt_37);  sub_37 = None
        squeeze_111: f32[256] = torch.ops.aten.squeeze.dims(getitem_77, [0, 2, 3]);  getitem_77 = None
        squeeze_112: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_37, [0, 2, 3]);  rsqrt_37 = None
        mul_260: f32[256] = torch.ops.aten.mul.Tensor(squeeze_111, 0.1)
        mul_261: f32[256] = torch.ops.aten.mul.Tensor(primals_273, 0.9);  primals_273 = None
        add_198: f32[256] = torch.ops.aten.add.Tensor(mul_260, mul_261);  mul_260 = mul_261 = None
        squeeze_113: f32[256] = torch.ops.aten.squeeze.dims(getitem_76, [0, 2, 3]);  getitem_76 = None
        mul_262: f32[256] = torch.ops.aten.mul.Tensor(squeeze_113, 1.0666666666666667);  squeeze_113 = None
        mul_263: f32[256] = torch.ops.aten.mul.Tensor(mul_262, 0.1);  mul_262 = None
        mul_264: f32[256] = torch.ops.aten.mul.Tensor(primals_274, 0.9);  primals_274 = None
        add_199: f32[256] = torch.ops.aten.add.Tensor(mul_263, mul_264);  mul_263 = mul_264 = None
        unsqueeze_148: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_113, -1)
        unsqueeze_149: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_148, -1);  unsqueeze_148 = None
        mul_265: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_259, unsqueeze_149);  mul_259 = unsqueeze_149 = None
        unsqueeze_150: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_114, -1);  primals_114 = None
        unsqueeze_151: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_150, -1);  unsqueeze_150 = None
        add_200: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_265, unsqueeze_151);  mul_265 = unsqueeze_151 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_34: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_200);  add_200 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_38: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_34, primals_115, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_201: i64[] = torch.ops.aten.add.Tensor(primals_278, 1);  primals_278 = None
        var_mean_38 = torch.ops.aten.var_mean.correction(convolution_38, [0, 2, 3], correction = 0, keepdim = True)
        getitem_78: f32[1, 256, 1, 1] = var_mean_38[0]
        getitem_79: f32[1, 256, 1, 1] = var_mean_38[1];  var_mean_38 = None
        add_202: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_78, 1e-05)
        rsqrt_38: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_202);  add_202 = None
        sub_38: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_38, getitem_79)
        mul_266: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_38, rsqrt_38);  sub_38 = None
        squeeze_114: f32[256] = torch.ops.aten.squeeze.dims(getitem_79, [0, 2, 3]);  getitem_79 = None
        squeeze_115: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_38, [0, 2, 3]);  rsqrt_38 = None
        mul_267: f32[256] = torch.ops.aten.mul.Tensor(squeeze_114, 0.1)
        mul_268: f32[256] = torch.ops.aten.mul.Tensor(primals_276, 0.9);  primals_276 = None
        add_203: f32[256] = torch.ops.aten.add.Tensor(mul_267, mul_268);  mul_267 = mul_268 = None
        squeeze_116: f32[256] = torch.ops.aten.squeeze.dims(getitem_78, [0, 2, 3]);  getitem_78 = None
        mul_269: f32[256] = torch.ops.aten.mul.Tensor(squeeze_116, 1.0666666666666667);  squeeze_116 = None
        mul_270: f32[256] = torch.ops.aten.mul.Tensor(mul_269, 0.1);  mul_269 = None
        mul_271: f32[256] = torch.ops.aten.mul.Tensor(primals_277, 0.9);  primals_277 = None
        add_204: f32[256] = torch.ops.aten.add.Tensor(mul_270, mul_271);  mul_270 = mul_271 = None
        unsqueeze_152: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_116, -1)
        unsqueeze_153: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_152, -1);  unsqueeze_152 = None
        mul_272: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_266, unsqueeze_153);  mul_266 = unsqueeze_153 = None
        unsqueeze_154: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_117, -1);  primals_117 = None
        unsqueeze_155: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_154, -1);  unsqueeze_154 = None
        add_205: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_272, unsqueeze_155);  mul_272 = unsqueeze_155 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_35: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_205);  add_205 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_39: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_35, primals_118, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_206: i64[] = torch.ops.aten.add.Tensor(primals_281, 1);  primals_281 = None
        var_mean_39 = torch.ops.aten.var_mean.correction(convolution_39, [0, 2, 3], correction = 0, keepdim = True)
        getitem_80: f32[1, 1024, 1, 1] = var_mean_39[0]
        getitem_81: f32[1, 1024, 1, 1] = var_mean_39[1];  var_mean_39 = None
        add_207: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_80, 1e-05)
        rsqrt_39: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_207);  add_207 = None
        sub_39: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_39, getitem_81)
        mul_273: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_39, rsqrt_39);  sub_39 = None
        squeeze_117: f32[1024] = torch.ops.aten.squeeze.dims(getitem_81, [0, 2, 3]);  getitem_81 = None
        squeeze_118: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_39, [0, 2, 3]);  rsqrt_39 = None
        mul_274: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_117, 0.1)
        mul_275: f32[1024] = torch.ops.aten.mul.Tensor(primals_279, 0.9);  primals_279 = None
        add_208: f32[1024] = torch.ops.aten.add.Tensor(mul_274, mul_275);  mul_274 = mul_275 = None
        squeeze_119: f32[1024] = torch.ops.aten.squeeze.dims(getitem_80, [0, 2, 3]);  getitem_80 = None
        mul_276: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_119, 1.0666666666666667);  squeeze_119 = None
        mul_277: f32[1024] = torch.ops.aten.mul.Tensor(mul_276, 0.1);  mul_276 = None
        mul_278: f32[1024] = torch.ops.aten.mul.Tensor(primals_280, 0.9);  primals_280 = None
        add_209: f32[1024] = torch.ops.aten.add.Tensor(mul_277, mul_278);  mul_277 = mul_278 = None
        unsqueeze_156: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_119, -1)
        unsqueeze_157: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_156, -1);  unsqueeze_156 = None
        mul_279: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_273, unsqueeze_157);  mul_273 = unsqueeze_157 = None
        unsqueeze_158: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_120, -1);  primals_120 = None
        unsqueeze_159: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_158, -1);  unsqueeze_158 = None
        add_210: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_279, unsqueeze_159);  mul_279 = unsqueeze_159 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_211: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_210, relu_33);  add_210 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_36: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_211);  add_211 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_40: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_36, primals_121, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_212: i64[] = torch.ops.aten.add.Tensor(primals_284, 1);  primals_284 = None
        var_mean_40 = torch.ops.aten.var_mean.correction(convolution_40, [0, 2, 3], correction = 0, keepdim = True)
        getitem_82: f32[1, 256, 1, 1] = var_mean_40[0]
        getitem_83: f32[1, 256, 1, 1] = var_mean_40[1];  var_mean_40 = None
        add_213: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_82, 1e-05)
        rsqrt_40: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_213);  add_213 = None
        sub_40: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_40, getitem_83)
        mul_280: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_40, rsqrt_40);  sub_40 = None
        squeeze_120: f32[256] = torch.ops.aten.squeeze.dims(getitem_83, [0, 2, 3]);  getitem_83 = None
        squeeze_121: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_40, [0, 2, 3]);  rsqrt_40 = None
        mul_281: f32[256] = torch.ops.aten.mul.Tensor(squeeze_120, 0.1)
        mul_282: f32[256] = torch.ops.aten.mul.Tensor(primals_282, 0.9);  primals_282 = None
        add_214: f32[256] = torch.ops.aten.add.Tensor(mul_281, mul_282);  mul_281 = mul_282 = None
        squeeze_122: f32[256] = torch.ops.aten.squeeze.dims(getitem_82, [0, 2, 3]);  getitem_82 = None
        mul_283: f32[256] = torch.ops.aten.mul.Tensor(squeeze_122, 1.0666666666666667);  squeeze_122 = None
        mul_284: f32[256] = torch.ops.aten.mul.Tensor(mul_283, 0.1);  mul_283 = None
        mul_285: f32[256] = torch.ops.aten.mul.Tensor(primals_283, 0.9);  primals_283 = None
        add_215: f32[256] = torch.ops.aten.add.Tensor(mul_284, mul_285);  mul_284 = mul_285 = None
        unsqueeze_160: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_122, -1)
        unsqueeze_161: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_160, -1);  unsqueeze_160 = None
        mul_286: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_280, unsqueeze_161);  mul_280 = unsqueeze_161 = None
        unsqueeze_162: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_123, -1);  primals_123 = None
        unsqueeze_163: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_162, -1);  unsqueeze_162 = None
        add_216: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_286, unsqueeze_163);  mul_286 = unsqueeze_163 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_37: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_216);  add_216 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_41: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_37, primals_124, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_217: i64[] = torch.ops.aten.add.Tensor(primals_287, 1);  primals_287 = None
        var_mean_41 = torch.ops.aten.var_mean.correction(convolution_41, [0, 2, 3], correction = 0, keepdim = True)
        getitem_84: f32[1, 256, 1, 1] = var_mean_41[0]
        getitem_85: f32[1, 256, 1, 1] = var_mean_41[1];  var_mean_41 = None
        add_218: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_84, 1e-05)
        rsqrt_41: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_218);  add_218 = None
        sub_41: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_41, getitem_85)
        mul_287: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_41, rsqrt_41);  sub_41 = None
        squeeze_123: f32[256] = torch.ops.aten.squeeze.dims(getitem_85, [0, 2, 3]);  getitem_85 = None
        squeeze_124: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_41, [0, 2, 3]);  rsqrt_41 = None
        mul_288: f32[256] = torch.ops.aten.mul.Tensor(squeeze_123, 0.1)
        mul_289: f32[256] = torch.ops.aten.mul.Tensor(primals_285, 0.9);  primals_285 = None
        add_219: f32[256] = torch.ops.aten.add.Tensor(mul_288, mul_289);  mul_288 = mul_289 = None
        squeeze_125: f32[256] = torch.ops.aten.squeeze.dims(getitem_84, [0, 2, 3]);  getitem_84 = None
        mul_290: f32[256] = torch.ops.aten.mul.Tensor(squeeze_125, 1.0666666666666667);  squeeze_125 = None
        mul_291: f32[256] = torch.ops.aten.mul.Tensor(mul_290, 0.1);  mul_290 = None
        mul_292: f32[256] = torch.ops.aten.mul.Tensor(primals_286, 0.9);  primals_286 = None
        add_220: f32[256] = torch.ops.aten.add.Tensor(mul_291, mul_292);  mul_291 = mul_292 = None
        unsqueeze_164: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_125, -1)
        unsqueeze_165: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_164, -1);  unsqueeze_164 = None
        mul_293: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_287, unsqueeze_165);  mul_287 = unsqueeze_165 = None
        unsqueeze_166: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_126, -1);  primals_126 = None
        unsqueeze_167: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_166, -1);  unsqueeze_166 = None
        add_221: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_293, unsqueeze_167);  mul_293 = unsqueeze_167 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_38: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_221);  add_221 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_42: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_38, primals_127, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_222: i64[] = torch.ops.aten.add.Tensor(primals_290, 1);  primals_290 = None
        var_mean_42 = torch.ops.aten.var_mean.correction(convolution_42, [0, 2, 3], correction = 0, keepdim = True)
        getitem_86: f32[1, 1024, 1, 1] = var_mean_42[0]
        getitem_87: f32[1, 1024, 1, 1] = var_mean_42[1];  var_mean_42 = None
        add_223: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_86, 1e-05)
        rsqrt_42: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_223);  add_223 = None
        sub_42: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_42, getitem_87)
        mul_294: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_42, rsqrt_42);  sub_42 = None
        squeeze_126: f32[1024] = torch.ops.aten.squeeze.dims(getitem_87, [0, 2, 3]);  getitem_87 = None
        squeeze_127: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_42, [0, 2, 3]);  rsqrt_42 = None
        mul_295: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_126, 0.1)
        mul_296: f32[1024] = torch.ops.aten.mul.Tensor(primals_288, 0.9);  primals_288 = None
        add_224: f32[1024] = torch.ops.aten.add.Tensor(mul_295, mul_296);  mul_295 = mul_296 = None
        squeeze_128: f32[1024] = torch.ops.aten.squeeze.dims(getitem_86, [0, 2, 3]);  getitem_86 = None
        mul_297: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_128, 1.0666666666666667);  squeeze_128 = None
        mul_298: f32[1024] = torch.ops.aten.mul.Tensor(mul_297, 0.1);  mul_297 = None
        mul_299: f32[1024] = torch.ops.aten.mul.Tensor(primals_289, 0.9);  primals_289 = None
        add_225: f32[1024] = torch.ops.aten.add.Tensor(mul_298, mul_299);  mul_298 = mul_299 = None
        unsqueeze_168: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_128, -1)
        unsqueeze_169: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_168, -1);  unsqueeze_168 = None
        mul_300: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_294, unsqueeze_169);  mul_294 = unsqueeze_169 = None
        unsqueeze_170: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_129, -1);  primals_129 = None
        unsqueeze_171: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_170, -1);  unsqueeze_170 = None
        add_226: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_300, unsqueeze_171);  mul_300 = unsqueeze_171 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_227: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_226, relu_36);  add_226 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_39: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_227);  add_227 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_43: f32[1, 512, 4, 4] = torch.ops.aten.convolution.default(relu_39, primals_130, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_228: i64[] = torch.ops.aten.add.Tensor(primals_293, 1);  primals_293 = None
        var_mean_43 = torch.ops.aten.var_mean.correction(convolution_43, [0, 2, 3], correction = 0, keepdim = True)
        getitem_88: f32[1, 512, 1, 1] = var_mean_43[0]
        getitem_89: f32[1, 512, 1, 1] = var_mean_43[1];  var_mean_43 = None
        add_229: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_88, 1e-05)
        rsqrt_43: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_229);  add_229 = None
        sub_43: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(convolution_43, getitem_89)
        mul_301: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(sub_43, rsqrt_43);  sub_43 = None
        squeeze_129: f32[512] = torch.ops.aten.squeeze.dims(getitem_89, [0, 2, 3]);  getitem_89 = None
        squeeze_130: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_43, [0, 2, 3]);  rsqrt_43 = None
        mul_302: f32[512] = torch.ops.aten.mul.Tensor(squeeze_129, 0.1)
        mul_303: f32[512] = torch.ops.aten.mul.Tensor(primals_291, 0.9);  primals_291 = None
        add_230: f32[512] = torch.ops.aten.add.Tensor(mul_302, mul_303);  mul_302 = mul_303 = None
        squeeze_131: f32[512] = torch.ops.aten.squeeze.dims(getitem_88, [0, 2, 3]);  getitem_88 = None
        mul_304: f32[512] = torch.ops.aten.mul.Tensor(squeeze_131, 1.0666666666666667);  squeeze_131 = None
        mul_305: f32[512] = torch.ops.aten.mul.Tensor(mul_304, 0.1);  mul_304 = None
        mul_306: f32[512] = torch.ops.aten.mul.Tensor(primals_292, 0.9);  primals_292 = None
        add_231: f32[512] = torch.ops.aten.add.Tensor(mul_305, mul_306);  mul_305 = mul_306 = None
        unsqueeze_172: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_131, -1)
        unsqueeze_173: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_172, -1);  unsqueeze_172 = None
        mul_307: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(mul_301, unsqueeze_173);  mul_301 = unsqueeze_173 = None
        unsqueeze_174: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_132, -1);  primals_132 = None
        unsqueeze_175: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_174, -1);  unsqueeze_174 = None
        add_232: f32[1, 512, 4, 4] = torch.ops.aten.add.Tensor(mul_307, unsqueeze_175);  mul_307 = unsqueeze_175 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_40: f32[1, 512, 4, 4] = torch.ops.aten.relu.default(add_232);  add_232 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_44: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_40, primals_133, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_233: i64[] = torch.ops.aten.add.Tensor(primals_296, 1);  primals_296 = None
        var_mean_44 = torch.ops.aten.var_mean.correction(convolution_44, [0, 2, 3], correction = 0, keepdim = True)
        getitem_90: f32[1, 512, 1, 1] = var_mean_44[0]
        getitem_91: f32[1, 512, 1, 1] = var_mean_44[1];  var_mean_44 = None
        add_234: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_90, 1e-05)
        rsqrt_44: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_234);  add_234 = None
        sub_44: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_44, getitem_91)
        mul_308: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_44, rsqrt_44);  sub_44 = None
        squeeze_132: f32[512] = torch.ops.aten.squeeze.dims(getitem_91, [0, 2, 3]);  getitem_91 = None
        squeeze_133: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_44, [0, 2, 3]);  rsqrt_44 = None
        mul_309: f32[512] = torch.ops.aten.mul.Tensor(squeeze_132, 0.1)
        mul_310: f32[512] = torch.ops.aten.mul.Tensor(primals_294, 0.9);  primals_294 = None
        add_235: f32[512] = torch.ops.aten.add.Tensor(mul_309, mul_310);  mul_309 = mul_310 = None
        squeeze_134: f32[512] = torch.ops.aten.squeeze.dims(getitem_90, [0, 2, 3]);  getitem_90 = None
        mul_311: f32[512] = torch.ops.aten.mul.Tensor(squeeze_134, 1.3333333333333333);  squeeze_134 = None
        mul_312: f32[512] = torch.ops.aten.mul.Tensor(mul_311, 0.1);  mul_311 = None
        mul_313: f32[512] = torch.ops.aten.mul.Tensor(primals_295, 0.9);  primals_295 = None
        add_236: f32[512] = torch.ops.aten.add.Tensor(mul_312, mul_313);  mul_312 = mul_313 = None
        unsqueeze_176: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_134, -1)
        unsqueeze_177: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_176, -1);  unsqueeze_176 = None
        mul_314: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_308, unsqueeze_177);  mul_308 = unsqueeze_177 = None
        unsqueeze_178: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_135, -1);  primals_135 = None
        unsqueeze_179: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_178, -1);  unsqueeze_178 = None
        add_237: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_314, unsqueeze_179);  mul_314 = unsqueeze_179 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_41: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_237);  add_237 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_45: f32[1, 2048, 2, 2] = torch.ops.aten.convolution.default(relu_41, primals_136, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_238: i64[] = torch.ops.aten.add.Tensor(primals_299, 1);  primals_299 = None
        var_mean_45 = torch.ops.aten.var_mean.correction(convolution_45, [0, 2, 3], correction = 0, keepdim = True)
        getitem_92: f32[1, 2048, 1, 1] = var_mean_45[0]
        getitem_93: f32[1, 2048, 1, 1] = var_mean_45[1];  var_mean_45 = None
        add_239: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_92, 1e-05)
        rsqrt_45: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_239);  add_239 = None
        sub_45: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_45, getitem_93)
        mul_315: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_45, rsqrt_45);  sub_45 = None
        squeeze_135: f32[2048] = torch.ops.aten.squeeze.dims(getitem_93, [0, 2, 3]);  getitem_93 = None
        squeeze_136: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_45, [0, 2, 3]);  rsqrt_45 = None
        mul_316: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_135, 0.1)
        mul_317: f32[2048] = torch.ops.aten.mul.Tensor(primals_297, 0.9);  primals_297 = None
        add_240: f32[2048] = torch.ops.aten.add.Tensor(mul_316, mul_317);  mul_316 = mul_317 = None
        squeeze_137: f32[2048] = torch.ops.aten.squeeze.dims(getitem_92, [0, 2, 3]);  getitem_92 = None
        mul_318: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_137, 1.3333333333333333);  squeeze_137 = None
        mul_319: f32[2048] = torch.ops.aten.mul.Tensor(mul_318, 0.1);  mul_318 = None
        mul_320: f32[2048] = torch.ops.aten.mul.Tensor(primals_298, 0.9);  primals_298 = None
        add_241: f32[2048] = torch.ops.aten.add.Tensor(mul_319, mul_320);  mul_319 = mul_320 = None
        unsqueeze_180: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_137, -1)
        unsqueeze_181: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_180, -1);  unsqueeze_180 = None
        mul_321: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(mul_315, unsqueeze_181);  mul_315 = unsqueeze_181 = None
        unsqueeze_182: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_138, -1);  primals_138 = None
        unsqueeze_183: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_182, -1);  unsqueeze_182 = None
        add_242: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(mul_321, unsqueeze_183);  mul_321 = unsqueeze_183 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        convolution_46: f32[1, 2048, 2, 2] = torch.ops.aten.convolution.default(relu_39, primals_139, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
        add_243: i64[] = torch.ops.aten.add.Tensor(primals_302, 1);  primals_302 = None
        var_mean_46 = torch.ops.aten.var_mean.correction(convolution_46, [0, 2, 3], correction = 0, keepdim = True)
        getitem_94: f32[1, 2048, 1, 1] = var_mean_46[0]
        getitem_95: f32[1, 2048, 1, 1] = var_mean_46[1];  var_mean_46 = None
        add_244: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_94, 1e-05)
        rsqrt_46: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_244);  add_244 = None
        sub_46: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_46, getitem_95)
        mul_322: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_46, rsqrt_46);  sub_46 = None
        squeeze_138: f32[2048] = torch.ops.aten.squeeze.dims(getitem_95, [0, 2, 3]);  getitem_95 = None
        squeeze_139: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_46, [0, 2, 3]);  rsqrt_46 = None
        mul_323: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_138, 0.1)
        mul_324: f32[2048] = torch.ops.aten.mul.Tensor(primals_300, 0.9);  primals_300 = None
        add_245: f32[2048] = torch.ops.aten.add.Tensor(mul_323, mul_324);  mul_323 = mul_324 = None
        squeeze_140: f32[2048] = torch.ops.aten.squeeze.dims(getitem_94, [0, 2, 3]);  getitem_94 = None
        mul_325: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_140, 1.3333333333333333);  squeeze_140 = None
        mul_326: f32[2048] = torch.ops.aten.mul.Tensor(mul_325, 0.1);  mul_325 = None
        mul_327: f32[2048] = torch.ops.aten.mul.Tensor(primals_301, 0.9);  primals_301 = None
        add_246: f32[2048] = torch.ops.aten.add.Tensor(mul_326, mul_327);  mul_326 = mul_327 = None
        unsqueeze_184: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_140, -1)
        unsqueeze_185: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_184, -1);  unsqueeze_184 = None
        mul_328: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(mul_322, unsqueeze_185);  mul_322 = unsqueeze_185 = None
        unsqueeze_186: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_141, -1);  primals_141 = None
        unsqueeze_187: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_186, -1);  unsqueeze_186 = None
        add_247: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(mul_328, unsqueeze_187);  mul_328 = unsqueeze_187 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_248: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(add_242, add_247);  add_242 = add_247 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_42: f32[1, 2048, 2, 2] = torch.ops.aten.relu.default(add_248);  add_248 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_47: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_42, primals_142, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_249: i64[] = torch.ops.aten.add.Tensor(primals_305, 1);  primals_305 = None
        var_mean_47 = torch.ops.aten.var_mean.correction(convolution_47, [0, 2, 3], correction = 0, keepdim = True)
        getitem_96: f32[1, 512, 1, 1] = var_mean_47[0]
        getitem_97: f32[1, 512, 1, 1] = var_mean_47[1];  var_mean_47 = None
        add_250: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_96, 1e-05)
        rsqrt_47: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_250);  add_250 = None
        sub_47: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_47, getitem_97)
        mul_329: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_47, rsqrt_47);  sub_47 = None
        squeeze_141: f32[512] = torch.ops.aten.squeeze.dims(getitem_97, [0, 2, 3]);  getitem_97 = None
        squeeze_142: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_47, [0, 2, 3]);  rsqrt_47 = None
        mul_330: f32[512] = torch.ops.aten.mul.Tensor(squeeze_141, 0.1)
        mul_331: f32[512] = torch.ops.aten.mul.Tensor(primals_303, 0.9);  primals_303 = None
        add_251: f32[512] = torch.ops.aten.add.Tensor(mul_330, mul_331);  mul_330 = mul_331 = None
        squeeze_143: f32[512] = torch.ops.aten.squeeze.dims(getitem_96, [0, 2, 3]);  getitem_96 = None
        mul_332: f32[512] = torch.ops.aten.mul.Tensor(squeeze_143, 1.3333333333333333);  squeeze_143 = None
        mul_333: f32[512] = torch.ops.aten.mul.Tensor(mul_332, 0.1);  mul_332 = None
        mul_334: f32[512] = torch.ops.aten.mul.Tensor(primals_304, 0.9);  primals_304 = None
        add_252: f32[512] = torch.ops.aten.add.Tensor(mul_333, mul_334);  mul_333 = mul_334 = None
        unsqueeze_188: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_143, -1)
        unsqueeze_189: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_188, -1);  unsqueeze_188 = None
        mul_335: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_329, unsqueeze_189);  mul_329 = unsqueeze_189 = None
        unsqueeze_190: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_144, -1);  primals_144 = None
        unsqueeze_191: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_190, -1);  unsqueeze_190 = None
        add_253: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_335, unsqueeze_191);  mul_335 = unsqueeze_191 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_43: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_253);  add_253 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_48: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_43, primals_145, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_254: i64[] = torch.ops.aten.add.Tensor(primals_308, 1);  primals_308 = None
        var_mean_48 = torch.ops.aten.var_mean.correction(convolution_48, [0, 2, 3], correction = 0, keepdim = True)
        getitem_98: f32[1, 512, 1, 1] = var_mean_48[0]
        getitem_99: f32[1, 512, 1, 1] = var_mean_48[1];  var_mean_48 = None
        add_255: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_98, 1e-05)
        rsqrt_48: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_255);  add_255 = None
        sub_48: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_48, getitem_99)
        mul_336: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_48, rsqrt_48);  sub_48 = None
        squeeze_144: f32[512] = torch.ops.aten.squeeze.dims(getitem_99, [0, 2, 3]);  getitem_99 = None
        squeeze_145: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_48, [0, 2, 3]);  rsqrt_48 = None
        mul_337: f32[512] = torch.ops.aten.mul.Tensor(squeeze_144, 0.1)
        mul_338: f32[512] = torch.ops.aten.mul.Tensor(primals_306, 0.9);  primals_306 = None
        add_256: f32[512] = torch.ops.aten.add.Tensor(mul_337, mul_338);  mul_337 = mul_338 = None
        squeeze_146: f32[512] = torch.ops.aten.squeeze.dims(getitem_98, [0, 2, 3]);  getitem_98 = None
        mul_339: f32[512] = torch.ops.aten.mul.Tensor(squeeze_146, 1.3333333333333333);  squeeze_146 = None
        mul_340: f32[512] = torch.ops.aten.mul.Tensor(mul_339, 0.1);  mul_339 = None
        mul_341: f32[512] = torch.ops.aten.mul.Tensor(primals_307, 0.9);  primals_307 = None
        add_257: f32[512] = torch.ops.aten.add.Tensor(mul_340, mul_341);  mul_340 = mul_341 = None
        unsqueeze_192: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_146, -1)
        unsqueeze_193: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_192, -1);  unsqueeze_192 = None
        mul_342: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_336, unsqueeze_193);  mul_336 = unsqueeze_193 = None
        unsqueeze_194: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_147, -1);  primals_147 = None
        unsqueeze_195: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_194, -1);  unsqueeze_194 = None
        add_258: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_342, unsqueeze_195);  mul_342 = unsqueeze_195 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_44: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_258);  add_258 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_49: f32[1, 2048, 2, 2] = torch.ops.aten.convolution.default(relu_44, primals_148, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_259: i64[] = torch.ops.aten.add.Tensor(primals_311, 1);  primals_311 = None
        var_mean_49 = torch.ops.aten.var_mean.correction(convolution_49, [0, 2, 3], correction = 0, keepdim = True)
        getitem_100: f32[1, 2048, 1, 1] = var_mean_49[0]
        getitem_101: f32[1, 2048, 1, 1] = var_mean_49[1];  var_mean_49 = None
        add_260: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_100, 1e-05)
        rsqrt_49: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_260);  add_260 = None
        sub_49: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_49, getitem_101)
        mul_343: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_49, rsqrt_49);  sub_49 = None
        squeeze_147: f32[2048] = torch.ops.aten.squeeze.dims(getitem_101, [0, 2, 3]);  getitem_101 = None
        squeeze_148: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_49, [0, 2, 3]);  rsqrt_49 = None
        mul_344: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_147, 0.1)
        mul_345: f32[2048] = torch.ops.aten.mul.Tensor(primals_309, 0.9);  primals_309 = None
        add_261: f32[2048] = torch.ops.aten.add.Tensor(mul_344, mul_345);  mul_344 = mul_345 = None
        squeeze_149: f32[2048] = torch.ops.aten.squeeze.dims(getitem_100, [0, 2, 3]);  getitem_100 = None
        mul_346: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_149, 1.3333333333333333);  squeeze_149 = None
        mul_347: f32[2048] = torch.ops.aten.mul.Tensor(mul_346, 0.1);  mul_346 = None
        mul_348: f32[2048] = torch.ops.aten.mul.Tensor(primals_310, 0.9);  primals_310 = None
        add_262: f32[2048] = torch.ops.aten.add.Tensor(mul_347, mul_348);  mul_347 = mul_348 = None
        unsqueeze_196: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_149, -1)
        unsqueeze_197: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_196, -1);  unsqueeze_196 = None
        mul_349: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(mul_343, unsqueeze_197);  mul_343 = unsqueeze_197 = None
        unsqueeze_198: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_150, -1);  primals_150 = None
        unsqueeze_199: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_198, -1);  unsqueeze_198 = None
        add_263: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(mul_349, unsqueeze_199);  mul_349 = unsqueeze_199 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_264: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(add_263, relu_42);  add_263 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_45: f32[1, 2048, 2, 2] = torch.ops.aten.relu.default(add_264);  add_264 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_50: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_45, primals_151, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_265: i64[] = torch.ops.aten.add.Tensor(primals_314, 1);  primals_314 = None
        var_mean_50 = torch.ops.aten.var_mean.correction(convolution_50, [0, 2, 3], correction = 0, keepdim = True)
        getitem_102: f32[1, 512, 1, 1] = var_mean_50[0]
        getitem_103: f32[1, 512, 1, 1] = var_mean_50[1];  var_mean_50 = None
        add_266: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_102, 1e-05)
        rsqrt_50: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_266);  add_266 = None
        sub_50: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_50, getitem_103)
        mul_350: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_50, rsqrt_50);  sub_50 = None
        squeeze_150: f32[512] = torch.ops.aten.squeeze.dims(getitem_103, [0, 2, 3]);  getitem_103 = None
        squeeze_151: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_50, [0, 2, 3]);  rsqrt_50 = None
        mul_351: f32[512] = torch.ops.aten.mul.Tensor(squeeze_150, 0.1)
        mul_352: f32[512] = torch.ops.aten.mul.Tensor(primals_312, 0.9);  primals_312 = None
        add_267: f32[512] = torch.ops.aten.add.Tensor(mul_351, mul_352);  mul_351 = mul_352 = None
        squeeze_152: f32[512] = torch.ops.aten.squeeze.dims(getitem_102, [0, 2, 3]);  getitem_102 = None
        mul_353: f32[512] = torch.ops.aten.mul.Tensor(squeeze_152, 1.3333333333333333);  squeeze_152 = None
        mul_354: f32[512] = torch.ops.aten.mul.Tensor(mul_353, 0.1);  mul_353 = None
        mul_355: f32[512] = torch.ops.aten.mul.Tensor(primals_313, 0.9);  primals_313 = None
        add_268: f32[512] = torch.ops.aten.add.Tensor(mul_354, mul_355);  mul_354 = mul_355 = None
        unsqueeze_200: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_152, -1)
        unsqueeze_201: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_200, -1);  unsqueeze_200 = None
        mul_356: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_350, unsqueeze_201);  mul_350 = unsqueeze_201 = None
        unsqueeze_202: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_153, -1);  primals_153 = None
        unsqueeze_203: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_202, -1);  unsqueeze_202 = None
        add_269: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_356, unsqueeze_203);  mul_356 = unsqueeze_203 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_46: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_269);  add_269 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_51: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_46, primals_154, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_270: i64[] = torch.ops.aten.add.Tensor(primals_317, 1);  primals_317 = None
        var_mean_51 = torch.ops.aten.var_mean.correction(convolution_51, [0, 2, 3], correction = 0, keepdim = True)
        getitem_104: f32[1, 512, 1, 1] = var_mean_51[0]
        getitem_105: f32[1, 512, 1, 1] = var_mean_51[1];  var_mean_51 = None
        add_271: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_104, 1e-05)
        rsqrt_51: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_271);  add_271 = None
        sub_51: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_51, getitem_105)
        mul_357: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_51, rsqrt_51);  sub_51 = None
        squeeze_153: f32[512] = torch.ops.aten.squeeze.dims(getitem_105, [0, 2, 3]);  getitem_105 = None
        squeeze_154: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_51, [0, 2, 3]);  rsqrt_51 = None
        mul_358: f32[512] = torch.ops.aten.mul.Tensor(squeeze_153, 0.1)
        mul_359: f32[512] = torch.ops.aten.mul.Tensor(primals_315, 0.9);  primals_315 = None
        add_272: f32[512] = torch.ops.aten.add.Tensor(mul_358, mul_359);  mul_358 = mul_359 = None
        squeeze_155: f32[512] = torch.ops.aten.squeeze.dims(getitem_104, [0, 2, 3]);  getitem_104 = None
        mul_360: f32[512] = torch.ops.aten.mul.Tensor(squeeze_155, 1.3333333333333333);  squeeze_155 = None
        mul_361: f32[512] = torch.ops.aten.mul.Tensor(mul_360, 0.1);  mul_360 = None
        mul_362: f32[512] = torch.ops.aten.mul.Tensor(primals_316, 0.9);  primals_316 = None
        add_273: f32[512] = torch.ops.aten.add.Tensor(mul_361, mul_362);  mul_361 = mul_362 = None
        unsqueeze_204: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_155, -1)
        unsqueeze_205: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_204, -1);  unsqueeze_204 = None
        mul_363: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_357, unsqueeze_205);  mul_357 = unsqueeze_205 = None
        unsqueeze_206: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_156, -1);  primals_156 = None
        unsqueeze_207: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_206, -1);  unsqueeze_206 = None
        add_274: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_363, unsqueeze_207);  mul_363 = unsqueeze_207 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_47: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_274);  add_274 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_52: f32[1, 2048, 2, 2] = torch.ops.aten.convolution.default(relu_47, primals_157, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_275: i64[] = torch.ops.aten.add.Tensor(primals_320, 1);  primals_320 = None
        var_mean_52 = torch.ops.aten.var_mean.correction(convolution_52, [0, 2, 3], correction = 0, keepdim = True)
        getitem_106: f32[1, 2048, 1, 1] = var_mean_52[0]
        getitem_107: f32[1, 2048, 1, 1] = var_mean_52[1];  var_mean_52 = None
        add_276: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_106, 1e-05)
        rsqrt_52: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_276);  add_276 = None
        sub_52: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_52, getitem_107)
        mul_364: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_52, rsqrt_52);  sub_52 = None
        squeeze_156: f32[2048] = torch.ops.aten.squeeze.dims(getitem_107, [0, 2, 3]);  getitem_107 = None
        squeeze_157: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_52, [0, 2, 3]);  rsqrt_52 = None
        mul_365: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_156, 0.1)
        mul_366: f32[2048] = torch.ops.aten.mul.Tensor(primals_318, 0.9);  primals_318 = None
        add_277: f32[2048] = torch.ops.aten.add.Tensor(mul_365, mul_366);  mul_365 = mul_366 = None
        squeeze_158: f32[2048] = torch.ops.aten.squeeze.dims(getitem_106, [0, 2, 3]);  getitem_106 = None
        mul_367: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_158, 1.3333333333333333);  squeeze_158 = None
        mul_368: f32[2048] = torch.ops.aten.mul.Tensor(mul_367, 0.1);  mul_367 = None
        mul_369: f32[2048] = torch.ops.aten.mul.Tensor(primals_319, 0.9);  primals_319 = None
        add_278: f32[2048] = torch.ops.aten.add.Tensor(mul_368, mul_369);  mul_368 = mul_369 = None
        unsqueeze_208: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_158, -1)
        unsqueeze_209: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_208, -1);  unsqueeze_208 = None
        mul_370: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(mul_364, unsqueeze_209);  mul_364 = unsqueeze_209 = None
        unsqueeze_210: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_159, -1);  primals_159 = None
        unsqueeze_211: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_210, -1);  unsqueeze_210 = None
        add_279: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(mul_370, unsqueeze_211);  mul_370 = unsqueeze_211 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_280: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(add_279, relu_45);  add_279 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_48: f32[1, 2048, 2, 2] = torch.ops.aten.relu.default(add_280);  add_280 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:242, code: x = self.avgpool(x)
        mean: f32[1, 2048, 1, 1] = torch.ops.aten.mean.dim(relu_48, [-1, -2], True)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:243, code: x = torch.flatten(x, 1)
        view: f32[1, 2048] = torch.ops.aten.view.default(mean, [1, 2048]);  mean = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:244, code: x = self.fc(x)
        permute: f32[2048, 1000] = torch.ops.aten.permute.default(primals_160, [1, 0]);  primals_160 = None
        addmm: f32[1, 1000] = torch.ops.aten.addmm.default(primals_161, view, permute);  primals_161 = None
        permute_1: f32[1000, 2048] = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
        mm: f32[1, 2048] = torch.ops.aten.mm.default(tangents_160, permute_1);  permute_1 = None
        permute_2: f32[1000, 1] = torch.ops.aten.permute.default(tangents_160, [1, 0])
        mm_1: f32[1000, 2048] = torch.ops.aten.mm.default(permute_2, view);  permute_2 = view = None
        permute_3: f32[2048, 1000] = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
        sum_1: f32[1, 1000] = torch.ops.aten.sum.dim_IntList(tangents_160, [0], True);  tangents_160 = None
        view_1: f32[1000] = torch.ops.aten.view.default(sum_1, [1000]);  sum_1 = None
        permute_4: f32[1000, 2048] = torch.ops.aten.permute.default(permute_3, [1, 0]);  permute_3 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:243, code: x = torch.flatten(x, 1)
        view_2: f32[1, 2048, 1, 1] = torch.ops.aten.view.default(mm, [1, 2048, 1, 1]);  mm = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:242, code: x = self.avgpool(x)
        expand: f32[1, 2048, 2, 2] = torch.ops.aten.expand.default(view_2, [1, 2048, 2, 2]);  view_2 = None
        div: f32[1, 2048, 2, 2] = torch.ops.aten.div.Scalar(expand, 4);  expand = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le: b8[1, 2048, 2, 2] = torch.ops.aten.le.Scalar(relu_48, 0);  relu_48 = None
        scalar_tensor: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where: f32[1, 2048, 2, 2] = torch.ops.aten.where.self(le, scalar_tensor, div);  le = scalar_tensor = div = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_212: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_156, 0);  squeeze_156 = None
        unsqueeze_213: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_212, 2);  unsqueeze_212 = None
        unsqueeze_214: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_213, 3);  unsqueeze_213 = None
        sum_2: f32[2048] = torch.ops.aten.sum.dim_IntList(where, [0, 2, 3])
        sub_53: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_52, unsqueeze_214)
        mul_371: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(where, sub_53);  sub_53 = None
        sum_3: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_371, [0, 2, 3]);  mul_371 = None
        mul_372: f32[2048] = torch.ops.aten.mul.Tensor(sum_2, 0.25)
        unsqueeze_215: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_372, 0);  mul_372 = None
        unsqueeze_216: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_215, 2);  unsqueeze_215 = None
        unsqueeze_217: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_216, 3);  unsqueeze_216 = None
        mul_373: f32[2048] = torch.ops.aten.mul.Tensor(sum_3, 0.25)
        mul_374: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_157, squeeze_157)
        mul_375: f32[2048] = torch.ops.aten.mul.Tensor(mul_373, mul_374);  mul_373 = mul_374 = None
        unsqueeze_218: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_375, 0);  mul_375 = None
        unsqueeze_219: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_218, 2);  unsqueeze_218 = None
        unsqueeze_220: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_219, 3);  unsqueeze_219 = None
        mul_376: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_157, primals_158);  primals_158 = None
        unsqueeze_221: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_376, 0);  mul_376 = None
        unsqueeze_222: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_221, 2);  unsqueeze_221 = None
        unsqueeze_223: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_222, 3);  unsqueeze_222 = None
        sub_54: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_52, unsqueeze_214);  convolution_52 = unsqueeze_214 = None
        mul_377: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_54, unsqueeze_220);  sub_54 = unsqueeze_220 = None
        sub_55: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(where, mul_377);  mul_377 = None
        sub_56: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(sub_55, unsqueeze_217);  sub_55 = unsqueeze_217 = None
        mul_378: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_56, unsqueeze_223);  sub_56 = unsqueeze_223 = None
        mul_379: f32[2048] = torch.ops.aten.mul.Tensor(sum_3, squeeze_157);  sum_3 = squeeze_157 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward = torch.ops.aten.convolution_backward.default(mul_378, relu_47, primals_157, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_378 = primals_157 = None
        getitem_108: f32[1, 512, 2, 2] = convolution_backward[0]
        getitem_109: f32[2048, 512, 1, 1] = convolution_backward[1];  convolution_backward = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_1: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_47, 0);  relu_47 = None
        scalar_tensor_1: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_1: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_1, scalar_tensor_1, getitem_108);  le_1 = scalar_tensor_1 = getitem_108 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_224: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_153, 0);  squeeze_153 = None
        unsqueeze_225: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_224, 2);  unsqueeze_224 = None
        unsqueeze_226: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_225, 3);  unsqueeze_225 = None
        sum_4: f32[512] = torch.ops.aten.sum.dim_IntList(where_1, [0, 2, 3])
        sub_57: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_51, unsqueeze_226)
        mul_380: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_1, sub_57);  sub_57 = None
        sum_5: f32[512] = torch.ops.aten.sum.dim_IntList(mul_380, [0, 2, 3]);  mul_380 = None
        mul_381: f32[512] = torch.ops.aten.mul.Tensor(sum_4, 0.25)
        unsqueeze_227: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_381, 0);  mul_381 = None
        unsqueeze_228: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_227, 2);  unsqueeze_227 = None
        unsqueeze_229: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_228, 3);  unsqueeze_228 = None
        mul_382: f32[512] = torch.ops.aten.mul.Tensor(sum_5, 0.25)
        mul_383: f32[512] = torch.ops.aten.mul.Tensor(squeeze_154, squeeze_154)
        mul_384: f32[512] = torch.ops.aten.mul.Tensor(mul_382, mul_383);  mul_382 = mul_383 = None
        unsqueeze_230: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_384, 0);  mul_384 = None
        unsqueeze_231: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_230, 2);  unsqueeze_230 = None
        unsqueeze_232: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_231, 3);  unsqueeze_231 = None
        mul_385: f32[512] = torch.ops.aten.mul.Tensor(squeeze_154, primals_155);  primals_155 = None
        unsqueeze_233: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_385, 0);  mul_385 = None
        unsqueeze_234: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_233, 2);  unsqueeze_233 = None
        unsqueeze_235: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_234, 3);  unsqueeze_234 = None
        sub_58: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_51, unsqueeze_226);  convolution_51 = unsqueeze_226 = None
        mul_386: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_58, unsqueeze_232);  sub_58 = unsqueeze_232 = None
        sub_59: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_1, mul_386);  where_1 = mul_386 = None
        sub_60: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_59, unsqueeze_229);  sub_59 = unsqueeze_229 = None
        mul_387: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_60, unsqueeze_235);  sub_60 = unsqueeze_235 = None
        mul_388: f32[512] = torch.ops.aten.mul.Tensor(sum_5, squeeze_154);  sum_5 = squeeze_154 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_1 = torch.ops.aten.convolution_backward.default(mul_387, relu_46, primals_154, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_387 = primals_154 = None
        getitem_111: f32[1, 512, 2, 2] = convolution_backward_1[0]
        getitem_112: f32[512, 512, 3, 3] = convolution_backward_1[1];  convolution_backward_1 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_2: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_46, 0);  relu_46 = None
        scalar_tensor_2: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_2: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_2, scalar_tensor_2, getitem_111);  le_2 = scalar_tensor_2 = getitem_111 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_236: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_150, 0);  squeeze_150 = None
        unsqueeze_237: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_236, 2);  unsqueeze_236 = None
        unsqueeze_238: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_237, 3);  unsqueeze_237 = None
        sum_6: f32[512] = torch.ops.aten.sum.dim_IntList(where_2, [0, 2, 3])
        sub_61: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_50, unsqueeze_238)
        mul_389: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_2, sub_61);  sub_61 = None
        sum_7: f32[512] = torch.ops.aten.sum.dim_IntList(mul_389, [0, 2, 3]);  mul_389 = None
        mul_390: f32[512] = torch.ops.aten.mul.Tensor(sum_6, 0.25)
        unsqueeze_239: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_390, 0);  mul_390 = None
        unsqueeze_240: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_239, 2);  unsqueeze_239 = None
        unsqueeze_241: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_240, 3);  unsqueeze_240 = None
        mul_391: f32[512] = torch.ops.aten.mul.Tensor(sum_7, 0.25)
        mul_392: f32[512] = torch.ops.aten.mul.Tensor(squeeze_151, squeeze_151)
        mul_393: f32[512] = torch.ops.aten.mul.Tensor(mul_391, mul_392);  mul_391 = mul_392 = None
        unsqueeze_242: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_393, 0);  mul_393 = None
        unsqueeze_243: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_242, 2);  unsqueeze_242 = None
        unsqueeze_244: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_243, 3);  unsqueeze_243 = None
        mul_394: f32[512] = torch.ops.aten.mul.Tensor(squeeze_151, primals_152);  primals_152 = None
        unsqueeze_245: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_394, 0);  mul_394 = None
        unsqueeze_246: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_245, 2);  unsqueeze_245 = None
        unsqueeze_247: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_246, 3);  unsqueeze_246 = None
        sub_62: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_50, unsqueeze_238);  convolution_50 = unsqueeze_238 = None
        mul_395: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_62, unsqueeze_244);  sub_62 = unsqueeze_244 = None
        sub_63: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_2, mul_395);  where_2 = mul_395 = None
        sub_64: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_63, unsqueeze_241);  sub_63 = unsqueeze_241 = None
        mul_396: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_64, unsqueeze_247);  sub_64 = unsqueeze_247 = None
        mul_397: f32[512] = torch.ops.aten.mul.Tensor(sum_7, squeeze_151);  sum_7 = squeeze_151 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_2 = torch.ops.aten.convolution_backward.default(mul_396, relu_45, primals_151, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_396 = primals_151 = None
        getitem_114: f32[1, 2048, 2, 2] = convolution_backward_2[0]
        getitem_115: f32[512, 2048, 1, 1] = convolution_backward_2[1];  convolution_backward_2 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_281: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(where, getitem_114);  where = getitem_114 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_3: b8[1, 2048, 2, 2] = torch.ops.aten.le.Scalar(relu_45, 0);  relu_45 = None
        scalar_tensor_3: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_3: f32[1, 2048, 2, 2] = torch.ops.aten.where.self(le_3, scalar_tensor_3, add_281);  le_3 = scalar_tensor_3 = add_281 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_248: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_147, 0);  squeeze_147 = None
        unsqueeze_249: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_248, 2);  unsqueeze_248 = None
        unsqueeze_250: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_249, 3);  unsqueeze_249 = None
        sum_8: f32[2048] = torch.ops.aten.sum.dim_IntList(where_3, [0, 2, 3])
        sub_65: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_49, unsqueeze_250)
        mul_398: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(where_3, sub_65);  sub_65 = None
        sum_9: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_398, [0, 2, 3]);  mul_398 = None
        mul_399: f32[2048] = torch.ops.aten.mul.Tensor(sum_8, 0.25)
        unsqueeze_251: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_399, 0);  mul_399 = None
        unsqueeze_252: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_251, 2);  unsqueeze_251 = None
        unsqueeze_253: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_252, 3);  unsqueeze_252 = None
        mul_400: f32[2048] = torch.ops.aten.mul.Tensor(sum_9, 0.25)
        mul_401: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_148, squeeze_148)
        mul_402: f32[2048] = torch.ops.aten.mul.Tensor(mul_400, mul_401);  mul_400 = mul_401 = None
        unsqueeze_254: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_402, 0);  mul_402 = None
        unsqueeze_255: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_254, 2);  unsqueeze_254 = None
        unsqueeze_256: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_255, 3);  unsqueeze_255 = None
        mul_403: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_148, primals_149);  primals_149 = None
        unsqueeze_257: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_403, 0);  mul_403 = None
        unsqueeze_258: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_257, 2);  unsqueeze_257 = None
        unsqueeze_259: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_258, 3);  unsqueeze_258 = None
        sub_66: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_49, unsqueeze_250);  convolution_49 = unsqueeze_250 = None
        mul_404: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_66, unsqueeze_256);  sub_66 = unsqueeze_256 = None
        sub_67: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(where_3, mul_404);  mul_404 = None
        sub_68: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(sub_67, unsqueeze_253);  sub_67 = unsqueeze_253 = None
        mul_405: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_68, unsqueeze_259);  sub_68 = unsqueeze_259 = None
        mul_406: f32[2048] = torch.ops.aten.mul.Tensor(sum_9, squeeze_148);  sum_9 = squeeze_148 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_3 = torch.ops.aten.convolution_backward.default(mul_405, relu_44, primals_148, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_405 = primals_148 = None
        getitem_117: f32[1, 512, 2, 2] = convolution_backward_3[0]
        getitem_118: f32[2048, 512, 1, 1] = convolution_backward_3[1];  convolution_backward_3 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_4: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_44, 0);  relu_44 = None
        scalar_tensor_4: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_4: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_4, scalar_tensor_4, getitem_117);  le_4 = scalar_tensor_4 = getitem_117 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_260: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_144, 0);  squeeze_144 = None
        unsqueeze_261: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_260, 2);  unsqueeze_260 = None
        unsqueeze_262: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_261, 3);  unsqueeze_261 = None
        sum_10: f32[512] = torch.ops.aten.sum.dim_IntList(where_4, [0, 2, 3])
        sub_69: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_48, unsqueeze_262)
        mul_407: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_4, sub_69);  sub_69 = None
        sum_11: f32[512] = torch.ops.aten.sum.dim_IntList(mul_407, [0, 2, 3]);  mul_407 = None
        mul_408: f32[512] = torch.ops.aten.mul.Tensor(sum_10, 0.25)
        unsqueeze_263: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_408, 0);  mul_408 = None
        unsqueeze_264: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_263, 2);  unsqueeze_263 = None
        unsqueeze_265: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_264, 3);  unsqueeze_264 = None
        mul_409: f32[512] = torch.ops.aten.mul.Tensor(sum_11, 0.25)
        mul_410: f32[512] = torch.ops.aten.mul.Tensor(squeeze_145, squeeze_145)
        mul_411: f32[512] = torch.ops.aten.mul.Tensor(mul_409, mul_410);  mul_409 = mul_410 = None
        unsqueeze_266: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_411, 0);  mul_411 = None
        unsqueeze_267: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_266, 2);  unsqueeze_266 = None
        unsqueeze_268: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_267, 3);  unsqueeze_267 = None
        mul_412: f32[512] = torch.ops.aten.mul.Tensor(squeeze_145, primals_146);  primals_146 = None
        unsqueeze_269: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_412, 0);  mul_412 = None
        unsqueeze_270: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_269, 2);  unsqueeze_269 = None
        unsqueeze_271: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_270, 3);  unsqueeze_270 = None
        sub_70: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_48, unsqueeze_262);  convolution_48 = unsqueeze_262 = None
        mul_413: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_70, unsqueeze_268);  sub_70 = unsqueeze_268 = None
        sub_71: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_4, mul_413);  where_4 = mul_413 = None
        sub_72: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_71, unsqueeze_265);  sub_71 = unsqueeze_265 = None
        mul_414: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_72, unsqueeze_271);  sub_72 = unsqueeze_271 = None
        mul_415: f32[512] = torch.ops.aten.mul.Tensor(sum_11, squeeze_145);  sum_11 = squeeze_145 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_4 = torch.ops.aten.convolution_backward.default(mul_414, relu_43, primals_145, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_414 = primals_145 = None
        getitem_120: f32[1, 512, 2, 2] = convolution_backward_4[0]
        getitem_121: f32[512, 512, 3, 3] = convolution_backward_4[1];  convolution_backward_4 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_5: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_43, 0);  relu_43 = None
        scalar_tensor_5: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_5: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_5, scalar_tensor_5, getitem_120);  le_5 = scalar_tensor_5 = getitem_120 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_272: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_141, 0);  squeeze_141 = None
        unsqueeze_273: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_272, 2);  unsqueeze_272 = None
        unsqueeze_274: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_273, 3);  unsqueeze_273 = None
        sum_12: f32[512] = torch.ops.aten.sum.dim_IntList(where_5, [0, 2, 3])
        sub_73: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_47, unsqueeze_274)
        mul_416: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_5, sub_73);  sub_73 = None
        sum_13: f32[512] = torch.ops.aten.sum.dim_IntList(mul_416, [0, 2, 3]);  mul_416 = None
        mul_417: f32[512] = torch.ops.aten.mul.Tensor(sum_12, 0.25)
        unsqueeze_275: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_417, 0);  mul_417 = None
        unsqueeze_276: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_275, 2);  unsqueeze_275 = None
        unsqueeze_277: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_276, 3);  unsqueeze_276 = None
        mul_418: f32[512] = torch.ops.aten.mul.Tensor(sum_13, 0.25)
        mul_419: f32[512] = torch.ops.aten.mul.Tensor(squeeze_142, squeeze_142)
        mul_420: f32[512] = torch.ops.aten.mul.Tensor(mul_418, mul_419);  mul_418 = mul_419 = None
        unsqueeze_278: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_420, 0);  mul_420 = None
        unsqueeze_279: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_278, 2);  unsqueeze_278 = None
        unsqueeze_280: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_279, 3);  unsqueeze_279 = None
        mul_421: f32[512] = torch.ops.aten.mul.Tensor(squeeze_142, primals_143);  primals_143 = None
        unsqueeze_281: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_421, 0);  mul_421 = None
        unsqueeze_282: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_281, 2);  unsqueeze_281 = None
        unsqueeze_283: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_282, 3);  unsqueeze_282 = None
        sub_74: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_47, unsqueeze_274);  convolution_47 = unsqueeze_274 = None
        mul_422: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_74, unsqueeze_280);  sub_74 = unsqueeze_280 = None
        sub_75: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_5, mul_422);  where_5 = mul_422 = None
        sub_76: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_75, unsqueeze_277);  sub_75 = unsqueeze_277 = None
        mul_423: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_76, unsqueeze_283);  sub_76 = unsqueeze_283 = None
        mul_424: f32[512] = torch.ops.aten.mul.Tensor(sum_13, squeeze_142);  sum_13 = squeeze_142 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_5 = torch.ops.aten.convolution_backward.default(mul_423, relu_42, primals_142, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_423 = primals_142 = None
        getitem_123: f32[1, 2048, 2, 2] = convolution_backward_5[0]
        getitem_124: f32[512, 2048, 1, 1] = convolution_backward_5[1];  convolution_backward_5 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_282: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(where_3, getitem_123);  where_3 = getitem_123 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_6: b8[1, 2048, 2, 2] = torch.ops.aten.le.Scalar(relu_42, 0);  relu_42 = None
        scalar_tensor_6: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_6: f32[1, 2048, 2, 2] = torch.ops.aten.where.self(le_6, scalar_tensor_6, add_282);  le_6 = scalar_tensor_6 = add_282 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        unsqueeze_284: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_138, 0);  squeeze_138 = None
        unsqueeze_285: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_284, 2);  unsqueeze_284 = None
        unsqueeze_286: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_285, 3);  unsqueeze_285 = None
        sum_14: f32[2048] = torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])
        sub_77: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_46, unsqueeze_286)
        mul_425: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(where_6, sub_77);  sub_77 = None
        sum_15: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_425, [0, 2, 3]);  mul_425 = None
        mul_426: f32[2048] = torch.ops.aten.mul.Tensor(sum_14, 0.25)
        unsqueeze_287: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_426, 0);  mul_426 = None
        unsqueeze_288: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_287, 2);  unsqueeze_287 = None
        unsqueeze_289: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_288, 3);  unsqueeze_288 = None
        mul_427: f32[2048] = torch.ops.aten.mul.Tensor(sum_15, 0.25)
        mul_428: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_139, squeeze_139)
        mul_429: f32[2048] = torch.ops.aten.mul.Tensor(mul_427, mul_428);  mul_427 = mul_428 = None
        unsqueeze_290: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_429, 0);  mul_429 = None
        unsqueeze_291: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_290, 2);  unsqueeze_290 = None
        unsqueeze_292: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_291, 3);  unsqueeze_291 = None
        mul_430: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_139, primals_140);  primals_140 = None
        unsqueeze_293: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_430, 0);  mul_430 = None
        unsqueeze_294: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_293, 2);  unsqueeze_293 = None
        unsqueeze_295: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_294, 3);  unsqueeze_294 = None
        sub_78: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_46, unsqueeze_286);  convolution_46 = unsqueeze_286 = None
        mul_431: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_78, unsqueeze_292);  sub_78 = unsqueeze_292 = None
        sub_79: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(where_6, mul_431);  mul_431 = None
        sub_80: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(sub_79, unsqueeze_289);  sub_79 = unsqueeze_289 = None
        mul_432: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_80, unsqueeze_295);  sub_80 = unsqueeze_295 = None
        mul_433: f32[2048] = torch.ops.aten.mul.Tensor(sum_15, squeeze_139);  sum_15 = squeeze_139 = None
        convolution_backward_6 = torch.ops.aten.convolution_backward.default(mul_432, relu_39, primals_139, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_432 = primals_139 = None
        getitem_126: f32[1, 1024, 4, 4] = convolution_backward_6[0]
        getitem_127: f32[2048, 1024, 1, 1] = convolution_backward_6[1];  convolution_backward_6 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_296: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_135, 0);  squeeze_135 = None
        unsqueeze_297: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_296, 2);  unsqueeze_296 = None
        unsqueeze_298: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_297, 3);  unsqueeze_297 = None
        sum_16: f32[2048] = torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])
        sub_81: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_45, unsqueeze_298)
        mul_434: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(where_6, sub_81);  sub_81 = None
        sum_17: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_434, [0, 2, 3]);  mul_434 = None
        mul_435: f32[2048] = torch.ops.aten.mul.Tensor(sum_16, 0.25)
        unsqueeze_299: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_435, 0);  mul_435 = None
        unsqueeze_300: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_299, 2);  unsqueeze_299 = None
        unsqueeze_301: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_300, 3);  unsqueeze_300 = None
        mul_436: f32[2048] = torch.ops.aten.mul.Tensor(sum_17, 0.25)
        mul_437: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_136, squeeze_136)
        mul_438: f32[2048] = torch.ops.aten.mul.Tensor(mul_436, mul_437);  mul_436 = mul_437 = None
        unsqueeze_302: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_438, 0);  mul_438 = None
        unsqueeze_303: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_302, 2);  unsqueeze_302 = None
        unsqueeze_304: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_303, 3);  unsqueeze_303 = None
        mul_439: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_136, primals_137);  primals_137 = None
        unsqueeze_305: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_439, 0);  mul_439 = None
        unsqueeze_306: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_305, 2);  unsqueeze_305 = None
        unsqueeze_307: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_306, 3);  unsqueeze_306 = None
        sub_82: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_45, unsqueeze_298);  convolution_45 = unsqueeze_298 = None
        mul_440: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_82, unsqueeze_304);  sub_82 = unsqueeze_304 = None
        sub_83: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(where_6, mul_440);  where_6 = mul_440 = None
        sub_84: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(sub_83, unsqueeze_301);  sub_83 = unsqueeze_301 = None
        mul_441: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_84, unsqueeze_307);  sub_84 = unsqueeze_307 = None
        mul_442: f32[2048] = torch.ops.aten.mul.Tensor(sum_17, squeeze_136);  sum_17 = squeeze_136 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_7 = torch.ops.aten.convolution_backward.default(mul_441, relu_41, primals_136, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_441 = primals_136 = None
        getitem_129: f32[1, 512, 2, 2] = convolution_backward_7[0]
        getitem_130: f32[2048, 512, 1, 1] = convolution_backward_7[1];  convolution_backward_7 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_7: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_41, 0);  relu_41 = None
        scalar_tensor_7: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_7: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_7, scalar_tensor_7, getitem_129);  le_7 = scalar_tensor_7 = getitem_129 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_308: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_132, 0);  squeeze_132 = None
        unsqueeze_309: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_308, 2);  unsqueeze_308 = None
        unsqueeze_310: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_309, 3);  unsqueeze_309 = None
        sum_18: f32[512] = torch.ops.aten.sum.dim_IntList(where_7, [0, 2, 3])
        sub_85: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_44, unsqueeze_310)
        mul_443: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_7, sub_85);  sub_85 = None
        sum_19: f32[512] = torch.ops.aten.sum.dim_IntList(mul_443, [0, 2, 3]);  mul_443 = None
        mul_444: f32[512] = torch.ops.aten.mul.Tensor(sum_18, 0.25)
        unsqueeze_311: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_444, 0);  mul_444 = None
        unsqueeze_312: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_311, 2);  unsqueeze_311 = None
        unsqueeze_313: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_312, 3);  unsqueeze_312 = None
        mul_445: f32[512] = torch.ops.aten.mul.Tensor(sum_19, 0.25)
        mul_446: f32[512] = torch.ops.aten.mul.Tensor(squeeze_133, squeeze_133)
        mul_447: f32[512] = torch.ops.aten.mul.Tensor(mul_445, mul_446);  mul_445 = mul_446 = None
        unsqueeze_314: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_447, 0);  mul_447 = None
        unsqueeze_315: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_314, 2);  unsqueeze_314 = None
        unsqueeze_316: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_315, 3);  unsqueeze_315 = None
        mul_448: f32[512] = torch.ops.aten.mul.Tensor(squeeze_133, primals_134);  primals_134 = None
        unsqueeze_317: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_448, 0);  mul_448 = None
        unsqueeze_318: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_317, 2);  unsqueeze_317 = None
        unsqueeze_319: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_318, 3);  unsqueeze_318 = None
        sub_86: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_44, unsqueeze_310);  convolution_44 = unsqueeze_310 = None
        mul_449: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_86, unsqueeze_316);  sub_86 = unsqueeze_316 = None
        sub_87: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_7, mul_449);  where_7 = mul_449 = None
        sub_88: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_87, unsqueeze_313);  sub_87 = unsqueeze_313 = None
        mul_450: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_88, unsqueeze_319);  sub_88 = unsqueeze_319 = None
        mul_451: f32[512] = torch.ops.aten.mul.Tensor(sum_19, squeeze_133);  sum_19 = squeeze_133 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_8 = torch.ops.aten.convolution_backward.default(mul_450, relu_40, primals_133, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_450 = primals_133 = None
        getitem_132: f32[1, 512, 4, 4] = convolution_backward_8[0]
        getitem_133: f32[512, 512, 3, 3] = convolution_backward_8[1];  convolution_backward_8 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_8: b8[1, 512, 4, 4] = torch.ops.aten.le.Scalar(relu_40, 0);  relu_40 = None
        scalar_tensor_8: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_8: f32[1, 512, 4, 4] = torch.ops.aten.where.self(le_8, scalar_tensor_8, getitem_132);  le_8 = scalar_tensor_8 = getitem_132 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_320: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_129, 0);  squeeze_129 = None
        unsqueeze_321: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_320, 2);  unsqueeze_320 = None
        unsqueeze_322: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_321, 3);  unsqueeze_321 = None
        sum_20: f32[512] = torch.ops.aten.sum.dim_IntList(where_8, [0, 2, 3])
        sub_89: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(convolution_43, unsqueeze_322)
        mul_452: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(where_8, sub_89);  sub_89 = None
        sum_21: f32[512] = torch.ops.aten.sum.dim_IntList(mul_452, [0, 2, 3]);  mul_452 = None
        mul_453: f32[512] = torch.ops.aten.mul.Tensor(sum_20, 0.0625)
        unsqueeze_323: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_453, 0);  mul_453 = None
        unsqueeze_324: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_323, 2);  unsqueeze_323 = None
        unsqueeze_325: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_324, 3);  unsqueeze_324 = None
        mul_454: f32[512] = torch.ops.aten.mul.Tensor(sum_21, 0.0625)
        mul_455: f32[512] = torch.ops.aten.mul.Tensor(squeeze_130, squeeze_130)
        mul_456: f32[512] = torch.ops.aten.mul.Tensor(mul_454, mul_455);  mul_454 = mul_455 = None
        unsqueeze_326: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_456, 0);  mul_456 = None
        unsqueeze_327: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_326, 2);  unsqueeze_326 = None
        unsqueeze_328: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_327, 3);  unsqueeze_327 = None
        mul_457: f32[512] = torch.ops.aten.mul.Tensor(squeeze_130, primals_131);  primals_131 = None
        unsqueeze_329: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_457, 0);  mul_457 = None
        unsqueeze_330: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_329, 2);  unsqueeze_329 = None
        unsqueeze_331: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_330, 3);  unsqueeze_330 = None
        sub_90: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(convolution_43, unsqueeze_322);  convolution_43 = unsqueeze_322 = None
        mul_458: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(sub_90, unsqueeze_328);  sub_90 = unsqueeze_328 = None
        sub_91: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(where_8, mul_458);  where_8 = mul_458 = None
        sub_92: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(sub_91, unsqueeze_325);  sub_91 = unsqueeze_325 = None
        mul_459: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(sub_92, unsqueeze_331);  sub_92 = unsqueeze_331 = None
        mul_460: f32[512] = torch.ops.aten.mul.Tensor(sum_21, squeeze_130);  sum_21 = squeeze_130 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_9 = torch.ops.aten.convolution_backward.default(mul_459, relu_39, primals_130, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_459 = primals_130 = None
        getitem_135: f32[1, 1024, 4, 4] = convolution_backward_9[0]
        getitem_136: f32[512, 1024, 1, 1] = convolution_backward_9[1];  convolution_backward_9 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_283: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(getitem_126, getitem_135);  getitem_126 = getitem_135 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_9: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_39, 0);  relu_39 = None
        scalar_tensor_9: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_9: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_9, scalar_tensor_9, add_283);  le_9 = scalar_tensor_9 = add_283 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_332: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_126, 0);  squeeze_126 = None
        unsqueeze_333: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_332, 2);  unsqueeze_332 = None
        unsqueeze_334: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_333, 3);  unsqueeze_333 = None
        sum_22: f32[1024] = torch.ops.aten.sum.dim_IntList(where_9, [0, 2, 3])
        sub_93: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_42, unsqueeze_334)
        mul_461: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_9, sub_93);  sub_93 = None
        sum_23: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_461, [0, 2, 3]);  mul_461 = None
        mul_462: f32[1024] = torch.ops.aten.mul.Tensor(sum_22, 0.0625)
        unsqueeze_335: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_462, 0);  mul_462 = None
        unsqueeze_336: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_335, 2);  unsqueeze_335 = None
        unsqueeze_337: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_336, 3);  unsqueeze_336 = None
        mul_463: f32[1024] = torch.ops.aten.mul.Tensor(sum_23, 0.0625)
        mul_464: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_127, squeeze_127)
        mul_465: f32[1024] = torch.ops.aten.mul.Tensor(mul_463, mul_464);  mul_463 = mul_464 = None
        unsqueeze_338: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_465, 0);  mul_465 = None
        unsqueeze_339: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_338, 2);  unsqueeze_338 = None
        unsqueeze_340: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_339, 3);  unsqueeze_339 = None
        mul_466: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_127, primals_128);  primals_128 = None
        unsqueeze_341: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_466, 0);  mul_466 = None
        unsqueeze_342: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_341, 2);  unsqueeze_341 = None
        unsqueeze_343: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_342, 3);  unsqueeze_342 = None
        sub_94: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_42, unsqueeze_334);  convolution_42 = unsqueeze_334 = None
        mul_467: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_94, unsqueeze_340);  sub_94 = unsqueeze_340 = None
        sub_95: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_9, mul_467);  mul_467 = None
        sub_96: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_95, unsqueeze_337);  sub_95 = unsqueeze_337 = None
        mul_468: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_96, unsqueeze_343);  sub_96 = unsqueeze_343 = None
        mul_469: f32[1024] = torch.ops.aten.mul.Tensor(sum_23, squeeze_127);  sum_23 = squeeze_127 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_10 = torch.ops.aten.convolution_backward.default(mul_468, relu_38, primals_127, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_468 = primals_127 = None
        getitem_138: f32[1, 256, 4, 4] = convolution_backward_10[0]
        getitem_139: f32[1024, 256, 1, 1] = convolution_backward_10[1];  convolution_backward_10 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_10: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_38, 0);  relu_38 = None
        scalar_tensor_10: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_10: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_10, scalar_tensor_10, getitem_138);  le_10 = scalar_tensor_10 = getitem_138 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_344: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_123, 0);  squeeze_123 = None
        unsqueeze_345: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_344, 2);  unsqueeze_344 = None
        unsqueeze_346: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_345, 3);  unsqueeze_345 = None
        sum_24: f32[256] = torch.ops.aten.sum.dim_IntList(where_10, [0, 2, 3])
        sub_97: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_41, unsqueeze_346)
        mul_470: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_10, sub_97);  sub_97 = None
        sum_25: f32[256] = torch.ops.aten.sum.dim_IntList(mul_470, [0, 2, 3]);  mul_470 = None
        mul_471: f32[256] = torch.ops.aten.mul.Tensor(sum_24, 0.0625)
        unsqueeze_347: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_471, 0);  mul_471 = None
        unsqueeze_348: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_347, 2);  unsqueeze_347 = None
        unsqueeze_349: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_348, 3);  unsqueeze_348 = None
        mul_472: f32[256] = torch.ops.aten.mul.Tensor(sum_25, 0.0625)
        mul_473: f32[256] = torch.ops.aten.mul.Tensor(squeeze_124, squeeze_124)
        mul_474: f32[256] = torch.ops.aten.mul.Tensor(mul_472, mul_473);  mul_472 = mul_473 = None
        unsqueeze_350: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_474, 0);  mul_474 = None
        unsqueeze_351: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_350, 2);  unsqueeze_350 = None
        unsqueeze_352: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_351, 3);  unsqueeze_351 = None
        mul_475: f32[256] = torch.ops.aten.mul.Tensor(squeeze_124, primals_125);  primals_125 = None
        unsqueeze_353: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_475, 0);  mul_475 = None
        unsqueeze_354: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_353, 2);  unsqueeze_353 = None
        unsqueeze_355: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_354, 3);  unsqueeze_354 = None
        sub_98: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_41, unsqueeze_346);  convolution_41 = unsqueeze_346 = None
        mul_476: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_98, unsqueeze_352);  sub_98 = unsqueeze_352 = None
        sub_99: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_10, mul_476);  where_10 = mul_476 = None
        sub_100: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_99, unsqueeze_349);  sub_99 = unsqueeze_349 = None
        mul_477: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_100, unsqueeze_355);  sub_100 = unsqueeze_355 = None
        mul_478: f32[256] = torch.ops.aten.mul.Tensor(sum_25, squeeze_124);  sum_25 = squeeze_124 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_11 = torch.ops.aten.convolution_backward.default(mul_477, relu_37, primals_124, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_477 = primals_124 = None
        getitem_141: f32[1, 256, 4, 4] = convolution_backward_11[0]
        getitem_142: f32[256, 256, 3, 3] = convolution_backward_11[1];  convolution_backward_11 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_11: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_37, 0);  relu_37 = None
        scalar_tensor_11: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_11: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_11, scalar_tensor_11, getitem_141);  le_11 = scalar_tensor_11 = getitem_141 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_356: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_120, 0);  squeeze_120 = None
        unsqueeze_357: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_356, 2);  unsqueeze_356 = None
        unsqueeze_358: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_357, 3);  unsqueeze_357 = None
        sum_26: f32[256] = torch.ops.aten.sum.dim_IntList(where_11, [0, 2, 3])
        sub_101: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_40, unsqueeze_358)
        mul_479: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_11, sub_101);  sub_101 = None
        sum_27: f32[256] = torch.ops.aten.sum.dim_IntList(mul_479, [0, 2, 3]);  mul_479 = None
        mul_480: f32[256] = torch.ops.aten.mul.Tensor(sum_26, 0.0625)
        unsqueeze_359: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_480, 0);  mul_480 = None
        unsqueeze_360: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_359, 2);  unsqueeze_359 = None
        unsqueeze_361: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_360, 3);  unsqueeze_360 = None
        mul_481: f32[256] = torch.ops.aten.mul.Tensor(sum_27, 0.0625)
        mul_482: f32[256] = torch.ops.aten.mul.Tensor(squeeze_121, squeeze_121)
        mul_483: f32[256] = torch.ops.aten.mul.Tensor(mul_481, mul_482);  mul_481 = mul_482 = None
        unsqueeze_362: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_483, 0);  mul_483 = None
        unsqueeze_363: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_362, 2);  unsqueeze_362 = None
        unsqueeze_364: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_363, 3);  unsqueeze_363 = None
        mul_484: f32[256] = torch.ops.aten.mul.Tensor(squeeze_121, primals_122);  primals_122 = None
        unsqueeze_365: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_484, 0);  mul_484 = None
        unsqueeze_366: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_365, 2);  unsqueeze_365 = None
        unsqueeze_367: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_366, 3);  unsqueeze_366 = None
        sub_102: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_40, unsqueeze_358);  convolution_40 = unsqueeze_358 = None
        mul_485: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_102, unsqueeze_364);  sub_102 = unsqueeze_364 = None
        sub_103: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_11, mul_485);  where_11 = mul_485 = None
        sub_104: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_103, unsqueeze_361);  sub_103 = unsqueeze_361 = None
        mul_486: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_104, unsqueeze_367);  sub_104 = unsqueeze_367 = None
        mul_487: f32[256] = torch.ops.aten.mul.Tensor(sum_27, squeeze_121);  sum_27 = squeeze_121 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_12 = torch.ops.aten.convolution_backward.default(mul_486, relu_36, primals_121, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_486 = primals_121 = None
        getitem_144: f32[1, 1024, 4, 4] = convolution_backward_12[0]
        getitem_145: f32[256, 1024, 1, 1] = convolution_backward_12[1];  convolution_backward_12 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_284: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_9, getitem_144);  where_9 = getitem_144 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_12: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_36, 0);  relu_36 = None
        scalar_tensor_12: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_12: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_12, scalar_tensor_12, add_284);  le_12 = scalar_tensor_12 = add_284 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_368: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_117, 0);  squeeze_117 = None
        unsqueeze_369: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_368, 2);  unsqueeze_368 = None
        unsqueeze_370: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_369, 3);  unsqueeze_369 = None
        sum_28: f32[1024] = torch.ops.aten.sum.dim_IntList(where_12, [0, 2, 3])
        sub_105: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_39, unsqueeze_370)
        mul_488: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_12, sub_105);  sub_105 = None
        sum_29: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_488, [0, 2, 3]);  mul_488 = None
        mul_489: f32[1024] = torch.ops.aten.mul.Tensor(sum_28, 0.0625)
        unsqueeze_371: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_489, 0);  mul_489 = None
        unsqueeze_372: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_371, 2);  unsqueeze_371 = None
        unsqueeze_373: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_372, 3);  unsqueeze_372 = None
        mul_490: f32[1024] = torch.ops.aten.mul.Tensor(sum_29, 0.0625)
        mul_491: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_118, squeeze_118)
        mul_492: f32[1024] = torch.ops.aten.mul.Tensor(mul_490, mul_491);  mul_490 = mul_491 = None
        unsqueeze_374: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_492, 0);  mul_492 = None
        unsqueeze_375: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_374, 2);  unsqueeze_374 = None
        unsqueeze_376: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_375, 3);  unsqueeze_375 = None
        mul_493: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_118, primals_119);  primals_119 = None
        unsqueeze_377: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_493, 0);  mul_493 = None
        unsqueeze_378: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_377, 2);  unsqueeze_377 = None
        unsqueeze_379: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_378, 3);  unsqueeze_378 = None
        sub_106: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_39, unsqueeze_370);  convolution_39 = unsqueeze_370 = None
        mul_494: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_106, unsqueeze_376);  sub_106 = unsqueeze_376 = None
        sub_107: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_12, mul_494);  mul_494 = None
        sub_108: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_107, unsqueeze_373);  sub_107 = unsqueeze_373 = None
        mul_495: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_108, unsqueeze_379);  sub_108 = unsqueeze_379 = None
        mul_496: f32[1024] = torch.ops.aten.mul.Tensor(sum_29, squeeze_118);  sum_29 = squeeze_118 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_13 = torch.ops.aten.convolution_backward.default(mul_495, relu_35, primals_118, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_495 = primals_118 = None
        getitem_147: f32[1, 256, 4, 4] = convolution_backward_13[0]
        getitem_148: f32[1024, 256, 1, 1] = convolution_backward_13[1];  convolution_backward_13 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_13: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_35, 0);  relu_35 = None
        scalar_tensor_13: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_13: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_13, scalar_tensor_13, getitem_147);  le_13 = scalar_tensor_13 = getitem_147 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_380: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_114, 0);  squeeze_114 = None
        unsqueeze_381: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_380, 2);  unsqueeze_380 = None
        unsqueeze_382: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_381, 3);  unsqueeze_381 = None
        sum_30: f32[256] = torch.ops.aten.sum.dim_IntList(where_13, [0, 2, 3])
        sub_109: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_38, unsqueeze_382)
        mul_497: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_13, sub_109);  sub_109 = None
        sum_31: f32[256] = torch.ops.aten.sum.dim_IntList(mul_497, [0, 2, 3]);  mul_497 = None
        mul_498: f32[256] = torch.ops.aten.mul.Tensor(sum_30, 0.0625)
        unsqueeze_383: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_498, 0);  mul_498 = None
        unsqueeze_384: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_383, 2);  unsqueeze_383 = None
        unsqueeze_385: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_384, 3);  unsqueeze_384 = None
        mul_499: f32[256] = torch.ops.aten.mul.Tensor(sum_31, 0.0625)
        mul_500: f32[256] = torch.ops.aten.mul.Tensor(squeeze_115, squeeze_115)
        mul_501: f32[256] = torch.ops.aten.mul.Tensor(mul_499, mul_500);  mul_499 = mul_500 = None
        unsqueeze_386: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_501, 0);  mul_501 = None
        unsqueeze_387: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_386, 2);  unsqueeze_386 = None
        unsqueeze_388: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_387, 3);  unsqueeze_387 = None
        mul_502: f32[256] = torch.ops.aten.mul.Tensor(squeeze_115, primals_116);  primals_116 = None
        unsqueeze_389: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_502, 0);  mul_502 = None
        unsqueeze_390: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_389, 2);  unsqueeze_389 = None
        unsqueeze_391: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_390, 3);  unsqueeze_390 = None
        sub_110: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_38, unsqueeze_382);  convolution_38 = unsqueeze_382 = None
        mul_503: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_110, unsqueeze_388);  sub_110 = unsqueeze_388 = None
        sub_111: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_13, mul_503);  where_13 = mul_503 = None
        sub_112: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_111, unsqueeze_385);  sub_111 = unsqueeze_385 = None
        mul_504: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_112, unsqueeze_391);  sub_112 = unsqueeze_391 = None
        mul_505: f32[256] = torch.ops.aten.mul.Tensor(sum_31, squeeze_115);  sum_31 = squeeze_115 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_14 = torch.ops.aten.convolution_backward.default(mul_504, relu_34, primals_115, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_504 = primals_115 = None
        getitem_150: f32[1, 256, 4, 4] = convolution_backward_14[0]
        getitem_151: f32[256, 256, 3, 3] = convolution_backward_14[1];  convolution_backward_14 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_14: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_34, 0);  relu_34 = None
        scalar_tensor_14: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_14: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_14, scalar_tensor_14, getitem_150);  le_14 = scalar_tensor_14 = getitem_150 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_392: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_111, 0);  squeeze_111 = None
        unsqueeze_393: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_392, 2);  unsqueeze_392 = None
        unsqueeze_394: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_393, 3);  unsqueeze_393 = None
        sum_32: f32[256] = torch.ops.aten.sum.dim_IntList(where_14, [0, 2, 3])
        sub_113: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_37, unsqueeze_394)
        mul_506: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_14, sub_113);  sub_113 = None
        sum_33: f32[256] = torch.ops.aten.sum.dim_IntList(mul_506, [0, 2, 3]);  mul_506 = None
        mul_507: f32[256] = torch.ops.aten.mul.Tensor(sum_32, 0.0625)
        unsqueeze_395: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_507, 0);  mul_507 = None
        unsqueeze_396: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_395, 2);  unsqueeze_395 = None
        unsqueeze_397: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_396, 3);  unsqueeze_396 = None
        mul_508: f32[256] = torch.ops.aten.mul.Tensor(sum_33, 0.0625)
        mul_509: f32[256] = torch.ops.aten.mul.Tensor(squeeze_112, squeeze_112)
        mul_510: f32[256] = torch.ops.aten.mul.Tensor(mul_508, mul_509);  mul_508 = mul_509 = None
        unsqueeze_398: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_510, 0);  mul_510 = None
        unsqueeze_399: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_398, 2);  unsqueeze_398 = None
        unsqueeze_400: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_399, 3);  unsqueeze_399 = None
        mul_511: f32[256] = torch.ops.aten.mul.Tensor(squeeze_112, primals_113);  primals_113 = None
        unsqueeze_401: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_511, 0);  mul_511 = None
        unsqueeze_402: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_401, 2);  unsqueeze_401 = None
        unsqueeze_403: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_402, 3);  unsqueeze_402 = None
        sub_114: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_37, unsqueeze_394);  convolution_37 = unsqueeze_394 = None
        mul_512: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_114, unsqueeze_400);  sub_114 = unsqueeze_400 = None
        sub_115: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_14, mul_512);  where_14 = mul_512 = None
        sub_116: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_115, unsqueeze_397);  sub_115 = unsqueeze_397 = None
        mul_513: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_116, unsqueeze_403);  sub_116 = unsqueeze_403 = None
        mul_514: f32[256] = torch.ops.aten.mul.Tensor(sum_33, squeeze_112);  sum_33 = squeeze_112 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_15 = torch.ops.aten.convolution_backward.default(mul_513, relu_33, primals_112, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_513 = primals_112 = None
        getitem_153: f32[1, 1024, 4, 4] = convolution_backward_15[0]
        getitem_154: f32[256, 1024, 1, 1] = convolution_backward_15[1];  convolution_backward_15 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_285: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_12, getitem_153);  where_12 = getitem_153 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_15: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_33, 0);  relu_33 = None
        scalar_tensor_15: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_15: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_15, scalar_tensor_15, add_285);  le_15 = scalar_tensor_15 = add_285 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_404: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_108, 0);  squeeze_108 = None
        unsqueeze_405: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_404, 2);  unsqueeze_404 = None
        unsqueeze_406: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_405, 3);  unsqueeze_405 = None
        sum_34: f32[1024] = torch.ops.aten.sum.dim_IntList(where_15, [0, 2, 3])
        sub_117: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_36, unsqueeze_406)
        mul_515: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_15, sub_117);  sub_117 = None
        sum_35: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_515, [0, 2, 3]);  mul_515 = None
        mul_516: f32[1024] = torch.ops.aten.mul.Tensor(sum_34, 0.0625)
        unsqueeze_407: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_516, 0);  mul_516 = None
        unsqueeze_408: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_407, 2);  unsqueeze_407 = None
        unsqueeze_409: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_408, 3);  unsqueeze_408 = None
        mul_517: f32[1024] = torch.ops.aten.mul.Tensor(sum_35, 0.0625)
        mul_518: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_109, squeeze_109)
        mul_519: f32[1024] = torch.ops.aten.mul.Tensor(mul_517, mul_518);  mul_517 = mul_518 = None
        unsqueeze_410: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_519, 0);  mul_519 = None
        unsqueeze_411: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_410, 2);  unsqueeze_410 = None
        unsqueeze_412: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_411, 3);  unsqueeze_411 = None
        mul_520: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_109, primals_110);  primals_110 = None
        unsqueeze_413: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_520, 0);  mul_520 = None
        unsqueeze_414: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_413, 2);  unsqueeze_413 = None
        unsqueeze_415: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_414, 3);  unsqueeze_414 = None
        sub_118: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_36, unsqueeze_406);  convolution_36 = unsqueeze_406 = None
        mul_521: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_118, unsqueeze_412);  sub_118 = unsqueeze_412 = None
        sub_119: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_15, mul_521);  mul_521 = None
        sub_120: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_119, unsqueeze_409);  sub_119 = unsqueeze_409 = None
        mul_522: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_120, unsqueeze_415);  sub_120 = unsqueeze_415 = None
        mul_523: f32[1024] = torch.ops.aten.mul.Tensor(sum_35, squeeze_109);  sum_35 = squeeze_109 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_16 = torch.ops.aten.convolution_backward.default(mul_522, relu_32, primals_109, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_522 = primals_109 = None
        getitem_156: f32[1, 256, 4, 4] = convolution_backward_16[0]
        getitem_157: f32[1024, 256, 1, 1] = convolution_backward_16[1];  convolution_backward_16 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_16: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_32, 0);  relu_32 = None
        scalar_tensor_16: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_16: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_16, scalar_tensor_16, getitem_156);  le_16 = scalar_tensor_16 = getitem_156 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_416: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_105, 0);  squeeze_105 = None
        unsqueeze_417: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_416, 2);  unsqueeze_416 = None
        unsqueeze_418: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_417, 3);  unsqueeze_417 = None
        sum_36: f32[256] = torch.ops.aten.sum.dim_IntList(where_16, [0, 2, 3])
        sub_121: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_35, unsqueeze_418)
        mul_524: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_16, sub_121);  sub_121 = None
        sum_37: f32[256] = torch.ops.aten.sum.dim_IntList(mul_524, [0, 2, 3]);  mul_524 = None
        mul_525: f32[256] = torch.ops.aten.mul.Tensor(sum_36, 0.0625)
        unsqueeze_419: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_525, 0);  mul_525 = None
        unsqueeze_420: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_419, 2);  unsqueeze_419 = None
        unsqueeze_421: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_420, 3);  unsqueeze_420 = None
        mul_526: f32[256] = torch.ops.aten.mul.Tensor(sum_37, 0.0625)
        mul_527: f32[256] = torch.ops.aten.mul.Tensor(squeeze_106, squeeze_106)
        mul_528: f32[256] = torch.ops.aten.mul.Tensor(mul_526, mul_527);  mul_526 = mul_527 = None
        unsqueeze_422: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_528, 0);  mul_528 = None
        unsqueeze_423: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_422, 2);  unsqueeze_422 = None
        unsqueeze_424: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_423, 3);  unsqueeze_423 = None
        mul_529: f32[256] = torch.ops.aten.mul.Tensor(squeeze_106, primals_107);  primals_107 = None
        unsqueeze_425: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_529, 0);  mul_529 = None
        unsqueeze_426: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_425, 2);  unsqueeze_425 = None
        unsqueeze_427: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_426, 3);  unsqueeze_426 = None
        sub_122: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_35, unsqueeze_418);  convolution_35 = unsqueeze_418 = None
        mul_530: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_122, unsqueeze_424);  sub_122 = unsqueeze_424 = None
        sub_123: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_16, mul_530);  where_16 = mul_530 = None
        sub_124: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_123, unsqueeze_421);  sub_123 = unsqueeze_421 = None
        mul_531: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_124, unsqueeze_427);  sub_124 = unsqueeze_427 = None
        mul_532: f32[256] = torch.ops.aten.mul.Tensor(sum_37, squeeze_106);  sum_37 = squeeze_106 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_17 = torch.ops.aten.convolution_backward.default(mul_531, relu_31, primals_106, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_531 = primals_106 = None
        getitem_159: f32[1, 256, 4, 4] = convolution_backward_17[0]
        getitem_160: f32[256, 256, 3, 3] = convolution_backward_17[1];  convolution_backward_17 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_17: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_31, 0);  relu_31 = None
        scalar_tensor_17: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_17: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_17, scalar_tensor_17, getitem_159);  le_17 = scalar_tensor_17 = getitem_159 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_428: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_102, 0);  squeeze_102 = None
        unsqueeze_429: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_428, 2);  unsqueeze_428 = None
        unsqueeze_430: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_429, 3);  unsqueeze_429 = None
        sum_38: f32[256] = torch.ops.aten.sum.dim_IntList(where_17, [0, 2, 3])
        sub_125: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_34, unsqueeze_430)
        mul_533: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_17, sub_125);  sub_125 = None
        sum_39: f32[256] = torch.ops.aten.sum.dim_IntList(mul_533, [0, 2, 3]);  mul_533 = None
        mul_534: f32[256] = torch.ops.aten.mul.Tensor(sum_38, 0.0625)
        unsqueeze_431: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_534, 0);  mul_534 = None
        unsqueeze_432: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_431, 2);  unsqueeze_431 = None
        unsqueeze_433: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_432, 3);  unsqueeze_432 = None
        mul_535: f32[256] = torch.ops.aten.mul.Tensor(sum_39, 0.0625)
        mul_536: f32[256] = torch.ops.aten.mul.Tensor(squeeze_103, squeeze_103)
        mul_537: f32[256] = torch.ops.aten.mul.Tensor(mul_535, mul_536);  mul_535 = mul_536 = None
        unsqueeze_434: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_537, 0);  mul_537 = None
        unsqueeze_435: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_434, 2);  unsqueeze_434 = None
        unsqueeze_436: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_435, 3);  unsqueeze_435 = None
        mul_538: f32[256] = torch.ops.aten.mul.Tensor(squeeze_103, primals_104);  primals_104 = None
        unsqueeze_437: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_538, 0);  mul_538 = None
        unsqueeze_438: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_437, 2);  unsqueeze_437 = None
        unsqueeze_439: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_438, 3);  unsqueeze_438 = None
        sub_126: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_34, unsqueeze_430);  convolution_34 = unsqueeze_430 = None
        mul_539: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_126, unsqueeze_436);  sub_126 = unsqueeze_436 = None
        sub_127: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_17, mul_539);  where_17 = mul_539 = None
        sub_128: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_127, unsqueeze_433);  sub_127 = unsqueeze_433 = None
        mul_540: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_128, unsqueeze_439);  sub_128 = unsqueeze_439 = None
        mul_541: f32[256] = torch.ops.aten.mul.Tensor(sum_39, squeeze_103);  sum_39 = squeeze_103 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_18 = torch.ops.aten.convolution_backward.default(mul_540, relu_30, primals_103, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_540 = primals_103 = None
        getitem_162: f32[1, 1024, 4, 4] = convolution_backward_18[0]
        getitem_163: f32[256, 1024, 1, 1] = convolution_backward_18[1];  convolution_backward_18 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_286: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_15, getitem_162);  where_15 = getitem_162 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_18: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_30, 0);  relu_30 = None
        scalar_tensor_18: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_18: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_18, scalar_tensor_18, add_286);  le_18 = scalar_tensor_18 = add_286 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_440: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_99, 0);  squeeze_99 = None
        unsqueeze_441: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_440, 2);  unsqueeze_440 = None
        unsqueeze_442: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_441, 3);  unsqueeze_441 = None
        sum_40: f32[1024] = torch.ops.aten.sum.dim_IntList(where_18, [0, 2, 3])
        sub_129: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_33, unsqueeze_442)
        mul_542: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_18, sub_129);  sub_129 = None
        sum_41: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_542, [0, 2, 3]);  mul_542 = None
        mul_543: f32[1024] = torch.ops.aten.mul.Tensor(sum_40, 0.0625)
        unsqueeze_443: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_543, 0);  mul_543 = None
        unsqueeze_444: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_443, 2);  unsqueeze_443 = None
        unsqueeze_445: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_444, 3);  unsqueeze_444 = None
        mul_544: f32[1024] = torch.ops.aten.mul.Tensor(sum_41, 0.0625)
        mul_545: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_100, squeeze_100)
        mul_546: f32[1024] = torch.ops.aten.mul.Tensor(mul_544, mul_545);  mul_544 = mul_545 = None
        unsqueeze_446: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_546, 0);  mul_546 = None
        unsqueeze_447: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_446, 2);  unsqueeze_446 = None
        unsqueeze_448: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_447, 3);  unsqueeze_447 = None
        mul_547: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_100, primals_101);  primals_101 = None
        unsqueeze_449: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_547, 0);  mul_547 = None
        unsqueeze_450: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_449, 2);  unsqueeze_449 = None
        unsqueeze_451: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_450, 3);  unsqueeze_450 = None
        sub_130: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_33, unsqueeze_442);  convolution_33 = unsqueeze_442 = None
        mul_548: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_130, unsqueeze_448);  sub_130 = unsqueeze_448 = None
        sub_131: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_18, mul_548);  mul_548 = None
        sub_132: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_131, unsqueeze_445);  sub_131 = unsqueeze_445 = None
        mul_549: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_132, unsqueeze_451);  sub_132 = unsqueeze_451 = None
        mul_550: f32[1024] = torch.ops.aten.mul.Tensor(sum_41, squeeze_100);  sum_41 = squeeze_100 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_19 = torch.ops.aten.convolution_backward.default(mul_549, relu_29, primals_100, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_549 = primals_100 = None
        getitem_165: f32[1, 256, 4, 4] = convolution_backward_19[0]
        getitem_166: f32[1024, 256, 1, 1] = convolution_backward_19[1];  convolution_backward_19 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_19: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_29, 0);  relu_29 = None
        scalar_tensor_19: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_19: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_19, scalar_tensor_19, getitem_165);  le_19 = scalar_tensor_19 = getitem_165 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_452: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_96, 0);  squeeze_96 = None
        unsqueeze_453: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_452, 2);  unsqueeze_452 = None
        unsqueeze_454: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_453, 3);  unsqueeze_453 = None
        sum_42: f32[256] = torch.ops.aten.sum.dim_IntList(where_19, [0, 2, 3])
        sub_133: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_32, unsqueeze_454)
        mul_551: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_19, sub_133);  sub_133 = None
        sum_43: f32[256] = torch.ops.aten.sum.dim_IntList(mul_551, [0, 2, 3]);  mul_551 = None
        mul_552: f32[256] = torch.ops.aten.mul.Tensor(sum_42, 0.0625)
        unsqueeze_455: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_552, 0);  mul_552 = None
        unsqueeze_456: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_455, 2);  unsqueeze_455 = None
        unsqueeze_457: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_456, 3);  unsqueeze_456 = None
        mul_553: f32[256] = torch.ops.aten.mul.Tensor(sum_43, 0.0625)
        mul_554: f32[256] = torch.ops.aten.mul.Tensor(squeeze_97, squeeze_97)
        mul_555: f32[256] = torch.ops.aten.mul.Tensor(mul_553, mul_554);  mul_553 = mul_554 = None
        unsqueeze_458: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_555, 0);  mul_555 = None
        unsqueeze_459: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_458, 2);  unsqueeze_458 = None
        unsqueeze_460: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_459, 3);  unsqueeze_459 = None
        mul_556: f32[256] = torch.ops.aten.mul.Tensor(squeeze_97, primals_98);  primals_98 = None
        unsqueeze_461: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_556, 0);  mul_556 = None
        unsqueeze_462: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_461, 2);  unsqueeze_461 = None
        unsqueeze_463: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_462, 3);  unsqueeze_462 = None
        sub_134: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_32, unsqueeze_454);  convolution_32 = unsqueeze_454 = None
        mul_557: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_134, unsqueeze_460);  sub_134 = unsqueeze_460 = None
        sub_135: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_19, mul_557);  where_19 = mul_557 = None
        sub_136: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_135, unsqueeze_457);  sub_135 = unsqueeze_457 = None
        mul_558: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_136, unsqueeze_463);  sub_136 = unsqueeze_463 = None
        mul_559: f32[256] = torch.ops.aten.mul.Tensor(sum_43, squeeze_97);  sum_43 = squeeze_97 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_20 = torch.ops.aten.convolution_backward.default(mul_558, relu_28, primals_97, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_558 = primals_97 = None
        getitem_168: f32[1, 256, 4, 4] = convolution_backward_20[0]
        getitem_169: f32[256, 256, 3, 3] = convolution_backward_20[1];  convolution_backward_20 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_20: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_28, 0);  relu_28 = None
        scalar_tensor_20: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_20: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_20, scalar_tensor_20, getitem_168);  le_20 = scalar_tensor_20 = getitem_168 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_464: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_93, 0);  squeeze_93 = None
        unsqueeze_465: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_464, 2);  unsqueeze_464 = None
        unsqueeze_466: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_465, 3);  unsqueeze_465 = None
        sum_44: f32[256] = torch.ops.aten.sum.dim_IntList(where_20, [0, 2, 3])
        sub_137: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_31, unsqueeze_466)
        mul_560: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_20, sub_137);  sub_137 = None
        sum_45: f32[256] = torch.ops.aten.sum.dim_IntList(mul_560, [0, 2, 3]);  mul_560 = None
        mul_561: f32[256] = torch.ops.aten.mul.Tensor(sum_44, 0.0625)
        unsqueeze_467: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_561, 0);  mul_561 = None
        unsqueeze_468: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_467, 2);  unsqueeze_467 = None
        unsqueeze_469: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_468, 3);  unsqueeze_468 = None
        mul_562: f32[256] = torch.ops.aten.mul.Tensor(sum_45, 0.0625)
        mul_563: f32[256] = torch.ops.aten.mul.Tensor(squeeze_94, squeeze_94)
        mul_564: f32[256] = torch.ops.aten.mul.Tensor(mul_562, mul_563);  mul_562 = mul_563 = None
        unsqueeze_470: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_564, 0);  mul_564 = None
        unsqueeze_471: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_470, 2);  unsqueeze_470 = None
        unsqueeze_472: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_471, 3);  unsqueeze_471 = None
        mul_565: f32[256] = torch.ops.aten.mul.Tensor(squeeze_94, primals_95);  primals_95 = None
        unsqueeze_473: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_565, 0);  mul_565 = None
        unsqueeze_474: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_473, 2);  unsqueeze_473 = None
        unsqueeze_475: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_474, 3);  unsqueeze_474 = None
        sub_138: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_31, unsqueeze_466);  convolution_31 = unsqueeze_466 = None
        mul_566: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_138, unsqueeze_472);  sub_138 = unsqueeze_472 = None
        sub_139: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_20, mul_566);  where_20 = mul_566 = None
        sub_140: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_139, unsqueeze_469);  sub_139 = unsqueeze_469 = None
        mul_567: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_140, unsqueeze_475);  sub_140 = unsqueeze_475 = None
        mul_568: f32[256] = torch.ops.aten.mul.Tensor(sum_45, squeeze_94);  sum_45 = squeeze_94 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_21 = torch.ops.aten.convolution_backward.default(mul_567, relu_27, primals_94, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_567 = primals_94 = None
        getitem_171: f32[1, 1024, 4, 4] = convolution_backward_21[0]
        getitem_172: f32[256, 1024, 1, 1] = convolution_backward_21[1];  convolution_backward_21 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_287: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_18, getitem_171);  where_18 = getitem_171 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_21: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_27, 0);  relu_27 = None
        scalar_tensor_21: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_21: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_21, scalar_tensor_21, add_287);  le_21 = scalar_tensor_21 = add_287 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_476: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_90, 0);  squeeze_90 = None
        unsqueeze_477: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_476, 2);  unsqueeze_476 = None
        unsqueeze_478: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_477, 3);  unsqueeze_477 = None
        sum_46: f32[1024] = torch.ops.aten.sum.dim_IntList(where_21, [0, 2, 3])
        sub_141: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_30, unsqueeze_478)
        mul_569: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_21, sub_141);  sub_141 = None
        sum_47: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_569, [0, 2, 3]);  mul_569 = None
        mul_570: f32[1024] = torch.ops.aten.mul.Tensor(sum_46, 0.0625)
        unsqueeze_479: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_570, 0);  mul_570 = None
        unsqueeze_480: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_479, 2);  unsqueeze_479 = None
        unsqueeze_481: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_480, 3);  unsqueeze_480 = None
        mul_571: f32[1024] = torch.ops.aten.mul.Tensor(sum_47, 0.0625)
        mul_572: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_91, squeeze_91)
        mul_573: f32[1024] = torch.ops.aten.mul.Tensor(mul_571, mul_572);  mul_571 = mul_572 = None
        unsqueeze_482: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_573, 0);  mul_573 = None
        unsqueeze_483: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_482, 2);  unsqueeze_482 = None
        unsqueeze_484: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_483, 3);  unsqueeze_483 = None
        mul_574: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_91, primals_92);  primals_92 = None
        unsqueeze_485: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_574, 0);  mul_574 = None
        unsqueeze_486: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_485, 2);  unsqueeze_485 = None
        unsqueeze_487: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_486, 3);  unsqueeze_486 = None
        sub_142: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_30, unsqueeze_478);  convolution_30 = unsqueeze_478 = None
        mul_575: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_142, unsqueeze_484);  sub_142 = unsqueeze_484 = None
        sub_143: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_21, mul_575);  mul_575 = None
        sub_144: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_143, unsqueeze_481);  sub_143 = unsqueeze_481 = None
        mul_576: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_144, unsqueeze_487);  sub_144 = unsqueeze_487 = None
        mul_577: f32[1024] = torch.ops.aten.mul.Tensor(sum_47, squeeze_91);  sum_47 = squeeze_91 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_22 = torch.ops.aten.convolution_backward.default(mul_576, relu_26, primals_91, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_576 = primals_91 = None
        getitem_174: f32[1, 256, 4, 4] = convolution_backward_22[0]
        getitem_175: f32[1024, 256, 1, 1] = convolution_backward_22[1];  convolution_backward_22 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_22: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_26, 0);  relu_26 = None
        scalar_tensor_22: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_22: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_22, scalar_tensor_22, getitem_174);  le_22 = scalar_tensor_22 = getitem_174 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_488: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_87, 0);  squeeze_87 = None
        unsqueeze_489: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_488, 2);  unsqueeze_488 = None
        unsqueeze_490: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_489, 3);  unsqueeze_489 = None
        sum_48: f32[256] = torch.ops.aten.sum.dim_IntList(where_22, [0, 2, 3])
        sub_145: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_29, unsqueeze_490)
        mul_578: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_22, sub_145);  sub_145 = None
        sum_49: f32[256] = torch.ops.aten.sum.dim_IntList(mul_578, [0, 2, 3]);  mul_578 = None
        mul_579: f32[256] = torch.ops.aten.mul.Tensor(sum_48, 0.0625)
        unsqueeze_491: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_579, 0);  mul_579 = None
        unsqueeze_492: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_491, 2);  unsqueeze_491 = None
        unsqueeze_493: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_492, 3);  unsqueeze_492 = None
        mul_580: f32[256] = torch.ops.aten.mul.Tensor(sum_49, 0.0625)
        mul_581: f32[256] = torch.ops.aten.mul.Tensor(squeeze_88, squeeze_88)
        mul_582: f32[256] = torch.ops.aten.mul.Tensor(mul_580, mul_581);  mul_580 = mul_581 = None
        unsqueeze_494: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_582, 0);  mul_582 = None
        unsqueeze_495: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_494, 2);  unsqueeze_494 = None
        unsqueeze_496: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_495, 3);  unsqueeze_495 = None
        mul_583: f32[256] = torch.ops.aten.mul.Tensor(squeeze_88, primals_89);  primals_89 = None
        unsqueeze_497: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_583, 0);  mul_583 = None
        unsqueeze_498: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_497, 2);  unsqueeze_497 = None
        unsqueeze_499: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_498, 3);  unsqueeze_498 = None
        sub_146: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_29, unsqueeze_490);  convolution_29 = unsqueeze_490 = None
        mul_584: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_146, unsqueeze_496);  sub_146 = unsqueeze_496 = None
        sub_147: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_22, mul_584);  where_22 = mul_584 = None
        sub_148: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_147, unsqueeze_493);  sub_147 = unsqueeze_493 = None
        mul_585: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_148, unsqueeze_499);  sub_148 = unsqueeze_499 = None
        mul_586: f32[256] = torch.ops.aten.mul.Tensor(sum_49, squeeze_88);  sum_49 = squeeze_88 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_23 = torch.ops.aten.convolution_backward.default(mul_585, relu_25, primals_88, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_585 = primals_88 = None
        getitem_177: f32[1, 256, 4, 4] = convolution_backward_23[0]
        getitem_178: f32[256, 256, 3, 3] = convolution_backward_23[1];  convolution_backward_23 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_23: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_25, 0);  relu_25 = None
        scalar_tensor_23: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_23: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_23, scalar_tensor_23, getitem_177);  le_23 = scalar_tensor_23 = getitem_177 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_500: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_84, 0);  squeeze_84 = None
        unsqueeze_501: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_500, 2);  unsqueeze_500 = None
        unsqueeze_502: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_501, 3);  unsqueeze_501 = None
        sum_50: f32[256] = torch.ops.aten.sum.dim_IntList(where_23, [0, 2, 3])
        sub_149: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_28, unsqueeze_502)
        mul_587: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_23, sub_149);  sub_149 = None
        sum_51: f32[256] = torch.ops.aten.sum.dim_IntList(mul_587, [0, 2, 3]);  mul_587 = None
        mul_588: f32[256] = torch.ops.aten.mul.Tensor(sum_50, 0.0625)
        unsqueeze_503: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_588, 0);  mul_588 = None
        unsqueeze_504: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_503, 2);  unsqueeze_503 = None
        unsqueeze_505: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_504, 3);  unsqueeze_504 = None
        mul_589: f32[256] = torch.ops.aten.mul.Tensor(sum_51, 0.0625)
        mul_590: f32[256] = torch.ops.aten.mul.Tensor(squeeze_85, squeeze_85)
        mul_591: f32[256] = torch.ops.aten.mul.Tensor(mul_589, mul_590);  mul_589 = mul_590 = None
        unsqueeze_506: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_591, 0);  mul_591 = None
        unsqueeze_507: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_506, 2);  unsqueeze_506 = None
        unsqueeze_508: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_507, 3);  unsqueeze_507 = None
        mul_592: f32[256] = torch.ops.aten.mul.Tensor(squeeze_85, primals_86);  primals_86 = None
        unsqueeze_509: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_592, 0);  mul_592 = None
        unsqueeze_510: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_509, 2);  unsqueeze_509 = None
        unsqueeze_511: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_510, 3);  unsqueeze_510 = None
        sub_150: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_28, unsqueeze_502);  convolution_28 = unsqueeze_502 = None
        mul_593: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_150, unsqueeze_508);  sub_150 = unsqueeze_508 = None
        sub_151: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_23, mul_593);  where_23 = mul_593 = None
        sub_152: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_151, unsqueeze_505);  sub_151 = unsqueeze_505 = None
        mul_594: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_152, unsqueeze_511);  sub_152 = unsqueeze_511 = None
        mul_595: f32[256] = torch.ops.aten.mul.Tensor(sum_51, squeeze_85);  sum_51 = squeeze_85 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_24 = torch.ops.aten.convolution_backward.default(mul_594, relu_24, primals_85, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_594 = primals_85 = None
        getitem_180: f32[1, 1024, 4, 4] = convolution_backward_24[0]
        getitem_181: f32[256, 1024, 1, 1] = convolution_backward_24[1];  convolution_backward_24 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_288: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_21, getitem_180);  where_21 = getitem_180 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_24: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_24, 0);  relu_24 = None
        scalar_tensor_24: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_24: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_24, scalar_tensor_24, add_288);  le_24 = scalar_tensor_24 = add_288 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        unsqueeze_512: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_81, 0);  squeeze_81 = None
        unsqueeze_513: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_512, 2);  unsqueeze_512 = None
        unsqueeze_514: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_513, 3);  unsqueeze_513 = None
        sum_52: f32[1024] = torch.ops.aten.sum.dim_IntList(where_24, [0, 2, 3])
        sub_153: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_27, unsqueeze_514)
        mul_596: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_24, sub_153);  sub_153 = None
        sum_53: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_596, [0, 2, 3]);  mul_596 = None
        mul_597: f32[1024] = torch.ops.aten.mul.Tensor(sum_52, 0.0625)
        unsqueeze_515: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_597, 0);  mul_597 = None
        unsqueeze_516: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_515, 2);  unsqueeze_515 = None
        unsqueeze_517: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_516, 3);  unsqueeze_516 = None
        mul_598: f32[1024] = torch.ops.aten.mul.Tensor(sum_53, 0.0625)
        mul_599: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_82, squeeze_82)
        mul_600: f32[1024] = torch.ops.aten.mul.Tensor(mul_598, mul_599);  mul_598 = mul_599 = None
        unsqueeze_518: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_600, 0);  mul_600 = None
        unsqueeze_519: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_518, 2);  unsqueeze_518 = None
        unsqueeze_520: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_519, 3);  unsqueeze_519 = None
        mul_601: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_82, primals_83);  primals_83 = None
        unsqueeze_521: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_601, 0);  mul_601 = None
        unsqueeze_522: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_521, 2);  unsqueeze_521 = None
        unsqueeze_523: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_522, 3);  unsqueeze_522 = None
        sub_154: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_27, unsqueeze_514);  convolution_27 = unsqueeze_514 = None
        mul_602: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_154, unsqueeze_520);  sub_154 = unsqueeze_520 = None
        sub_155: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_24, mul_602);  mul_602 = None
        sub_156: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_155, unsqueeze_517);  sub_155 = unsqueeze_517 = None
        mul_603: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_156, unsqueeze_523);  sub_156 = unsqueeze_523 = None
        mul_604: f32[1024] = torch.ops.aten.mul.Tensor(sum_53, squeeze_82);  sum_53 = squeeze_82 = None
        convolution_backward_25 = torch.ops.aten.convolution_backward.default(mul_603, relu_21, primals_82, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_603 = primals_82 = None
        getitem_183: f32[1, 512, 8, 8] = convolution_backward_25[0]
        getitem_184: f32[1024, 512, 1, 1] = convolution_backward_25[1];  convolution_backward_25 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_524: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_78, 0);  squeeze_78 = None
        unsqueeze_525: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_524, 2);  unsqueeze_524 = None
        unsqueeze_526: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_525, 3);  unsqueeze_525 = None
        sum_54: f32[1024] = torch.ops.aten.sum.dim_IntList(where_24, [0, 2, 3])
        sub_157: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_26, unsqueeze_526)
        mul_605: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_24, sub_157);  sub_157 = None
        sum_55: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_605, [0, 2, 3]);  mul_605 = None
        mul_606: f32[1024] = torch.ops.aten.mul.Tensor(sum_54, 0.0625)
        unsqueeze_527: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_606, 0);  mul_606 = None
        unsqueeze_528: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_527, 2);  unsqueeze_527 = None
        unsqueeze_529: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_528, 3);  unsqueeze_528 = None
        mul_607: f32[1024] = torch.ops.aten.mul.Tensor(sum_55, 0.0625)
        mul_608: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_79, squeeze_79)
        mul_609: f32[1024] = torch.ops.aten.mul.Tensor(mul_607, mul_608);  mul_607 = mul_608 = None
        unsqueeze_530: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_609, 0);  mul_609 = None
        unsqueeze_531: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_530, 2);  unsqueeze_530 = None
        unsqueeze_532: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_531, 3);  unsqueeze_531 = None
        mul_610: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_79, primals_80);  primals_80 = None
        unsqueeze_533: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_610, 0);  mul_610 = None
        unsqueeze_534: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_533, 2);  unsqueeze_533 = None
        unsqueeze_535: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_534, 3);  unsqueeze_534 = None
        sub_158: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_26, unsqueeze_526);  convolution_26 = unsqueeze_526 = None
        mul_611: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_158, unsqueeze_532);  sub_158 = unsqueeze_532 = None
        sub_159: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_24, mul_611);  where_24 = mul_611 = None
        sub_160: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_159, unsqueeze_529);  sub_159 = unsqueeze_529 = None
        mul_612: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_160, unsqueeze_535);  sub_160 = unsqueeze_535 = None
        mul_613: f32[1024] = torch.ops.aten.mul.Tensor(sum_55, squeeze_79);  sum_55 = squeeze_79 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_26 = torch.ops.aten.convolution_backward.default(mul_612, relu_23, primals_79, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_612 = primals_79 = None
        getitem_186: f32[1, 256, 4, 4] = convolution_backward_26[0]
        getitem_187: f32[1024, 256, 1, 1] = convolution_backward_26[1];  convolution_backward_26 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_25: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_23, 0);  relu_23 = None
        scalar_tensor_25: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_25: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_25, scalar_tensor_25, getitem_186);  le_25 = scalar_tensor_25 = getitem_186 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_536: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_75, 0);  squeeze_75 = None
        unsqueeze_537: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_536, 2);  unsqueeze_536 = None
        unsqueeze_538: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_537, 3);  unsqueeze_537 = None
        sum_56: f32[256] = torch.ops.aten.sum.dim_IntList(where_25, [0, 2, 3])
        sub_161: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_25, unsqueeze_538)
        mul_614: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_25, sub_161);  sub_161 = None
        sum_57: f32[256] = torch.ops.aten.sum.dim_IntList(mul_614, [0, 2, 3]);  mul_614 = None
        mul_615: f32[256] = torch.ops.aten.mul.Tensor(sum_56, 0.0625)
        unsqueeze_539: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_615, 0);  mul_615 = None
        unsqueeze_540: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_539, 2);  unsqueeze_539 = None
        unsqueeze_541: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_540, 3);  unsqueeze_540 = None
        mul_616: f32[256] = torch.ops.aten.mul.Tensor(sum_57, 0.0625)
        mul_617: f32[256] = torch.ops.aten.mul.Tensor(squeeze_76, squeeze_76)
        mul_618: f32[256] = torch.ops.aten.mul.Tensor(mul_616, mul_617);  mul_616 = mul_617 = None
        unsqueeze_542: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_618, 0);  mul_618 = None
        unsqueeze_543: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_542, 2);  unsqueeze_542 = None
        unsqueeze_544: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_543, 3);  unsqueeze_543 = None
        mul_619: f32[256] = torch.ops.aten.mul.Tensor(squeeze_76, primals_77);  primals_77 = None
        unsqueeze_545: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_619, 0);  mul_619 = None
        unsqueeze_546: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_545, 2);  unsqueeze_545 = None
        unsqueeze_547: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_546, 3);  unsqueeze_546 = None
        sub_162: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_25, unsqueeze_538);  convolution_25 = unsqueeze_538 = None
        mul_620: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_162, unsqueeze_544);  sub_162 = unsqueeze_544 = None
        sub_163: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_25, mul_620);  where_25 = mul_620 = None
        sub_164: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_163, unsqueeze_541);  sub_163 = unsqueeze_541 = None
        mul_621: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_164, unsqueeze_547);  sub_164 = unsqueeze_547 = None
        mul_622: f32[256] = torch.ops.aten.mul.Tensor(sum_57, squeeze_76);  sum_57 = squeeze_76 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_27 = torch.ops.aten.convolution_backward.default(mul_621, relu_22, primals_76, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_621 = primals_76 = None
        getitem_189: f32[1, 256, 8, 8] = convolution_backward_27[0]
        getitem_190: f32[256, 256, 3, 3] = convolution_backward_27[1];  convolution_backward_27 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_26: b8[1, 256, 8, 8] = torch.ops.aten.le.Scalar(relu_22, 0);  relu_22 = None
        scalar_tensor_26: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_26: f32[1, 256, 8, 8] = torch.ops.aten.where.self(le_26, scalar_tensor_26, getitem_189);  le_26 = scalar_tensor_26 = getitem_189 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_548: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_72, 0);  squeeze_72 = None
        unsqueeze_549: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_548, 2);  unsqueeze_548 = None
        unsqueeze_550: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_549, 3);  unsqueeze_549 = None
        sum_58: f32[256] = torch.ops.aten.sum.dim_IntList(where_26, [0, 2, 3])
        sub_165: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(convolution_24, unsqueeze_550)
        mul_623: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(where_26, sub_165);  sub_165 = None
        sum_59: f32[256] = torch.ops.aten.sum.dim_IntList(mul_623, [0, 2, 3]);  mul_623 = None
        mul_624: f32[256] = torch.ops.aten.mul.Tensor(sum_58, 0.015625)
        unsqueeze_551: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_624, 0);  mul_624 = None
        unsqueeze_552: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_551, 2);  unsqueeze_551 = None
        unsqueeze_553: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_552, 3);  unsqueeze_552 = None
        mul_625: f32[256] = torch.ops.aten.mul.Tensor(sum_59, 0.015625)
        mul_626: f32[256] = torch.ops.aten.mul.Tensor(squeeze_73, squeeze_73)
        mul_627: f32[256] = torch.ops.aten.mul.Tensor(mul_625, mul_626);  mul_625 = mul_626 = None
        unsqueeze_554: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_627, 0);  mul_627 = None
        unsqueeze_555: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_554, 2);  unsqueeze_554 = None
        unsqueeze_556: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_555, 3);  unsqueeze_555 = None
        mul_628: f32[256] = torch.ops.aten.mul.Tensor(squeeze_73, primals_74);  primals_74 = None
        unsqueeze_557: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_628, 0);  mul_628 = None
        unsqueeze_558: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_557, 2);  unsqueeze_557 = None
        unsqueeze_559: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_558, 3);  unsqueeze_558 = None
        sub_166: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(convolution_24, unsqueeze_550);  convolution_24 = unsqueeze_550 = None
        mul_629: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(sub_166, unsqueeze_556);  sub_166 = unsqueeze_556 = None
        sub_167: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(where_26, mul_629);  where_26 = mul_629 = None
        sub_168: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(sub_167, unsqueeze_553);  sub_167 = unsqueeze_553 = None
        mul_630: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(sub_168, unsqueeze_559);  sub_168 = unsqueeze_559 = None
        mul_631: f32[256] = torch.ops.aten.mul.Tensor(sum_59, squeeze_73);  sum_59 = squeeze_73 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_28 = torch.ops.aten.convolution_backward.default(mul_630, relu_21, primals_73, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_630 = primals_73 = None
        getitem_192: f32[1, 512, 8, 8] = convolution_backward_28[0]
        getitem_193: f32[256, 512, 1, 1] = convolution_backward_28[1];  convolution_backward_28 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_289: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(getitem_183, getitem_192);  getitem_183 = getitem_192 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_27: b8[1, 512, 8, 8] = torch.ops.aten.le.Scalar(relu_21, 0);  relu_21 = None
        scalar_tensor_27: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_27: f32[1, 512, 8, 8] = torch.ops.aten.where.self(le_27, scalar_tensor_27, add_289);  le_27 = scalar_tensor_27 = add_289 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_560: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_69, 0);  squeeze_69 = None
        unsqueeze_561: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_560, 2);  unsqueeze_560 = None
        unsqueeze_562: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_561, 3);  unsqueeze_561 = None
        sum_60: f32[512] = torch.ops.aten.sum.dim_IntList(where_27, [0, 2, 3])
        sub_169: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_23, unsqueeze_562)
        mul_632: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_27, sub_169);  sub_169 = None
        sum_61: f32[512] = torch.ops.aten.sum.dim_IntList(mul_632, [0, 2, 3]);  mul_632 = None
        mul_633: f32[512] = torch.ops.aten.mul.Tensor(sum_60, 0.015625)
        unsqueeze_563: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_633, 0);  mul_633 = None
        unsqueeze_564: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_563, 2);  unsqueeze_563 = None
        unsqueeze_565: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_564, 3);  unsqueeze_564 = None
        mul_634: f32[512] = torch.ops.aten.mul.Tensor(sum_61, 0.015625)
        mul_635: f32[512] = torch.ops.aten.mul.Tensor(squeeze_70, squeeze_70)
        mul_636: f32[512] = torch.ops.aten.mul.Tensor(mul_634, mul_635);  mul_634 = mul_635 = None
        unsqueeze_566: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_636, 0);  mul_636 = None
        unsqueeze_567: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_566, 2);  unsqueeze_566 = None
        unsqueeze_568: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_567, 3);  unsqueeze_567 = None
        mul_637: f32[512] = torch.ops.aten.mul.Tensor(squeeze_70, primals_71);  primals_71 = None
        unsqueeze_569: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_637, 0);  mul_637 = None
        unsqueeze_570: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_569, 2);  unsqueeze_569 = None
        unsqueeze_571: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_570, 3);  unsqueeze_570 = None
        sub_170: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_23, unsqueeze_562);  convolution_23 = unsqueeze_562 = None
        mul_638: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_170, unsqueeze_568);  sub_170 = unsqueeze_568 = None
        sub_171: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_27, mul_638);  mul_638 = None
        sub_172: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_171, unsqueeze_565);  sub_171 = unsqueeze_565 = None
        mul_639: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_172, unsqueeze_571);  sub_172 = unsqueeze_571 = None
        mul_640: f32[512] = torch.ops.aten.mul.Tensor(sum_61, squeeze_70);  sum_61 = squeeze_70 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_29 = torch.ops.aten.convolution_backward.default(mul_639, relu_20, primals_70, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_639 = primals_70 = None
        getitem_195: f32[1, 128, 8, 8] = convolution_backward_29[0]
        getitem_196: f32[512, 128, 1, 1] = convolution_backward_29[1];  convolution_backward_29 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_28: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_20, 0);  relu_20 = None
        scalar_tensor_28: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_28: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_28, scalar_tensor_28, getitem_195);  le_28 = scalar_tensor_28 = getitem_195 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_572: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_66, 0);  squeeze_66 = None
        unsqueeze_573: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_572, 2);  unsqueeze_572 = None
        unsqueeze_574: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_573, 3);  unsqueeze_573 = None
        sum_62: f32[128] = torch.ops.aten.sum.dim_IntList(where_28, [0, 2, 3])
        sub_173: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_22, unsqueeze_574)
        mul_641: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_28, sub_173);  sub_173 = None
        sum_63: f32[128] = torch.ops.aten.sum.dim_IntList(mul_641, [0, 2, 3]);  mul_641 = None
        mul_642: f32[128] = torch.ops.aten.mul.Tensor(sum_62, 0.015625)
        unsqueeze_575: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_642, 0);  mul_642 = None
        unsqueeze_576: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_575, 2);  unsqueeze_575 = None
        unsqueeze_577: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_576, 3);  unsqueeze_576 = None
        mul_643: f32[128] = torch.ops.aten.mul.Tensor(sum_63, 0.015625)
        mul_644: f32[128] = torch.ops.aten.mul.Tensor(squeeze_67, squeeze_67)
        mul_645: f32[128] = torch.ops.aten.mul.Tensor(mul_643, mul_644);  mul_643 = mul_644 = None
        unsqueeze_578: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_645, 0);  mul_645 = None
        unsqueeze_579: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_578, 2);  unsqueeze_578 = None
        unsqueeze_580: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_579, 3);  unsqueeze_579 = None
        mul_646: f32[128] = torch.ops.aten.mul.Tensor(squeeze_67, primals_68);  primals_68 = None
        unsqueeze_581: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_646, 0);  mul_646 = None
        unsqueeze_582: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_581, 2);  unsqueeze_581 = None
        unsqueeze_583: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_582, 3);  unsqueeze_582 = None
        sub_174: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_22, unsqueeze_574);  convolution_22 = unsqueeze_574 = None
        mul_647: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_174, unsqueeze_580);  sub_174 = unsqueeze_580 = None
        sub_175: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_28, mul_647);  where_28 = mul_647 = None
        sub_176: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_175, unsqueeze_577);  sub_175 = unsqueeze_577 = None
        mul_648: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_176, unsqueeze_583);  sub_176 = unsqueeze_583 = None
        mul_649: f32[128] = torch.ops.aten.mul.Tensor(sum_63, squeeze_67);  sum_63 = squeeze_67 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_30 = torch.ops.aten.convolution_backward.default(mul_648, relu_19, primals_67, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_648 = primals_67 = None
        getitem_198: f32[1, 128, 8, 8] = convolution_backward_30[0]
        getitem_199: f32[128, 128, 3, 3] = convolution_backward_30[1];  convolution_backward_30 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_29: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_19, 0);  relu_19 = None
        scalar_tensor_29: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_29: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_29, scalar_tensor_29, getitem_198);  le_29 = scalar_tensor_29 = getitem_198 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_584: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_63, 0);  squeeze_63 = None
        unsqueeze_585: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_584, 2);  unsqueeze_584 = None
        unsqueeze_586: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_585, 3);  unsqueeze_585 = None
        sum_64: f32[128] = torch.ops.aten.sum.dim_IntList(where_29, [0, 2, 3])
        sub_177: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_21, unsqueeze_586)
        mul_650: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_29, sub_177);  sub_177 = None
        sum_65: f32[128] = torch.ops.aten.sum.dim_IntList(mul_650, [0, 2, 3]);  mul_650 = None
        mul_651: f32[128] = torch.ops.aten.mul.Tensor(sum_64, 0.015625)
        unsqueeze_587: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_651, 0);  mul_651 = None
        unsqueeze_588: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_587, 2);  unsqueeze_587 = None
        unsqueeze_589: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_588, 3);  unsqueeze_588 = None
        mul_652: f32[128] = torch.ops.aten.mul.Tensor(sum_65, 0.015625)
        mul_653: f32[128] = torch.ops.aten.mul.Tensor(squeeze_64, squeeze_64)
        mul_654: f32[128] = torch.ops.aten.mul.Tensor(mul_652, mul_653);  mul_652 = mul_653 = None
        unsqueeze_590: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_654, 0);  mul_654 = None
        unsqueeze_591: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_590, 2);  unsqueeze_590 = None
        unsqueeze_592: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_591, 3);  unsqueeze_591 = None
        mul_655: f32[128] = torch.ops.aten.mul.Tensor(squeeze_64, primals_65);  primals_65 = None
        unsqueeze_593: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_655, 0);  mul_655 = None
        unsqueeze_594: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_593, 2);  unsqueeze_593 = None
        unsqueeze_595: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_594, 3);  unsqueeze_594 = None
        sub_178: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_21, unsqueeze_586);  convolution_21 = unsqueeze_586 = None
        mul_656: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_178, unsqueeze_592);  sub_178 = unsqueeze_592 = None
        sub_179: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_29, mul_656);  where_29 = mul_656 = None
        sub_180: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_179, unsqueeze_589);  sub_179 = unsqueeze_589 = None
        mul_657: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_180, unsqueeze_595);  sub_180 = unsqueeze_595 = None
        mul_658: f32[128] = torch.ops.aten.mul.Tensor(sum_65, squeeze_64);  sum_65 = squeeze_64 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_31 = torch.ops.aten.convolution_backward.default(mul_657, relu_18, primals_64, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_657 = primals_64 = None
        getitem_201: f32[1, 512, 8, 8] = convolution_backward_31[0]
        getitem_202: f32[128, 512, 1, 1] = convolution_backward_31[1];  convolution_backward_31 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_290: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(where_27, getitem_201);  where_27 = getitem_201 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_30: b8[1, 512, 8, 8] = torch.ops.aten.le.Scalar(relu_18, 0);  relu_18 = None
        scalar_tensor_30: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_30: f32[1, 512, 8, 8] = torch.ops.aten.where.self(le_30, scalar_tensor_30, add_290);  le_30 = scalar_tensor_30 = add_290 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_596: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_60, 0);  squeeze_60 = None
        unsqueeze_597: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_596, 2);  unsqueeze_596 = None
        unsqueeze_598: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_597, 3);  unsqueeze_597 = None
        sum_66: f32[512] = torch.ops.aten.sum.dim_IntList(where_30, [0, 2, 3])
        sub_181: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_20, unsqueeze_598)
        mul_659: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_30, sub_181);  sub_181 = None
        sum_67: f32[512] = torch.ops.aten.sum.dim_IntList(mul_659, [0, 2, 3]);  mul_659 = None
        mul_660: f32[512] = torch.ops.aten.mul.Tensor(sum_66, 0.015625)
        unsqueeze_599: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_660, 0);  mul_660 = None
        unsqueeze_600: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_599, 2);  unsqueeze_599 = None
        unsqueeze_601: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_600, 3);  unsqueeze_600 = None
        mul_661: f32[512] = torch.ops.aten.mul.Tensor(sum_67, 0.015625)
        mul_662: f32[512] = torch.ops.aten.mul.Tensor(squeeze_61, squeeze_61)
        mul_663: f32[512] = torch.ops.aten.mul.Tensor(mul_661, mul_662);  mul_661 = mul_662 = None
        unsqueeze_602: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_663, 0);  mul_663 = None
        unsqueeze_603: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_602, 2);  unsqueeze_602 = None
        unsqueeze_604: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_603, 3);  unsqueeze_603 = None
        mul_664: f32[512] = torch.ops.aten.mul.Tensor(squeeze_61, primals_62);  primals_62 = None
        unsqueeze_605: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_664, 0);  mul_664 = None
        unsqueeze_606: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_605, 2);  unsqueeze_605 = None
        unsqueeze_607: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_606, 3);  unsqueeze_606 = None
        sub_182: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_20, unsqueeze_598);  convolution_20 = unsqueeze_598 = None
        mul_665: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_182, unsqueeze_604);  sub_182 = unsqueeze_604 = None
        sub_183: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_30, mul_665);  mul_665 = None
        sub_184: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_183, unsqueeze_601);  sub_183 = unsqueeze_601 = None
        mul_666: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_184, unsqueeze_607);  sub_184 = unsqueeze_607 = None
        mul_667: f32[512] = torch.ops.aten.mul.Tensor(sum_67, squeeze_61);  sum_67 = squeeze_61 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_32 = torch.ops.aten.convolution_backward.default(mul_666, relu_17, primals_61, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_666 = primals_61 = None
        getitem_204: f32[1, 128, 8, 8] = convolution_backward_32[0]
        getitem_205: f32[512, 128, 1, 1] = convolution_backward_32[1];  convolution_backward_32 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_31: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_17, 0);  relu_17 = None
        scalar_tensor_31: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_31: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_31, scalar_tensor_31, getitem_204);  le_31 = scalar_tensor_31 = getitem_204 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_608: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_57, 0);  squeeze_57 = None
        unsqueeze_609: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_608, 2);  unsqueeze_608 = None
        unsqueeze_610: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_609, 3);  unsqueeze_609 = None
        sum_68: f32[128] = torch.ops.aten.sum.dim_IntList(where_31, [0, 2, 3])
        sub_185: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_610)
        mul_668: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_31, sub_185);  sub_185 = None
        sum_69: f32[128] = torch.ops.aten.sum.dim_IntList(mul_668, [0, 2, 3]);  mul_668 = None
        mul_669: f32[128] = torch.ops.aten.mul.Tensor(sum_68, 0.015625)
        unsqueeze_611: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_669, 0);  mul_669 = None
        unsqueeze_612: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_611, 2);  unsqueeze_611 = None
        unsqueeze_613: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_612, 3);  unsqueeze_612 = None
        mul_670: f32[128] = torch.ops.aten.mul.Tensor(sum_69, 0.015625)
        mul_671: f32[128] = torch.ops.aten.mul.Tensor(squeeze_58, squeeze_58)
        mul_672: f32[128] = torch.ops.aten.mul.Tensor(mul_670, mul_671);  mul_670 = mul_671 = None
        unsqueeze_614: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_672, 0);  mul_672 = None
        unsqueeze_615: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_614, 2);  unsqueeze_614 = None
        unsqueeze_616: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_615, 3);  unsqueeze_615 = None
        mul_673: f32[128] = torch.ops.aten.mul.Tensor(squeeze_58, primals_59);  primals_59 = None
        unsqueeze_617: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_673, 0);  mul_673 = None
        unsqueeze_618: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_617, 2);  unsqueeze_617 = None
        unsqueeze_619: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_618, 3);  unsqueeze_618 = None
        sub_186: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_610);  convolution_19 = unsqueeze_610 = None
        mul_674: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_186, unsqueeze_616);  sub_186 = unsqueeze_616 = None
        sub_187: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_31, mul_674);  where_31 = mul_674 = None
        sub_188: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_187, unsqueeze_613);  sub_187 = unsqueeze_613 = None
        mul_675: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_188, unsqueeze_619);  sub_188 = unsqueeze_619 = None
        mul_676: f32[128] = torch.ops.aten.mul.Tensor(sum_69, squeeze_58);  sum_69 = squeeze_58 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_33 = torch.ops.aten.convolution_backward.default(mul_675, relu_16, primals_58, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_675 = primals_58 = None
        getitem_207: f32[1, 128, 8, 8] = convolution_backward_33[0]
        getitem_208: f32[128, 128, 3, 3] = convolution_backward_33[1];  convolution_backward_33 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_32: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_16, 0);  relu_16 = None
        scalar_tensor_32: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_32: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_32, scalar_tensor_32, getitem_207);  le_32 = scalar_tensor_32 = getitem_207 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_620: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_54, 0);  squeeze_54 = None
        unsqueeze_621: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_620, 2);  unsqueeze_620 = None
        unsqueeze_622: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_621, 3);  unsqueeze_621 = None
        sum_70: f32[128] = torch.ops.aten.sum.dim_IntList(where_32, [0, 2, 3])
        sub_189: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_622)
        mul_677: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_32, sub_189);  sub_189 = None
        sum_71: f32[128] = torch.ops.aten.sum.dim_IntList(mul_677, [0, 2, 3]);  mul_677 = None
        mul_678: f32[128] = torch.ops.aten.mul.Tensor(sum_70, 0.015625)
        unsqueeze_623: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_678, 0);  mul_678 = None
        unsqueeze_624: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_623, 2);  unsqueeze_623 = None
        unsqueeze_625: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_624, 3);  unsqueeze_624 = None
        mul_679: f32[128] = torch.ops.aten.mul.Tensor(sum_71, 0.015625)
        mul_680: f32[128] = torch.ops.aten.mul.Tensor(squeeze_55, squeeze_55)
        mul_681: f32[128] = torch.ops.aten.mul.Tensor(mul_679, mul_680);  mul_679 = mul_680 = None
        unsqueeze_626: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_681, 0);  mul_681 = None
        unsqueeze_627: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_626, 2);  unsqueeze_626 = None
        unsqueeze_628: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_627, 3);  unsqueeze_627 = None
        mul_682: f32[128] = torch.ops.aten.mul.Tensor(squeeze_55, primals_56);  primals_56 = None
        unsqueeze_629: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_682, 0);  mul_682 = None
        unsqueeze_630: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_629, 2);  unsqueeze_629 = None
        unsqueeze_631: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_630, 3);  unsqueeze_630 = None
        sub_190: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_622);  convolution_18 = unsqueeze_622 = None
        mul_683: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_190, unsqueeze_628);  sub_190 = unsqueeze_628 = None
        sub_191: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_32, mul_683);  where_32 = mul_683 = None
        sub_192: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_191, unsqueeze_625);  sub_191 = unsqueeze_625 = None
        mul_684: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_192, unsqueeze_631);  sub_192 = unsqueeze_631 = None
        mul_685: f32[128] = torch.ops.aten.mul.Tensor(sum_71, squeeze_55);  sum_71 = squeeze_55 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_34 = torch.ops.aten.convolution_backward.default(mul_684, relu_15, primals_55, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_684 = primals_55 = None
        getitem_210: f32[1, 512, 8, 8] = convolution_backward_34[0]
        getitem_211: f32[128, 512, 1, 1] = convolution_backward_34[1];  convolution_backward_34 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_291: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(where_30, getitem_210);  where_30 = getitem_210 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_33: b8[1, 512, 8, 8] = torch.ops.aten.le.Scalar(relu_15, 0);  relu_15 = None
        scalar_tensor_33: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_33: f32[1, 512, 8, 8] = torch.ops.aten.where.self(le_33, scalar_tensor_33, add_291);  le_33 = scalar_tensor_33 = add_291 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_632: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_51, 0);  squeeze_51 = None
        unsqueeze_633: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_632, 2);  unsqueeze_632 = None
        unsqueeze_634: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_633, 3);  unsqueeze_633 = None
        sum_72: f32[512] = torch.ops.aten.sum.dim_IntList(where_33, [0, 2, 3])
        sub_193: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_634)
        mul_686: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_33, sub_193);  sub_193 = None
        sum_73: f32[512] = torch.ops.aten.sum.dim_IntList(mul_686, [0, 2, 3]);  mul_686 = None
        mul_687: f32[512] = torch.ops.aten.mul.Tensor(sum_72, 0.015625)
        unsqueeze_635: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_687, 0);  mul_687 = None
        unsqueeze_636: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_635, 2);  unsqueeze_635 = None
        unsqueeze_637: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_636, 3);  unsqueeze_636 = None
        mul_688: f32[512] = torch.ops.aten.mul.Tensor(sum_73, 0.015625)
        mul_689: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, squeeze_52)
        mul_690: f32[512] = torch.ops.aten.mul.Tensor(mul_688, mul_689);  mul_688 = mul_689 = None
        unsqueeze_638: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_690, 0);  mul_690 = None
        unsqueeze_639: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_638, 2);  unsqueeze_638 = None
        unsqueeze_640: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_639, 3);  unsqueeze_639 = None
        mul_691: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, primals_53);  primals_53 = None
        unsqueeze_641: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_691, 0);  mul_691 = None
        unsqueeze_642: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_641, 2);  unsqueeze_641 = None
        unsqueeze_643: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_642, 3);  unsqueeze_642 = None
        sub_194: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_634);  convolution_17 = unsqueeze_634 = None
        mul_692: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_194, unsqueeze_640);  sub_194 = unsqueeze_640 = None
        sub_195: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_33, mul_692);  mul_692 = None
        sub_196: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_195, unsqueeze_637);  sub_195 = unsqueeze_637 = None
        mul_693: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_196, unsqueeze_643);  sub_196 = unsqueeze_643 = None
        mul_694: f32[512] = torch.ops.aten.mul.Tensor(sum_73, squeeze_52);  sum_73 = squeeze_52 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_35 = torch.ops.aten.convolution_backward.default(mul_693, relu_14, primals_52, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_693 = primals_52 = None
        getitem_213: f32[1, 128, 8, 8] = convolution_backward_35[0]
        getitem_214: f32[512, 128, 1, 1] = convolution_backward_35[1];  convolution_backward_35 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_34: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_14, 0);  relu_14 = None
        scalar_tensor_34: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_34: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_34, scalar_tensor_34, getitem_213);  le_34 = scalar_tensor_34 = getitem_213 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_644: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_48, 0);  squeeze_48 = None
        unsqueeze_645: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_644, 2);  unsqueeze_644 = None
        unsqueeze_646: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_645, 3);  unsqueeze_645 = None
        sum_74: f32[128] = torch.ops.aten.sum.dim_IntList(where_34, [0, 2, 3])
        sub_197: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_646)
        mul_695: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_34, sub_197);  sub_197 = None
        sum_75: f32[128] = torch.ops.aten.sum.dim_IntList(mul_695, [0, 2, 3]);  mul_695 = None
        mul_696: f32[128] = torch.ops.aten.mul.Tensor(sum_74, 0.015625)
        unsqueeze_647: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_696, 0);  mul_696 = None
        unsqueeze_648: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_647, 2);  unsqueeze_647 = None
        unsqueeze_649: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_648, 3);  unsqueeze_648 = None
        mul_697: f32[128] = torch.ops.aten.mul.Tensor(sum_75, 0.015625)
        mul_698: f32[128] = torch.ops.aten.mul.Tensor(squeeze_49, squeeze_49)
        mul_699: f32[128] = torch.ops.aten.mul.Tensor(mul_697, mul_698);  mul_697 = mul_698 = None
        unsqueeze_650: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_699, 0);  mul_699 = None
        unsqueeze_651: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_650, 2);  unsqueeze_650 = None
        unsqueeze_652: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_651, 3);  unsqueeze_651 = None
        mul_700: f32[128] = torch.ops.aten.mul.Tensor(squeeze_49, primals_50);  primals_50 = None
        unsqueeze_653: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_700, 0);  mul_700 = None
        unsqueeze_654: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_653, 2);  unsqueeze_653 = None
        unsqueeze_655: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_654, 3);  unsqueeze_654 = None
        sub_198: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_646);  convolution_16 = unsqueeze_646 = None
        mul_701: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_198, unsqueeze_652);  sub_198 = unsqueeze_652 = None
        sub_199: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_34, mul_701);  where_34 = mul_701 = None
        sub_200: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_199, unsqueeze_649);  sub_199 = unsqueeze_649 = None
        mul_702: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_200, unsqueeze_655);  sub_200 = unsqueeze_655 = None
        mul_703: f32[128] = torch.ops.aten.mul.Tensor(sum_75, squeeze_49);  sum_75 = squeeze_49 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_36 = torch.ops.aten.convolution_backward.default(mul_702, relu_13, primals_49, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_702 = primals_49 = None
        getitem_216: f32[1, 128, 8, 8] = convolution_backward_36[0]
        getitem_217: f32[128, 128, 3, 3] = convolution_backward_36[1];  convolution_backward_36 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_35: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_13, 0);  relu_13 = None
        scalar_tensor_35: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_35: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_35, scalar_tensor_35, getitem_216);  le_35 = scalar_tensor_35 = getitem_216 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_656: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_45, 0);  squeeze_45 = None
        unsqueeze_657: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_656, 2);  unsqueeze_656 = None
        unsqueeze_658: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_657, 3);  unsqueeze_657 = None
        sum_76: f32[128] = torch.ops.aten.sum.dim_IntList(where_35, [0, 2, 3])
        sub_201: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_658)
        mul_704: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_35, sub_201);  sub_201 = None
        sum_77: f32[128] = torch.ops.aten.sum.dim_IntList(mul_704, [0, 2, 3]);  mul_704 = None
        mul_705: f32[128] = torch.ops.aten.mul.Tensor(sum_76, 0.015625)
        unsqueeze_659: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_705, 0);  mul_705 = None
        unsqueeze_660: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_659, 2);  unsqueeze_659 = None
        unsqueeze_661: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_660, 3);  unsqueeze_660 = None
        mul_706: f32[128] = torch.ops.aten.mul.Tensor(sum_77, 0.015625)
        mul_707: f32[128] = torch.ops.aten.mul.Tensor(squeeze_46, squeeze_46)
        mul_708: f32[128] = torch.ops.aten.mul.Tensor(mul_706, mul_707);  mul_706 = mul_707 = None
        unsqueeze_662: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_708, 0);  mul_708 = None
        unsqueeze_663: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_662, 2);  unsqueeze_662 = None
        unsqueeze_664: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_663, 3);  unsqueeze_663 = None
        mul_709: f32[128] = torch.ops.aten.mul.Tensor(squeeze_46, primals_47);  primals_47 = None
        unsqueeze_665: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_709, 0);  mul_709 = None
        unsqueeze_666: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_665, 2);  unsqueeze_665 = None
        unsqueeze_667: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_666, 3);  unsqueeze_666 = None
        sub_202: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_658);  convolution_15 = unsqueeze_658 = None
        mul_710: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_202, unsqueeze_664);  sub_202 = unsqueeze_664 = None
        sub_203: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_35, mul_710);  where_35 = mul_710 = None
        sub_204: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_203, unsqueeze_661);  sub_203 = unsqueeze_661 = None
        mul_711: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_204, unsqueeze_667);  sub_204 = unsqueeze_667 = None
        mul_712: f32[128] = torch.ops.aten.mul.Tensor(sum_77, squeeze_46);  sum_77 = squeeze_46 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_37 = torch.ops.aten.convolution_backward.default(mul_711, relu_12, primals_46, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_711 = primals_46 = None
        getitem_219: f32[1, 512, 8, 8] = convolution_backward_37[0]
        getitem_220: f32[128, 512, 1, 1] = convolution_backward_37[1];  convolution_backward_37 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_292: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(where_33, getitem_219);  where_33 = getitem_219 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_36: b8[1, 512, 8, 8] = torch.ops.aten.le.Scalar(relu_12, 0);  relu_12 = None
        scalar_tensor_36: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_36: f32[1, 512, 8, 8] = torch.ops.aten.where.self(le_36, scalar_tensor_36, add_292);  le_36 = scalar_tensor_36 = add_292 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        unsqueeze_668: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_42, 0);  squeeze_42 = None
        unsqueeze_669: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_668, 2);  unsqueeze_668 = None
        unsqueeze_670: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_669, 3);  unsqueeze_669 = None
        sum_78: f32[512] = torch.ops.aten.sum.dim_IntList(where_36, [0, 2, 3])
        sub_205: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_670)
        mul_713: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_36, sub_205);  sub_205 = None
        sum_79: f32[512] = torch.ops.aten.sum.dim_IntList(mul_713, [0, 2, 3]);  mul_713 = None
        mul_714: f32[512] = torch.ops.aten.mul.Tensor(sum_78, 0.015625)
        unsqueeze_671: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_714, 0);  mul_714 = None
        unsqueeze_672: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_671, 2);  unsqueeze_671 = None
        unsqueeze_673: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_672, 3);  unsqueeze_672 = None
        mul_715: f32[512] = torch.ops.aten.mul.Tensor(sum_79, 0.015625)
        mul_716: f32[512] = torch.ops.aten.mul.Tensor(squeeze_43, squeeze_43)
        mul_717: f32[512] = torch.ops.aten.mul.Tensor(mul_715, mul_716);  mul_715 = mul_716 = None
        unsqueeze_674: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_717, 0);  mul_717 = None
        unsqueeze_675: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_674, 2);  unsqueeze_674 = None
        unsqueeze_676: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_675, 3);  unsqueeze_675 = None
        mul_718: f32[512] = torch.ops.aten.mul.Tensor(squeeze_43, primals_44);  primals_44 = None
        unsqueeze_677: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_718, 0);  mul_718 = None
        unsqueeze_678: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_677, 2);  unsqueeze_677 = None
        unsqueeze_679: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_678, 3);  unsqueeze_678 = None
        sub_206: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_670);  convolution_14 = unsqueeze_670 = None
        mul_719: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_206, unsqueeze_676);  sub_206 = unsqueeze_676 = None
        sub_207: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_36, mul_719);  mul_719 = None
        sub_208: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_207, unsqueeze_673);  sub_207 = unsqueeze_673 = None
        mul_720: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_208, unsqueeze_679);  sub_208 = unsqueeze_679 = None
        mul_721: f32[512] = torch.ops.aten.mul.Tensor(sum_79, squeeze_43);  sum_79 = squeeze_43 = None
        convolution_backward_38 = torch.ops.aten.convolution_backward.default(mul_720, relu_9, primals_43, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_720 = primals_43 = None
        getitem_222: f32[1, 256, 16, 16] = convolution_backward_38[0]
        getitem_223: f32[512, 256, 1, 1] = convolution_backward_38[1];  convolution_backward_38 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_680: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_39, 0);  squeeze_39 = None
        unsqueeze_681: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_680, 2);  unsqueeze_680 = None
        unsqueeze_682: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_681, 3);  unsqueeze_681 = None
        sum_80: f32[512] = torch.ops.aten.sum.dim_IntList(where_36, [0, 2, 3])
        sub_209: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_682)
        mul_722: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_36, sub_209);  sub_209 = None
        sum_81: f32[512] = torch.ops.aten.sum.dim_IntList(mul_722, [0, 2, 3]);  mul_722 = None
        mul_723: f32[512] = torch.ops.aten.mul.Tensor(sum_80, 0.015625)
        unsqueeze_683: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_723, 0);  mul_723 = None
        unsqueeze_684: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_683, 2);  unsqueeze_683 = None
        unsqueeze_685: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_684, 3);  unsqueeze_684 = None
        mul_724: f32[512] = torch.ops.aten.mul.Tensor(sum_81, 0.015625)
        mul_725: f32[512] = torch.ops.aten.mul.Tensor(squeeze_40, squeeze_40)
        mul_726: f32[512] = torch.ops.aten.mul.Tensor(mul_724, mul_725);  mul_724 = mul_725 = None
        unsqueeze_686: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_726, 0);  mul_726 = None
        unsqueeze_687: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_686, 2);  unsqueeze_686 = None
        unsqueeze_688: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_687, 3);  unsqueeze_687 = None
        mul_727: f32[512] = torch.ops.aten.mul.Tensor(squeeze_40, primals_41);  primals_41 = None
        unsqueeze_689: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_727, 0);  mul_727 = None
        unsqueeze_690: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_689, 2);  unsqueeze_689 = None
        unsqueeze_691: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_690, 3);  unsqueeze_690 = None
        sub_210: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_682);  convolution_13 = unsqueeze_682 = None
        mul_728: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_210, unsqueeze_688);  sub_210 = unsqueeze_688 = None
        sub_211: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_36, mul_728);  where_36 = mul_728 = None
        sub_212: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_211, unsqueeze_685);  sub_211 = unsqueeze_685 = None
        mul_729: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_212, unsqueeze_691);  sub_212 = unsqueeze_691 = None
        mul_730: f32[512] = torch.ops.aten.mul.Tensor(sum_81, squeeze_40);  sum_81 = squeeze_40 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_39 = torch.ops.aten.convolution_backward.default(mul_729, relu_11, primals_40, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_729 = primals_40 = None
        getitem_225: f32[1, 128, 8, 8] = convolution_backward_39[0]
        getitem_226: f32[512, 128, 1, 1] = convolution_backward_39[1];  convolution_backward_39 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_37: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_11, 0);  relu_11 = None
        scalar_tensor_37: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_37: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_37, scalar_tensor_37, getitem_225);  le_37 = scalar_tensor_37 = getitem_225 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_692: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_36, 0);  squeeze_36 = None
        unsqueeze_693: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_692, 2);  unsqueeze_692 = None
        unsqueeze_694: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_693, 3);  unsqueeze_693 = None
        sum_82: f32[128] = torch.ops.aten.sum.dim_IntList(where_37, [0, 2, 3])
        sub_213: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_694)
        mul_731: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_37, sub_213);  sub_213 = None
        sum_83: f32[128] = torch.ops.aten.sum.dim_IntList(mul_731, [0, 2, 3]);  mul_731 = None
        mul_732: f32[128] = torch.ops.aten.mul.Tensor(sum_82, 0.015625)
        unsqueeze_695: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_732, 0);  mul_732 = None
        unsqueeze_696: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_695, 2);  unsqueeze_695 = None
        unsqueeze_697: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_696, 3);  unsqueeze_696 = None
        mul_733: f32[128] = torch.ops.aten.mul.Tensor(sum_83, 0.015625)
        mul_734: f32[128] = torch.ops.aten.mul.Tensor(squeeze_37, squeeze_37)
        mul_735: f32[128] = torch.ops.aten.mul.Tensor(mul_733, mul_734);  mul_733 = mul_734 = None
        unsqueeze_698: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_735, 0);  mul_735 = None
        unsqueeze_699: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_698, 2);  unsqueeze_698 = None
        unsqueeze_700: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_699, 3);  unsqueeze_699 = None
        mul_736: f32[128] = torch.ops.aten.mul.Tensor(squeeze_37, primals_38);  primals_38 = None
        unsqueeze_701: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_736, 0);  mul_736 = None
        unsqueeze_702: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_701, 2);  unsqueeze_701 = None
        unsqueeze_703: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_702, 3);  unsqueeze_702 = None
        sub_214: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_694);  convolution_12 = unsqueeze_694 = None
        mul_737: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_214, unsqueeze_700);  sub_214 = unsqueeze_700 = None
        sub_215: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_37, mul_737);  where_37 = mul_737 = None
        sub_216: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_215, unsqueeze_697);  sub_215 = unsqueeze_697 = None
        mul_738: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_216, unsqueeze_703);  sub_216 = unsqueeze_703 = None
        mul_739: f32[128] = torch.ops.aten.mul.Tensor(sum_83, squeeze_37);  sum_83 = squeeze_37 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_40 = torch.ops.aten.convolution_backward.default(mul_738, relu_10, primals_37, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_738 = primals_37 = None
        getitem_228: f32[1, 128, 16, 16] = convolution_backward_40[0]
        getitem_229: f32[128, 128, 3, 3] = convolution_backward_40[1];  convolution_backward_40 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_38: b8[1, 128, 16, 16] = torch.ops.aten.le.Scalar(relu_10, 0);  relu_10 = None
        scalar_tensor_38: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_38: f32[1, 128, 16, 16] = torch.ops.aten.where.self(le_38, scalar_tensor_38, getitem_228);  le_38 = scalar_tensor_38 = getitem_228 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_704: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_33, 0);  squeeze_33 = None
        unsqueeze_705: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_704, 2);  unsqueeze_704 = None
        unsqueeze_706: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_705, 3);  unsqueeze_705 = None
        sum_84: f32[128] = torch.ops.aten.sum.dim_IntList(where_38, [0, 2, 3])
        sub_217: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_706)
        mul_740: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(where_38, sub_217);  sub_217 = None
        sum_85: f32[128] = torch.ops.aten.sum.dim_IntList(mul_740, [0, 2, 3]);  mul_740 = None
        mul_741: f32[128] = torch.ops.aten.mul.Tensor(sum_84, 0.00390625)
        unsqueeze_707: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_741, 0);  mul_741 = None
        unsqueeze_708: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_707, 2);  unsqueeze_707 = None
        unsqueeze_709: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_708, 3);  unsqueeze_708 = None
        mul_742: f32[128] = torch.ops.aten.mul.Tensor(sum_85, 0.00390625)
        mul_743: f32[128] = torch.ops.aten.mul.Tensor(squeeze_34, squeeze_34)
        mul_744: f32[128] = torch.ops.aten.mul.Tensor(mul_742, mul_743);  mul_742 = mul_743 = None
        unsqueeze_710: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_744, 0);  mul_744 = None
        unsqueeze_711: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_710, 2);  unsqueeze_710 = None
        unsqueeze_712: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_711, 3);  unsqueeze_711 = None
        mul_745: f32[128] = torch.ops.aten.mul.Tensor(squeeze_34, primals_35);  primals_35 = None
        unsqueeze_713: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_745, 0);  mul_745 = None
        unsqueeze_714: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_713, 2);  unsqueeze_713 = None
        unsqueeze_715: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_714, 3);  unsqueeze_714 = None
        sub_218: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_706);  convolution_11 = unsqueeze_706 = None
        mul_746: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(sub_218, unsqueeze_712);  sub_218 = unsqueeze_712 = None
        sub_219: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(where_38, mul_746);  where_38 = mul_746 = None
        sub_220: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(sub_219, unsqueeze_709);  sub_219 = unsqueeze_709 = None
        mul_747: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(sub_220, unsqueeze_715);  sub_220 = unsqueeze_715 = None
        mul_748: f32[128] = torch.ops.aten.mul.Tensor(sum_85, squeeze_34);  sum_85 = squeeze_34 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_41 = torch.ops.aten.convolution_backward.default(mul_747, relu_9, primals_34, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_747 = primals_34 = None
        getitem_231: f32[1, 256, 16, 16] = convolution_backward_41[0]
        getitem_232: f32[128, 256, 1, 1] = convolution_backward_41[1];  convolution_backward_41 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_293: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(getitem_222, getitem_231);  getitem_222 = getitem_231 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_39: b8[1, 256, 16, 16] = torch.ops.aten.le.Scalar(relu_9, 0);  relu_9 = None
        scalar_tensor_39: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_39: f32[1, 256, 16, 16] = torch.ops.aten.where.self(le_39, scalar_tensor_39, add_293);  le_39 = scalar_tensor_39 = add_293 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_716: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_30, 0);  squeeze_30 = None
        unsqueeze_717: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_716, 2);  unsqueeze_716 = None
        unsqueeze_718: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_717, 3);  unsqueeze_717 = None
        sum_86: f32[256] = torch.ops.aten.sum.dim_IntList(where_39, [0, 2, 3])
        sub_221: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_718)
        mul_749: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(where_39, sub_221);  sub_221 = None
        sum_87: f32[256] = torch.ops.aten.sum.dim_IntList(mul_749, [0, 2, 3]);  mul_749 = None
        mul_750: f32[256] = torch.ops.aten.mul.Tensor(sum_86, 0.00390625)
        unsqueeze_719: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_750, 0);  mul_750 = None
        unsqueeze_720: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_719, 2);  unsqueeze_719 = None
        unsqueeze_721: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_720, 3);  unsqueeze_720 = None
        mul_751: f32[256] = torch.ops.aten.mul.Tensor(sum_87, 0.00390625)
        mul_752: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, squeeze_31)
        mul_753: f32[256] = torch.ops.aten.mul.Tensor(mul_751, mul_752);  mul_751 = mul_752 = None
        unsqueeze_722: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_753, 0);  mul_753 = None
        unsqueeze_723: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_722, 2);  unsqueeze_722 = None
        unsqueeze_724: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_723, 3);  unsqueeze_723 = None
        mul_754: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, primals_32);  primals_32 = None
        unsqueeze_725: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_754, 0);  mul_754 = None
        unsqueeze_726: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_725, 2);  unsqueeze_725 = None
        unsqueeze_727: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_726, 3);  unsqueeze_726 = None
        sub_222: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_718);  convolution_10 = unsqueeze_718 = None
        mul_755: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_222, unsqueeze_724);  sub_222 = unsqueeze_724 = None
        sub_223: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(where_39, mul_755);  mul_755 = None
        sub_224: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(sub_223, unsqueeze_721);  sub_223 = unsqueeze_721 = None
        mul_756: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_224, unsqueeze_727);  sub_224 = unsqueeze_727 = None
        mul_757: f32[256] = torch.ops.aten.mul.Tensor(sum_87, squeeze_31);  sum_87 = squeeze_31 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_42 = torch.ops.aten.convolution_backward.default(mul_756, relu_8, primals_31, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_756 = primals_31 = None
        getitem_234: f32[1, 64, 16, 16] = convolution_backward_42[0]
        getitem_235: f32[256, 64, 1, 1] = convolution_backward_42[1];  convolution_backward_42 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_40: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_8, 0);  relu_8 = None
        scalar_tensor_40: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_40: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_40, scalar_tensor_40, getitem_234);  le_40 = scalar_tensor_40 = getitem_234 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_728: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_27, 0);  squeeze_27 = None
        unsqueeze_729: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_728, 2);  unsqueeze_728 = None
        unsqueeze_730: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_729, 3);  unsqueeze_729 = None
        sum_88: f32[64] = torch.ops.aten.sum.dim_IntList(where_40, [0, 2, 3])
        sub_225: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_730)
        mul_758: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_40, sub_225);  sub_225 = None
        sum_89: f32[64] = torch.ops.aten.sum.dim_IntList(mul_758, [0, 2, 3]);  mul_758 = None
        mul_759: f32[64] = torch.ops.aten.mul.Tensor(sum_88, 0.00390625)
        unsqueeze_731: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_759, 0);  mul_759 = None
        unsqueeze_732: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_731, 2);  unsqueeze_731 = None
        unsqueeze_733: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_732, 3);  unsqueeze_732 = None
        mul_760: f32[64] = torch.ops.aten.mul.Tensor(sum_89, 0.00390625)
        mul_761: f32[64] = torch.ops.aten.mul.Tensor(squeeze_28, squeeze_28)
        mul_762: f32[64] = torch.ops.aten.mul.Tensor(mul_760, mul_761);  mul_760 = mul_761 = None
        unsqueeze_734: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_762, 0);  mul_762 = None
        unsqueeze_735: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_734, 2);  unsqueeze_734 = None
        unsqueeze_736: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_735, 3);  unsqueeze_735 = None
        mul_763: f32[64] = torch.ops.aten.mul.Tensor(squeeze_28, primals_29);  primals_29 = None
        unsqueeze_737: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_763, 0);  mul_763 = None
        unsqueeze_738: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_737, 2);  unsqueeze_737 = None
        unsqueeze_739: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_738, 3);  unsqueeze_738 = None
        sub_226: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_730);  convolution_9 = unsqueeze_730 = None
        mul_764: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_226, unsqueeze_736);  sub_226 = unsqueeze_736 = None
        sub_227: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_40, mul_764);  where_40 = mul_764 = None
        sub_228: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_227, unsqueeze_733);  sub_227 = unsqueeze_733 = None
        mul_765: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_228, unsqueeze_739);  sub_228 = unsqueeze_739 = None
        mul_766: f32[64] = torch.ops.aten.mul.Tensor(sum_89, squeeze_28);  sum_89 = squeeze_28 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_43 = torch.ops.aten.convolution_backward.default(mul_765, relu_7, primals_28, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_765 = primals_28 = None
        getitem_237: f32[1, 64, 16, 16] = convolution_backward_43[0]
        getitem_238: f32[64, 64, 3, 3] = convolution_backward_43[1];  convolution_backward_43 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_41: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_7, 0);  relu_7 = None
        scalar_tensor_41: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_41: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_41, scalar_tensor_41, getitem_237);  le_41 = scalar_tensor_41 = getitem_237 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_740: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_24, 0);  squeeze_24 = None
        unsqueeze_741: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_740, 2);  unsqueeze_740 = None
        unsqueeze_742: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_741, 3);  unsqueeze_741 = None
        sum_90: f32[64] = torch.ops.aten.sum.dim_IntList(where_41, [0, 2, 3])
        sub_229: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_742)
        mul_767: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_41, sub_229);  sub_229 = None
        sum_91: f32[64] = torch.ops.aten.sum.dim_IntList(mul_767, [0, 2, 3]);  mul_767 = None
        mul_768: f32[64] = torch.ops.aten.mul.Tensor(sum_90, 0.00390625)
        unsqueeze_743: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_768, 0);  mul_768 = None
        unsqueeze_744: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_743, 2);  unsqueeze_743 = None
        unsqueeze_745: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_744, 3);  unsqueeze_744 = None
        mul_769: f32[64] = torch.ops.aten.mul.Tensor(sum_91, 0.00390625)
        mul_770: f32[64] = torch.ops.aten.mul.Tensor(squeeze_25, squeeze_25)
        mul_771: f32[64] = torch.ops.aten.mul.Tensor(mul_769, mul_770);  mul_769 = mul_770 = None
        unsqueeze_746: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_771, 0);  mul_771 = None
        unsqueeze_747: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_746, 2);  unsqueeze_746 = None
        unsqueeze_748: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_747, 3);  unsqueeze_747 = None
        mul_772: f32[64] = torch.ops.aten.mul.Tensor(squeeze_25, primals_26);  primals_26 = None
        unsqueeze_749: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_772, 0);  mul_772 = None
        unsqueeze_750: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_749, 2);  unsqueeze_749 = None
        unsqueeze_751: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_750, 3);  unsqueeze_750 = None
        sub_230: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_742);  convolution_8 = unsqueeze_742 = None
        mul_773: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_230, unsqueeze_748);  sub_230 = unsqueeze_748 = None
        sub_231: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_41, mul_773);  where_41 = mul_773 = None
        sub_232: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_231, unsqueeze_745);  sub_231 = unsqueeze_745 = None
        mul_774: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_232, unsqueeze_751);  sub_232 = unsqueeze_751 = None
        mul_775: f32[64] = torch.ops.aten.mul.Tensor(sum_91, squeeze_25);  sum_91 = squeeze_25 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_44 = torch.ops.aten.convolution_backward.default(mul_774, relu_6, primals_25, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_774 = primals_25 = None
        getitem_240: f32[1, 256, 16, 16] = convolution_backward_44[0]
        getitem_241: f32[64, 256, 1, 1] = convolution_backward_44[1];  convolution_backward_44 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_294: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(where_39, getitem_240);  where_39 = getitem_240 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_42: b8[1, 256, 16, 16] = torch.ops.aten.le.Scalar(relu_6, 0);  relu_6 = None
        scalar_tensor_42: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_42: f32[1, 256, 16, 16] = torch.ops.aten.where.self(le_42, scalar_tensor_42, add_294);  le_42 = scalar_tensor_42 = add_294 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_752: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_21, 0);  squeeze_21 = None
        unsqueeze_753: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_752, 2);  unsqueeze_752 = None
        unsqueeze_754: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_753, 3);  unsqueeze_753 = None
        sum_92: f32[256] = torch.ops.aten.sum.dim_IntList(where_42, [0, 2, 3])
        sub_233: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_754)
        mul_776: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(where_42, sub_233);  sub_233 = None
        sum_93: f32[256] = torch.ops.aten.sum.dim_IntList(mul_776, [0, 2, 3]);  mul_776 = None
        mul_777: f32[256] = torch.ops.aten.mul.Tensor(sum_92, 0.00390625)
        unsqueeze_755: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_777, 0);  mul_777 = None
        unsqueeze_756: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_755, 2);  unsqueeze_755 = None
        unsqueeze_757: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_756, 3);  unsqueeze_756 = None
        mul_778: f32[256] = torch.ops.aten.mul.Tensor(sum_93, 0.00390625)
        mul_779: f32[256] = torch.ops.aten.mul.Tensor(squeeze_22, squeeze_22)
        mul_780: f32[256] = torch.ops.aten.mul.Tensor(mul_778, mul_779);  mul_778 = mul_779 = None
        unsqueeze_758: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_780, 0);  mul_780 = None
        unsqueeze_759: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_758, 2);  unsqueeze_758 = None
        unsqueeze_760: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_759, 3);  unsqueeze_759 = None
        mul_781: f32[256] = torch.ops.aten.mul.Tensor(squeeze_22, primals_23);  primals_23 = None
        unsqueeze_761: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_781, 0);  mul_781 = None
        unsqueeze_762: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_761, 2);  unsqueeze_761 = None
        unsqueeze_763: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_762, 3);  unsqueeze_762 = None
        sub_234: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_754);  convolution_7 = unsqueeze_754 = None
        mul_782: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_234, unsqueeze_760);  sub_234 = unsqueeze_760 = None
        sub_235: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(where_42, mul_782);  mul_782 = None
        sub_236: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(sub_235, unsqueeze_757);  sub_235 = unsqueeze_757 = None
        mul_783: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_236, unsqueeze_763);  sub_236 = unsqueeze_763 = None
        mul_784: f32[256] = torch.ops.aten.mul.Tensor(sum_93, squeeze_22);  sum_93 = squeeze_22 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_45 = torch.ops.aten.convolution_backward.default(mul_783, relu_5, primals_22, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_783 = primals_22 = None
        getitem_243: f32[1, 64, 16, 16] = convolution_backward_45[0]
        getitem_244: f32[256, 64, 1, 1] = convolution_backward_45[1];  convolution_backward_45 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_43: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_5, 0);  relu_5 = None
        scalar_tensor_43: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_43: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_43, scalar_tensor_43, getitem_243);  le_43 = scalar_tensor_43 = getitem_243 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_764: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_18, 0);  squeeze_18 = None
        unsqueeze_765: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_764, 2);  unsqueeze_764 = None
        unsqueeze_766: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_765, 3);  unsqueeze_765 = None
        sum_94: f32[64] = torch.ops.aten.sum.dim_IntList(where_43, [0, 2, 3])
        sub_237: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_766)
        mul_785: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_43, sub_237);  sub_237 = None
        sum_95: f32[64] = torch.ops.aten.sum.dim_IntList(mul_785, [0, 2, 3]);  mul_785 = None
        mul_786: f32[64] = torch.ops.aten.mul.Tensor(sum_94, 0.00390625)
        unsqueeze_767: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_786, 0);  mul_786 = None
        unsqueeze_768: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_767, 2);  unsqueeze_767 = None
        unsqueeze_769: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_768, 3);  unsqueeze_768 = None
        mul_787: f32[64] = torch.ops.aten.mul.Tensor(sum_95, 0.00390625)
        mul_788: f32[64] = torch.ops.aten.mul.Tensor(squeeze_19, squeeze_19)
        mul_789: f32[64] = torch.ops.aten.mul.Tensor(mul_787, mul_788);  mul_787 = mul_788 = None
        unsqueeze_770: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_789, 0);  mul_789 = None
        unsqueeze_771: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_770, 2);  unsqueeze_770 = None
        unsqueeze_772: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_771, 3);  unsqueeze_771 = None
        mul_790: f32[64] = torch.ops.aten.mul.Tensor(squeeze_19, primals_20);  primals_20 = None
        unsqueeze_773: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_790, 0);  mul_790 = None
        unsqueeze_774: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_773, 2);  unsqueeze_773 = None
        unsqueeze_775: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_774, 3);  unsqueeze_774 = None
        sub_238: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_766);  convolution_6 = unsqueeze_766 = None
        mul_791: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_238, unsqueeze_772);  sub_238 = unsqueeze_772 = None
        sub_239: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_43, mul_791);  where_43 = mul_791 = None
        sub_240: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_239, unsqueeze_769);  sub_239 = unsqueeze_769 = None
        mul_792: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_240, unsqueeze_775);  sub_240 = unsqueeze_775 = None
        mul_793: f32[64] = torch.ops.aten.mul.Tensor(sum_95, squeeze_19);  sum_95 = squeeze_19 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_46 = torch.ops.aten.convolution_backward.default(mul_792, relu_4, primals_19, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_792 = primals_19 = None
        getitem_246: f32[1, 64, 16, 16] = convolution_backward_46[0]
        getitem_247: f32[64, 64, 3, 3] = convolution_backward_46[1];  convolution_backward_46 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_44: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_4, 0);  relu_4 = None
        scalar_tensor_44: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_44: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_44, scalar_tensor_44, getitem_246);  le_44 = scalar_tensor_44 = getitem_246 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_776: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_15, 0);  squeeze_15 = None
        unsqueeze_777: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_776, 2);  unsqueeze_776 = None
        unsqueeze_778: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_777, 3);  unsqueeze_777 = None
        sum_96: f32[64] = torch.ops.aten.sum.dim_IntList(where_44, [0, 2, 3])
        sub_241: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_778)
        mul_794: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_44, sub_241);  sub_241 = None
        sum_97: f32[64] = torch.ops.aten.sum.dim_IntList(mul_794, [0, 2, 3]);  mul_794 = None
        mul_795: f32[64] = torch.ops.aten.mul.Tensor(sum_96, 0.00390625)
        unsqueeze_779: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_795, 0);  mul_795 = None
        unsqueeze_780: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_779, 2);  unsqueeze_779 = None
        unsqueeze_781: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_780, 3);  unsqueeze_780 = None
        mul_796: f32[64] = torch.ops.aten.mul.Tensor(sum_97, 0.00390625)
        mul_797: f32[64] = torch.ops.aten.mul.Tensor(squeeze_16, squeeze_16)
        mul_798: f32[64] = torch.ops.aten.mul.Tensor(mul_796, mul_797);  mul_796 = mul_797 = None
        unsqueeze_782: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_798, 0);  mul_798 = None
        unsqueeze_783: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_782, 2);  unsqueeze_782 = None
        unsqueeze_784: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_783, 3);  unsqueeze_783 = None
        mul_799: f32[64] = torch.ops.aten.mul.Tensor(squeeze_16, primals_17);  primals_17 = None
        unsqueeze_785: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_799, 0);  mul_799 = None
        unsqueeze_786: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_785, 2);  unsqueeze_785 = None
        unsqueeze_787: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_786, 3);  unsqueeze_786 = None
        sub_242: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_778);  convolution_5 = unsqueeze_778 = None
        mul_800: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_242, unsqueeze_784);  sub_242 = unsqueeze_784 = None
        sub_243: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_44, mul_800);  where_44 = mul_800 = None
        sub_244: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_243, unsqueeze_781);  sub_243 = unsqueeze_781 = None
        mul_801: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_244, unsqueeze_787);  sub_244 = unsqueeze_787 = None
        mul_802: f32[64] = torch.ops.aten.mul.Tensor(sum_97, squeeze_16);  sum_97 = squeeze_16 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_47 = torch.ops.aten.convolution_backward.default(mul_801, relu_3, primals_16, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_801 = primals_16 = None
        getitem_249: f32[1, 256, 16, 16] = convolution_backward_47[0]
        getitem_250: f32[64, 256, 1, 1] = convolution_backward_47[1];  convolution_backward_47 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_295: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(where_42, getitem_249);  where_42 = getitem_249 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_45: b8[1, 256, 16, 16] = torch.ops.aten.le.Scalar(relu_3, 0);  relu_3 = None
        scalar_tensor_45: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_45: f32[1, 256, 16, 16] = torch.ops.aten.where.self(le_45, scalar_tensor_45, add_295);  le_45 = scalar_tensor_45 = add_295 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        unsqueeze_788: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_12, 0);  squeeze_12 = None
        unsqueeze_789: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_788, 2);  unsqueeze_788 = None
        unsqueeze_790: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_789, 3);  unsqueeze_789 = None
        sum_98: f32[256] = torch.ops.aten.sum.dim_IntList(where_45, [0, 2, 3])
        sub_245: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_790)
        mul_803: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(where_45, sub_245);  sub_245 = None
        sum_99: f32[256] = torch.ops.aten.sum.dim_IntList(mul_803, [0, 2, 3]);  mul_803 = None
        mul_804: f32[256] = torch.ops.aten.mul.Tensor(sum_98, 0.00390625)
        unsqueeze_791: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_804, 0);  mul_804 = None
        unsqueeze_792: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_791, 2);  unsqueeze_791 = None
        unsqueeze_793: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_792, 3);  unsqueeze_792 = None
        mul_805: f32[256] = torch.ops.aten.mul.Tensor(sum_99, 0.00390625)
        mul_806: f32[256] = torch.ops.aten.mul.Tensor(squeeze_13, squeeze_13)
        mul_807: f32[256] = torch.ops.aten.mul.Tensor(mul_805, mul_806);  mul_805 = mul_806 = None
        unsqueeze_794: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_807, 0);  mul_807 = None
        unsqueeze_795: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_794, 2);  unsqueeze_794 = None
        unsqueeze_796: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_795, 3);  unsqueeze_795 = None
        mul_808: f32[256] = torch.ops.aten.mul.Tensor(squeeze_13, primals_14);  primals_14 = None
        unsqueeze_797: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_808, 0);  mul_808 = None
        unsqueeze_798: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_797, 2);  unsqueeze_797 = None
        unsqueeze_799: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_798, 3);  unsqueeze_798 = None
        sub_246: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_790);  convolution_4 = unsqueeze_790 = None
        mul_809: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_246, unsqueeze_796);  sub_246 = unsqueeze_796 = None
        sub_247: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(where_45, mul_809);  mul_809 = None
        sub_248: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(sub_247, unsqueeze_793);  sub_247 = unsqueeze_793 = None
        mul_810: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_248, unsqueeze_799);  sub_248 = unsqueeze_799 = None
        mul_811: f32[256] = torch.ops.aten.mul.Tensor(sum_99, squeeze_13);  sum_99 = squeeze_13 = None
        convolution_backward_48 = torch.ops.aten.convolution_backward.default(mul_810, getitem_2, primals_13, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_810 = primals_13 = None
        getitem_252: f32[1, 64, 16, 16] = convolution_backward_48[0]
        getitem_253: f32[256, 64, 1, 1] = convolution_backward_48[1];  convolution_backward_48 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_800: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_9, 0);  squeeze_9 = None
        unsqueeze_801: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_800, 2);  unsqueeze_800 = None
        unsqueeze_802: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_801, 3);  unsqueeze_801 = None
        sum_100: f32[256] = torch.ops.aten.sum.dim_IntList(where_45, [0, 2, 3])
        sub_249: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_802)
        mul_812: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(where_45, sub_249);  sub_249 = None
        sum_101: f32[256] = torch.ops.aten.sum.dim_IntList(mul_812, [0, 2, 3]);  mul_812 = None
        mul_813: f32[256] = torch.ops.aten.mul.Tensor(sum_100, 0.00390625)
        unsqueeze_803: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_813, 0);  mul_813 = None
        unsqueeze_804: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_803, 2);  unsqueeze_803 = None
        unsqueeze_805: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_804, 3);  unsqueeze_804 = None
        mul_814: f32[256] = torch.ops.aten.mul.Tensor(sum_101, 0.00390625)
        mul_815: f32[256] = torch.ops.aten.mul.Tensor(squeeze_10, squeeze_10)
        mul_816: f32[256] = torch.ops.aten.mul.Tensor(mul_814, mul_815);  mul_814 = mul_815 = None
        unsqueeze_806: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_816, 0);  mul_816 = None
        unsqueeze_807: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_806, 2);  unsqueeze_806 = None
        unsqueeze_808: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_807, 3);  unsqueeze_807 = None
        mul_817: f32[256] = torch.ops.aten.mul.Tensor(squeeze_10, primals_11);  primals_11 = None
        unsqueeze_809: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_817, 0);  mul_817 = None
        unsqueeze_810: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_809, 2);  unsqueeze_809 = None
        unsqueeze_811: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_810, 3);  unsqueeze_810 = None
        sub_250: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_802);  convolution_3 = unsqueeze_802 = None
        mul_818: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_250, unsqueeze_808);  sub_250 = unsqueeze_808 = None
        sub_251: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(where_45, mul_818);  where_45 = mul_818 = None
        sub_252: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(sub_251, unsqueeze_805);  sub_251 = unsqueeze_805 = None
        mul_819: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_252, unsqueeze_811);  sub_252 = unsqueeze_811 = None
        mul_820: f32[256] = torch.ops.aten.mul.Tensor(sum_101, squeeze_10);  sum_101 = squeeze_10 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_49 = torch.ops.aten.convolution_backward.default(mul_819, relu_2, primals_10, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_819 = primals_10 = None
        getitem_255: f32[1, 64, 16, 16] = convolution_backward_49[0]
        getitem_256: f32[256, 64, 1, 1] = convolution_backward_49[1];  convolution_backward_49 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_46: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_2, 0);  relu_2 = None
        scalar_tensor_46: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_46: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_46, scalar_tensor_46, getitem_255);  le_46 = scalar_tensor_46 = getitem_255 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_812: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_6, 0);  squeeze_6 = None
        unsqueeze_813: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_812, 2);  unsqueeze_812 = None
        unsqueeze_814: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_813, 3);  unsqueeze_813 = None
        sum_102: f32[64] = torch.ops.aten.sum.dim_IntList(where_46, [0, 2, 3])
        sub_253: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_814)
        mul_821: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_46, sub_253);  sub_253 = None
        sum_103: f32[64] = torch.ops.aten.sum.dim_IntList(mul_821, [0, 2, 3]);  mul_821 = None
        mul_822: f32[64] = torch.ops.aten.mul.Tensor(sum_102, 0.00390625)
        unsqueeze_815: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_822, 0);  mul_822 = None
        unsqueeze_816: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_815, 2);  unsqueeze_815 = None
        unsqueeze_817: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_816, 3);  unsqueeze_816 = None
        mul_823: f32[64] = torch.ops.aten.mul.Tensor(sum_103, 0.00390625)
        mul_824: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, squeeze_7)
        mul_825: f32[64] = torch.ops.aten.mul.Tensor(mul_823, mul_824);  mul_823 = mul_824 = None
        unsqueeze_818: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_825, 0);  mul_825 = None
        unsqueeze_819: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_818, 2);  unsqueeze_818 = None
        unsqueeze_820: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_819, 3);  unsqueeze_819 = None
        mul_826: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, primals_8);  primals_8 = None
        unsqueeze_821: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_826, 0);  mul_826 = None
        unsqueeze_822: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_821, 2);  unsqueeze_821 = None
        unsqueeze_823: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_822, 3);  unsqueeze_822 = None
        sub_254: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_814);  convolution_2 = unsqueeze_814 = None
        mul_827: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_254, unsqueeze_820);  sub_254 = unsqueeze_820 = None
        sub_255: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_46, mul_827);  where_46 = mul_827 = None
        sub_256: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_255, unsqueeze_817);  sub_255 = unsqueeze_817 = None
        mul_828: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_256, unsqueeze_823);  sub_256 = unsqueeze_823 = None
        mul_829: f32[64] = torch.ops.aten.mul.Tensor(sum_103, squeeze_7);  sum_103 = squeeze_7 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_50 = torch.ops.aten.convolution_backward.default(mul_828, relu_1, primals_7, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_828 = primals_7 = None
        getitem_258: f32[1, 64, 16, 16] = convolution_backward_50[0]
        getitem_259: f32[64, 64, 3, 3] = convolution_backward_50[1];  convolution_backward_50 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_47: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_1, 0);  relu_1 = None
        scalar_tensor_47: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_47: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_47, scalar_tensor_47, getitem_258);  le_47 = scalar_tensor_47 = getitem_258 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_824: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_3, 0);  squeeze_3 = None
        unsqueeze_825: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_824, 2);  unsqueeze_824 = None
        unsqueeze_826: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_825, 3);  unsqueeze_825 = None
        sum_104: f32[64] = torch.ops.aten.sum.dim_IntList(where_47, [0, 2, 3])
        sub_257: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_826)
        mul_830: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_47, sub_257);  sub_257 = None
        sum_105: f32[64] = torch.ops.aten.sum.dim_IntList(mul_830, [0, 2, 3]);  mul_830 = None
        mul_831: f32[64] = torch.ops.aten.mul.Tensor(sum_104, 0.00390625)
        unsqueeze_827: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_831, 0);  mul_831 = None
        unsqueeze_828: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_827, 2);  unsqueeze_827 = None
        unsqueeze_829: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_828, 3);  unsqueeze_828 = None
        mul_832: f32[64] = torch.ops.aten.mul.Tensor(sum_105, 0.00390625)
        mul_833: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, squeeze_4)
        mul_834: f32[64] = torch.ops.aten.mul.Tensor(mul_832, mul_833);  mul_832 = mul_833 = None
        unsqueeze_830: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_834, 0);  mul_834 = None
        unsqueeze_831: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_830, 2);  unsqueeze_830 = None
        unsqueeze_832: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_831, 3);  unsqueeze_831 = None
        mul_835: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, primals_5);  primals_5 = None
        unsqueeze_833: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_835, 0);  mul_835 = None
        unsqueeze_834: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_833, 2);  unsqueeze_833 = None
        unsqueeze_835: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_834, 3);  unsqueeze_834 = None
        sub_258: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_826);  convolution_1 = unsqueeze_826 = None
        mul_836: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_258, unsqueeze_832);  sub_258 = unsqueeze_832 = None
        sub_259: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_47, mul_836);  where_47 = mul_836 = None
        sub_260: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_259, unsqueeze_829);  sub_259 = unsqueeze_829 = None
        mul_837: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_260, unsqueeze_835);  sub_260 = unsqueeze_835 = None
        mul_838: f32[64] = torch.ops.aten.mul.Tensor(sum_105, squeeze_4);  sum_105 = squeeze_4 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_51 = torch.ops.aten.convolution_backward.default(mul_837, getitem_2, primals_4, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_837 = getitem_2 = primals_4 = None
        getitem_261: f32[1, 64, 16, 16] = convolution_backward_51[0]
        getitem_262: f32[64, 64, 1, 1] = convolution_backward_51[1];  convolution_backward_51 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_296: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(getitem_252, getitem_261);  getitem_252 = getitem_261 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:235, code: x = self.maxpool(x)
        max_pool2d_with_indices_backward: f32[1, 64, 32, 32] = torch.ops.aten.max_pool2d_with_indices_backward.default(add_296, relu, [3, 3], [2, 2], [1, 1], [1, 1], False, getitem_3);  add_296 = getitem_3 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:234, code: x = self.relu(x)
        le_48: b8[1, 64, 32, 32] = torch.ops.aten.le.Scalar(relu, 0);  relu = None
        scalar_tensor_48: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))
        where_48: f32[1, 64, 32, 32] = torch.ops.aten.where.self(le_48, scalar_tensor_48, max_pool2d_with_indices_backward);  le_48 = scalar_tensor_48 = max_pool2d_with_indices_backward = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:233, code: x = self.bn1(x)
        unsqueeze_836: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze, 0);  squeeze = None
        unsqueeze_837: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_836, 2);  unsqueeze_836 = None
        unsqueeze_838: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_837, 3);  unsqueeze_837 = None
        sum_106: f32[64] = torch.ops.aten.sum.dim_IntList(where_48, [0, 2, 3])
        sub_261: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(convolution, unsqueeze_838)
        mul_839: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(where_48, sub_261);  sub_261 = None
        sum_107: f32[64] = torch.ops.aten.sum.dim_IntList(mul_839, [0, 2, 3]);  mul_839 = None
        mul_840: f32[64] = torch.ops.aten.mul.Tensor(sum_106, 0.0009765625)
        unsqueeze_839: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_840, 0);  mul_840 = None
        unsqueeze_840: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_839, 2);  unsqueeze_839 = None
        unsqueeze_841: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_840, 3);  unsqueeze_840 = None
        mul_841: f32[64] = torch.ops.aten.mul.Tensor(sum_107, 0.0009765625)
        mul_842: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, squeeze_1)
        mul_843: f32[64] = torch.ops.aten.mul.Tensor(mul_841, mul_842);  mul_841 = mul_842 = None
        unsqueeze_842: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_843, 0);  mul_843 = None
        unsqueeze_843: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_842, 2);  unsqueeze_842 = None
        unsqueeze_844: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_843, 3);  unsqueeze_843 = None
        mul_844: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, primals_2);  primals_2 = None
        unsqueeze_845: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_844, 0);  mul_844 = None
        unsqueeze_846: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_845, 2);  unsqueeze_845 = None
        unsqueeze_847: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_846, 3);  unsqueeze_846 = None
        sub_262: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(convolution, unsqueeze_838);  convolution = unsqueeze_838 = None
        mul_845: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(sub_262, unsqueeze_844);  sub_262 = unsqueeze_844 = None
        sub_263: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(where_48, mul_845);  where_48 = mul_845 = None
        sub_264: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(sub_263, unsqueeze_841);  sub_263 = unsqueeze_841 = None
        mul_846: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(sub_264, unsqueeze_847);  sub_264 = unsqueeze_847 = None
        mul_847: f32[64] = torch.ops.aten.mul.Tensor(sum_107, squeeze_1);  sum_107 = squeeze_1 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:232, code: x = self.conv1(x)
        convolution_backward_52 = torch.ops.aten.convolution_backward.default(mul_846, primals_321, primals_1, [0], [2, 2], [3, 3], [1, 1], False, [0, 0], 1, [False, True, False]);  mul_846 = primals_321 = primals_1 = None
        getitem_265: f32[64, 3, 7, 7] = convolution_backward_52[1];  convolution_backward_52 = None
        return pytree.tree_unflatten([add_2, add_3, add, add_7, add_8, add_5, add_12, add_13, add_10, add_17, add_18, add_15, add_22, add_23, add_20, add_28, add_29, add_26, add_33, add_34, add_31, add_38, add_39, add_36, add_44, add_45, add_42, add_49, add_50, add_47, add_54, add_55, add_52, add_60, add_61, add_58, add_65, add_66, add_63, add_70, add_71, add_68, add_75, add_76, add_73, add_81, add_82, add_79, add_86, add_87, add_84, add_91, add_92, add_89, add_97, add_98, add_95, add_102, add_103, add_100, add_107, add_108, add_105, add_113, add_114, add_111, add_118, add_119, add_116, add_123, add_124, add_121, add_129, add_130, add_127, add_134, add_135, add_132, add_139, add_140, add_137, add_144, add_145, add_142, add_150, add_151, add_148, add_155, add_156, add_153, add_160, add_161, add_158, add_166, add_167, add_164, add_171, add_172, add_169, add_176, add_177, add_174, add_182, add_183, add_180, add_187, add_188, add_185, add_192, add_193, add_190, add_198, add_199, add_196, add_203, add_204, add_201, add_208, add_209, add_206, add_214, add_215, add_212, add_219, add_220, add_217, add_224, add_225, add_222, add_230, add_231, add_228, add_235, add_236, add_233, add_240, add_241, add_238, add_245, add_246, add_243, add_251, add_252, add_249, add_256, add_257, add_254, add_261, add_262, add_259, add_267, add_268, add_265, add_272, add_273, add_270, add_277, add_278, add_275, addmm, getitem_265, mul_847, sum_106, getitem_262, mul_838, sum_104, getitem_259, mul_829, sum_102, getitem_256, mul_820, sum_100, getitem_253, mul_811, sum_98, getitem_250, mul_802, sum_96, getitem_247, mul_793, sum_94, getitem_244, mul_784, sum_92, getitem_241, mul_775, sum_90, getitem_238, mul_766, sum_88, getitem_235, mul_757, sum_86, getitem_232, mul_748, sum_84, getitem_229, mul_739, sum_82, getitem_226, mul_730, sum_80, getitem_223, mul_721, sum_78, getitem_220, mul_712, sum_76, getitem_217, mul_703, sum_74, getitem_214, mul_694, sum_72, getitem_211, mul_685, sum_70, getitem_208, mul_676, sum_68, getitem_205, mul_667, sum_66, getitem_202, mul_658, sum_64, getitem_199, mul_649, sum_62, getitem_196, mul_640, sum_60, getitem_193, mul_631, sum_58, getitem_190, mul_622, sum_56, getitem_187, mul_613, sum_54, getitem_184, mul_604, sum_52, getitem_181, mul_595, sum_50, getitem_178, mul_586, sum_48, getitem_175, mul_577, sum_46, getitem_172, mul_568, sum_44, getitem_169, mul_559, sum_42, getitem_166, mul_550, sum_40, getitem_163, mul_541, sum_38, getitem_160, mul_532, sum_36, getitem_157, mul_523, sum_34, getitem_154, mul_514, sum_32, getitem_151, mul_505, sum_30, getitem_148, mul_496, sum_28, getitem_145, mul_487, sum_26, getitem_142, mul_478, sum_24, getitem_139, mul_469, sum_22, getitem_136, mul_460, sum_20, getitem_133, mul_451, sum_18, getitem_130, mul_442, sum_16, getitem_127, mul_433, sum_14, getitem_124, mul_424, sum_12, getitem_121, mul_415, sum_10, getitem_118, mul_406, sum_8, getitem_115, mul_397, sum_6, getitem_112, mul_388, sum_4, getitem_109, mul_379, sum_2, permute_4, view_1, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], self._out_spec)
        

[aot_autograd.py:2899 INFO] TRACED GRAPH
 ===== Forward graph 28 =====
 <eval_with_key>.307 class GraphModule(torch.nn.Module):
    def forward(self, primals_1: f32[64, 3, 7, 7], primals_2: f32[64], primals_3: f32[64], primals_4: f32[64, 64, 1, 1], primals_5: f32[64], primals_6: f32[64], primals_7: f32[64, 64, 3, 3], primals_8: f32[64], primals_9: f32[64], primals_10: f32[256, 64, 1, 1], primals_11: f32[256], primals_12: f32[256], primals_13: f32[256, 64, 1, 1], primals_14: f32[256], primals_15: f32[256], primals_16: f32[64, 256, 1, 1], primals_17: f32[64], primals_18: f32[64], primals_19: f32[64, 64, 3, 3], primals_20: f32[64], primals_21: f32[64], primals_22: f32[256, 64, 1, 1], primals_23: f32[256], primals_24: f32[256], primals_25: f32[64, 256, 1, 1], primals_26: f32[64], primals_27: f32[64], primals_28: f32[64, 64, 3, 3], primals_29: f32[64], primals_30: f32[64], primals_31: f32[256, 64, 1, 1], primals_32: f32[256], primals_33: f32[256], primals_34: f32[128, 256, 1, 1], primals_35: f32[128], primals_36: f32[128], primals_37: f32[128, 128, 3, 3], primals_38: f32[128], primals_39: f32[128], primals_40: f32[512, 128, 1, 1], primals_41: f32[512], primals_42: f32[512], primals_43: f32[512, 256, 1, 1], primals_44: f32[512], primals_45: f32[512], primals_46: f32[128, 512, 1, 1], primals_47: f32[128], primals_48: f32[128], primals_49: f32[128, 128, 3, 3], primals_50: f32[128], primals_51: f32[128], primals_52: f32[512, 128, 1, 1], primals_53: f32[512], primals_54: f32[512], primals_55: f32[128, 512, 1, 1], primals_56: f32[128], primals_57: f32[128], primals_58: f32[128, 128, 3, 3], primals_59: f32[128], primals_60: f32[128], primals_61: f32[512, 128, 1, 1], primals_62: f32[512], primals_63: f32[512], primals_64: f32[128, 512, 1, 1], primals_65: f32[128], primals_66: f32[128], primals_67: f32[128, 128, 3, 3], primals_68: f32[128], primals_69: f32[128], primals_70: f32[512, 128, 1, 1], primals_71: f32[512], primals_72: f32[512], primals_73: f32[256, 512, 1, 1], primals_74: f32[256], primals_75: f32[256], primals_76: f32[256, 256, 3, 3], primals_77: f32[256], primals_78: f32[256], primals_79: f32[1024, 256, 1, 1], primals_80: f32[1024], primals_81: f32[1024], primals_82: f32[1024, 512, 1, 1], primals_83: f32[1024], primals_84: f32[1024], primals_85: f32[256, 1024, 1, 1], primals_86: f32[256], primals_87: f32[256], primals_88: f32[256, 256, 3, 3], primals_89: f32[256], primals_90: f32[256], primals_91: f32[1024, 256, 1, 1], primals_92: f32[1024], primals_93: f32[1024], primals_94: f32[256, 1024, 1, 1], primals_95: f32[256], primals_96: f32[256], primals_97: f32[256, 256, 3, 3], primals_98: f32[256], primals_99: f32[256], primals_100: f32[1024, 256, 1, 1], primals_101: f32[1024], primals_102: f32[1024], primals_103: f32[256, 1024, 1, 1], primals_104: f32[256], primals_105: f32[256], primals_106: f32[256, 256, 3, 3], primals_107: f32[256], primals_108: f32[256], primals_109: f32[1024, 256, 1, 1], primals_110: f32[1024], primals_111: f32[1024], primals_112: f32[256, 1024, 1, 1], primals_113: f32[256], primals_114: f32[256], primals_115: f32[256, 256, 3, 3], primals_116: f32[256], primals_117: f32[256], primals_118: f32[1024, 256, 1, 1], primals_119: f32[1024], primals_120: f32[1024], primals_121: f32[256, 1024, 1, 1], primals_122: f32[256], primals_123: f32[256], primals_124: f32[256, 256, 3, 3], primals_125: f32[256], primals_126: f32[256], primals_127: f32[1024, 256, 1, 1], primals_128: f32[1024], primals_129: f32[1024], primals_130: f32[512, 1024, 1, 1], primals_131: f32[512], primals_132: f32[512], primals_133: f32[512, 512, 3, 3], primals_134: f32[512], primals_135: f32[512], primals_136: f32[2048, 512, 1, 1], primals_137: f32[2048], primals_138: f32[2048], primals_139: f32[2048, 1024, 1, 1], primals_140: f32[2048], primals_141: f32[2048], primals_142: f32[512, 2048, 1, 1], primals_143: f32[512], primals_144: f32[512], primals_145: f32[512, 512, 3, 3], primals_146: f32[512], primals_147: f32[512], primals_148: f32[2048, 512, 1, 1], primals_149: f32[2048], primals_150: f32[2048], primals_151: f32[512, 2048, 1, 1], primals_152: f32[512], primals_153: f32[512], primals_154: f32[512, 512, 3, 3], primals_155: f32[512], primals_156: f32[512], primals_157: f32[2048, 512, 1, 1], primals_158: f32[2048], primals_159: f32[2048], primals_160: f32[1000, 2048], primals_161: f32[1000], primals_162: f32[64], primals_163: f32[64], primals_164: i64[], primals_165: f32[64], primals_166: f32[64], primals_167: i64[], primals_168: f32[64], primals_169: f32[64], primals_170: i64[], primals_171: f32[256], primals_172: f32[256], primals_173: i64[], primals_174: f32[256], primals_175: f32[256], primals_176: i64[], primals_177: f32[64], primals_178: f32[64], primals_179: i64[], primals_180: f32[64], primals_181: f32[64], primals_182: i64[], primals_183: f32[256], primals_184: f32[256], primals_185: i64[], primals_186: f32[64], primals_187: f32[64], primals_188: i64[], primals_189: f32[64], primals_190: f32[64], primals_191: i64[], primals_192: f32[256], primals_193: f32[256], primals_194: i64[], primals_195: f32[128], primals_196: f32[128], primals_197: i64[], primals_198: f32[128], primals_199: f32[128], primals_200: i64[], primals_201: f32[512], primals_202: f32[512], primals_203: i64[], primals_204: f32[512], primals_205: f32[512], primals_206: i64[], primals_207: f32[128], primals_208: f32[128], primals_209: i64[], primals_210: f32[128], primals_211: f32[128], primals_212: i64[], primals_213: f32[512], primals_214: f32[512], primals_215: i64[], primals_216: f32[128], primals_217: f32[128], primals_218: i64[], primals_219: f32[128], primals_220: f32[128], primals_221: i64[], primals_222: f32[512], primals_223: f32[512], primals_224: i64[], primals_225: f32[128], primals_226: f32[128], primals_227: i64[], primals_228: f32[128], primals_229: f32[128], primals_230: i64[], primals_231: f32[512], primals_232: f32[512], primals_233: i64[], primals_234: f32[256], primals_235: f32[256], primals_236: i64[], primals_237: f32[256], primals_238: f32[256], primals_239: i64[], primals_240: f32[1024], primals_241: f32[1024], primals_242: i64[], primals_243: f32[1024], primals_244: f32[1024], primals_245: i64[], primals_246: f32[256], primals_247: f32[256], primals_248: i64[], primals_249: f32[256], primals_250: f32[256], primals_251: i64[], primals_252: f32[1024], primals_253: f32[1024], primals_254: i64[], primals_255: f32[256], primals_256: f32[256], primals_257: i64[], primals_258: f32[256], primals_259: f32[256], primals_260: i64[], primals_261: f32[1024], primals_262: f32[1024], primals_263: i64[], primals_264: f32[256], primals_265: f32[256], primals_266: i64[], primals_267: f32[256], primals_268: f32[256], primals_269: i64[], primals_270: f32[1024], primals_271: f32[1024], primals_272: i64[], primals_273: f32[256], primals_274: f32[256], primals_275: i64[], primals_276: f32[256], primals_277: f32[256], primals_278: i64[], primals_279: f32[1024], primals_280: f32[1024], primals_281: i64[], primals_282: f32[256], primals_283: f32[256], primals_284: i64[], primals_285: f32[256], primals_286: f32[256], primals_287: i64[], primals_288: f32[1024], primals_289: f32[1024], primals_290: i64[], primals_291: f32[512], primals_292: f32[512], primals_293: i64[], primals_294: f32[512], primals_295: f32[512], primals_296: i64[], primals_297: f32[2048], primals_298: f32[2048], primals_299: i64[], primals_300: f32[2048], primals_301: f32[2048], primals_302: i64[], primals_303: f32[512], primals_304: f32[512], primals_305: i64[], primals_306: f32[512], primals_307: f32[512], primals_308: i64[], primals_309: f32[2048], primals_310: f32[2048], primals_311: i64[], primals_312: f32[512], primals_313: f32[512], primals_314: i64[], primals_315: f32[512], primals_316: f32[512], primals_317: i64[], primals_318: f32[2048], primals_319: f32[2048], primals_320: i64[], primals_321: f32[1, 3, 64, 64]):
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:232, code: x = self.conv1(x)
        convolution: f32[1, 64, 32, 32] = torch.ops.aten.convolution.default(primals_321, primals_1, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:233, code: x = self.bn1(x)
        add: i64[] = torch.ops.aten.add.Tensor(primals_164, 1);  primals_164 = None
        var_mean = torch.ops.aten.var_mean.correction(convolution, [0, 2, 3], correction = 0, keepdim = True)
        getitem: f32[1, 64, 1, 1] = var_mean[0]
        getitem_1: f32[1, 64, 1, 1] = var_mean[1];  var_mean = None
        add_1: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem, 1e-05)
        rsqrt: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
        sub: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(convolution, getitem_1)
        mul: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
        squeeze: f32[64] = torch.ops.aten.squeeze.dims(getitem_1, [0, 2, 3]);  getitem_1 = None
        squeeze_1: f32[64] = torch.ops.aten.squeeze.dims(rsqrt, [0, 2, 3]);  rsqrt = None
        mul_1: f32[64] = torch.ops.aten.mul.Tensor(squeeze, 0.1)
        mul_2: f32[64] = torch.ops.aten.mul.Tensor(primals_162, 0.9);  primals_162 = None
        add_2: f32[64] = torch.ops.aten.add.Tensor(mul_1, mul_2);  mul_1 = mul_2 = None
        squeeze_2: f32[64] = torch.ops.aten.squeeze.dims(getitem, [0, 2, 3]);  getitem = None
        mul_3: f32[64] = torch.ops.aten.mul.Tensor(squeeze_2, 1.0009775171065494);  squeeze_2 = None
        mul_4: f32[64] = torch.ops.aten.mul.Tensor(mul_3, 0.1);  mul_3 = None
        mul_5: f32[64] = torch.ops.aten.mul.Tensor(primals_163, 0.9);  primals_163 = None
        add_3: f32[64] = torch.ops.aten.add.Tensor(mul_4, mul_5);  mul_4 = mul_5 = None
        unsqueeze: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_2, -1)
        unsqueeze_1: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze, -1);  unsqueeze = None
        mul_6: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(mul, unsqueeze_1);  mul = unsqueeze_1 = None
        unsqueeze_2: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_3, -1);  primals_3 = None
        unsqueeze_3: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_2, -1);  unsqueeze_2 = None
        add_4: f32[1, 64, 32, 32] = torch.ops.aten.add.Tensor(mul_6, unsqueeze_3);  mul_6 = unsqueeze_3 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:234, code: x = self.relu(x)
        relu: f32[1, 64, 32, 32] = torch.ops.aten.relu.default(add_4);  add_4 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:235, code: x = self.maxpool(x)
        max_pool2d_with_indices = torch.ops.aten.max_pool2d_with_indices.default(relu, [3, 3], [2, 2], [1, 1])
        getitem_2: f32[1, 64, 16, 16] = max_pool2d_with_indices[0]
        getitem_3: i64[1, 64, 16, 16] = max_pool2d_with_indices[1];  max_pool2d_with_indices = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_1: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(getitem_2, primals_4, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_5: i64[] = torch.ops.aten.add.Tensor(primals_167, 1);  primals_167 = None
        var_mean_1 = torch.ops.aten.var_mean.correction(convolution_1, [0, 2, 3], correction = 0, keepdim = True)
        getitem_4: f32[1, 64, 1, 1] = var_mean_1[0]
        getitem_5: f32[1, 64, 1, 1] = var_mean_1[1];  var_mean_1 = None
        add_6: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_4, 1e-05)
        rsqrt_1: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_6);  add_6 = None
        sub_1: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_1, getitem_5)
        mul_7: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_1, rsqrt_1);  sub_1 = None
        squeeze_3: f32[64] = torch.ops.aten.squeeze.dims(getitem_5, [0, 2, 3]);  getitem_5 = None
        squeeze_4: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_1, [0, 2, 3]);  rsqrt_1 = None
        mul_8: f32[64] = torch.ops.aten.mul.Tensor(squeeze_3, 0.1)
        mul_9: f32[64] = torch.ops.aten.mul.Tensor(primals_165, 0.9);  primals_165 = None
        add_7: f32[64] = torch.ops.aten.add.Tensor(mul_8, mul_9);  mul_8 = mul_9 = None
        squeeze_5: f32[64] = torch.ops.aten.squeeze.dims(getitem_4, [0, 2, 3]);  getitem_4 = None
        mul_10: f32[64] = torch.ops.aten.mul.Tensor(squeeze_5, 1.003921568627451);  squeeze_5 = None
        mul_11: f32[64] = torch.ops.aten.mul.Tensor(mul_10, 0.1);  mul_10 = None
        mul_12: f32[64] = torch.ops.aten.mul.Tensor(primals_166, 0.9);  primals_166 = None
        add_8: f32[64] = torch.ops.aten.add.Tensor(mul_11, mul_12);  mul_11 = mul_12 = None
        unsqueeze_4: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_5, -1)
        unsqueeze_5: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_4, -1);  unsqueeze_4 = None
        mul_13: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_7, unsqueeze_5);  mul_7 = unsqueeze_5 = None
        unsqueeze_6: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_6, -1);  primals_6 = None
        unsqueeze_7: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_6, -1);  unsqueeze_6 = None
        add_9: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_13, unsqueeze_7);  mul_13 = unsqueeze_7 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_1: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_9);  add_9 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_2: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_1, primals_7, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_10: i64[] = torch.ops.aten.add.Tensor(primals_170, 1);  primals_170 = None
        var_mean_2 = torch.ops.aten.var_mean.correction(convolution_2, [0, 2, 3], correction = 0, keepdim = True)
        getitem_6: f32[1, 64, 1, 1] = var_mean_2[0]
        getitem_7: f32[1, 64, 1, 1] = var_mean_2[1];  var_mean_2 = None
        add_11: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_6, 1e-05)
        rsqrt_2: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_11);  add_11 = None
        sub_2: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_2, getitem_7)
        mul_14: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_2, rsqrt_2);  sub_2 = None
        squeeze_6: f32[64] = torch.ops.aten.squeeze.dims(getitem_7, [0, 2, 3]);  getitem_7 = None
        squeeze_7: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_2, [0, 2, 3]);  rsqrt_2 = None
        mul_15: f32[64] = torch.ops.aten.mul.Tensor(squeeze_6, 0.1)
        mul_16: f32[64] = torch.ops.aten.mul.Tensor(primals_168, 0.9);  primals_168 = None
        add_12: f32[64] = torch.ops.aten.add.Tensor(mul_15, mul_16);  mul_15 = mul_16 = None
        squeeze_8: f32[64] = torch.ops.aten.squeeze.dims(getitem_6, [0, 2, 3]);  getitem_6 = None
        mul_17: f32[64] = torch.ops.aten.mul.Tensor(squeeze_8, 1.003921568627451);  squeeze_8 = None
        mul_18: f32[64] = torch.ops.aten.mul.Tensor(mul_17, 0.1);  mul_17 = None
        mul_19: f32[64] = torch.ops.aten.mul.Tensor(primals_169, 0.9);  primals_169 = None
        add_13: f32[64] = torch.ops.aten.add.Tensor(mul_18, mul_19);  mul_18 = mul_19 = None
        unsqueeze_8: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_8, -1)
        unsqueeze_9: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_8, -1);  unsqueeze_8 = None
        mul_20: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_14, unsqueeze_9);  mul_14 = unsqueeze_9 = None
        unsqueeze_10: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_9, -1);  primals_9 = None
        unsqueeze_11: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_10, -1);  unsqueeze_10 = None
        add_14: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_20, unsqueeze_11);  mul_20 = unsqueeze_11 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_2: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_14);  add_14 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_3: f32[1, 256, 16, 16] = torch.ops.aten.convolution.default(relu_2, primals_10, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_15: i64[] = torch.ops.aten.add.Tensor(primals_173, 1);  primals_173 = None
        var_mean_3 = torch.ops.aten.var_mean.correction(convolution_3, [0, 2, 3], correction = 0, keepdim = True)
        getitem_8: f32[1, 256, 1, 1] = var_mean_3[0]
        getitem_9: f32[1, 256, 1, 1] = var_mean_3[1];  var_mean_3 = None
        add_16: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_8, 1e-05)
        rsqrt_3: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
        sub_3: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_3, getitem_9)
        mul_21: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_3, rsqrt_3);  sub_3 = None
        squeeze_9: f32[256] = torch.ops.aten.squeeze.dims(getitem_9, [0, 2, 3]);  getitem_9 = None
        squeeze_10: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_3, [0, 2, 3]);  rsqrt_3 = None
        mul_22: f32[256] = torch.ops.aten.mul.Tensor(squeeze_9, 0.1)
        mul_23: f32[256] = torch.ops.aten.mul.Tensor(primals_171, 0.9);  primals_171 = None
        add_17: f32[256] = torch.ops.aten.add.Tensor(mul_22, mul_23);  mul_22 = mul_23 = None
        squeeze_11: f32[256] = torch.ops.aten.squeeze.dims(getitem_8, [0, 2, 3]);  getitem_8 = None
        mul_24: f32[256] = torch.ops.aten.mul.Tensor(squeeze_11, 1.003921568627451);  squeeze_11 = None
        mul_25: f32[256] = torch.ops.aten.mul.Tensor(mul_24, 0.1);  mul_24 = None
        mul_26: f32[256] = torch.ops.aten.mul.Tensor(primals_172, 0.9);  primals_172 = None
        add_18: f32[256] = torch.ops.aten.add.Tensor(mul_25, mul_26);  mul_25 = mul_26 = None
        unsqueeze_12: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_11, -1)
        unsqueeze_13: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_12, -1);  unsqueeze_12 = None
        mul_27: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(mul_21, unsqueeze_13);  mul_21 = unsqueeze_13 = None
        unsqueeze_14: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_12, -1);  primals_12 = None
        unsqueeze_15: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_14, -1);  unsqueeze_14 = None
        add_19: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(mul_27, unsqueeze_15);  mul_27 = unsqueeze_15 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        convolution_4: f32[1, 256, 16, 16] = torch.ops.aten.convolution.default(getitem_2, primals_13, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        add_20: i64[] = torch.ops.aten.add.Tensor(primals_176, 1);  primals_176 = None
        var_mean_4 = torch.ops.aten.var_mean.correction(convolution_4, [0, 2, 3], correction = 0, keepdim = True)
        getitem_10: f32[1, 256, 1, 1] = var_mean_4[0]
        getitem_11: f32[1, 256, 1, 1] = var_mean_4[1];  var_mean_4 = None
        add_21: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_10, 1e-05)
        rsqrt_4: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_21);  add_21 = None
        sub_4: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_4, getitem_11)
        mul_28: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_4, rsqrt_4);  sub_4 = None
        squeeze_12: f32[256] = torch.ops.aten.squeeze.dims(getitem_11, [0, 2, 3]);  getitem_11 = None
        squeeze_13: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_4, [0, 2, 3]);  rsqrt_4 = None
        mul_29: f32[256] = torch.ops.aten.mul.Tensor(squeeze_12, 0.1)
        mul_30: f32[256] = torch.ops.aten.mul.Tensor(primals_174, 0.9);  primals_174 = None
        add_22: f32[256] = torch.ops.aten.add.Tensor(mul_29, mul_30);  mul_29 = mul_30 = None
        squeeze_14: f32[256] = torch.ops.aten.squeeze.dims(getitem_10, [0, 2, 3]);  getitem_10 = None
        mul_31: f32[256] = torch.ops.aten.mul.Tensor(squeeze_14, 1.003921568627451);  squeeze_14 = None
        mul_32: f32[256] = torch.ops.aten.mul.Tensor(mul_31, 0.1);  mul_31 = None
        mul_33: f32[256] = torch.ops.aten.mul.Tensor(primals_175, 0.9);  primals_175 = None
        add_23: f32[256] = torch.ops.aten.add.Tensor(mul_32, mul_33);  mul_32 = mul_33 = None
        unsqueeze_16: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_14, -1)
        unsqueeze_17: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_16, -1);  unsqueeze_16 = None
        mul_34: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(mul_28, unsqueeze_17);  mul_28 = unsqueeze_17 = None
        unsqueeze_18: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_15, -1);  primals_15 = None
        unsqueeze_19: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_18, -1);  unsqueeze_18 = None
        add_24: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(mul_34, unsqueeze_19);  mul_34 = unsqueeze_19 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_25: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(add_19, add_24);  add_19 = add_24 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_3: f32[1, 256, 16, 16] = torch.ops.aten.relu.default(add_25);  add_25 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_5: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_3, primals_16, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_26: i64[] = torch.ops.aten.add.Tensor(primals_179, 1);  primals_179 = None
        var_mean_5 = torch.ops.aten.var_mean.correction(convolution_5, [0, 2, 3], correction = 0, keepdim = True)
        getitem_12: f32[1, 64, 1, 1] = var_mean_5[0]
        getitem_13: f32[1, 64, 1, 1] = var_mean_5[1];  var_mean_5 = None
        add_27: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_12, 1e-05)
        rsqrt_5: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_27);  add_27 = None
        sub_5: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_5, getitem_13)
        mul_35: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_5, rsqrt_5);  sub_5 = None
        squeeze_15: f32[64] = torch.ops.aten.squeeze.dims(getitem_13, [0, 2, 3]);  getitem_13 = None
        squeeze_16: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_5, [0, 2, 3]);  rsqrt_5 = None
        mul_36: f32[64] = torch.ops.aten.mul.Tensor(squeeze_15, 0.1)
        mul_37: f32[64] = torch.ops.aten.mul.Tensor(primals_177, 0.9);  primals_177 = None
        add_28: f32[64] = torch.ops.aten.add.Tensor(mul_36, mul_37);  mul_36 = mul_37 = None
        squeeze_17: f32[64] = torch.ops.aten.squeeze.dims(getitem_12, [0, 2, 3]);  getitem_12 = None
        mul_38: f32[64] = torch.ops.aten.mul.Tensor(squeeze_17, 1.003921568627451);  squeeze_17 = None
        mul_39: f32[64] = torch.ops.aten.mul.Tensor(mul_38, 0.1);  mul_38 = None
        mul_40: f32[64] = torch.ops.aten.mul.Tensor(primals_178, 0.9);  primals_178 = None
        add_29: f32[64] = torch.ops.aten.add.Tensor(mul_39, mul_40);  mul_39 = mul_40 = None
        unsqueeze_20: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_17, -1)
        unsqueeze_21: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_20, -1);  unsqueeze_20 = None
        mul_41: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_35, unsqueeze_21);  mul_35 = unsqueeze_21 = None
        unsqueeze_22: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_18, -1);  primals_18 = None
        unsqueeze_23: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_22, -1);  unsqueeze_22 = None
        add_30: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_41, unsqueeze_23);  mul_41 = unsqueeze_23 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_4: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_30);  add_30 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_6: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_4, primals_19, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_31: i64[] = torch.ops.aten.add.Tensor(primals_182, 1);  primals_182 = None
        var_mean_6 = torch.ops.aten.var_mean.correction(convolution_6, [0, 2, 3], correction = 0, keepdim = True)
        getitem_14: f32[1, 64, 1, 1] = var_mean_6[0]
        getitem_15: f32[1, 64, 1, 1] = var_mean_6[1];  var_mean_6 = None
        add_32: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_14, 1e-05)
        rsqrt_6: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_32);  add_32 = None
        sub_6: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_6, getitem_15)
        mul_42: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_6, rsqrt_6);  sub_6 = None
        squeeze_18: f32[64] = torch.ops.aten.squeeze.dims(getitem_15, [0, 2, 3]);  getitem_15 = None
        squeeze_19: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_6, [0, 2, 3]);  rsqrt_6 = None
        mul_43: f32[64] = torch.ops.aten.mul.Tensor(squeeze_18, 0.1)
        mul_44: f32[64] = torch.ops.aten.mul.Tensor(primals_180, 0.9);  primals_180 = None
        add_33: f32[64] = torch.ops.aten.add.Tensor(mul_43, mul_44);  mul_43 = mul_44 = None
        squeeze_20: f32[64] = torch.ops.aten.squeeze.dims(getitem_14, [0, 2, 3]);  getitem_14 = None
        mul_45: f32[64] = torch.ops.aten.mul.Tensor(squeeze_20, 1.003921568627451);  squeeze_20 = None
        mul_46: f32[64] = torch.ops.aten.mul.Tensor(mul_45, 0.1);  mul_45 = None
        mul_47: f32[64] = torch.ops.aten.mul.Tensor(primals_181, 0.9);  primals_181 = None
        add_34: f32[64] = torch.ops.aten.add.Tensor(mul_46, mul_47);  mul_46 = mul_47 = None
        unsqueeze_24: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_20, -1)
        unsqueeze_25: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_24, -1);  unsqueeze_24 = None
        mul_48: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_42, unsqueeze_25);  mul_42 = unsqueeze_25 = None
        unsqueeze_26: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_21, -1);  primals_21 = None
        unsqueeze_27: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_26, -1);  unsqueeze_26 = None
        add_35: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_48, unsqueeze_27);  mul_48 = unsqueeze_27 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_5: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_35);  add_35 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_7: f32[1, 256, 16, 16] = torch.ops.aten.convolution.default(relu_5, primals_22, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_36: i64[] = torch.ops.aten.add.Tensor(primals_185, 1);  primals_185 = None
        var_mean_7 = torch.ops.aten.var_mean.correction(convolution_7, [0, 2, 3], correction = 0, keepdim = True)
        getitem_16: f32[1, 256, 1, 1] = var_mean_7[0]
        getitem_17: f32[1, 256, 1, 1] = var_mean_7[1];  var_mean_7 = None
        add_37: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_16, 1e-05)
        rsqrt_7: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_37);  add_37 = None
        sub_7: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_7, getitem_17)
        mul_49: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_7, rsqrt_7);  sub_7 = None
        squeeze_21: f32[256] = torch.ops.aten.squeeze.dims(getitem_17, [0, 2, 3]);  getitem_17 = None
        squeeze_22: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_7, [0, 2, 3]);  rsqrt_7 = None
        mul_50: f32[256] = torch.ops.aten.mul.Tensor(squeeze_21, 0.1)
        mul_51: f32[256] = torch.ops.aten.mul.Tensor(primals_183, 0.9);  primals_183 = None
        add_38: f32[256] = torch.ops.aten.add.Tensor(mul_50, mul_51);  mul_50 = mul_51 = None
        squeeze_23: f32[256] = torch.ops.aten.squeeze.dims(getitem_16, [0, 2, 3]);  getitem_16 = None
        mul_52: f32[256] = torch.ops.aten.mul.Tensor(squeeze_23, 1.003921568627451);  squeeze_23 = None
        mul_53: f32[256] = torch.ops.aten.mul.Tensor(mul_52, 0.1);  mul_52 = None
        mul_54: f32[256] = torch.ops.aten.mul.Tensor(primals_184, 0.9);  primals_184 = None
        add_39: f32[256] = torch.ops.aten.add.Tensor(mul_53, mul_54);  mul_53 = mul_54 = None
        unsqueeze_28: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_23, -1)
        unsqueeze_29: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_28, -1);  unsqueeze_28 = None
        mul_55: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(mul_49, unsqueeze_29);  mul_49 = unsqueeze_29 = None
        unsqueeze_30: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_24, -1);  primals_24 = None
        unsqueeze_31: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_30, -1);  unsqueeze_30 = None
        add_40: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(mul_55, unsqueeze_31);  mul_55 = unsqueeze_31 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_41: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(add_40, relu_3);  add_40 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_6: f32[1, 256, 16, 16] = torch.ops.aten.relu.default(add_41);  add_41 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_8: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_6, primals_25, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_42: i64[] = torch.ops.aten.add.Tensor(primals_188, 1);  primals_188 = None
        var_mean_8 = torch.ops.aten.var_mean.correction(convolution_8, [0, 2, 3], correction = 0, keepdim = True)
        getitem_18: f32[1, 64, 1, 1] = var_mean_8[0]
        getitem_19: f32[1, 64, 1, 1] = var_mean_8[1];  var_mean_8 = None
        add_43: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_18, 1e-05)
        rsqrt_8: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_43);  add_43 = None
        sub_8: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_8, getitem_19)
        mul_56: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_8, rsqrt_8);  sub_8 = None
        squeeze_24: f32[64] = torch.ops.aten.squeeze.dims(getitem_19, [0, 2, 3]);  getitem_19 = None
        squeeze_25: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_8, [0, 2, 3]);  rsqrt_8 = None
        mul_57: f32[64] = torch.ops.aten.mul.Tensor(squeeze_24, 0.1)
        mul_58: f32[64] = torch.ops.aten.mul.Tensor(primals_186, 0.9);  primals_186 = None
        add_44: f32[64] = torch.ops.aten.add.Tensor(mul_57, mul_58);  mul_57 = mul_58 = None
        squeeze_26: f32[64] = torch.ops.aten.squeeze.dims(getitem_18, [0, 2, 3]);  getitem_18 = None
        mul_59: f32[64] = torch.ops.aten.mul.Tensor(squeeze_26, 1.003921568627451);  squeeze_26 = None
        mul_60: f32[64] = torch.ops.aten.mul.Tensor(mul_59, 0.1);  mul_59 = None
        mul_61: f32[64] = torch.ops.aten.mul.Tensor(primals_187, 0.9);  primals_187 = None
        add_45: f32[64] = torch.ops.aten.add.Tensor(mul_60, mul_61);  mul_60 = mul_61 = None
        unsqueeze_32: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_26, -1)
        unsqueeze_33: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_32, -1);  unsqueeze_32 = None
        mul_62: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_56, unsqueeze_33);  mul_56 = unsqueeze_33 = None
        unsqueeze_34: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_27, -1);  primals_27 = None
        unsqueeze_35: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_34, -1);  unsqueeze_34 = None
        add_46: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_62, unsqueeze_35);  mul_62 = unsqueeze_35 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_7: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_46);  add_46 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_9: f32[1, 64, 16, 16] = torch.ops.aten.convolution.default(relu_7, primals_28, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_47: i64[] = torch.ops.aten.add.Tensor(primals_191, 1);  primals_191 = None
        var_mean_9 = torch.ops.aten.var_mean.correction(convolution_9, [0, 2, 3], correction = 0, keepdim = True)
        getitem_20: f32[1, 64, 1, 1] = var_mean_9[0]
        getitem_21: f32[1, 64, 1, 1] = var_mean_9[1];  var_mean_9 = None
        add_48: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_20, 1e-05)
        rsqrt_9: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_48);  add_48 = None
        sub_9: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_9, getitem_21)
        mul_63: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_9, rsqrt_9);  sub_9 = None
        squeeze_27: f32[64] = torch.ops.aten.squeeze.dims(getitem_21, [0, 2, 3]);  getitem_21 = None
        squeeze_28: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_9, [0, 2, 3]);  rsqrt_9 = None
        mul_64: f32[64] = torch.ops.aten.mul.Tensor(squeeze_27, 0.1)
        mul_65: f32[64] = torch.ops.aten.mul.Tensor(primals_189, 0.9);  primals_189 = None
        add_49: f32[64] = torch.ops.aten.add.Tensor(mul_64, mul_65);  mul_64 = mul_65 = None
        squeeze_29: f32[64] = torch.ops.aten.squeeze.dims(getitem_20, [0, 2, 3]);  getitem_20 = None
        mul_66: f32[64] = torch.ops.aten.mul.Tensor(squeeze_29, 1.003921568627451);  squeeze_29 = None
        mul_67: f32[64] = torch.ops.aten.mul.Tensor(mul_66, 0.1);  mul_66 = None
        mul_68: f32[64] = torch.ops.aten.mul.Tensor(primals_190, 0.9);  primals_190 = None
        add_50: f32[64] = torch.ops.aten.add.Tensor(mul_67, mul_68);  mul_67 = mul_68 = None
        unsqueeze_36: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_29, -1)
        unsqueeze_37: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_36, -1);  unsqueeze_36 = None
        mul_69: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(mul_63, unsqueeze_37);  mul_63 = unsqueeze_37 = None
        unsqueeze_38: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_30, -1);  primals_30 = None
        unsqueeze_39: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_38, -1);  unsqueeze_38 = None
        add_51: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(mul_69, unsqueeze_39);  mul_69 = unsqueeze_39 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_8: f32[1, 64, 16, 16] = torch.ops.aten.relu.default(add_51);  add_51 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_10: f32[1, 256, 16, 16] = torch.ops.aten.convolution.default(relu_8, primals_31, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_52: i64[] = torch.ops.aten.add.Tensor(primals_194, 1);  primals_194 = None
        var_mean_10 = torch.ops.aten.var_mean.correction(convolution_10, [0, 2, 3], correction = 0, keepdim = True)
        getitem_22: f32[1, 256, 1, 1] = var_mean_10[0]
        getitem_23: f32[1, 256, 1, 1] = var_mean_10[1];  var_mean_10 = None
        add_53: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_22, 1e-05)
        rsqrt_10: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_53);  add_53 = None
        sub_10: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_10, getitem_23)
        mul_70: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_10, rsqrt_10);  sub_10 = None
        squeeze_30: f32[256] = torch.ops.aten.squeeze.dims(getitem_23, [0, 2, 3]);  getitem_23 = None
        squeeze_31: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_10, [0, 2, 3]);  rsqrt_10 = None
        mul_71: f32[256] = torch.ops.aten.mul.Tensor(squeeze_30, 0.1)
        mul_72: f32[256] = torch.ops.aten.mul.Tensor(primals_192, 0.9);  primals_192 = None
        add_54: f32[256] = torch.ops.aten.add.Tensor(mul_71, mul_72);  mul_71 = mul_72 = None
        squeeze_32: f32[256] = torch.ops.aten.squeeze.dims(getitem_22, [0, 2, 3]);  getitem_22 = None
        mul_73: f32[256] = torch.ops.aten.mul.Tensor(squeeze_32, 1.003921568627451);  squeeze_32 = None
        mul_74: f32[256] = torch.ops.aten.mul.Tensor(mul_73, 0.1);  mul_73 = None
        mul_75: f32[256] = torch.ops.aten.mul.Tensor(primals_193, 0.9);  primals_193 = None
        add_55: f32[256] = torch.ops.aten.add.Tensor(mul_74, mul_75);  mul_74 = mul_75 = None
        unsqueeze_40: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_32, -1)
        unsqueeze_41: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_40, -1);  unsqueeze_40 = None
        mul_76: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(mul_70, unsqueeze_41);  mul_70 = unsqueeze_41 = None
        unsqueeze_42: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_33, -1);  primals_33 = None
        unsqueeze_43: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_42, -1);  unsqueeze_42 = None
        add_56: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(mul_76, unsqueeze_43);  mul_76 = unsqueeze_43 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_57: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(add_56, relu_6);  add_56 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_9: f32[1, 256, 16, 16] = torch.ops.aten.relu.default(add_57);  add_57 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_11: f32[1, 128, 16, 16] = torch.ops.aten.convolution.default(relu_9, primals_34, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_58: i64[] = torch.ops.aten.add.Tensor(primals_197, 1);  primals_197 = None
        var_mean_11 = torch.ops.aten.var_mean.correction(convolution_11, [0, 2, 3], correction = 0, keepdim = True)
        getitem_24: f32[1, 128, 1, 1] = var_mean_11[0]
        getitem_25: f32[1, 128, 1, 1] = var_mean_11[1];  var_mean_11 = None
        add_59: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_24, 1e-05)
        rsqrt_11: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_59);  add_59 = None
        sub_11: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(convolution_11, getitem_25)
        mul_77: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(sub_11, rsqrt_11);  sub_11 = None
        squeeze_33: f32[128] = torch.ops.aten.squeeze.dims(getitem_25, [0, 2, 3]);  getitem_25 = None
        squeeze_34: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_11, [0, 2, 3]);  rsqrt_11 = None
        mul_78: f32[128] = torch.ops.aten.mul.Tensor(squeeze_33, 0.1)
        mul_79: f32[128] = torch.ops.aten.mul.Tensor(primals_195, 0.9);  primals_195 = None
        add_60: f32[128] = torch.ops.aten.add.Tensor(mul_78, mul_79);  mul_78 = mul_79 = None
        squeeze_35: f32[128] = torch.ops.aten.squeeze.dims(getitem_24, [0, 2, 3]);  getitem_24 = None
        mul_80: f32[128] = torch.ops.aten.mul.Tensor(squeeze_35, 1.003921568627451);  squeeze_35 = None
        mul_81: f32[128] = torch.ops.aten.mul.Tensor(mul_80, 0.1);  mul_80 = None
        mul_82: f32[128] = torch.ops.aten.mul.Tensor(primals_196, 0.9);  primals_196 = None
        add_61: f32[128] = torch.ops.aten.add.Tensor(mul_81, mul_82);  mul_81 = mul_82 = None
        unsqueeze_44: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_35, -1)
        unsqueeze_45: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_44, -1);  unsqueeze_44 = None
        mul_83: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(mul_77, unsqueeze_45);  mul_77 = unsqueeze_45 = None
        unsqueeze_46: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_36, -1);  primals_36 = None
        unsqueeze_47: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_46, -1);  unsqueeze_46 = None
        add_62: f32[1, 128, 16, 16] = torch.ops.aten.add.Tensor(mul_83, unsqueeze_47);  mul_83 = unsqueeze_47 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_10: f32[1, 128, 16, 16] = torch.ops.aten.relu.default(add_62);  add_62 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_12: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_10, primals_37, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_63: i64[] = torch.ops.aten.add.Tensor(primals_200, 1);  primals_200 = None
        var_mean_12 = torch.ops.aten.var_mean.correction(convolution_12, [0, 2, 3], correction = 0, keepdim = True)
        getitem_26: f32[1, 128, 1, 1] = var_mean_12[0]
        getitem_27: f32[1, 128, 1, 1] = var_mean_12[1];  var_mean_12 = None
        add_64: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_26, 1e-05)
        rsqrt_12: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_64);  add_64 = None
        sub_12: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_12, getitem_27)
        mul_84: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_12, rsqrt_12);  sub_12 = None
        squeeze_36: f32[128] = torch.ops.aten.squeeze.dims(getitem_27, [0, 2, 3]);  getitem_27 = None
        squeeze_37: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_12, [0, 2, 3]);  rsqrt_12 = None
        mul_85: f32[128] = torch.ops.aten.mul.Tensor(squeeze_36, 0.1)
        mul_86: f32[128] = torch.ops.aten.mul.Tensor(primals_198, 0.9);  primals_198 = None
        add_65: f32[128] = torch.ops.aten.add.Tensor(mul_85, mul_86);  mul_85 = mul_86 = None
        squeeze_38: f32[128] = torch.ops.aten.squeeze.dims(getitem_26, [0, 2, 3]);  getitem_26 = None
        mul_87: f32[128] = torch.ops.aten.mul.Tensor(squeeze_38, 1.0158730158730158);  squeeze_38 = None
        mul_88: f32[128] = torch.ops.aten.mul.Tensor(mul_87, 0.1);  mul_87 = None
        mul_89: f32[128] = torch.ops.aten.mul.Tensor(primals_199, 0.9);  primals_199 = None
        add_66: f32[128] = torch.ops.aten.add.Tensor(mul_88, mul_89);  mul_88 = mul_89 = None
        unsqueeze_48: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_38, -1)
        unsqueeze_49: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_48, -1);  unsqueeze_48 = None
        mul_90: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_84, unsqueeze_49);  mul_84 = unsqueeze_49 = None
        unsqueeze_50: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_39, -1);  primals_39 = None
        unsqueeze_51: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_50, -1);  unsqueeze_50 = None
        add_67: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_90, unsqueeze_51);  mul_90 = unsqueeze_51 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_11: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_67);  add_67 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_13: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_11, primals_40, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_68: i64[] = torch.ops.aten.add.Tensor(primals_203, 1);  primals_203 = None
        var_mean_13 = torch.ops.aten.var_mean.correction(convolution_13, [0, 2, 3], correction = 0, keepdim = True)
        getitem_28: f32[1, 512, 1, 1] = var_mean_13[0]
        getitem_29: f32[1, 512, 1, 1] = var_mean_13[1];  var_mean_13 = None
        add_69: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_28, 1e-05)
        rsqrt_13: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_69);  add_69 = None
        sub_13: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_13, getitem_29)
        mul_91: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_13, rsqrt_13);  sub_13 = None
        squeeze_39: f32[512] = torch.ops.aten.squeeze.dims(getitem_29, [0, 2, 3]);  getitem_29 = None
        squeeze_40: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_13, [0, 2, 3]);  rsqrt_13 = None
        mul_92: f32[512] = torch.ops.aten.mul.Tensor(squeeze_39, 0.1)
        mul_93: f32[512] = torch.ops.aten.mul.Tensor(primals_201, 0.9);  primals_201 = None
        add_70: f32[512] = torch.ops.aten.add.Tensor(mul_92, mul_93);  mul_92 = mul_93 = None
        squeeze_41: f32[512] = torch.ops.aten.squeeze.dims(getitem_28, [0, 2, 3]);  getitem_28 = None
        mul_94: f32[512] = torch.ops.aten.mul.Tensor(squeeze_41, 1.0158730158730158);  squeeze_41 = None
        mul_95: f32[512] = torch.ops.aten.mul.Tensor(mul_94, 0.1);  mul_94 = None
        mul_96: f32[512] = torch.ops.aten.mul.Tensor(primals_202, 0.9);  primals_202 = None
        add_71: f32[512] = torch.ops.aten.add.Tensor(mul_95, mul_96);  mul_95 = mul_96 = None
        unsqueeze_52: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_41, -1)
        unsqueeze_53: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_52, -1);  unsqueeze_52 = None
        mul_97: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_91, unsqueeze_53);  mul_91 = unsqueeze_53 = None
        unsqueeze_54: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_42, -1);  primals_42 = None
        unsqueeze_55: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_54, -1);  unsqueeze_54 = None
        add_72: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_97, unsqueeze_55);  mul_97 = unsqueeze_55 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        convolution_14: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_9, primals_43, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
        add_73: i64[] = torch.ops.aten.add.Tensor(primals_206, 1);  primals_206 = None
        var_mean_14 = torch.ops.aten.var_mean.correction(convolution_14, [0, 2, 3], correction = 0, keepdim = True)
        getitem_30: f32[1, 512, 1, 1] = var_mean_14[0]
        getitem_31: f32[1, 512, 1, 1] = var_mean_14[1];  var_mean_14 = None
        add_74: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_30, 1e-05)
        rsqrt_14: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_74);  add_74 = None
        sub_14: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_14, getitem_31)
        mul_98: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_14, rsqrt_14);  sub_14 = None
        squeeze_42: f32[512] = torch.ops.aten.squeeze.dims(getitem_31, [0, 2, 3]);  getitem_31 = None
        squeeze_43: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_14, [0, 2, 3]);  rsqrt_14 = None
        mul_99: f32[512] = torch.ops.aten.mul.Tensor(squeeze_42, 0.1)
        mul_100: f32[512] = torch.ops.aten.mul.Tensor(primals_204, 0.9);  primals_204 = None
        add_75: f32[512] = torch.ops.aten.add.Tensor(mul_99, mul_100);  mul_99 = mul_100 = None
        squeeze_44: f32[512] = torch.ops.aten.squeeze.dims(getitem_30, [0, 2, 3]);  getitem_30 = None
        mul_101: f32[512] = torch.ops.aten.mul.Tensor(squeeze_44, 1.0158730158730158);  squeeze_44 = None
        mul_102: f32[512] = torch.ops.aten.mul.Tensor(mul_101, 0.1);  mul_101 = None
        mul_103: f32[512] = torch.ops.aten.mul.Tensor(primals_205, 0.9);  primals_205 = None
        add_76: f32[512] = torch.ops.aten.add.Tensor(mul_102, mul_103);  mul_102 = mul_103 = None
        unsqueeze_56: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_44, -1)
        unsqueeze_57: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_56, -1);  unsqueeze_56 = None
        mul_104: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_98, unsqueeze_57);  mul_98 = unsqueeze_57 = None
        unsqueeze_58: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_45, -1);  primals_45 = None
        unsqueeze_59: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_58, -1);  unsqueeze_58 = None
        add_77: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_104, unsqueeze_59);  mul_104 = unsqueeze_59 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_78: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(add_72, add_77);  add_72 = add_77 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_12: f32[1, 512, 8, 8] = torch.ops.aten.relu.default(add_78);  add_78 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_15: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_12, primals_46, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_79: i64[] = torch.ops.aten.add.Tensor(primals_209, 1);  primals_209 = None
        var_mean_15 = torch.ops.aten.var_mean.correction(convolution_15, [0, 2, 3], correction = 0, keepdim = True)
        getitem_32: f32[1, 128, 1, 1] = var_mean_15[0]
        getitem_33: f32[1, 128, 1, 1] = var_mean_15[1];  var_mean_15 = None
        add_80: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_32, 1e-05)
        rsqrt_15: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_80);  add_80 = None
        sub_15: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_15, getitem_33)
        mul_105: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_15, rsqrt_15);  sub_15 = None
        squeeze_45: f32[128] = torch.ops.aten.squeeze.dims(getitem_33, [0, 2, 3]);  getitem_33 = None
        squeeze_46: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_15, [0, 2, 3]);  rsqrt_15 = None
        mul_106: f32[128] = torch.ops.aten.mul.Tensor(squeeze_45, 0.1)
        mul_107: f32[128] = torch.ops.aten.mul.Tensor(primals_207, 0.9);  primals_207 = None
        add_81: f32[128] = torch.ops.aten.add.Tensor(mul_106, mul_107);  mul_106 = mul_107 = None
        squeeze_47: f32[128] = torch.ops.aten.squeeze.dims(getitem_32, [0, 2, 3]);  getitem_32 = None
        mul_108: f32[128] = torch.ops.aten.mul.Tensor(squeeze_47, 1.0158730158730158);  squeeze_47 = None
        mul_109: f32[128] = torch.ops.aten.mul.Tensor(mul_108, 0.1);  mul_108 = None
        mul_110: f32[128] = torch.ops.aten.mul.Tensor(primals_208, 0.9);  primals_208 = None
        add_82: f32[128] = torch.ops.aten.add.Tensor(mul_109, mul_110);  mul_109 = mul_110 = None
        unsqueeze_60: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_47, -1)
        unsqueeze_61: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_60, -1);  unsqueeze_60 = None
        mul_111: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_105, unsqueeze_61);  mul_105 = unsqueeze_61 = None
        unsqueeze_62: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_48, -1);  primals_48 = None
        unsqueeze_63: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_62, -1);  unsqueeze_62 = None
        add_83: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_111, unsqueeze_63);  mul_111 = unsqueeze_63 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_13: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_83);  add_83 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_16: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_13, primals_49, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_84: i64[] = torch.ops.aten.add.Tensor(primals_212, 1);  primals_212 = None
        var_mean_16 = torch.ops.aten.var_mean.correction(convolution_16, [0, 2, 3], correction = 0, keepdim = True)
        getitem_34: f32[1, 128, 1, 1] = var_mean_16[0]
        getitem_35: f32[1, 128, 1, 1] = var_mean_16[1];  var_mean_16 = None
        add_85: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_34, 1e-05)
        rsqrt_16: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_85);  add_85 = None
        sub_16: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_16, getitem_35)
        mul_112: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_16, rsqrt_16);  sub_16 = None
        squeeze_48: f32[128] = torch.ops.aten.squeeze.dims(getitem_35, [0, 2, 3]);  getitem_35 = None
        squeeze_49: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_16, [0, 2, 3]);  rsqrt_16 = None
        mul_113: f32[128] = torch.ops.aten.mul.Tensor(squeeze_48, 0.1)
        mul_114: f32[128] = torch.ops.aten.mul.Tensor(primals_210, 0.9);  primals_210 = None
        add_86: f32[128] = torch.ops.aten.add.Tensor(mul_113, mul_114);  mul_113 = mul_114 = None
        squeeze_50: f32[128] = torch.ops.aten.squeeze.dims(getitem_34, [0, 2, 3]);  getitem_34 = None
        mul_115: f32[128] = torch.ops.aten.mul.Tensor(squeeze_50, 1.0158730158730158);  squeeze_50 = None
        mul_116: f32[128] = torch.ops.aten.mul.Tensor(mul_115, 0.1);  mul_115 = None
        mul_117: f32[128] = torch.ops.aten.mul.Tensor(primals_211, 0.9);  primals_211 = None
        add_87: f32[128] = torch.ops.aten.add.Tensor(mul_116, mul_117);  mul_116 = mul_117 = None
        unsqueeze_64: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_50, -1)
        unsqueeze_65: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_64, -1);  unsqueeze_64 = None
        mul_118: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_112, unsqueeze_65);  mul_112 = unsqueeze_65 = None
        unsqueeze_66: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_51, -1);  primals_51 = None
        unsqueeze_67: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_66, -1);  unsqueeze_66 = None
        add_88: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_118, unsqueeze_67);  mul_118 = unsqueeze_67 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_14: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_88);  add_88 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_17: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_14, primals_52, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_89: i64[] = torch.ops.aten.add.Tensor(primals_215, 1);  primals_215 = None
        var_mean_17 = torch.ops.aten.var_mean.correction(convolution_17, [0, 2, 3], correction = 0, keepdim = True)
        getitem_36: f32[1, 512, 1, 1] = var_mean_17[0]
        getitem_37: f32[1, 512, 1, 1] = var_mean_17[1];  var_mean_17 = None
        add_90: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_36, 1e-05)
        rsqrt_17: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_90);  add_90 = None
        sub_17: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_17, getitem_37)
        mul_119: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_17, rsqrt_17);  sub_17 = None
        squeeze_51: f32[512] = torch.ops.aten.squeeze.dims(getitem_37, [0, 2, 3]);  getitem_37 = None
        squeeze_52: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_17, [0, 2, 3]);  rsqrt_17 = None
        mul_120: f32[512] = torch.ops.aten.mul.Tensor(squeeze_51, 0.1)
        mul_121: f32[512] = torch.ops.aten.mul.Tensor(primals_213, 0.9);  primals_213 = None
        add_91: f32[512] = torch.ops.aten.add.Tensor(mul_120, mul_121);  mul_120 = mul_121 = None
        squeeze_53: f32[512] = torch.ops.aten.squeeze.dims(getitem_36, [0, 2, 3]);  getitem_36 = None
        mul_122: f32[512] = torch.ops.aten.mul.Tensor(squeeze_53, 1.0158730158730158);  squeeze_53 = None
        mul_123: f32[512] = torch.ops.aten.mul.Tensor(mul_122, 0.1);  mul_122 = None
        mul_124: f32[512] = torch.ops.aten.mul.Tensor(primals_214, 0.9);  primals_214 = None
        add_92: f32[512] = torch.ops.aten.add.Tensor(mul_123, mul_124);  mul_123 = mul_124 = None
        unsqueeze_68: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_53, -1)
        unsqueeze_69: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_68, -1);  unsqueeze_68 = None
        mul_125: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_119, unsqueeze_69);  mul_119 = unsqueeze_69 = None
        unsqueeze_70: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_54, -1);  primals_54 = None
        unsqueeze_71: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_70, -1);  unsqueeze_70 = None
        add_93: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_125, unsqueeze_71);  mul_125 = unsqueeze_71 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_94: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(add_93, relu_12);  add_93 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_15: f32[1, 512, 8, 8] = torch.ops.aten.relu.default(add_94);  add_94 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_18: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_15, primals_55, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_95: i64[] = torch.ops.aten.add.Tensor(primals_218, 1);  primals_218 = None
        var_mean_18 = torch.ops.aten.var_mean.correction(convolution_18, [0, 2, 3], correction = 0, keepdim = True)
        getitem_38: f32[1, 128, 1, 1] = var_mean_18[0]
        getitem_39: f32[1, 128, 1, 1] = var_mean_18[1];  var_mean_18 = None
        add_96: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_38, 1e-05)
        rsqrt_18: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_96);  add_96 = None
        sub_18: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_18, getitem_39)
        mul_126: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_18, rsqrt_18);  sub_18 = None
        squeeze_54: f32[128] = torch.ops.aten.squeeze.dims(getitem_39, [0, 2, 3]);  getitem_39 = None
        squeeze_55: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_18, [0, 2, 3]);  rsqrt_18 = None
        mul_127: f32[128] = torch.ops.aten.mul.Tensor(squeeze_54, 0.1)
        mul_128: f32[128] = torch.ops.aten.mul.Tensor(primals_216, 0.9);  primals_216 = None
        add_97: f32[128] = torch.ops.aten.add.Tensor(mul_127, mul_128);  mul_127 = mul_128 = None
        squeeze_56: f32[128] = torch.ops.aten.squeeze.dims(getitem_38, [0, 2, 3]);  getitem_38 = None
        mul_129: f32[128] = torch.ops.aten.mul.Tensor(squeeze_56, 1.0158730158730158);  squeeze_56 = None
        mul_130: f32[128] = torch.ops.aten.mul.Tensor(mul_129, 0.1);  mul_129 = None
        mul_131: f32[128] = torch.ops.aten.mul.Tensor(primals_217, 0.9);  primals_217 = None
        add_98: f32[128] = torch.ops.aten.add.Tensor(mul_130, mul_131);  mul_130 = mul_131 = None
        unsqueeze_72: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_56, -1)
        unsqueeze_73: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_72, -1);  unsqueeze_72 = None
        mul_132: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_126, unsqueeze_73);  mul_126 = unsqueeze_73 = None
        unsqueeze_74: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_57, -1);  primals_57 = None
        unsqueeze_75: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_74, -1);  unsqueeze_74 = None
        add_99: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_132, unsqueeze_75);  mul_132 = unsqueeze_75 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_16: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_99);  add_99 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_19: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_16, primals_58, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_100: i64[] = torch.ops.aten.add.Tensor(primals_221, 1);  primals_221 = None
        var_mean_19 = torch.ops.aten.var_mean.correction(convolution_19, [0, 2, 3], correction = 0, keepdim = True)
        getitem_40: f32[1, 128, 1, 1] = var_mean_19[0]
        getitem_41: f32[1, 128, 1, 1] = var_mean_19[1];  var_mean_19 = None
        add_101: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_40, 1e-05)
        rsqrt_19: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_101);  add_101 = None
        sub_19: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_19, getitem_41)
        mul_133: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_19, rsqrt_19);  sub_19 = None
        squeeze_57: f32[128] = torch.ops.aten.squeeze.dims(getitem_41, [0, 2, 3]);  getitem_41 = None
        squeeze_58: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_19, [0, 2, 3]);  rsqrt_19 = None
        mul_134: f32[128] = torch.ops.aten.mul.Tensor(squeeze_57, 0.1)
        mul_135: f32[128] = torch.ops.aten.mul.Tensor(primals_219, 0.9);  primals_219 = None
        add_102: f32[128] = torch.ops.aten.add.Tensor(mul_134, mul_135);  mul_134 = mul_135 = None
        squeeze_59: f32[128] = torch.ops.aten.squeeze.dims(getitem_40, [0, 2, 3]);  getitem_40 = None
        mul_136: f32[128] = torch.ops.aten.mul.Tensor(squeeze_59, 1.0158730158730158);  squeeze_59 = None
        mul_137: f32[128] = torch.ops.aten.mul.Tensor(mul_136, 0.1);  mul_136 = None
        mul_138: f32[128] = torch.ops.aten.mul.Tensor(primals_220, 0.9);  primals_220 = None
        add_103: f32[128] = torch.ops.aten.add.Tensor(mul_137, mul_138);  mul_137 = mul_138 = None
        unsqueeze_76: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_59, -1)
        unsqueeze_77: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_76, -1);  unsqueeze_76 = None
        mul_139: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_133, unsqueeze_77);  mul_133 = unsqueeze_77 = None
        unsqueeze_78: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_60, -1);  primals_60 = None
        unsqueeze_79: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_78, -1);  unsqueeze_78 = None
        add_104: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_139, unsqueeze_79);  mul_139 = unsqueeze_79 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_17: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_104);  add_104 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_20: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_17, primals_61, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_105: i64[] = torch.ops.aten.add.Tensor(primals_224, 1);  primals_224 = None
        var_mean_20 = torch.ops.aten.var_mean.correction(convolution_20, [0, 2, 3], correction = 0, keepdim = True)
        getitem_42: f32[1, 512, 1, 1] = var_mean_20[0]
        getitem_43: f32[1, 512, 1, 1] = var_mean_20[1];  var_mean_20 = None
        add_106: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_42, 1e-05)
        rsqrt_20: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_106);  add_106 = None
        sub_20: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_20, getitem_43)
        mul_140: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_20, rsqrt_20);  sub_20 = None
        squeeze_60: f32[512] = torch.ops.aten.squeeze.dims(getitem_43, [0, 2, 3]);  getitem_43 = None
        squeeze_61: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_20, [0, 2, 3]);  rsqrt_20 = None
        mul_141: f32[512] = torch.ops.aten.mul.Tensor(squeeze_60, 0.1)
        mul_142: f32[512] = torch.ops.aten.mul.Tensor(primals_222, 0.9);  primals_222 = None
        add_107: f32[512] = torch.ops.aten.add.Tensor(mul_141, mul_142);  mul_141 = mul_142 = None
        squeeze_62: f32[512] = torch.ops.aten.squeeze.dims(getitem_42, [0, 2, 3]);  getitem_42 = None
        mul_143: f32[512] = torch.ops.aten.mul.Tensor(squeeze_62, 1.0158730158730158);  squeeze_62 = None
        mul_144: f32[512] = torch.ops.aten.mul.Tensor(mul_143, 0.1);  mul_143 = None
        mul_145: f32[512] = torch.ops.aten.mul.Tensor(primals_223, 0.9);  primals_223 = None
        add_108: f32[512] = torch.ops.aten.add.Tensor(mul_144, mul_145);  mul_144 = mul_145 = None
        unsqueeze_80: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_62, -1)
        unsqueeze_81: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_80, -1);  unsqueeze_80 = None
        mul_146: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_140, unsqueeze_81);  mul_140 = unsqueeze_81 = None
        unsqueeze_82: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_63, -1);  primals_63 = None
        unsqueeze_83: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_82, -1);  unsqueeze_82 = None
        add_109: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_146, unsqueeze_83);  mul_146 = unsqueeze_83 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_110: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(add_109, relu_15);  add_109 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_18: f32[1, 512, 8, 8] = torch.ops.aten.relu.default(add_110);  add_110 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_21: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_18, primals_64, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_111: i64[] = torch.ops.aten.add.Tensor(primals_227, 1);  primals_227 = None
        var_mean_21 = torch.ops.aten.var_mean.correction(convolution_21, [0, 2, 3], correction = 0, keepdim = True)
        getitem_44: f32[1, 128, 1, 1] = var_mean_21[0]
        getitem_45: f32[1, 128, 1, 1] = var_mean_21[1];  var_mean_21 = None
        add_112: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_44, 1e-05)
        rsqrt_21: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_112);  add_112 = None
        sub_21: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_21, getitem_45)
        mul_147: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_21, rsqrt_21);  sub_21 = None
        squeeze_63: f32[128] = torch.ops.aten.squeeze.dims(getitem_45, [0, 2, 3]);  getitem_45 = None
        squeeze_64: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_21, [0, 2, 3]);  rsqrt_21 = None
        mul_148: f32[128] = torch.ops.aten.mul.Tensor(squeeze_63, 0.1)
        mul_149: f32[128] = torch.ops.aten.mul.Tensor(primals_225, 0.9);  primals_225 = None
        add_113: f32[128] = torch.ops.aten.add.Tensor(mul_148, mul_149);  mul_148 = mul_149 = None
        squeeze_65: f32[128] = torch.ops.aten.squeeze.dims(getitem_44, [0, 2, 3]);  getitem_44 = None
        mul_150: f32[128] = torch.ops.aten.mul.Tensor(squeeze_65, 1.0158730158730158);  squeeze_65 = None
        mul_151: f32[128] = torch.ops.aten.mul.Tensor(mul_150, 0.1);  mul_150 = None
        mul_152: f32[128] = torch.ops.aten.mul.Tensor(primals_226, 0.9);  primals_226 = None
        add_114: f32[128] = torch.ops.aten.add.Tensor(mul_151, mul_152);  mul_151 = mul_152 = None
        unsqueeze_84: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_65, -1)
        unsqueeze_85: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_84, -1);  unsqueeze_84 = None
        mul_153: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_147, unsqueeze_85);  mul_147 = unsqueeze_85 = None
        unsqueeze_86: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_66, -1);  primals_66 = None
        unsqueeze_87: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_86, -1);  unsqueeze_86 = None
        add_115: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_153, unsqueeze_87);  mul_153 = unsqueeze_87 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_19: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_115);  add_115 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_22: f32[1, 128, 8, 8] = torch.ops.aten.convolution.default(relu_19, primals_67, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_116: i64[] = torch.ops.aten.add.Tensor(primals_230, 1);  primals_230 = None
        var_mean_22 = torch.ops.aten.var_mean.correction(convolution_22, [0, 2, 3], correction = 0, keepdim = True)
        getitem_46: f32[1, 128, 1, 1] = var_mean_22[0]
        getitem_47: f32[1, 128, 1, 1] = var_mean_22[1];  var_mean_22 = None
        add_117: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_46, 1e-05)
        rsqrt_22: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_117);  add_117 = None
        sub_22: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_22, getitem_47)
        mul_154: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_22, rsqrt_22);  sub_22 = None
        squeeze_66: f32[128] = torch.ops.aten.squeeze.dims(getitem_47, [0, 2, 3]);  getitem_47 = None
        squeeze_67: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_22, [0, 2, 3]);  rsqrt_22 = None
        mul_155: f32[128] = torch.ops.aten.mul.Tensor(squeeze_66, 0.1)
        mul_156: f32[128] = torch.ops.aten.mul.Tensor(primals_228, 0.9);  primals_228 = None
        add_118: f32[128] = torch.ops.aten.add.Tensor(mul_155, mul_156);  mul_155 = mul_156 = None
        squeeze_68: f32[128] = torch.ops.aten.squeeze.dims(getitem_46, [0, 2, 3]);  getitem_46 = None
        mul_157: f32[128] = torch.ops.aten.mul.Tensor(squeeze_68, 1.0158730158730158);  squeeze_68 = None
        mul_158: f32[128] = torch.ops.aten.mul.Tensor(mul_157, 0.1);  mul_157 = None
        mul_159: f32[128] = torch.ops.aten.mul.Tensor(primals_229, 0.9);  primals_229 = None
        add_119: f32[128] = torch.ops.aten.add.Tensor(mul_158, mul_159);  mul_158 = mul_159 = None
        unsqueeze_88: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_68, -1)
        unsqueeze_89: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_88, -1);  unsqueeze_88 = None
        mul_160: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(mul_154, unsqueeze_89);  mul_154 = unsqueeze_89 = None
        unsqueeze_90: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_69, -1);  primals_69 = None
        unsqueeze_91: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_90, -1);  unsqueeze_90 = None
        add_120: f32[1, 128, 8, 8] = torch.ops.aten.add.Tensor(mul_160, unsqueeze_91);  mul_160 = unsqueeze_91 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_20: f32[1, 128, 8, 8] = torch.ops.aten.relu.default(add_120);  add_120 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_23: f32[1, 512, 8, 8] = torch.ops.aten.convolution.default(relu_20, primals_70, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_121: i64[] = torch.ops.aten.add.Tensor(primals_233, 1);  primals_233 = None
        var_mean_23 = torch.ops.aten.var_mean.correction(convolution_23, [0, 2, 3], correction = 0, keepdim = True)
        getitem_48: f32[1, 512, 1, 1] = var_mean_23[0]
        getitem_49: f32[1, 512, 1, 1] = var_mean_23[1];  var_mean_23 = None
        add_122: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_48, 1e-05)
        rsqrt_23: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_122);  add_122 = None
        sub_23: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_23, getitem_49)
        mul_161: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_23, rsqrt_23);  sub_23 = None
        squeeze_69: f32[512] = torch.ops.aten.squeeze.dims(getitem_49, [0, 2, 3]);  getitem_49 = None
        squeeze_70: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_23, [0, 2, 3]);  rsqrt_23 = None
        mul_162: f32[512] = torch.ops.aten.mul.Tensor(squeeze_69, 0.1)
        mul_163: f32[512] = torch.ops.aten.mul.Tensor(primals_231, 0.9);  primals_231 = None
        add_123: f32[512] = torch.ops.aten.add.Tensor(mul_162, mul_163);  mul_162 = mul_163 = None
        squeeze_71: f32[512] = torch.ops.aten.squeeze.dims(getitem_48, [0, 2, 3]);  getitem_48 = None
        mul_164: f32[512] = torch.ops.aten.mul.Tensor(squeeze_71, 1.0158730158730158);  squeeze_71 = None
        mul_165: f32[512] = torch.ops.aten.mul.Tensor(mul_164, 0.1);  mul_164 = None
        mul_166: f32[512] = torch.ops.aten.mul.Tensor(primals_232, 0.9);  primals_232 = None
        add_124: f32[512] = torch.ops.aten.add.Tensor(mul_165, mul_166);  mul_165 = mul_166 = None
        unsqueeze_92: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_71, -1)
        unsqueeze_93: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_92, -1);  unsqueeze_92 = None
        mul_167: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(mul_161, unsqueeze_93);  mul_161 = unsqueeze_93 = None
        unsqueeze_94: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_72, -1);  primals_72 = None
        unsqueeze_95: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_94, -1);  unsqueeze_94 = None
        add_125: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(mul_167, unsqueeze_95);  mul_167 = unsqueeze_95 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_126: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(add_125, relu_18);  add_125 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_21: f32[1, 512, 8, 8] = torch.ops.aten.relu.default(add_126);  add_126 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_24: f32[1, 256, 8, 8] = torch.ops.aten.convolution.default(relu_21, primals_73, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_127: i64[] = torch.ops.aten.add.Tensor(primals_236, 1);  primals_236 = None
        var_mean_24 = torch.ops.aten.var_mean.correction(convolution_24, [0, 2, 3], correction = 0, keepdim = True)
        getitem_50: f32[1, 256, 1, 1] = var_mean_24[0]
        getitem_51: f32[1, 256, 1, 1] = var_mean_24[1];  var_mean_24 = None
        add_128: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_50, 1e-05)
        rsqrt_24: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_128);  add_128 = None
        sub_24: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(convolution_24, getitem_51)
        mul_168: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(sub_24, rsqrt_24);  sub_24 = None
        squeeze_72: f32[256] = torch.ops.aten.squeeze.dims(getitem_51, [0, 2, 3]);  getitem_51 = None
        squeeze_73: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_24, [0, 2, 3]);  rsqrt_24 = None
        mul_169: f32[256] = torch.ops.aten.mul.Tensor(squeeze_72, 0.1)
        mul_170: f32[256] = torch.ops.aten.mul.Tensor(primals_234, 0.9);  primals_234 = None
        add_129: f32[256] = torch.ops.aten.add.Tensor(mul_169, mul_170);  mul_169 = mul_170 = None
        squeeze_74: f32[256] = torch.ops.aten.squeeze.dims(getitem_50, [0, 2, 3]);  getitem_50 = None
        mul_171: f32[256] = torch.ops.aten.mul.Tensor(squeeze_74, 1.0158730158730158);  squeeze_74 = None
        mul_172: f32[256] = torch.ops.aten.mul.Tensor(mul_171, 0.1);  mul_171 = None
        mul_173: f32[256] = torch.ops.aten.mul.Tensor(primals_235, 0.9);  primals_235 = None
        add_130: f32[256] = torch.ops.aten.add.Tensor(mul_172, mul_173);  mul_172 = mul_173 = None
        unsqueeze_96: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_74, -1)
        unsqueeze_97: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_96, -1);  unsqueeze_96 = None
        mul_174: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(mul_168, unsqueeze_97);  mul_168 = unsqueeze_97 = None
        unsqueeze_98: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_75, -1);  primals_75 = None
        unsqueeze_99: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_98, -1);  unsqueeze_98 = None
        add_131: f32[1, 256, 8, 8] = torch.ops.aten.add.Tensor(mul_174, unsqueeze_99);  mul_174 = unsqueeze_99 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_22: f32[1, 256, 8, 8] = torch.ops.aten.relu.default(add_131);  add_131 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_25: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_22, primals_76, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_132: i64[] = torch.ops.aten.add.Tensor(primals_239, 1);  primals_239 = None
        var_mean_25 = torch.ops.aten.var_mean.correction(convolution_25, [0, 2, 3], correction = 0, keepdim = True)
        getitem_52: f32[1, 256, 1, 1] = var_mean_25[0]
        getitem_53: f32[1, 256, 1, 1] = var_mean_25[1];  var_mean_25 = None
        add_133: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_52, 1e-05)
        rsqrt_25: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_133);  add_133 = None
        sub_25: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_25, getitem_53)
        mul_175: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_25, rsqrt_25);  sub_25 = None
        squeeze_75: f32[256] = torch.ops.aten.squeeze.dims(getitem_53, [0, 2, 3]);  getitem_53 = None
        squeeze_76: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_25, [0, 2, 3]);  rsqrt_25 = None
        mul_176: f32[256] = torch.ops.aten.mul.Tensor(squeeze_75, 0.1)
        mul_177: f32[256] = torch.ops.aten.mul.Tensor(primals_237, 0.9);  primals_237 = None
        add_134: f32[256] = torch.ops.aten.add.Tensor(mul_176, mul_177);  mul_176 = mul_177 = None
        squeeze_77: f32[256] = torch.ops.aten.squeeze.dims(getitem_52, [0, 2, 3]);  getitem_52 = None
        mul_178: f32[256] = torch.ops.aten.mul.Tensor(squeeze_77, 1.0666666666666667);  squeeze_77 = None
        mul_179: f32[256] = torch.ops.aten.mul.Tensor(mul_178, 0.1);  mul_178 = None
        mul_180: f32[256] = torch.ops.aten.mul.Tensor(primals_238, 0.9);  primals_238 = None
        add_135: f32[256] = torch.ops.aten.add.Tensor(mul_179, mul_180);  mul_179 = mul_180 = None
        unsqueeze_100: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_77, -1)
        unsqueeze_101: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_100, -1);  unsqueeze_100 = None
        mul_181: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_175, unsqueeze_101);  mul_175 = unsqueeze_101 = None
        unsqueeze_102: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_78, -1);  primals_78 = None
        unsqueeze_103: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_102, -1);  unsqueeze_102 = None
        add_136: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_181, unsqueeze_103);  mul_181 = unsqueeze_103 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_23: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_136);  add_136 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_26: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_23, primals_79, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_137: i64[] = torch.ops.aten.add.Tensor(primals_242, 1);  primals_242 = None
        var_mean_26 = torch.ops.aten.var_mean.correction(convolution_26, [0, 2, 3], correction = 0, keepdim = True)
        getitem_54: f32[1, 1024, 1, 1] = var_mean_26[0]
        getitem_55: f32[1, 1024, 1, 1] = var_mean_26[1];  var_mean_26 = None
        add_138: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_54, 1e-05)
        rsqrt_26: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_138);  add_138 = None
        sub_26: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_26, getitem_55)
        mul_182: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_26, rsqrt_26);  sub_26 = None
        squeeze_78: f32[1024] = torch.ops.aten.squeeze.dims(getitem_55, [0, 2, 3]);  getitem_55 = None
        squeeze_79: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_26, [0, 2, 3]);  rsqrt_26 = None
        mul_183: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_78, 0.1)
        mul_184: f32[1024] = torch.ops.aten.mul.Tensor(primals_240, 0.9);  primals_240 = None
        add_139: f32[1024] = torch.ops.aten.add.Tensor(mul_183, mul_184);  mul_183 = mul_184 = None
        squeeze_80: f32[1024] = torch.ops.aten.squeeze.dims(getitem_54, [0, 2, 3]);  getitem_54 = None
        mul_185: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_80, 1.0666666666666667);  squeeze_80 = None
        mul_186: f32[1024] = torch.ops.aten.mul.Tensor(mul_185, 0.1);  mul_185 = None
        mul_187: f32[1024] = torch.ops.aten.mul.Tensor(primals_241, 0.9);  primals_241 = None
        add_140: f32[1024] = torch.ops.aten.add.Tensor(mul_186, mul_187);  mul_186 = mul_187 = None
        unsqueeze_104: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_80, -1)
        unsqueeze_105: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_104, -1);  unsqueeze_104 = None
        mul_188: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_182, unsqueeze_105);  mul_182 = unsqueeze_105 = None
        unsqueeze_106: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_81, -1);  primals_81 = None
        unsqueeze_107: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_106, -1);  unsqueeze_106 = None
        add_141: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_188, unsqueeze_107);  mul_188 = unsqueeze_107 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        convolution_27: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_21, primals_82, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
        add_142: i64[] = torch.ops.aten.add.Tensor(primals_245, 1);  primals_245 = None
        var_mean_27 = torch.ops.aten.var_mean.correction(convolution_27, [0, 2, 3], correction = 0, keepdim = True)
        getitem_56: f32[1, 1024, 1, 1] = var_mean_27[0]
        getitem_57: f32[1, 1024, 1, 1] = var_mean_27[1];  var_mean_27 = None
        add_143: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_56, 1e-05)
        rsqrt_27: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_143);  add_143 = None
        sub_27: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_27, getitem_57)
        mul_189: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_27, rsqrt_27);  sub_27 = None
        squeeze_81: f32[1024] = torch.ops.aten.squeeze.dims(getitem_57, [0, 2, 3]);  getitem_57 = None
        squeeze_82: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_27, [0, 2, 3]);  rsqrt_27 = None
        mul_190: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_81, 0.1)
        mul_191: f32[1024] = torch.ops.aten.mul.Tensor(primals_243, 0.9);  primals_243 = None
        add_144: f32[1024] = torch.ops.aten.add.Tensor(mul_190, mul_191);  mul_190 = mul_191 = None
        squeeze_83: f32[1024] = torch.ops.aten.squeeze.dims(getitem_56, [0, 2, 3]);  getitem_56 = None
        mul_192: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_83, 1.0666666666666667);  squeeze_83 = None
        mul_193: f32[1024] = torch.ops.aten.mul.Tensor(mul_192, 0.1);  mul_192 = None
        mul_194: f32[1024] = torch.ops.aten.mul.Tensor(primals_244, 0.9);  primals_244 = None
        add_145: f32[1024] = torch.ops.aten.add.Tensor(mul_193, mul_194);  mul_193 = mul_194 = None
        unsqueeze_108: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_83, -1)
        unsqueeze_109: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_108, -1);  unsqueeze_108 = None
        mul_195: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_189, unsqueeze_109);  mul_189 = unsqueeze_109 = None
        unsqueeze_110: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_84, -1);  primals_84 = None
        unsqueeze_111: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_110, -1);  unsqueeze_110 = None
        add_146: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_195, unsqueeze_111);  mul_195 = unsqueeze_111 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_147: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_141, add_146);  add_141 = add_146 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_24: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_147);  add_147 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_28: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_24, primals_85, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_148: i64[] = torch.ops.aten.add.Tensor(primals_248, 1);  primals_248 = None
        var_mean_28 = torch.ops.aten.var_mean.correction(convolution_28, [0, 2, 3], correction = 0, keepdim = True)
        getitem_58: f32[1, 256, 1, 1] = var_mean_28[0]
        getitem_59: f32[1, 256, 1, 1] = var_mean_28[1];  var_mean_28 = None
        add_149: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_58, 1e-05)
        rsqrt_28: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_149);  add_149 = None
        sub_28: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_28, getitem_59)
        mul_196: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_28, rsqrt_28);  sub_28 = None
        squeeze_84: f32[256] = torch.ops.aten.squeeze.dims(getitem_59, [0, 2, 3]);  getitem_59 = None
        squeeze_85: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_28, [0, 2, 3]);  rsqrt_28 = None
        mul_197: f32[256] = torch.ops.aten.mul.Tensor(squeeze_84, 0.1)
        mul_198: f32[256] = torch.ops.aten.mul.Tensor(primals_246, 0.9);  primals_246 = None
        add_150: f32[256] = torch.ops.aten.add.Tensor(mul_197, mul_198);  mul_197 = mul_198 = None
        squeeze_86: f32[256] = torch.ops.aten.squeeze.dims(getitem_58, [0, 2, 3]);  getitem_58 = None
        mul_199: f32[256] = torch.ops.aten.mul.Tensor(squeeze_86, 1.0666666666666667);  squeeze_86 = None
        mul_200: f32[256] = torch.ops.aten.mul.Tensor(mul_199, 0.1);  mul_199 = None
        mul_201: f32[256] = torch.ops.aten.mul.Tensor(primals_247, 0.9);  primals_247 = None
        add_151: f32[256] = torch.ops.aten.add.Tensor(mul_200, mul_201);  mul_200 = mul_201 = None
        unsqueeze_112: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_86, -1)
        unsqueeze_113: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_112, -1);  unsqueeze_112 = None
        mul_202: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_196, unsqueeze_113);  mul_196 = unsqueeze_113 = None
        unsqueeze_114: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_87, -1);  primals_87 = None
        unsqueeze_115: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_114, -1);  unsqueeze_114 = None
        add_152: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_202, unsqueeze_115);  mul_202 = unsqueeze_115 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_25: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_152);  add_152 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_29: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_25, primals_88, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_153: i64[] = torch.ops.aten.add.Tensor(primals_251, 1);  primals_251 = None
        var_mean_29 = torch.ops.aten.var_mean.correction(convolution_29, [0, 2, 3], correction = 0, keepdim = True)
        getitem_60: f32[1, 256, 1, 1] = var_mean_29[0]
        getitem_61: f32[1, 256, 1, 1] = var_mean_29[1];  var_mean_29 = None
        add_154: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_60, 1e-05)
        rsqrt_29: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_154);  add_154 = None
        sub_29: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_29, getitem_61)
        mul_203: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_29, rsqrt_29);  sub_29 = None
        squeeze_87: f32[256] = torch.ops.aten.squeeze.dims(getitem_61, [0, 2, 3]);  getitem_61 = None
        squeeze_88: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_29, [0, 2, 3]);  rsqrt_29 = None
        mul_204: f32[256] = torch.ops.aten.mul.Tensor(squeeze_87, 0.1)
        mul_205: f32[256] = torch.ops.aten.mul.Tensor(primals_249, 0.9);  primals_249 = None
        add_155: f32[256] = torch.ops.aten.add.Tensor(mul_204, mul_205);  mul_204 = mul_205 = None
        squeeze_89: f32[256] = torch.ops.aten.squeeze.dims(getitem_60, [0, 2, 3]);  getitem_60 = None
        mul_206: f32[256] = torch.ops.aten.mul.Tensor(squeeze_89, 1.0666666666666667);  squeeze_89 = None
        mul_207: f32[256] = torch.ops.aten.mul.Tensor(mul_206, 0.1);  mul_206 = None
        mul_208: f32[256] = torch.ops.aten.mul.Tensor(primals_250, 0.9);  primals_250 = None
        add_156: f32[256] = torch.ops.aten.add.Tensor(mul_207, mul_208);  mul_207 = mul_208 = None
        unsqueeze_116: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_89, -1)
        unsqueeze_117: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_116, -1);  unsqueeze_116 = None
        mul_209: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_203, unsqueeze_117);  mul_203 = unsqueeze_117 = None
        unsqueeze_118: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_90, -1);  primals_90 = None
        unsqueeze_119: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_118, -1);  unsqueeze_118 = None
        add_157: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_209, unsqueeze_119);  mul_209 = unsqueeze_119 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_26: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_157);  add_157 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_30: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_26, primals_91, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_158: i64[] = torch.ops.aten.add.Tensor(primals_254, 1);  primals_254 = None
        var_mean_30 = torch.ops.aten.var_mean.correction(convolution_30, [0, 2, 3], correction = 0, keepdim = True)
        getitem_62: f32[1, 1024, 1, 1] = var_mean_30[0]
        getitem_63: f32[1, 1024, 1, 1] = var_mean_30[1];  var_mean_30 = None
        add_159: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_62, 1e-05)
        rsqrt_30: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_159);  add_159 = None
        sub_30: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_30, getitem_63)
        mul_210: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_30, rsqrt_30);  sub_30 = None
        squeeze_90: f32[1024] = torch.ops.aten.squeeze.dims(getitem_63, [0, 2, 3]);  getitem_63 = None
        squeeze_91: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_30, [0, 2, 3]);  rsqrt_30 = None
        mul_211: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_90, 0.1)
        mul_212: f32[1024] = torch.ops.aten.mul.Tensor(primals_252, 0.9);  primals_252 = None
        add_160: f32[1024] = torch.ops.aten.add.Tensor(mul_211, mul_212);  mul_211 = mul_212 = None
        squeeze_92: f32[1024] = torch.ops.aten.squeeze.dims(getitem_62, [0, 2, 3]);  getitem_62 = None
        mul_213: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_92, 1.0666666666666667);  squeeze_92 = None
        mul_214: f32[1024] = torch.ops.aten.mul.Tensor(mul_213, 0.1);  mul_213 = None
        mul_215: f32[1024] = torch.ops.aten.mul.Tensor(primals_253, 0.9);  primals_253 = None
        add_161: f32[1024] = torch.ops.aten.add.Tensor(mul_214, mul_215);  mul_214 = mul_215 = None
        unsqueeze_120: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_92, -1)
        unsqueeze_121: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_120, -1);  unsqueeze_120 = None
        mul_216: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_210, unsqueeze_121);  mul_210 = unsqueeze_121 = None
        unsqueeze_122: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_93, -1);  primals_93 = None
        unsqueeze_123: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_122, -1);  unsqueeze_122 = None
        add_162: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_216, unsqueeze_123);  mul_216 = unsqueeze_123 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_163: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_162, relu_24);  add_162 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_27: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_163);  add_163 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_31: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_27, primals_94, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_164: i64[] = torch.ops.aten.add.Tensor(primals_257, 1);  primals_257 = None
        var_mean_31 = torch.ops.aten.var_mean.correction(convolution_31, [0, 2, 3], correction = 0, keepdim = True)
        getitem_64: f32[1, 256, 1, 1] = var_mean_31[0]
        getitem_65: f32[1, 256, 1, 1] = var_mean_31[1];  var_mean_31 = None
        add_165: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_64, 1e-05)
        rsqrt_31: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_165);  add_165 = None
        sub_31: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_31, getitem_65)
        mul_217: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_31, rsqrt_31);  sub_31 = None
        squeeze_93: f32[256] = torch.ops.aten.squeeze.dims(getitem_65, [0, 2, 3]);  getitem_65 = None
        squeeze_94: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_31, [0, 2, 3]);  rsqrt_31 = None
        mul_218: f32[256] = torch.ops.aten.mul.Tensor(squeeze_93, 0.1)
        mul_219: f32[256] = torch.ops.aten.mul.Tensor(primals_255, 0.9);  primals_255 = None
        add_166: f32[256] = torch.ops.aten.add.Tensor(mul_218, mul_219);  mul_218 = mul_219 = None
        squeeze_95: f32[256] = torch.ops.aten.squeeze.dims(getitem_64, [0, 2, 3]);  getitem_64 = None
        mul_220: f32[256] = torch.ops.aten.mul.Tensor(squeeze_95, 1.0666666666666667);  squeeze_95 = None
        mul_221: f32[256] = torch.ops.aten.mul.Tensor(mul_220, 0.1);  mul_220 = None
        mul_222: f32[256] = torch.ops.aten.mul.Tensor(primals_256, 0.9);  primals_256 = None
        add_167: f32[256] = torch.ops.aten.add.Tensor(mul_221, mul_222);  mul_221 = mul_222 = None
        unsqueeze_124: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_95, -1)
        unsqueeze_125: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_124, -1);  unsqueeze_124 = None
        mul_223: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_217, unsqueeze_125);  mul_217 = unsqueeze_125 = None
        unsqueeze_126: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_96, -1);  primals_96 = None
        unsqueeze_127: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_126, -1);  unsqueeze_126 = None
        add_168: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_223, unsqueeze_127);  mul_223 = unsqueeze_127 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_28: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_168);  add_168 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_32: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_28, primals_97, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_169: i64[] = torch.ops.aten.add.Tensor(primals_260, 1);  primals_260 = None
        var_mean_32 = torch.ops.aten.var_mean.correction(convolution_32, [0, 2, 3], correction = 0, keepdim = True)
        getitem_66: f32[1, 256, 1, 1] = var_mean_32[0]
        getitem_67: f32[1, 256, 1, 1] = var_mean_32[1];  var_mean_32 = None
        add_170: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_66, 1e-05)
        rsqrt_32: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_170);  add_170 = None
        sub_32: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_32, getitem_67)
        mul_224: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_32, rsqrt_32);  sub_32 = None
        squeeze_96: f32[256] = torch.ops.aten.squeeze.dims(getitem_67, [0, 2, 3]);  getitem_67 = None
        squeeze_97: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_32, [0, 2, 3]);  rsqrt_32 = None
        mul_225: f32[256] = torch.ops.aten.mul.Tensor(squeeze_96, 0.1)
        mul_226: f32[256] = torch.ops.aten.mul.Tensor(primals_258, 0.9);  primals_258 = None
        add_171: f32[256] = torch.ops.aten.add.Tensor(mul_225, mul_226);  mul_225 = mul_226 = None
        squeeze_98: f32[256] = torch.ops.aten.squeeze.dims(getitem_66, [0, 2, 3]);  getitem_66 = None
        mul_227: f32[256] = torch.ops.aten.mul.Tensor(squeeze_98, 1.0666666666666667);  squeeze_98 = None
        mul_228: f32[256] = torch.ops.aten.mul.Tensor(mul_227, 0.1);  mul_227 = None
        mul_229: f32[256] = torch.ops.aten.mul.Tensor(primals_259, 0.9);  primals_259 = None
        add_172: f32[256] = torch.ops.aten.add.Tensor(mul_228, mul_229);  mul_228 = mul_229 = None
        unsqueeze_128: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_98, -1)
        unsqueeze_129: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_128, -1);  unsqueeze_128 = None
        mul_230: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_224, unsqueeze_129);  mul_224 = unsqueeze_129 = None
        unsqueeze_130: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_99, -1);  primals_99 = None
        unsqueeze_131: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_130, -1);  unsqueeze_130 = None
        add_173: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_230, unsqueeze_131);  mul_230 = unsqueeze_131 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_29: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_173);  add_173 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_33: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_29, primals_100, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_174: i64[] = torch.ops.aten.add.Tensor(primals_263, 1);  primals_263 = None
        var_mean_33 = torch.ops.aten.var_mean.correction(convolution_33, [0, 2, 3], correction = 0, keepdim = True)
        getitem_68: f32[1, 1024, 1, 1] = var_mean_33[0]
        getitem_69: f32[1, 1024, 1, 1] = var_mean_33[1];  var_mean_33 = None
        add_175: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_68, 1e-05)
        rsqrt_33: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_175);  add_175 = None
        sub_33: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_33, getitem_69)
        mul_231: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_33, rsqrt_33);  sub_33 = None
        squeeze_99: f32[1024] = torch.ops.aten.squeeze.dims(getitem_69, [0, 2, 3]);  getitem_69 = None
        squeeze_100: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_33, [0, 2, 3]);  rsqrt_33 = None
        mul_232: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_99, 0.1)
        mul_233: f32[1024] = torch.ops.aten.mul.Tensor(primals_261, 0.9);  primals_261 = None
        add_176: f32[1024] = torch.ops.aten.add.Tensor(mul_232, mul_233);  mul_232 = mul_233 = None
        squeeze_101: f32[1024] = torch.ops.aten.squeeze.dims(getitem_68, [0, 2, 3]);  getitem_68 = None
        mul_234: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_101, 1.0666666666666667);  squeeze_101 = None
        mul_235: f32[1024] = torch.ops.aten.mul.Tensor(mul_234, 0.1);  mul_234 = None
        mul_236: f32[1024] = torch.ops.aten.mul.Tensor(primals_262, 0.9);  primals_262 = None
        add_177: f32[1024] = torch.ops.aten.add.Tensor(mul_235, mul_236);  mul_235 = mul_236 = None
        unsqueeze_132: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_101, -1)
        unsqueeze_133: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_132, -1);  unsqueeze_132 = None
        mul_237: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_231, unsqueeze_133);  mul_231 = unsqueeze_133 = None
        unsqueeze_134: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_102, -1);  primals_102 = None
        unsqueeze_135: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_134, -1);  unsqueeze_134 = None
        add_178: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_237, unsqueeze_135);  mul_237 = unsqueeze_135 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_179: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_178, relu_27);  add_178 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_30: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_179);  add_179 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_34: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_30, primals_103, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_180: i64[] = torch.ops.aten.add.Tensor(primals_266, 1);  primals_266 = None
        var_mean_34 = torch.ops.aten.var_mean.correction(convolution_34, [0, 2, 3], correction = 0, keepdim = True)
        getitem_70: f32[1, 256, 1, 1] = var_mean_34[0]
        getitem_71: f32[1, 256, 1, 1] = var_mean_34[1];  var_mean_34 = None
        add_181: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_70, 1e-05)
        rsqrt_34: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_181);  add_181 = None
        sub_34: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_34, getitem_71)
        mul_238: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_34, rsqrt_34);  sub_34 = None
        squeeze_102: f32[256] = torch.ops.aten.squeeze.dims(getitem_71, [0, 2, 3]);  getitem_71 = None
        squeeze_103: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_34, [0, 2, 3]);  rsqrt_34 = None
        mul_239: f32[256] = torch.ops.aten.mul.Tensor(squeeze_102, 0.1)
        mul_240: f32[256] = torch.ops.aten.mul.Tensor(primals_264, 0.9);  primals_264 = None
        add_182: f32[256] = torch.ops.aten.add.Tensor(mul_239, mul_240);  mul_239 = mul_240 = None
        squeeze_104: f32[256] = torch.ops.aten.squeeze.dims(getitem_70, [0, 2, 3]);  getitem_70 = None
        mul_241: f32[256] = torch.ops.aten.mul.Tensor(squeeze_104, 1.0666666666666667);  squeeze_104 = None
        mul_242: f32[256] = torch.ops.aten.mul.Tensor(mul_241, 0.1);  mul_241 = None
        mul_243: f32[256] = torch.ops.aten.mul.Tensor(primals_265, 0.9);  primals_265 = None
        add_183: f32[256] = torch.ops.aten.add.Tensor(mul_242, mul_243);  mul_242 = mul_243 = None
        unsqueeze_136: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_104, -1)
        unsqueeze_137: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_136, -1);  unsqueeze_136 = None
        mul_244: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_238, unsqueeze_137);  mul_238 = unsqueeze_137 = None
        unsqueeze_138: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_105, -1);  primals_105 = None
        unsqueeze_139: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_138, -1);  unsqueeze_138 = None
        add_184: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_244, unsqueeze_139);  mul_244 = unsqueeze_139 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_31: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_184);  add_184 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_35: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_31, primals_106, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_185: i64[] = torch.ops.aten.add.Tensor(primals_269, 1);  primals_269 = None
        var_mean_35 = torch.ops.aten.var_mean.correction(convolution_35, [0, 2, 3], correction = 0, keepdim = True)
        getitem_72: f32[1, 256, 1, 1] = var_mean_35[0]
        getitem_73: f32[1, 256, 1, 1] = var_mean_35[1];  var_mean_35 = None
        add_186: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_72, 1e-05)
        rsqrt_35: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_186);  add_186 = None
        sub_35: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_35, getitem_73)
        mul_245: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_35, rsqrt_35);  sub_35 = None
        squeeze_105: f32[256] = torch.ops.aten.squeeze.dims(getitem_73, [0, 2, 3]);  getitem_73 = None
        squeeze_106: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_35, [0, 2, 3]);  rsqrt_35 = None
        mul_246: f32[256] = torch.ops.aten.mul.Tensor(squeeze_105, 0.1)
        mul_247: f32[256] = torch.ops.aten.mul.Tensor(primals_267, 0.9);  primals_267 = None
        add_187: f32[256] = torch.ops.aten.add.Tensor(mul_246, mul_247);  mul_246 = mul_247 = None
        squeeze_107: f32[256] = torch.ops.aten.squeeze.dims(getitem_72, [0, 2, 3]);  getitem_72 = None
        mul_248: f32[256] = torch.ops.aten.mul.Tensor(squeeze_107, 1.0666666666666667);  squeeze_107 = None
        mul_249: f32[256] = torch.ops.aten.mul.Tensor(mul_248, 0.1);  mul_248 = None
        mul_250: f32[256] = torch.ops.aten.mul.Tensor(primals_268, 0.9);  primals_268 = None
        add_188: f32[256] = torch.ops.aten.add.Tensor(mul_249, mul_250);  mul_249 = mul_250 = None
        unsqueeze_140: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_107, -1)
        unsqueeze_141: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_140, -1);  unsqueeze_140 = None
        mul_251: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_245, unsqueeze_141);  mul_245 = unsqueeze_141 = None
        unsqueeze_142: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_108, -1);  primals_108 = None
        unsqueeze_143: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_142, -1);  unsqueeze_142 = None
        add_189: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_251, unsqueeze_143);  mul_251 = unsqueeze_143 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_32: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_189);  add_189 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_36: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_32, primals_109, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_190: i64[] = torch.ops.aten.add.Tensor(primals_272, 1);  primals_272 = None
        var_mean_36 = torch.ops.aten.var_mean.correction(convolution_36, [0, 2, 3], correction = 0, keepdim = True)
        getitem_74: f32[1, 1024, 1, 1] = var_mean_36[0]
        getitem_75: f32[1, 1024, 1, 1] = var_mean_36[1];  var_mean_36 = None
        add_191: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_74, 1e-05)
        rsqrt_36: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_191);  add_191 = None
        sub_36: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_36, getitem_75)
        mul_252: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_36, rsqrt_36);  sub_36 = None
        squeeze_108: f32[1024] = torch.ops.aten.squeeze.dims(getitem_75, [0, 2, 3]);  getitem_75 = None
        squeeze_109: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_36, [0, 2, 3]);  rsqrt_36 = None
        mul_253: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_108, 0.1)
        mul_254: f32[1024] = torch.ops.aten.mul.Tensor(primals_270, 0.9);  primals_270 = None
        add_192: f32[1024] = torch.ops.aten.add.Tensor(mul_253, mul_254);  mul_253 = mul_254 = None
        squeeze_110: f32[1024] = torch.ops.aten.squeeze.dims(getitem_74, [0, 2, 3]);  getitem_74 = None
        mul_255: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_110, 1.0666666666666667);  squeeze_110 = None
        mul_256: f32[1024] = torch.ops.aten.mul.Tensor(mul_255, 0.1);  mul_255 = None
        mul_257: f32[1024] = torch.ops.aten.mul.Tensor(primals_271, 0.9);  primals_271 = None
        add_193: f32[1024] = torch.ops.aten.add.Tensor(mul_256, mul_257);  mul_256 = mul_257 = None
        unsqueeze_144: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_110, -1)
        unsqueeze_145: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_144, -1);  unsqueeze_144 = None
        mul_258: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_252, unsqueeze_145);  mul_252 = unsqueeze_145 = None
        unsqueeze_146: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_111, -1);  primals_111 = None
        unsqueeze_147: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_146, -1);  unsqueeze_146 = None
        add_194: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_258, unsqueeze_147);  mul_258 = unsqueeze_147 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_195: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_194, relu_30);  add_194 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_33: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_195);  add_195 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_37: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_33, primals_112, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_196: i64[] = torch.ops.aten.add.Tensor(primals_275, 1);  primals_275 = None
        var_mean_37 = torch.ops.aten.var_mean.correction(convolution_37, [0, 2, 3], correction = 0, keepdim = True)
        getitem_76: f32[1, 256, 1, 1] = var_mean_37[0]
        getitem_77: f32[1, 256, 1, 1] = var_mean_37[1];  var_mean_37 = None
        add_197: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_76, 1e-05)
        rsqrt_37: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_197);  add_197 = None
        sub_37: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_37, getitem_77)
        mul_259: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_37, rsqrt_37);  sub_37 = None
        squeeze_111: f32[256] = torch.ops.aten.squeeze.dims(getitem_77, [0, 2, 3]);  getitem_77 = None
        squeeze_112: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_37, [0, 2, 3]);  rsqrt_37 = None
        mul_260: f32[256] = torch.ops.aten.mul.Tensor(squeeze_111, 0.1)
        mul_261: f32[256] = torch.ops.aten.mul.Tensor(primals_273, 0.9);  primals_273 = None
        add_198: f32[256] = torch.ops.aten.add.Tensor(mul_260, mul_261);  mul_260 = mul_261 = None
        squeeze_113: f32[256] = torch.ops.aten.squeeze.dims(getitem_76, [0, 2, 3]);  getitem_76 = None
        mul_262: f32[256] = torch.ops.aten.mul.Tensor(squeeze_113, 1.0666666666666667);  squeeze_113 = None
        mul_263: f32[256] = torch.ops.aten.mul.Tensor(mul_262, 0.1);  mul_262 = None
        mul_264: f32[256] = torch.ops.aten.mul.Tensor(primals_274, 0.9);  primals_274 = None
        add_199: f32[256] = torch.ops.aten.add.Tensor(mul_263, mul_264);  mul_263 = mul_264 = None
        unsqueeze_148: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_113, -1)
        unsqueeze_149: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_148, -1);  unsqueeze_148 = None
        mul_265: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_259, unsqueeze_149);  mul_259 = unsqueeze_149 = None
        unsqueeze_150: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_114, -1);  primals_114 = None
        unsqueeze_151: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_150, -1);  unsqueeze_150 = None
        add_200: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_265, unsqueeze_151);  mul_265 = unsqueeze_151 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_34: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_200);  add_200 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_38: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_34, primals_115, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_201: i64[] = torch.ops.aten.add.Tensor(primals_278, 1);  primals_278 = None
        var_mean_38 = torch.ops.aten.var_mean.correction(convolution_38, [0, 2, 3], correction = 0, keepdim = True)
        getitem_78: f32[1, 256, 1, 1] = var_mean_38[0]
        getitem_79: f32[1, 256, 1, 1] = var_mean_38[1];  var_mean_38 = None
        add_202: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_78, 1e-05)
        rsqrt_38: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_202);  add_202 = None
        sub_38: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_38, getitem_79)
        mul_266: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_38, rsqrt_38);  sub_38 = None
        squeeze_114: f32[256] = torch.ops.aten.squeeze.dims(getitem_79, [0, 2, 3]);  getitem_79 = None
        squeeze_115: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_38, [0, 2, 3]);  rsqrt_38 = None
        mul_267: f32[256] = torch.ops.aten.mul.Tensor(squeeze_114, 0.1)
        mul_268: f32[256] = torch.ops.aten.mul.Tensor(primals_276, 0.9);  primals_276 = None
        add_203: f32[256] = torch.ops.aten.add.Tensor(mul_267, mul_268);  mul_267 = mul_268 = None
        squeeze_116: f32[256] = torch.ops.aten.squeeze.dims(getitem_78, [0, 2, 3]);  getitem_78 = None
        mul_269: f32[256] = torch.ops.aten.mul.Tensor(squeeze_116, 1.0666666666666667);  squeeze_116 = None
        mul_270: f32[256] = torch.ops.aten.mul.Tensor(mul_269, 0.1);  mul_269 = None
        mul_271: f32[256] = torch.ops.aten.mul.Tensor(primals_277, 0.9);  primals_277 = None
        add_204: f32[256] = torch.ops.aten.add.Tensor(mul_270, mul_271);  mul_270 = mul_271 = None
        unsqueeze_152: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_116, -1)
        unsqueeze_153: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_152, -1);  unsqueeze_152 = None
        mul_272: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_266, unsqueeze_153);  mul_266 = unsqueeze_153 = None
        unsqueeze_154: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_117, -1);  primals_117 = None
        unsqueeze_155: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_154, -1);  unsqueeze_154 = None
        add_205: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_272, unsqueeze_155);  mul_272 = unsqueeze_155 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_35: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_205);  add_205 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_39: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_35, primals_118, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_206: i64[] = torch.ops.aten.add.Tensor(primals_281, 1);  primals_281 = None
        var_mean_39 = torch.ops.aten.var_mean.correction(convolution_39, [0, 2, 3], correction = 0, keepdim = True)
        getitem_80: f32[1, 1024, 1, 1] = var_mean_39[0]
        getitem_81: f32[1, 1024, 1, 1] = var_mean_39[1];  var_mean_39 = None
        add_207: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_80, 1e-05)
        rsqrt_39: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_207);  add_207 = None
        sub_39: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_39, getitem_81)
        mul_273: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_39, rsqrt_39);  sub_39 = None
        squeeze_117: f32[1024] = torch.ops.aten.squeeze.dims(getitem_81, [0, 2, 3]);  getitem_81 = None
        squeeze_118: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_39, [0, 2, 3]);  rsqrt_39 = None
        mul_274: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_117, 0.1)
        mul_275: f32[1024] = torch.ops.aten.mul.Tensor(primals_279, 0.9);  primals_279 = None
        add_208: f32[1024] = torch.ops.aten.add.Tensor(mul_274, mul_275);  mul_274 = mul_275 = None
        squeeze_119: f32[1024] = torch.ops.aten.squeeze.dims(getitem_80, [0, 2, 3]);  getitem_80 = None
        mul_276: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_119, 1.0666666666666667);  squeeze_119 = None
        mul_277: f32[1024] = torch.ops.aten.mul.Tensor(mul_276, 0.1);  mul_276 = None
        mul_278: f32[1024] = torch.ops.aten.mul.Tensor(primals_280, 0.9);  primals_280 = None
        add_209: f32[1024] = torch.ops.aten.add.Tensor(mul_277, mul_278);  mul_277 = mul_278 = None
        unsqueeze_156: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_119, -1)
        unsqueeze_157: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_156, -1);  unsqueeze_156 = None
        mul_279: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_273, unsqueeze_157);  mul_273 = unsqueeze_157 = None
        unsqueeze_158: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_120, -1);  primals_120 = None
        unsqueeze_159: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_158, -1);  unsqueeze_158 = None
        add_210: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_279, unsqueeze_159);  mul_279 = unsqueeze_159 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_211: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_210, relu_33);  add_210 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_36: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_211);  add_211 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_40: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_36, primals_121, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_212: i64[] = torch.ops.aten.add.Tensor(primals_284, 1);  primals_284 = None
        var_mean_40 = torch.ops.aten.var_mean.correction(convolution_40, [0, 2, 3], correction = 0, keepdim = True)
        getitem_82: f32[1, 256, 1, 1] = var_mean_40[0]
        getitem_83: f32[1, 256, 1, 1] = var_mean_40[1];  var_mean_40 = None
        add_213: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_82, 1e-05)
        rsqrt_40: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_213);  add_213 = None
        sub_40: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_40, getitem_83)
        mul_280: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_40, rsqrt_40);  sub_40 = None
        squeeze_120: f32[256] = torch.ops.aten.squeeze.dims(getitem_83, [0, 2, 3]);  getitem_83 = None
        squeeze_121: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_40, [0, 2, 3]);  rsqrt_40 = None
        mul_281: f32[256] = torch.ops.aten.mul.Tensor(squeeze_120, 0.1)
        mul_282: f32[256] = torch.ops.aten.mul.Tensor(primals_282, 0.9);  primals_282 = None
        add_214: f32[256] = torch.ops.aten.add.Tensor(mul_281, mul_282);  mul_281 = mul_282 = None
        squeeze_122: f32[256] = torch.ops.aten.squeeze.dims(getitem_82, [0, 2, 3]);  getitem_82 = None
        mul_283: f32[256] = torch.ops.aten.mul.Tensor(squeeze_122, 1.0666666666666667);  squeeze_122 = None
        mul_284: f32[256] = torch.ops.aten.mul.Tensor(mul_283, 0.1);  mul_283 = None
        mul_285: f32[256] = torch.ops.aten.mul.Tensor(primals_283, 0.9);  primals_283 = None
        add_215: f32[256] = torch.ops.aten.add.Tensor(mul_284, mul_285);  mul_284 = mul_285 = None
        unsqueeze_160: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_122, -1)
        unsqueeze_161: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_160, -1);  unsqueeze_160 = None
        mul_286: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_280, unsqueeze_161);  mul_280 = unsqueeze_161 = None
        unsqueeze_162: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_123, -1);  primals_123 = None
        unsqueeze_163: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_162, -1);  unsqueeze_162 = None
        add_216: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_286, unsqueeze_163);  mul_286 = unsqueeze_163 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_37: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_216);  add_216 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_41: f32[1, 256, 4, 4] = torch.ops.aten.convolution.default(relu_37, primals_124, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_217: i64[] = torch.ops.aten.add.Tensor(primals_287, 1);  primals_287 = None
        var_mean_41 = torch.ops.aten.var_mean.correction(convolution_41, [0, 2, 3], correction = 0, keepdim = True)
        getitem_84: f32[1, 256, 1, 1] = var_mean_41[0]
        getitem_85: f32[1, 256, 1, 1] = var_mean_41[1];  var_mean_41 = None
        add_218: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_84, 1e-05)
        rsqrt_41: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_218);  add_218 = None
        sub_41: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_41, getitem_85)
        mul_287: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_41, rsqrt_41);  sub_41 = None
        squeeze_123: f32[256] = torch.ops.aten.squeeze.dims(getitem_85, [0, 2, 3]);  getitem_85 = None
        squeeze_124: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_41, [0, 2, 3]);  rsqrt_41 = None
        mul_288: f32[256] = torch.ops.aten.mul.Tensor(squeeze_123, 0.1)
        mul_289: f32[256] = torch.ops.aten.mul.Tensor(primals_285, 0.9);  primals_285 = None
        add_219: f32[256] = torch.ops.aten.add.Tensor(mul_288, mul_289);  mul_288 = mul_289 = None
        squeeze_125: f32[256] = torch.ops.aten.squeeze.dims(getitem_84, [0, 2, 3]);  getitem_84 = None
        mul_290: f32[256] = torch.ops.aten.mul.Tensor(squeeze_125, 1.0666666666666667);  squeeze_125 = None
        mul_291: f32[256] = torch.ops.aten.mul.Tensor(mul_290, 0.1);  mul_290 = None
        mul_292: f32[256] = torch.ops.aten.mul.Tensor(primals_286, 0.9);  primals_286 = None
        add_220: f32[256] = torch.ops.aten.add.Tensor(mul_291, mul_292);  mul_291 = mul_292 = None
        unsqueeze_164: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_125, -1)
        unsqueeze_165: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_164, -1);  unsqueeze_164 = None
        mul_293: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(mul_287, unsqueeze_165);  mul_287 = unsqueeze_165 = None
        unsqueeze_166: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_126, -1);  primals_126 = None
        unsqueeze_167: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_166, -1);  unsqueeze_166 = None
        add_221: f32[1, 256, 4, 4] = torch.ops.aten.add.Tensor(mul_293, unsqueeze_167);  mul_293 = unsqueeze_167 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_38: f32[1, 256, 4, 4] = torch.ops.aten.relu.default(add_221);  add_221 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_42: f32[1, 1024, 4, 4] = torch.ops.aten.convolution.default(relu_38, primals_127, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_222: i64[] = torch.ops.aten.add.Tensor(primals_290, 1);  primals_290 = None
        var_mean_42 = torch.ops.aten.var_mean.correction(convolution_42, [0, 2, 3], correction = 0, keepdim = True)
        getitem_86: f32[1, 1024, 1, 1] = var_mean_42[0]
        getitem_87: f32[1, 1024, 1, 1] = var_mean_42[1];  var_mean_42 = None
        add_223: f32[1, 1024, 1, 1] = torch.ops.aten.add.Tensor(getitem_86, 1e-05)
        rsqrt_42: f32[1, 1024, 1, 1] = torch.ops.aten.rsqrt.default(add_223);  add_223 = None
        sub_42: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_42, getitem_87)
        mul_294: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_42, rsqrt_42);  sub_42 = None
        squeeze_126: f32[1024] = torch.ops.aten.squeeze.dims(getitem_87, [0, 2, 3]);  getitem_87 = None
        squeeze_127: f32[1024] = torch.ops.aten.squeeze.dims(rsqrt_42, [0, 2, 3]);  rsqrt_42 = None
        mul_295: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_126, 0.1)
        mul_296: f32[1024] = torch.ops.aten.mul.Tensor(primals_288, 0.9);  primals_288 = None
        add_224: f32[1024] = torch.ops.aten.add.Tensor(mul_295, mul_296);  mul_295 = mul_296 = None
        squeeze_128: f32[1024] = torch.ops.aten.squeeze.dims(getitem_86, [0, 2, 3]);  getitem_86 = None
        mul_297: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_128, 1.0666666666666667);  squeeze_128 = None
        mul_298: f32[1024] = torch.ops.aten.mul.Tensor(mul_297, 0.1);  mul_297 = None
        mul_299: f32[1024] = torch.ops.aten.mul.Tensor(primals_289, 0.9);  primals_289 = None
        add_225: f32[1024] = torch.ops.aten.add.Tensor(mul_298, mul_299);  mul_298 = mul_299 = None
        unsqueeze_168: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_128, -1)
        unsqueeze_169: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_168, -1);  unsqueeze_168 = None
        mul_300: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(mul_294, unsqueeze_169);  mul_294 = unsqueeze_169 = None
        unsqueeze_170: f32[1024, 1] = torch.ops.aten.unsqueeze.default(primals_129, -1);  primals_129 = None
        unsqueeze_171: f32[1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_170, -1);  unsqueeze_170 = None
        add_226: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(mul_300, unsqueeze_171);  mul_300 = unsqueeze_171 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_227: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(add_226, relu_36);  add_226 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_39: f32[1, 1024, 4, 4] = torch.ops.aten.relu.default(add_227);  add_227 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_43: f32[1, 512, 4, 4] = torch.ops.aten.convolution.default(relu_39, primals_130, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_228: i64[] = torch.ops.aten.add.Tensor(primals_293, 1);  primals_293 = None
        var_mean_43 = torch.ops.aten.var_mean.correction(convolution_43, [0, 2, 3], correction = 0, keepdim = True)
        getitem_88: f32[1, 512, 1, 1] = var_mean_43[0]
        getitem_89: f32[1, 512, 1, 1] = var_mean_43[1];  var_mean_43 = None
        add_229: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_88, 1e-05)
        rsqrt_43: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_229);  add_229 = None
        sub_43: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(convolution_43, getitem_89)
        mul_301: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(sub_43, rsqrt_43);  sub_43 = None
        squeeze_129: f32[512] = torch.ops.aten.squeeze.dims(getitem_89, [0, 2, 3]);  getitem_89 = None
        squeeze_130: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_43, [0, 2, 3]);  rsqrt_43 = None
        mul_302: f32[512] = torch.ops.aten.mul.Tensor(squeeze_129, 0.1)
        mul_303: f32[512] = torch.ops.aten.mul.Tensor(primals_291, 0.9);  primals_291 = None
        add_230: f32[512] = torch.ops.aten.add.Tensor(mul_302, mul_303);  mul_302 = mul_303 = None
        squeeze_131: f32[512] = torch.ops.aten.squeeze.dims(getitem_88, [0, 2, 3]);  getitem_88 = None
        mul_304: f32[512] = torch.ops.aten.mul.Tensor(squeeze_131, 1.0666666666666667);  squeeze_131 = None
        mul_305: f32[512] = torch.ops.aten.mul.Tensor(mul_304, 0.1);  mul_304 = None
        mul_306: f32[512] = torch.ops.aten.mul.Tensor(primals_292, 0.9);  primals_292 = None
        add_231: f32[512] = torch.ops.aten.add.Tensor(mul_305, mul_306);  mul_305 = mul_306 = None
        unsqueeze_172: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_131, -1)
        unsqueeze_173: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_172, -1);  unsqueeze_172 = None
        mul_307: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(mul_301, unsqueeze_173);  mul_301 = unsqueeze_173 = None
        unsqueeze_174: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_132, -1);  primals_132 = None
        unsqueeze_175: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_174, -1);  unsqueeze_174 = None
        add_232: f32[1, 512, 4, 4] = torch.ops.aten.add.Tensor(mul_307, unsqueeze_175);  mul_307 = unsqueeze_175 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_40: f32[1, 512, 4, 4] = torch.ops.aten.relu.default(add_232);  add_232 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_44: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_40, primals_133, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_233: i64[] = torch.ops.aten.add.Tensor(primals_296, 1);  primals_296 = None
        var_mean_44 = torch.ops.aten.var_mean.correction(convolution_44, [0, 2, 3], correction = 0, keepdim = True)
        getitem_90: f32[1, 512, 1, 1] = var_mean_44[0]
        getitem_91: f32[1, 512, 1, 1] = var_mean_44[1];  var_mean_44 = None
        add_234: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_90, 1e-05)
        rsqrt_44: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_234);  add_234 = None
        sub_44: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_44, getitem_91)
        mul_308: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_44, rsqrt_44);  sub_44 = rsqrt_44 = None
        squeeze_132: f32[512] = torch.ops.aten.squeeze.dims(getitem_91, [0, 2, 3]);  getitem_91 = None
        mul_309: f32[512] = torch.ops.aten.mul.Tensor(squeeze_132, 0.1);  squeeze_132 = None
        mul_310: f32[512] = torch.ops.aten.mul.Tensor(primals_294, 0.9);  primals_294 = None
        add_235: f32[512] = torch.ops.aten.add.Tensor(mul_309, mul_310);  mul_309 = mul_310 = None
        squeeze_134: f32[512] = torch.ops.aten.squeeze.dims(getitem_90, [0, 2, 3]);  getitem_90 = None
        mul_311: f32[512] = torch.ops.aten.mul.Tensor(squeeze_134, 1.3333333333333333);  squeeze_134 = None
        mul_312: f32[512] = torch.ops.aten.mul.Tensor(mul_311, 0.1);  mul_311 = None
        mul_313: f32[512] = torch.ops.aten.mul.Tensor(primals_295, 0.9);  primals_295 = None
        add_236: f32[512] = torch.ops.aten.add.Tensor(mul_312, mul_313);  mul_312 = mul_313 = None
        unsqueeze_176: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_134, -1)
        unsqueeze_177: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_176, -1);  unsqueeze_176 = None
        mul_314: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_308, unsqueeze_177);  mul_308 = unsqueeze_177 = None
        unsqueeze_178: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_135, -1);  primals_135 = None
        unsqueeze_179: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_178, -1);  unsqueeze_178 = None
        add_237: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_314, unsqueeze_179);  mul_314 = unsqueeze_179 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_41: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_237);  add_237 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_45: f32[1, 2048, 2, 2] = torch.ops.aten.convolution.default(relu_41, primals_136, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_238: i64[] = torch.ops.aten.add.Tensor(primals_299, 1);  primals_299 = None
        var_mean_45 = torch.ops.aten.var_mean.correction(convolution_45, [0, 2, 3], correction = 0, keepdim = True)
        getitem_92: f32[1, 2048, 1, 1] = var_mean_45[0]
        getitem_93: f32[1, 2048, 1, 1] = var_mean_45[1];  var_mean_45 = None
        add_239: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_92, 1e-05)
        rsqrt_45: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_239);  add_239 = None
        sub_45: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_45, getitem_93)
        mul_315: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_45, rsqrt_45);  sub_45 = rsqrt_45 = None
        squeeze_135: f32[2048] = torch.ops.aten.squeeze.dims(getitem_93, [0, 2, 3]);  getitem_93 = None
        mul_316: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_135, 0.1);  squeeze_135 = None
        mul_317: f32[2048] = torch.ops.aten.mul.Tensor(primals_297, 0.9);  primals_297 = None
        add_240: f32[2048] = torch.ops.aten.add.Tensor(mul_316, mul_317);  mul_316 = mul_317 = None
        squeeze_137: f32[2048] = torch.ops.aten.squeeze.dims(getitem_92, [0, 2, 3]);  getitem_92 = None
        mul_318: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_137, 1.3333333333333333);  squeeze_137 = None
        mul_319: f32[2048] = torch.ops.aten.mul.Tensor(mul_318, 0.1);  mul_318 = None
        mul_320: f32[2048] = torch.ops.aten.mul.Tensor(primals_298, 0.9);  primals_298 = None
        add_241: f32[2048] = torch.ops.aten.add.Tensor(mul_319, mul_320);  mul_319 = mul_320 = None
        unsqueeze_180: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_137, -1)
        unsqueeze_181: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_180, -1);  unsqueeze_180 = None
        mul_321: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(mul_315, unsqueeze_181);  mul_315 = unsqueeze_181 = None
        unsqueeze_182: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_138, -1);  primals_138 = None
        unsqueeze_183: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_182, -1);  unsqueeze_182 = None
        add_242: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(mul_321, unsqueeze_183);  mul_321 = unsqueeze_183 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        convolution_46: f32[1, 2048, 2, 2] = torch.ops.aten.convolution.default(relu_39, primals_139, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)
        add_243: i64[] = torch.ops.aten.add.Tensor(primals_302, 1);  primals_302 = None
        var_mean_46 = torch.ops.aten.var_mean.correction(convolution_46, [0, 2, 3], correction = 0, keepdim = True)
        getitem_94: f32[1, 2048, 1, 1] = var_mean_46[0]
        getitem_95: f32[1, 2048, 1, 1] = var_mean_46[1];  var_mean_46 = None
        add_244: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_94, 1e-05)
        rsqrt_46: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_244);  add_244 = None
        sub_46: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_46, getitem_95)
        mul_322: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_46, rsqrt_46);  sub_46 = rsqrt_46 = None
        squeeze_138: f32[2048] = torch.ops.aten.squeeze.dims(getitem_95, [0, 2, 3]);  getitem_95 = None
        mul_323: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_138, 0.1);  squeeze_138 = None
        mul_324: f32[2048] = torch.ops.aten.mul.Tensor(primals_300, 0.9);  primals_300 = None
        add_245: f32[2048] = torch.ops.aten.add.Tensor(mul_323, mul_324);  mul_323 = mul_324 = None
        squeeze_140: f32[2048] = torch.ops.aten.squeeze.dims(getitem_94, [0, 2, 3]);  getitem_94 = None
        mul_325: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_140, 1.3333333333333333);  squeeze_140 = None
        mul_326: f32[2048] = torch.ops.aten.mul.Tensor(mul_325, 0.1);  mul_325 = None
        mul_327: f32[2048] = torch.ops.aten.mul.Tensor(primals_301, 0.9);  primals_301 = None
        add_246: f32[2048] = torch.ops.aten.add.Tensor(mul_326, mul_327);  mul_326 = mul_327 = None
        unsqueeze_184: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_140, -1)
        unsqueeze_185: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_184, -1);  unsqueeze_184 = None
        mul_328: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(mul_322, unsqueeze_185);  mul_322 = unsqueeze_185 = None
        unsqueeze_186: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_141, -1);  primals_141 = None
        unsqueeze_187: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_186, -1);  unsqueeze_186 = None
        add_247: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(mul_328, unsqueeze_187);  mul_328 = unsqueeze_187 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_248: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(add_242, add_247);  add_242 = add_247 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_42: f32[1, 2048, 2, 2] = torch.ops.aten.relu.default(add_248);  add_248 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_47: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_42, primals_142, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_249: i64[] = torch.ops.aten.add.Tensor(primals_305, 1);  primals_305 = None
        var_mean_47 = torch.ops.aten.var_mean.correction(convolution_47, [0, 2, 3], correction = 0, keepdim = True)
        getitem_96: f32[1, 512, 1, 1] = var_mean_47[0]
        getitem_97: f32[1, 512, 1, 1] = var_mean_47[1];  var_mean_47 = None
        add_250: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_96, 1e-05)
        rsqrt_47: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_250);  add_250 = None
        sub_47: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_47, getitem_97)
        mul_329: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_47, rsqrt_47);  sub_47 = rsqrt_47 = None
        squeeze_141: f32[512] = torch.ops.aten.squeeze.dims(getitem_97, [0, 2, 3]);  getitem_97 = None
        mul_330: f32[512] = torch.ops.aten.mul.Tensor(squeeze_141, 0.1);  squeeze_141 = None
        mul_331: f32[512] = torch.ops.aten.mul.Tensor(primals_303, 0.9);  primals_303 = None
        add_251: f32[512] = torch.ops.aten.add.Tensor(mul_330, mul_331);  mul_330 = mul_331 = None
        squeeze_143: f32[512] = torch.ops.aten.squeeze.dims(getitem_96, [0, 2, 3]);  getitem_96 = None
        mul_332: f32[512] = torch.ops.aten.mul.Tensor(squeeze_143, 1.3333333333333333);  squeeze_143 = None
        mul_333: f32[512] = torch.ops.aten.mul.Tensor(mul_332, 0.1);  mul_332 = None
        mul_334: f32[512] = torch.ops.aten.mul.Tensor(primals_304, 0.9);  primals_304 = None
        add_252: f32[512] = torch.ops.aten.add.Tensor(mul_333, mul_334);  mul_333 = mul_334 = None
        unsqueeze_188: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_143, -1)
        unsqueeze_189: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_188, -1);  unsqueeze_188 = None
        mul_335: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_329, unsqueeze_189);  mul_329 = unsqueeze_189 = None
        unsqueeze_190: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_144, -1);  primals_144 = None
        unsqueeze_191: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_190, -1);  unsqueeze_190 = None
        add_253: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_335, unsqueeze_191);  mul_335 = unsqueeze_191 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_43: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_253);  add_253 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_48: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_43, primals_145, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_254: i64[] = torch.ops.aten.add.Tensor(primals_308, 1);  primals_308 = None
        var_mean_48 = torch.ops.aten.var_mean.correction(convolution_48, [0, 2, 3], correction = 0, keepdim = True)
        getitem_98: f32[1, 512, 1, 1] = var_mean_48[0]
        getitem_99: f32[1, 512, 1, 1] = var_mean_48[1];  var_mean_48 = None
        add_255: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_98, 1e-05)
        rsqrt_48: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_255);  add_255 = None
        sub_48: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_48, getitem_99)
        mul_336: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_48, rsqrt_48);  sub_48 = rsqrt_48 = None
        squeeze_144: f32[512] = torch.ops.aten.squeeze.dims(getitem_99, [0, 2, 3]);  getitem_99 = None
        mul_337: f32[512] = torch.ops.aten.mul.Tensor(squeeze_144, 0.1);  squeeze_144 = None
        mul_338: f32[512] = torch.ops.aten.mul.Tensor(primals_306, 0.9);  primals_306 = None
        add_256: f32[512] = torch.ops.aten.add.Tensor(mul_337, mul_338);  mul_337 = mul_338 = None
        squeeze_146: f32[512] = torch.ops.aten.squeeze.dims(getitem_98, [0, 2, 3]);  getitem_98 = None
        mul_339: f32[512] = torch.ops.aten.mul.Tensor(squeeze_146, 1.3333333333333333);  squeeze_146 = None
        mul_340: f32[512] = torch.ops.aten.mul.Tensor(mul_339, 0.1);  mul_339 = None
        mul_341: f32[512] = torch.ops.aten.mul.Tensor(primals_307, 0.9);  primals_307 = None
        add_257: f32[512] = torch.ops.aten.add.Tensor(mul_340, mul_341);  mul_340 = mul_341 = None
        unsqueeze_192: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_146, -1)
        unsqueeze_193: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_192, -1);  unsqueeze_192 = None
        mul_342: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_336, unsqueeze_193);  mul_336 = unsqueeze_193 = None
        unsqueeze_194: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_147, -1);  primals_147 = None
        unsqueeze_195: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_194, -1);  unsqueeze_194 = None
        add_258: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_342, unsqueeze_195);  mul_342 = unsqueeze_195 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_44: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_258);  add_258 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_49: f32[1, 2048, 2, 2] = torch.ops.aten.convolution.default(relu_44, primals_148, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_259: i64[] = torch.ops.aten.add.Tensor(primals_311, 1);  primals_311 = None
        var_mean_49 = torch.ops.aten.var_mean.correction(convolution_49, [0, 2, 3], correction = 0, keepdim = True)
        getitem_100: f32[1, 2048, 1, 1] = var_mean_49[0]
        getitem_101: f32[1, 2048, 1, 1] = var_mean_49[1];  var_mean_49 = None
        add_260: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_100, 1e-05)
        rsqrt_49: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_260);  add_260 = None
        sub_49: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_49, getitem_101)
        mul_343: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_49, rsqrt_49);  sub_49 = rsqrt_49 = None
        squeeze_147: f32[2048] = torch.ops.aten.squeeze.dims(getitem_101, [0, 2, 3]);  getitem_101 = None
        mul_344: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_147, 0.1);  squeeze_147 = None
        mul_345: f32[2048] = torch.ops.aten.mul.Tensor(primals_309, 0.9);  primals_309 = None
        add_261: f32[2048] = torch.ops.aten.add.Tensor(mul_344, mul_345);  mul_344 = mul_345 = None
        squeeze_149: f32[2048] = torch.ops.aten.squeeze.dims(getitem_100, [0, 2, 3]);  getitem_100 = None
        mul_346: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_149, 1.3333333333333333);  squeeze_149 = None
        mul_347: f32[2048] = torch.ops.aten.mul.Tensor(mul_346, 0.1);  mul_346 = None
        mul_348: f32[2048] = torch.ops.aten.mul.Tensor(primals_310, 0.9);  primals_310 = None
        add_262: f32[2048] = torch.ops.aten.add.Tensor(mul_347, mul_348);  mul_347 = mul_348 = None
        unsqueeze_196: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_149, -1)
        unsqueeze_197: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_196, -1);  unsqueeze_196 = None
        mul_349: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(mul_343, unsqueeze_197);  mul_343 = unsqueeze_197 = None
        unsqueeze_198: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_150, -1);  primals_150 = None
        unsqueeze_199: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_198, -1);  unsqueeze_198 = None
        add_263: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(mul_349, unsqueeze_199);  mul_349 = unsqueeze_199 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_264: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(add_263, relu_42);  add_263 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_45: f32[1, 2048, 2, 2] = torch.ops.aten.relu.default(add_264);  add_264 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_50: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_45, primals_151, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        add_265: i64[] = torch.ops.aten.add.Tensor(primals_314, 1);  primals_314 = None
        var_mean_50 = torch.ops.aten.var_mean.correction(convolution_50, [0, 2, 3], correction = 0, keepdim = True)
        getitem_102: f32[1, 512, 1, 1] = var_mean_50[0]
        getitem_103: f32[1, 512, 1, 1] = var_mean_50[1];  var_mean_50 = None
        add_266: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_102, 1e-05)
        rsqrt_50: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_266);  add_266 = None
        sub_50: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_50, getitem_103)
        mul_350: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_50, rsqrt_50);  sub_50 = rsqrt_50 = None
        squeeze_150: f32[512] = torch.ops.aten.squeeze.dims(getitem_103, [0, 2, 3]);  getitem_103 = None
        mul_351: f32[512] = torch.ops.aten.mul.Tensor(squeeze_150, 0.1);  squeeze_150 = None
        mul_352: f32[512] = torch.ops.aten.mul.Tensor(primals_312, 0.9);  primals_312 = None
        add_267: f32[512] = torch.ops.aten.add.Tensor(mul_351, mul_352);  mul_351 = mul_352 = None
        squeeze_152: f32[512] = torch.ops.aten.squeeze.dims(getitem_102, [0, 2, 3]);  getitem_102 = None
        mul_353: f32[512] = torch.ops.aten.mul.Tensor(squeeze_152, 1.3333333333333333);  squeeze_152 = None
        mul_354: f32[512] = torch.ops.aten.mul.Tensor(mul_353, 0.1);  mul_353 = None
        mul_355: f32[512] = torch.ops.aten.mul.Tensor(primals_313, 0.9);  primals_313 = None
        add_268: f32[512] = torch.ops.aten.add.Tensor(mul_354, mul_355);  mul_354 = mul_355 = None
        unsqueeze_200: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_152, -1)
        unsqueeze_201: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_200, -1);  unsqueeze_200 = None
        mul_356: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_350, unsqueeze_201);  mul_350 = unsqueeze_201 = None
        unsqueeze_202: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_153, -1);  primals_153 = None
        unsqueeze_203: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_202, -1);  unsqueeze_202 = None
        add_269: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_356, unsqueeze_203);  mul_356 = unsqueeze_203 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        relu_46: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_269);  add_269 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_51: f32[1, 512, 2, 2] = torch.ops.aten.convolution.default(relu_46, primals_154, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        add_270: i64[] = torch.ops.aten.add.Tensor(primals_317, 1);  primals_317 = None
        var_mean_51 = torch.ops.aten.var_mean.correction(convolution_51, [0, 2, 3], correction = 0, keepdim = True)
        getitem_104: f32[1, 512, 1, 1] = var_mean_51[0]
        getitem_105: f32[1, 512, 1, 1] = var_mean_51[1];  var_mean_51 = None
        add_271: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_104, 1e-05)
        rsqrt_51: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_271);  add_271 = None
        sub_51: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_51, getitem_105)
        mul_357: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_51, rsqrt_51);  sub_51 = rsqrt_51 = None
        squeeze_153: f32[512] = torch.ops.aten.squeeze.dims(getitem_105, [0, 2, 3]);  getitem_105 = None
        mul_358: f32[512] = torch.ops.aten.mul.Tensor(squeeze_153, 0.1);  squeeze_153 = None
        mul_359: f32[512] = torch.ops.aten.mul.Tensor(primals_315, 0.9);  primals_315 = None
        add_272: f32[512] = torch.ops.aten.add.Tensor(mul_358, mul_359);  mul_358 = mul_359 = None
        squeeze_155: f32[512] = torch.ops.aten.squeeze.dims(getitem_104, [0, 2, 3]);  getitem_104 = None
        mul_360: f32[512] = torch.ops.aten.mul.Tensor(squeeze_155, 1.3333333333333333);  squeeze_155 = None
        mul_361: f32[512] = torch.ops.aten.mul.Tensor(mul_360, 0.1);  mul_360 = None
        mul_362: f32[512] = torch.ops.aten.mul.Tensor(primals_316, 0.9);  primals_316 = None
        add_273: f32[512] = torch.ops.aten.add.Tensor(mul_361, mul_362);  mul_361 = mul_362 = None
        unsqueeze_204: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_155, -1)
        unsqueeze_205: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_204, -1);  unsqueeze_204 = None
        mul_363: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(mul_357, unsqueeze_205);  mul_357 = unsqueeze_205 = None
        unsqueeze_206: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_156, -1);  primals_156 = None
        unsqueeze_207: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_206, -1);  unsqueeze_206 = None
        add_274: f32[1, 512, 2, 2] = torch.ops.aten.add.Tensor(mul_363, unsqueeze_207);  mul_363 = unsqueeze_207 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        relu_47: f32[1, 512, 2, 2] = torch.ops.aten.relu.default(add_274);  add_274 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_52: f32[1, 2048, 2, 2] = torch.ops.aten.convolution.default(relu_47, primals_157, None, [1, 1], [0, 0], [1, 1], False, [0, 0], 1)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        add_275: i64[] = torch.ops.aten.add.Tensor(primals_320, 1);  primals_320 = None
        var_mean_52 = torch.ops.aten.var_mean.correction(convolution_52, [0, 2, 3], correction = 0, keepdim = True)
        getitem_106: f32[1, 2048, 1, 1] = var_mean_52[0]
        getitem_107: f32[1, 2048, 1, 1] = var_mean_52[1];  var_mean_52 = None
        add_276: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_106, 1e-05)
        rsqrt_52: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_276);  add_276 = None
        sub_52: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_52, getitem_107)
        mul_364: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_52, rsqrt_52);  sub_52 = rsqrt_52 = None
        squeeze_156: f32[2048] = torch.ops.aten.squeeze.dims(getitem_107, [0, 2, 3]);  getitem_107 = None
        mul_365: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_156, 0.1);  squeeze_156 = None
        mul_366: f32[2048] = torch.ops.aten.mul.Tensor(primals_318, 0.9);  primals_318 = None
        add_277: f32[2048] = torch.ops.aten.add.Tensor(mul_365, mul_366);  mul_365 = mul_366 = None
        squeeze_158: f32[2048] = torch.ops.aten.squeeze.dims(getitem_106, [0, 2, 3]);  getitem_106 = None
        mul_367: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_158, 1.3333333333333333);  squeeze_158 = None
        mul_368: f32[2048] = torch.ops.aten.mul.Tensor(mul_367, 0.1);  mul_367 = None
        mul_369: f32[2048] = torch.ops.aten.mul.Tensor(primals_319, 0.9);  primals_319 = None
        add_278: f32[2048] = torch.ops.aten.add.Tensor(mul_368, mul_369);  mul_368 = mul_369 = None
        unsqueeze_208: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_158, -1)
        unsqueeze_209: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_208, -1);  unsqueeze_208 = None
        mul_370: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(mul_364, unsqueeze_209);  mul_364 = unsqueeze_209 = None
        unsqueeze_210: f32[2048, 1] = torch.ops.aten.unsqueeze.default(primals_159, -1);  primals_159 = None
        unsqueeze_211: f32[2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_210, -1);  unsqueeze_210 = None
        add_279: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(mul_370, unsqueeze_211);  mul_370 = unsqueeze_211 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:138, code: out += identity
        add_280: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(add_279, relu_45);  add_279 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        relu_48: f32[1, 2048, 2, 2] = torch.ops.aten.relu.default(add_280);  add_280 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:242, code: x = self.avgpool(x)
        mean: f32[1, 2048, 1, 1] = torch.ops.aten.mean.dim(relu_48, [-1, -2], True)
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:243, code: x = torch.flatten(x, 1)
        view: f32[1, 2048] = torch.ops.aten.view.default(mean, [1, 2048]);  mean = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:244, code: x = self.fc(x)
        permute: f32[2048, 1000] = torch.ops.aten.permute.default(primals_160, [1, 0]);  primals_160 = None
        addmm: f32[1, 1000] = torch.ops.aten.addmm.default(primals_161, view, permute);  primals_161 = None
        permute_1: f32[1000, 2048] = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le: b8[1, 2048, 2, 2] = torch.ops.aten.le.Scalar(relu_48, 0);  relu_48 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_320: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_129, 0);  squeeze_129 = None
        unsqueeze_321: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_320, 2);  unsqueeze_320 = None
        unsqueeze_322: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_321, 3);  unsqueeze_321 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_332: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_126, 0);  squeeze_126 = None
        unsqueeze_333: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_332, 2);  unsqueeze_332 = None
        unsqueeze_334: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_333, 3);  unsqueeze_333 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_344: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_123, 0);  squeeze_123 = None
        unsqueeze_345: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_344, 2);  unsqueeze_344 = None
        unsqueeze_346: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_345, 3);  unsqueeze_345 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_356: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_120, 0);  squeeze_120 = None
        unsqueeze_357: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_356, 2);  unsqueeze_356 = None
        unsqueeze_358: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_357, 3);  unsqueeze_357 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_368: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_117, 0);  squeeze_117 = None
        unsqueeze_369: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_368, 2);  unsqueeze_368 = None
        unsqueeze_370: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_369, 3);  unsqueeze_369 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_380: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_114, 0);  squeeze_114 = None
        unsqueeze_381: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_380, 2);  unsqueeze_380 = None
        unsqueeze_382: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_381, 3);  unsqueeze_381 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_392: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_111, 0);  squeeze_111 = None
        unsqueeze_393: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_392, 2);  unsqueeze_392 = None
        unsqueeze_394: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_393, 3);  unsqueeze_393 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_404: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_108, 0);  squeeze_108 = None
        unsqueeze_405: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_404, 2);  unsqueeze_404 = None
        unsqueeze_406: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_405, 3);  unsqueeze_405 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_416: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_105, 0);  squeeze_105 = None
        unsqueeze_417: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_416, 2);  unsqueeze_416 = None
        unsqueeze_418: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_417, 3);  unsqueeze_417 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_428: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_102, 0);  squeeze_102 = None
        unsqueeze_429: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_428, 2);  unsqueeze_428 = None
        unsqueeze_430: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_429, 3);  unsqueeze_429 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_440: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_99, 0);  squeeze_99 = None
        unsqueeze_441: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_440, 2);  unsqueeze_440 = None
        unsqueeze_442: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_441, 3);  unsqueeze_441 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_452: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_96, 0);  squeeze_96 = None
        unsqueeze_453: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_452, 2);  unsqueeze_452 = None
        unsqueeze_454: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_453, 3);  unsqueeze_453 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_464: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_93, 0);  squeeze_93 = None
        unsqueeze_465: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_464, 2);  unsqueeze_464 = None
        unsqueeze_466: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_465, 3);  unsqueeze_465 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_476: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_90, 0);  squeeze_90 = None
        unsqueeze_477: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_476, 2);  unsqueeze_476 = None
        unsqueeze_478: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_477, 3);  unsqueeze_477 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_488: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_87, 0);  squeeze_87 = None
        unsqueeze_489: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_488, 2);  unsqueeze_488 = None
        unsqueeze_490: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_489, 3);  unsqueeze_489 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_500: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_84, 0);  squeeze_84 = None
        unsqueeze_501: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_500, 2);  unsqueeze_500 = None
        unsqueeze_502: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_501, 3);  unsqueeze_501 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        unsqueeze_512: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_81, 0);  squeeze_81 = None
        unsqueeze_513: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_512, 2);  unsqueeze_512 = None
        unsqueeze_514: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_513, 3);  unsqueeze_513 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_524: f32[1, 1024] = torch.ops.aten.unsqueeze.default(squeeze_78, 0);  squeeze_78 = None
        unsqueeze_525: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_524, 2);  unsqueeze_524 = None
        unsqueeze_526: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_525, 3);  unsqueeze_525 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_536: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_75, 0);  squeeze_75 = None
        unsqueeze_537: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_536, 2);  unsqueeze_536 = None
        unsqueeze_538: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_537, 3);  unsqueeze_537 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_548: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_72, 0);  squeeze_72 = None
        unsqueeze_549: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_548, 2);  unsqueeze_548 = None
        unsqueeze_550: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_549, 3);  unsqueeze_549 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_560: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_69, 0);  squeeze_69 = None
        unsqueeze_561: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_560, 2);  unsqueeze_560 = None
        unsqueeze_562: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_561, 3);  unsqueeze_561 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_572: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_66, 0);  squeeze_66 = None
        unsqueeze_573: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_572, 2);  unsqueeze_572 = None
        unsqueeze_574: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_573, 3);  unsqueeze_573 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_584: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_63, 0);  squeeze_63 = None
        unsqueeze_585: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_584, 2);  unsqueeze_584 = None
        unsqueeze_586: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_585, 3);  unsqueeze_585 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_596: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_60, 0);  squeeze_60 = None
        unsqueeze_597: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_596, 2);  unsqueeze_596 = None
        unsqueeze_598: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_597, 3);  unsqueeze_597 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_608: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_57, 0);  squeeze_57 = None
        unsqueeze_609: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_608, 2);  unsqueeze_608 = None
        unsqueeze_610: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_609, 3);  unsqueeze_609 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_620: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_54, 0);  squeeze_54 = None
        unsqueeze_621: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_620, 2);  unsqueeze_620 = None
        unsqueeze_622: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_621, 3);  unsqueeze_621 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_632: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_51, 0);  squeeze_51 = None
        unsqueeze_633: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_632, 2);  unsqueeze_632 = None
        unsqueeze_634: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_633, 3);  unsqueeze_633 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_644: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_48, 0);  squeeze_48 = None
        unsqueeze_645: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_644, 2);  unsqueeze_644 = None
        unsqueeze_646: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_645, 3);  unsqueeze_645 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_656: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_45, 0);  squeeze_45 = None
        unsqueeze_657: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_656, 2);  unsqueeze_656 = None
        unsqueeze_658: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_657, 3);  unsqueeze_657 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        unsqueeze_668: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_42, 0);  squeeze_42 = None
        unsqueeze_669: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_668, 2);  unsqueeze_668 = None
        unsqueeze_670: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_669, 3);  unsqueeze_669 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_680: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_39, 0);  squeeze_39 = None
        unsqueeze_681: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_680, 2);  unsqueeze_680 = None
        unsqueeze_682: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_681, 3);  unsqueeze_681 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_692: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_36, 0);  squeeze_36 = None
        unsqueeze_693: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_692, 2);  unsqueeze_692 = None
        unsqueeze_694: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_693, 3);  unsqueeze_693 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_704: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_33, 0);  squeeze_33 = None
        unsqueeze_705: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_704, 2);  unsqueeze_704 = None
        unsqueeze_706: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_705, 3);  unsqueeze_705 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_716: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_30, 0);  squeeze_30 = None
        unsqueeze_717: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_716, 2);  unsqueeze_716 = None
        unsqueeze_718: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_717, 3);  unsqueeze_717 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_728: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_27, 0);  squeeze_27 = None
        unsqueeze_729: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_728, 2);  unsqueeze_728 = None
        unsqueeze_730: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_729, 3);  unsqueeze_729 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_740: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_24, 0);  squeeze_24 = None
        unsqueeze_741: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_740, 2);  unsqueeze_740 = None
        unsqueeze_742: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_741, 3);  unsqueeze_741 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_752: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_21, 0);  squeeze_21 = None
        unsqueeze_753: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_752, 2);  unsqueeze_752 = None
        unsqueeze_754: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_753, 3);  unsqueeze_753 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_764: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_18, 0);  squeeze_18 = None
        unsqueeze_765: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_764, 2);  unsqueeze_764 = None
        unsqueeze_766: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_765, 3);  unsqueeze_765 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_776: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_15, 0);  squeeze_15 = None
        unsqueeze_777: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_776, 2);  unsqueeze_776 = None
        unsqueeze_778: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_777, 3);  unsqueeze_777 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        unsqueeze_788: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_12, 0);  squeeze_12 = None
        unsqueeze_789: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_788, 2);  unsqueeze_788 = None
        unsqueeze_790: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_789, 3);  unsqueeze_789 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_800: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_9, 0);  squeeze_9 = None
        unsqueeze_801: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_800, 2);  unsqueeze_800 = None
        unsqueeze_802: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_801, 3);  unsqueeze_801 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_812: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_6, 0);  squeeze_6 = None
        unsqueeze_813: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_812, 2);  unsqueeze_812 = None
        unsqueeze_814: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_813, 3);  unsqueeze_813 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_824: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_3, 0);  squeeze_3 = None
        unsqueeze_825: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_824, 2);  unsqueeze_824 = None
        unsqueeze_826: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_825, 3);  unsqueeze_825 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:233, code: x = self.bn1(x)
        unsqueeze_836: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze, 0);  squeeze = None
        unsqueeze_837: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_836, 2);  unsqueeze_836 = None
        unsqueeze_838: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_837, 3);  unsqueeze_837 = None
        return [add_2, add_3, add, add_7, add_8, add_5, add_12, add_13, add_10, add_17, add_18, add_15, add_22, add_23, add_20, add_28, add_29, add_26, add_33, add_34, add_31, add_38, add_39, add_36, add_44, add_45, add_42, add_49, add_50, add_47, add_54, add_55, add_52, add_60, add_61, add_58, add_65, add_66, add_63, add_70, add_71, add_68, add_75, add_76, add_73, add_81, add_82, add_79, add_86, add_87, add_84, add_91, add_92, add_89, add_97, add_98, add_95, add_102, add_103, add_100, add_107, add_108, add_105, add_113, add_114, add_111, add_118, add_119, add_116, add_123, add_124, add_121, add_129, add_130, add_127, add_134, add_135, add_132, add_139, add_140, add_137, add_144, add_145, add_142, add_150, add_151, add_148, add_155, add_156, add_153, add_160, add_161, add_158, add_166, add_167, add_164, add_171, add_172, add_169, add_176, add_177, add_174, add_182, add_183, add_180, add_187, add_188, add_185, add_192, add_193, add_190, add_198, add_199, add_196, add_203, add_204, add_201, add_208, add_209, add_206, add_214, add_215, add_212, add_219, add_220, add_217, add_224, add_225, add_222, add_230, add_231, add_228, add_235, add_236, add_233, add_240, add_241, add_238, add_245, add_246, add_243, add_251, add_252, add_249, add_256, add_257, add_254, add_261, add_262, add_259, add_267, add_268, add_265, add_272, add_273, add_270, add_277, add_278, add_275, addmm, primals_1, primals_2, primals_4, primals_5, primals_7, primals_8, primals_10, primals_11, primals_13, primals_14, primals_16, primals_17, primals_19, primals_20, primals_22, primals_23, primals_25, primals_26, primals_28, primals_29, primals_31, primals_32, primals_34, primals_35, primals_37, primals_38, primals_40, primals_41, primals_43, primals_44, primals_46, primals_47, primals_49, primals_50, primals_52, primals_53, primals_55, primals_56, primals_58, primals_59, primals_61, primals_62, primals_64, primals_65, primals_67, primals_68, primals_70, primals_71, primals_73, primals_74, primals_76, primals_77, primals_79, primals_80, primals_82, primals_83, primals_85, primals_86, primals_88, primals_89, primals_91, primals_92, primals_94, primals_95, primals_97, primals_98, primals_100, primals_101, primals_103, primals_104, primals_106, primals_107, primals_109, primals_110, primals_112, primals_113, primals_115, primals_116, primals_118, primals_119, primals_121, primals_122, primals_124, primals_125, primals_127, primals_128, primals_130, primals_131, primals_133, primals_134, primals_136, primals_137, primals_139, primals_140, primals_142, primals_143, primals_145, primals_146, primals_148, primals_149, primals_151, primals_152, primals_154, primals_155, primals_157, primals_158, primals_321, convolution, squeeze_1, relu, getitem_2, getitem_3, convolution_1, squeeze_4, relu_1, convolution_2, squeeze_7, relu_2, convolution_3, squeeze_10, convolution_4, squeeze_13, relu_3, convolution_5, squeeze_16, relu_4, convolution_6, squeeze_19, relu_5, convolution_7, squeeze_22, relu_6, convolution_8, squeeze_25, relu_7, convolution_9, squeeze_28, relu_8, convolution_10, squeeze_31, relu_9, convolution_11, squeeze_34, relu_10, convolution_12, squeeze_37, relu_11, convolution_13, squeeze_40, convolution_14, squeeze_43, relu_12, convolution_15, squeeze_46, relu_13, convolution_16, squeeze_49, relu_14, convolution_17, squeeze_52, relu_15, convolution_18, squeeze_55, relu_16, convolution_19, squeeze_58, relu_17, convolution_20, squeeze_61, relu_18, convolution_21, squeeze_64, relu_19, convolution_22, squeeze_67, relu_20, convolution_23, squeeze_70, relu_21, convolution_24, squeeze_73, relu_22, convolution_25, squeeze_76, relu_23, convolution_26, squeeze_79, convolution_27, squeeze_82, relu_24, convolution_28, squeeze_85, relu_25, convolution_29, squeeze_88, relu_26, convolution_30, squeeze_91, relu_27, convolution_31, squeeze_94, relu_28, convolution_32, squeeze_97, relu_29, convolution_33, squeeze_100, relu_30, convolution_34, squeeze_103, relu_31, convolution_35, squeeze_106, relu_32, convolution_36, squeeze_109, relu_33, convolution_37, squeeze_112, relu_34, convolution_38, squeeze_115, relu_35, convolution_39, squeeze_118, relu_36, convolution_40, squeeze_121, relu_37, convolution_41, squeeze_124, relu_38, convolution_42, squeeze_127, relu_39, convolution_43, squeeze_130, relu_40, convolution_44, relu_41, convolution_45, convolution_46, relu_42, convolution_47, relu_43, convolution_48, relu_44, convolution_49, relu_45, convolution_50, relu_46, convolution_51, relu_47, convolution_52, view, permute_1, le, unsqueeze_322, unsqueeze_334, unsqueeze_346, unsqueeze_358, unsqueeze_370, unsqueeze_382, unsqueeze_394, unsqueeze_406, unsqueeze_418, unsqueeze_430, unsqueeze_442, unsqueeze_454, unsqueeze_466, unsqueeze_478, unsqueeze_490, unsqueeze_502, unsqueeze_514, unsqueeze_526, unsqueeze_538, unsqueeze_550, unsqueeze_562, unsqueeze_574, unsqueeze_586, unsqueeze_598, unsqueeze_610, unsqueeze_622, unsqueeze_634, unsqueeze_646, unsqueeze_658, unsqueeze_670, unsqueeze_682, unsqueeze_694, unsqueeze_706, unsqueeze_718, unsqueeze_730, unsqueeze_742, unsqueeze_754, unsqueeze_766, unsqueeze_778, unsqueeze_790, unsqueeze_802, unsqueeze_814, unsqueeze_826, unsqueeze_838]
        

[aot_autograd.py:2900 INFO] TRACED GRAPH
 ===== Backward graph 28 =====
 <eval_with_key>.308 class GraphModule(torch.nn.Module):
    def forward(self, primals_1: f32[64, 3, 7, 7], primals_2: f32[64], primals_4: f32[64, 64, 1, 1], primals_5: f32[64], primals_7: f32[64, 64, 3, 3], primals_8: f32[64], primals_10: f32[256, 64, 1, 1], primals_11: f32[256], primals_13: f32[256, 64, 1, 1], primals_14: f32[256], primals_16: f32[64, 256, 1, 1], primals_17: f32[64], primals_19: f32[64, 64, 3, 3], primals_20: f32[64], primals_22: f32[256, 64, 1, 1], primals_23: f32[256], primals_25: f32[64, 256, 1, 1], primals_26: f32[64], primals_28: f32[64, 64, 3, 3], primals_29: f32[64], primals_31: f32[256, 64, 1, 1], primals_32: f32[256], primals_34: f32[128, 256, 1, 1], primals_35: f32[128], primals_37: f32[128, 128, 3, 3], primals_38: f32[128], primals_40: f32[512, 128, 1, 1], primals_41: f32[512], primals_43: f32[512, 256, 1, 1], primals_44: f32[512], primals_46: f32[128, 512, 1, 1], primals_47: f32[128], primals_49: f32[128, 128, 3, 3], primals_50: f32[128], primals_52: f32[512, 128, 1, 1], primals_53: f32[512], primals_55: f32[128, 512, 1, 1], primals_56: f32[128], primals_58: f32[128, 128, 3, 3], primals_59: f32[128], primals_61: f32[512, 128, 1, 1], primals_62: f32[512], primals_64: f32[128, 512, 1, 1], primals_65: f32[128], primals_67: f32[128, 128, 3, 3], primals_68: f32[128], primals_70: f32[512, 128, 1, 1], primals_71: f32[512], primals_73: f32[256, 512, 1, 1], primals_74: f32[256], primals_76: f32[256, 256, 3, 3], primals_77: f32[256], primals_79: f32[1024, 256, 1, 1], primals_80: f32[1024], primals_82: f32[1024, 512, 1, 1], primals_83: f32[1024], primals_85: f32[256, 1024, 1, 1], primals_86: f32[256], primals_88: f32[256, 256, 3, 3], primals_89: f32[256], primals_91: f32[1024, 256, 1, 1], primals_92: f32[1024], primals_94: f32[256, 1024, 1, 1], primals_95: f32[256], primals_97: f32[256, 256, 3, 3], primals_98: f32[256], primals_100: f32[1024, 256, 1, 1], primals_101: f32[1024], primals_103: f32[256, 1024, 1, 1], primals_104: f32[256], primals_106: f32[256, 256, 3, 3], primals_107: f32[256], primals_109: f32[1024, 256, 1, 1], primals_110: f32[1024], primals_112: f32[256, 1024, 1, 1], primals_113: f32[256], primals_115: f32[256, 256, 3, 3], primals_116: f32[256], primals_118: f32[1024, 256, 1, 1], primals_119: f32[1024], primals_121: f32[256, 1024, 1, 1], primals_122: f32[256], primals_124: f32[256, 256, 3, 3], primals_125: f32[256], primals_127: f32[1024, 256, 1, 1], primals_128: f32[1024], primals_130: f32[512, 1024, 1, 1], primals_131: f32[512], primals_133: f32[512, 512, 3, 3], primals_134: f32[512], primals_136: f32[2048, 512, 1, 1], primals_137: f32[2048], primals_139: f32[2048, 1024, 1, 1], primals_140: f32[2048], primals_142: f32[512, 2048, 1, 1], primals_143: f32[512], primals_145: f32[512, 512, 3, 3], primals_146: f32[512], primals_148: f32[2048, 512, 1, 1], primals_149: f32[2048], primals_151: f32[512, 2048, 1, 1], primals_152: f32[512], primals_154: f32[512, 512, 3, 3], primals_155: f32[512], primals_157: f32[2048, 512, 1, 1], primals_158: f32[2048], primals_321: f32[1, 3, 64, 64], convolution: f32[1, 64, 32, 32], squeeze_1: f32[64], relu: f32[1, 64, 32, 32], getitem_2: f32[1, 64, 16, 16], getitem_3: i64[1, 64, 16, 16], convolution_1: f32[1, 64, 16, 16], squeeze_4: f32[64], relu_1: f32[1, 64, 16, 16], convolution_2: f32[1, 64, 16, 16], squeeze_7: f32[64], relu_2: f32[1, 64, 16, 16], convolution_3: f32[1, 256, 16, 16], squeeze_10: f32[256], convolution_4: f32[1, 256, 16, 16], squeeze_13: f32[256], relu_3: f32[1, 256, 16, 16], convolution_5: f32[1, 64, 16, 16], squeeze_16: f32[64], relu_4: f32[1, 64, 16, 16], convolution_6: f32[1, 64, 16, 16], squeeze_19: f32[64], relu_5: f32[1, 64, 16, 16], convolution_7: f32[1, 256, 16, 16], squeeze_22: f32[256], relu_6: f32[1, 256, 16, 16], convolution_8: f32[1, 64, 16, 16], squeeze_25: f32[64], relu_7: f32[1, 64, 16, 16], convolution_9: f32[1, 64, 16, 16], squeeze_28: f32[64], relu_8: f32[1, 64, 16, 16], convolution_10: f32[1, 256, 16, 16], squeeze_31: f32[256], relu_9: f32[1, 256, 16, 16], convolution_11: f32[1, 128, 16, 16], squeeze_34: f32[128], relu_10: f32[1, 128, 16, 16], convolution_12: f32[1, 128, 8, 8], squeeze_37: f32[128], relu_11: f32[1, 128, 8, 8], convolution_13: f32[1, 512, 8, 8], squeeze_40: f32[512], convolution_14: f32[1, 512, 8, 8], squeeze_43: f32[512], relu_12: f32[1, 512, 8, 8], convolution_15: f32[1, 128, 8, 8], squeeze_46: f32[128], relu_13: f32[1, 128, 8, 8], convolution_16: f32[1, 128, 8, 8], squeeze_49: f32[128], relu_14: f32[1, 128, 8, 8], convolution_17: f32[1, 512, 8, 8], squeeze_52: f32[512], relu_15: f32[1, 512, 8, 8], convolution_18: f32[1, 128, 8, 8], squeeze_55: f32[128], relu_16: f32[1, 128, 8, 8], convolution_19: f32[1, 128, 8, 8], squeeze_58: f32[128], relu_17: f32[1, 128, 8, 8], convolution_20: f32[1, 512, 8, 8], squeeze_61: f32[512], relu_18: f32[1, 512, 8, 8], convolution_21: f32[1, 128, 8, 8], squeeze_64: f32[128], relu_19: f32[1, 128, 8, 8], convolution_22: f32[1, 128, 8, 8], squeeze_67: f32[128], relu_20: f32[1, 128, 8, 8], convolution_23: f32[1, 512, 8, 8], squeeze_70: f32[512], relu_21: f32[1, 512, 8, 8], convolution_24: f32[1, 256, 8, 8], squeeze_73: f32[256], relu_22: f32[1, 256, 8, 8], convolution_25: f32[1, 256, 4, 4], squeeze_76: f32[256], relu_23: f32[1, 256, 4, 4], convolution_26: f32[1, 1024, 4, 4], squeeze_79: f32[1024], convolution_27: f32[1, 1024, 4, 4], squeeze_82: f32[1024], relu_24: f32[1, 1024, 4, 4], convolution_28: f32[1, 256, 4, 4], squeeze_85: f32[256], relu_25: f32[1, 256, 4, 4], convolution_29: f32[1, 256, 4, 4], squeeze_88: f32[256], relu_26: f32[1, 256, 4, 4], convolution_30: f32[1, 1024, 4, 4], squeeze_91: f32[1024], relu_27: f32[1, 1024, 4, 4], convolution_31: f32[1, 256, 4, 4], squeeze_94: f32[256], relu_28: f32[1, 256, 4, 4], convolution_32: f32[1, 256, 4, 4], squeeze_97: f32[256], relu_29: f32[1, 256, 4, 4], convolution_33: f32[1, 1024, 4, 4], squeeze_100: f32[1024], relu_30: f32[1, 1024, 4, 4], convolution_34: f32[1, 256, 4, 4], squeeze_103: f32[256], relu_31: f32[1, 256, 4, 4], convolution_35: f32[1, 256, 4, 4], squeeze_106: f32[256], relu_32: f32[1, 256, 4, 4], convolution_36: f32[1, 1024, 4, 4], squeeze_109: f32[1024], relu_33: f32[1, 1024, 4, 4], convolution_37: f32[1, 256, 4, 4], squeeze_112: f32[256], relu_34: f32[1, 256, 4, 4], convolution_38: f32[1, 256, 4, 4], squeeze_115: f32[256], relu_35: f32[1, 256, 4, 4], convolution_39: f32[1, 1024, 4, 4], squeeze_118: f32[1024], relu_36: f32[1, 1024, 4, 4], convolution_40: f32[1, 256, 4, 4], squeeze_121: f32[256], relu_37: f32[1, 256, 4, 4], convolution_41: f32[1, 256, 4, 4], squeeze_124: f32[256], relu_38: f32[1, 256, 4, 4], convolution_42: f32[1, 1024, 4, 4], squeeze_127: f32[1024], relu_39: f32[1, 1024, 4, 4], convolution_43: f32[1, 512, 4, 4], squeeze_130: f32[512], relu_40: f32[1, 512, 4, 4], convolution_44: f32[1, 512, 2, 2], relu_41: f32[1, 512, 2, 2], convolution_45: f32[1, 2048, 2, 2], convolution_46: f32[1, 2048, 2, 2], relu_42: f32[1, 2048, 2, 2], convolution_47: f32[1, 512, 2, 2], relu_43: f32[1, 512, 2, 2], convolution_48: f32[1, 512, 2, 2], relu_44: f32[1, 512, 2, 2], convolution_49: f32[1, 2048, 2, 2], relu_45: f32[1, 2048, 2, 2], convolution_50: f32[1, 512, 2, 2], relu_46: f32[1, 512, 2, 2], convolution_51: f32[1, 512, 2, 2], relu_47: f32[1, 512, 2, 2], convolution_52: f32[1, 2048, 2, 2], view: f32[1, 2048], permute_1: f32[1000, 2048], le: b8[1, 2048, 2, 2], unsqueeze_322: f32[1, 512, 1, 1], unsqueeze_334: f32[1, 1024, 1, 1], unsqueeze_346: f32[1, 256, 1, 1], unsqueeze_358: f32[1, 256, 1, 1], unsqueeze_370: f32[1, 1024, 1, 1], unsqueeze_382: f32[1, 256, 1, 1], unsqueeze_394: f32[1, 256, 1, 1], unsqueeze_406: f32[1, 1024, 1, 1], unsqueeze_418: f32[1, 256, 1, 1], unsqueeze_430: f32[1, 256, 1, 1], unsqueeze_442: f32[1, 1024, 1, 1], unsqueeze_454: f32[1, 256, 1, 1], unsqueeze_466: f32[1, 256, 1, 1], unsqueeze_478: f32[1, 1024, 1, 1], unsqueeze_490: f32[1, 256, 1, 1], unsqueeze_502: f32[1, 256, 1, 1], unsqueeze_514: f32[1, 1024, 1, 1], unsqueeze_526: f32[1, 1024, 1, 1], unsqueeze_538: f32[1, 256, 1, 1], unsqueeze_550: f32[1, 256, 1, 1], unsqueeze_562: f32[1, 512, 1, 1], unsqueeze_574: f32[1, 128, 1, 1], unsqueeze_586: f32[1, 128, 1, 1], unsqueeze_598: f32[1, 512, 1, 1], unsqueeze_610: f32[1, 128, 1, 1], unsqueeze_622: f32[1, 128, 1, 1], unsqueeze_634: f32[1, 512, 1, 1], unsqueeze_646: f32[1, 128, 1, 1], unsqueeze_658: f32[1, 128, 1, 1], unsqueeze_670: f32[1, 512, 1, 1], unsqueeze_682: f32[1, 512, 1, 1], unsqueeze_694: f32[1, 128, 1, 1], unsqueeze_706: f32[1, 128, 1, 1], unsqueeze_718: f32[1, 256, 1, 1], unsqueeze_730: f32[1, 64, 1, 1], unsqueeze_742: f32[1, 64, 1, 1], unsqueeze_754: f32[1, 256, 1, 1], unsqueeze_766: f32[1, 64, 1, 1], unsqueeze_778: f32[1, 64, 1, 1], unsqueeze_790: f32[1, 256, 1, 1], unsqueeze_802: f32[1, 256, 1, 1], unsqueeze_814: f32[1, 64, 1, 1], unsqueeze_826: f32[1, 64, 1, 1], unsqueeze_838: f32[1, 64, 1, 1], tangents_1: f32[64], tangents_2: f32[64], tangents_3: i64[], tangents_4: f32[64], tangents_5: f32[64], tangents_6: i64[], tangents_7: f32[64], tangents_8: f32[64], tangents_9: i64[], tangents_10: f32[256], tangents_11: f32[256], tangents_12: i64[], tangents_13: f32[256], tangents_14: f32[256], tangents_15: i64[], tangents_16: f32[64], tangents_17: f32[64], tangents_18: i64[], tangents_19: f32[64], tangents_20: f32[64], tangents_21: i64[], tangents_22: f32[256], tangents_23: f32[256], tangents_24: i64[], tangents_25: f32[64], tangents_26: f32[64], tangents_27: i64[], tangents_28: f32[64], tangents_29: f32[64], tangents_30: i64[], tangents_31: f32[256], tangents_32: f32[256], tangents_33: i64[], tangents_34: f32[128], tangents_35: f32[128], tangents_36: i64[], tangents_37: f32[128], tangents_38: f32[128], tangents_39: i64[], tangents_40: f32[512], tangents_41: f32[512], tangents_42: i64[], tangents_43: f32[512], tangents_44: f32[512], tangents_45: i64[], tangents_46: f32[128], tangents_47: f32[128], tangents_48: i64[], tangents_49: f32[128], tangents_50: f32[128], tangents_51: i64[], tangents_52: f32[512], tangents_53: f32[512], tangents_54: i64[], tangents_55: f32[128], tangents_56: f32[128], tangents_57: i64[], tangents_58: f32[128], tangents_59: f32[128], tangents_60: i64[], tangents_61: f32[512], tangents_62: f32[512], tangents_63: i64[], tangents_64: f32[128], tangents_65: f32[128], tangents_66: i64[], tangents_67: f32[128], tangents_68: f32[128], tangents_69: i64[], tangents_70: f32[512], tangents_71: f32[512], tangents_72: i64[], tangents_73: f32[256], tangents_74: f32[256], tangents_75: i64[], tangents_76: f32[256], tangents_77: f32[256], tangents_78: i64[], tangents_79: f32[1024], tangents_80: f32[1024], tangents_81: i64[], tangents_82: f32[1024], tangents_83: f32[1024], tangents_84: i64[], tangents_85: f32[256], tangents_86: f32[256], tangents_87: i64[], tangents_88: f32[256], tangents_89: f32[256], tangents_90: i64[], tangents_91: f32[1024], tangents_92: f32[1024], tangents_93: i64[], tangents_94: f32[256], tangents_95: f32[256], tangents_96: i64[], tangents_97: f32[256], tangents_98: f32[256], tangents_99: i64[], tangents_100: f32[1024], tangents_101: f32[1024], tangents_102: i64[], tangents_103: f32[256], tangents_104: f32[256], tangents_105: i64[], tangents_106: f32[256], tangents_107: f32[256], tangents_108: i64[], tangents_109: f32[1024], tangents_110: f32[1024], tangents_111: i64[], tangents_112: f32[256], tangents_113: f32[256], tangents_114: i64[], tangents_115: f32[256], tangents_116: f32[256], tangents_117: i64[], tangents_118: f32[1024], tangents_119: f32[1024], tangents_120: i64[], tangents_121: f32[256], tangents_122: f32[256], tangents_123: i64[], tangents_124: f32[256], tangents_125: f32[256], tangents_126: i64[], tangents_127: f32[1024], tangents_128: f32[1024], tangents_129: i64[], tangents_130: f32[512], tangents_131: f32[512], tangents_132: i64[], tangents_133: f32[512], tangents_134: f32[512], tangents_135: i64[], tangents_136: f32[2048], tangents_137: f32[2048], tangents_138: i64[], tangents_139: f32[2048], tangents_140: f32[2048], tangents_141: i64[], tangents_142: f32[512], tangents_143: f32[512], tangents_144: i64[], tangents_145: f32[512], tangents_146: f32[512], tangents_147: i64[], tangents_148: f32[2048], tangents_149: f32[2048], tangents_150: i64[], tangents_151: f32[512], tangents_152: f32[512], tangents_153: i64[], tangents_154: f32[512], tangents_155: f32[512], tangents_156: i64[], tangents_157: f32[2048], tangents_158: f32[2048], tangents_159: i64[], tangents_160: f32[1, 1000]):
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        var_mean_44 = torch.ops.aten.var_mean.correction(convolution_44, [0, 2, 3], correction = 0, keepdim = True)
        getitem_90: f32[1, 512, 1, 1] = var_mean_44[0]
        getitem_91: f32[1, 512, 1, 1] = var_mean_44[1];  var_mean_44 = None
        add_234: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_90, 1e-05);  getitem_90 = None
        rsqrt_44: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_234);  add_234 = None
        squeeze_132: f32[512] = torch.ops.aten.squeeze.dims(getitem_91, [0, 2, 3]);  getitem_91 = None
        squeeze_133: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_44, [0, 2, 3]);  rsqrt_44 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        var_mean_45 = torch.ops.aten.var_mean.correction(convolution_45, [0, 2, 3], correction = 0, keepdim = True)
        getitem_92: f32[1, 2048, 1, 1] = var_mean_45[0]
        getitem_93: f32[1, 2048, 1, 1] = var_mean_45[1];  var_mean_45 = None
        add_239: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_92, 1e-05);  getitem_92 = None
        rsqrt_45: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_239);  add_239 = None
        squeeze_135: f32[2048] = torch.ops.aten.squeeze.dims(getitem_93, [0, 2, 3]);  getitem_93 = None
        squeeze_136: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_45, [0, 2, 3]);  rsqrt_45 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        var_mean_46 = torch.ops.aten.var_mean.correction(convolution_46, [0, 2, 3], correction = 0, keepdim = True)
        getitem_94: f32[1, 2048, 1, 1] = var_mean_46[0]
        getitem_95: f32[1, 2048, 1, 1] = var_mean_46[1];  var_mean_46 = None
        add_244: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_94, 1e-05);  getitem_94 = None
        rsqrt_46: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_244);  add_244 = None
        squeeze_138: f32[2048] = torch.ops.aten.squeeze.dims(getitem_95, [0, 2, 3]);  getitem_95 = None
        squeeze_139: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_46, [0, 2, 3]);  rsqrt_46 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        var_mean_47 = torch.ops.aten.var_mean.correction(convolution_47, [0, 2, 3], correction = 0, keepdim = True)
        getitem_96: f32[1, 512, 1, 1] = var_mean_47[0]
        getitem_97: f32[1, 512, 1, 1] = var_mean_47[1];  var_mean_47 = None
        add_250: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_96, 1e-05);  getitem_96 = None
        rsqrt_47: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_250);  add_250 = None
        squeeze_141: f32[512] = torch.ops.aten.squeeze.dims(getitem_97, [0, 2, 3]);  getitem_97 = None
        squeeze_142: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_47, [0, 2, 3]);  rsqrt_47 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        var_mean_48 = torch.ops.aten.var_mean.correction(convolution_48, [0, 2, 3], correction = 0, keepdim = True)
        getitem_98: f32[1, 512, 1, 1] = var_mean_48[0]
        getitem_99: f32[1, 512, 1, 1] = var_mean_48[1];  var_mean_48 = None
        add_255: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_98, 1e-05);  getitem_98 = None
        rsqrt_48: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_255);  add_255 = None
        squeeze_144: f32[512] = torch.ops.aten.squeeze.dims(getitem_99, [0, 2, 3]);  getitem_99 = None
        squeeze_145: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_48, [0, 2, 3]);  rsqrt_48 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        var_mean_49 = torch.ops.aten.var_mean.correction(convolution_49, [0, 2, 3], correction = 0, keepdim = True)
        getitem_100: f32[1, 2048, 1, 1] = var_mean_49[0]
        getitem_101: f32[1, 2048, 1, 1] = var_mean_49[1];  var_mean_49 = None
        add_260: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_100, 1e-05);  getitem_100 = None
        rsqrt_49: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_260);  add_260 = None
        squeeze_147: f32[2048] = torch.ops.aten.squeeze.dims(getitem_101, [0, 2, 3]);  getitem_101 = None
        squeeze_148: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_49, [0, 2, 3]);  rsqrt_49 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        var_mean_50 = torch.ops.aten.var_mean.correction(convolution_50, [0, 2, 3], correction = 0, keepdim = True)
        getitem_102: f32[1, 512, 1, 1] = var_mean_50[0]
        getitem_103: f32[1, 512, 1, 1] = var_mean_50[1];  var_mean_50 = None
        add_266: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_102, 1e-05);  getitem_102 = None
        rsqrt_50: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_266);  add_266 = None
        squeeze_150: f32[512] = torch.ops.aten.squeeze.dims(getitem_103, [0, 2, 3]);  getitem_103 = None
        squeeze_151: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_50, [0, 2, 3]);  rsqrt_50 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        var_mean_51 = torch.ops.aten.var_mean.correction(convolution_51, [0, 2, 3], correction = 0, keepdim = True)
        getitem_104: f32[1, 512, 1, 1] = var_mean_51[0]
        getitem_105: f32[1, 512, 1, 1] = var_mean_51[1];  var_mean_51 = None
        add_271: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_104, 1e-05);  getitem_104 = None
        rsqrt_51: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_271);  add_271 = None
        squeeze_153: f32[512] = torch.ops.aten.squeeze.dims(getitem_105, [0, 2, 3]);  getitem_105 = None
        squeeze_154: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_51, [0, 2, 3]);  rsqrt_51 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        var_mean_52 = torch.ops.aten.var_mean.correction(convolution_52, [0, 2, 3], correction = 0, keepdim = True)
        getitem_106: f32[1, 2048, 1, 1] = var_mean_52[0]
        getitem_107: f32[1, 2048, 1, 1] = var_mean_52[1];  var_mean_52 = None
        add_276: f32[1, 2048, 1, 1] = torch.ops.aten.add.Tensor(getitem_106, 1e-05);  getitem_106 = None
        rsqrt_52: f32[1, 2048, 1, 1] = torch.ops.aten.rsqrt.default(add_276);  add_276 = None
        squeeze_156: f32[2048] = torch.ops.aten.squeeze.dims(getitem_107, [0, 2, 3]);  getitem_107 = None
        squeeze_157: f32[2048] = torch.ops.aten.squeeze.dims(rsqrt_52, [0, 2, 3]);  rsqrt_52 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:244, code: x = self.fc(x)
        mm: f32[1, 2048] = torch.ops.aten.mm.default(tangents_160, permute_1);  permute_1 = None
        permute_2: f32[1000, 1] = torch.ops.aten.permute.default(tangents_160, [1, 0])
        mm_1: f32[1000, 2048] = torch.ops.aten.mm.default(permute_2, view);  permute_2 = view = None
        permute_3: f32[2048, 1000] = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
        sum_1: f32[1, 1000] = torch.ops.aten.sum.dim_IntList(tangents_160, [0], True);  tangents_160 = None
        view_1: f32[1000] = torch.ops.aten.view.default(sum_1, [1000]);  sum_1 = None
        permute_4: f32[1000, 2048] = torch.ops.aten.permute.default(permute_3, [1, 0]);  permute_3 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:243, code: x = torch.flatten(x, 1)
        view_2: f32[1, 2048, 1, 1] = torch.ops.aten.view.default(mm, [1, 2048, 1, 1]);  mm = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:242, code: x = self.avgpool(x)
        expand: f32[1, 2048, 2, 2] = torch.ops.aten.expand.default(view_2, [1, 2048, 2, 2]);  view_2 = None
        div: f32[1, 2048, 2, 2] = torch.ops.aten.div.Scalar(expand, 4);  expand = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        full_default: f32[] = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        where: f32[1, 2048, 2, 2] = torch.ops.aten.where.self(le, full_default, div);  le = div = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_212: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_156, 0);  squeeze_156 = None
        unsqueeze_213: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_212, 2);  unsqueeze_212 = None
        unsqueeze_214: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_213, 3);  unsqueeze_213 = None
        sum_2: f32[2048] = torch.ops.aten.sum.dim_IntList(where, [0, 2, 3])
        sub_53: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_52, unsqueeze_214);  convolution_52 = unsqueeze_214 = None
        mul_371: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(where, sub_53)
        sum_3: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_371, [0, 2, 3]);  mul_371 = None
        mul_372: f32[2048] = torch.ops.aten.mul.Tensor(sum_2, 0.25)
        unsqueeze_215: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_372, 0);  mul_372 = None
        unsqueeze_216: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_215, 2);  unsqueeze_215 = None
        unsqueeze_217: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_216, 3);  unsqueeze_216 = None
        mul_373: f32[2048] = torch.ops.aten.mul.Tensor(sum_3, 0.25)
        mul_374: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_157, squeeze_157)
        mul_375: f32[2048] = torch.ops.aten.mul.Tensor(mul_373, mul_374);  mul_373 = mul_374 = None
        unsqueeze_218: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_375, 0);  mul_375 = None
        unsqueeze_219: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_218, 2);  unsqueeze_218 = None
        unsqueeze_220: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_219, 3);  unsqueeze_219 = None
        mul_376: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_157, primals_158);  primals_158 = None
        unsqueeze_221: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_376, 0);  mul_376 = None
        unsqueeze_222: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_221, 2);  unsqueeze_221 = None
        unsqueeze_223: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_222, 3);  unsqueeze_222 = None
        mul_377: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_53, unsqueeze_220);  sub_53 = unsqueeze_220 = None
        sub_55: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(where, mul_377);  mul_377 = None
        sub_56: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(sub_55, unsqueeze_217);  sub_55 = unsqueeze_217 = None
        mul_378: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_56, unsqueeze_223);  sub_56 = unsqueeze_223 = None
        mul_379: f32[2048] = torch.ops.aten.mul.Tensor(sum_3, squeeze_157);  sum_3 = squeeze_157 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward = torch.ops.aten.convolution_backward.default(mul_378, relu_47, primals_157, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_378 = primals_157 = None
        getitem_108: f32[1, 512, 2, 2] = convolution_backward[0]
        getitem_109: f32[2048, 512, 1, 1] = convolution_backward[1];  convolution_backward = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_1: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_47, 0);  relu_47 = None
        where_1: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_1, full_default, getitem_108);  le_1 = getitem_108 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_224: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_153, 0);  squeeze_153 = None
        unsqueeze_225: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_224, 2);  unsqueeze_224 = None
        unsqueeze_226: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_225, 3);  unsqueeze_225 = None
        sum_4: f32[512] = torch.ops.aten.sum.dim_IntList(where_1, [0, 2, 3])
        sub_57: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_51, unsqueeze_226);  convolution_51 = unsqueeze_226 = None
        mul_380: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_1, sub_57)
        sum_5: f32[512] = torch.ops.aten.sum.dim_IntList(mul_380, [0, 2, 3]);  mul_380 = None
        mul_381: f32[512] = torch.ops.aten.mul.Tensor(sum_4, 0.25)
        unsqueeze_227: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_381, 0);  mul_381 = None
        unsqueeze_228: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_227, 2);  unsqueeze_227 = None
        unsqueeze_229: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_228, 3);  unsqueeze_228 = None
        mul_382: f32[512] = torch.ops.aten.mul.Tensor(sum_5, 0.25)
        mul_383: f32[512] = torch.ops.aten.mul.Tensor(squeeze_154, squeeze_154)
        mul_384: f32[512] = torch.ops.aten.mul.Tensor(mul_382, mul_383);  mul_382 = mul_383 = None
        unsqueeze_230: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_384, 0);  mul_384 = None
        unsqueeze_231: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_230, 2);  unsqueeze_230 = None
        unsqueeze_232: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_231, 3);  unsqueeze_231 = None
        mul_385: f32[512] = torch.ops.aten.mul.Tensor(squeeze_154, primals_155);  primals_155 = None
        unsqueeze_233: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_385, 0);  mul_385 = None
        unsqueeze_234: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_233, 2);  unsqueeze_233 = None
        unsqueeze_235: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_234, 3);  unsqueeze_234 = None
        mul_386: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_57, unsqueeze_232);  sub_57 = unsqueeze_232 = None
        sub_59: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_1, mul_386);  where_1 = mul_386 = None
        sub_60: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_59, unsqueeze_229);  sub_59 = unsqueeze_229 = None
        mul_387: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_60, unsqueeze_235);  sub_60 = unsqueeze_235 = None
        mul_388: f32[512] = torch.ops.aten.mul.Tensor(sum_5, squeeze_154);  sum_5 = squeeze_154 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_1 = torch.ops.aten.convolution_backward.default(mul_387, relu_46, primals_154, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_387 = primals_154 = None
        getitem_111: f32[1, 512, 2, 2] = convolution_backward_1[0]
        getitem_112: f32[512, 512, 3, 3] = convolution_backward_1[1];  convolution_backward_1 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_2: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_46, 0);  relu_46 = None
        where_2: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_2, full_default, getitem_111);  le_2 = getitem_111 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_236: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_150, 0);  squeeze_150 = None
        unsqueeze_237: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_236, 2);  unsqueeze_236 = None
        unsqueeze_238: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_237, 3);  unsqueeze_237 = None
        sum_6: f32[512] = torch.ops.aten.sum.dim_IntList(where_2, [0, 2, 3])
        sub_61: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_50, unsqueeze_238);  convolution_50 = unsqueeze_238 = None
        mul_389: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_2, sub_61)
        sum_7: f32[512] = torch.ops.aten.sum.dim_IntList(mul_389, [0, 2, 3]);  mul_389 = None
        mul_390: f32[512] = torch.ops.aten.mul.Tensor(sum_6, 0.25)
        unsqueeze_239: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_390, 0);  mul_390 = None
        unsqueeze_240: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_239, 2);  unsqueeze_239 = None
        unsqueeze_241: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_240, 3);  unsqueeze_240 = None
        mul_391: f32[512] = torch.ops.aten.mul.Tensor(sum_7, 0.25)
        mul_392: f32[512] = torch.ops.aten.mul.Tensor(squeeze_151, squeeze_151)
        mul_393: f32[512] = torch.ops.aten.mul.Tensor(mul_391, mul_392);  mul_391 = mul_392 = None
        unsqueeze_242: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_393, 0);  mul_393 = None
        unsqueeze_243: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_242, 2);  unsqueeze_242 = None
        unsqueeze_244: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_243, 3);  unsqueeze_243 = None
        mul_394: f32[512] = torch.ops.aten.mul.Tensor(squeeze_151, primals_152);  primals_152 = None
        unsqueeze_245: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_394, 0);  mul_394 = None
        unsqueeze_246: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_245, 2);  unsqueeze_245 = None
        unsqueeze_247: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_246, 3);  unsqueeze_246 = None
        mul_395: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_61, unsqueeze_244);  sub_61 = unsqueeze_244 = None
        sub_63: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_2, mul_395);  where_2 = mul_395 = None
        sub_64: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_63, unsqueeze_241);  sub_63 = unsqueeze_241 = None
        mul_396: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_64, unsqueeze_247);  sub_64 = unsqueeze_247 = None
        mul_397: f32[512] = torch.ops.aten.mul.Tensor(sum_7, squeeze_151);  sum_7 = squeeze_151 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_2 = torch.ops.aten.convolution_backward.default(mul_396, relu_45, primals_151, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_396 = primals_151 = None
        getitem_114: f32[1, 2048, 2, 2] = convolution_backward_2[0]
        getitem_115: f32[512, 2048, 1, 1] = convolution_backward_2[1];  convolution_backward_2 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_281: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(where, getitem_114);  where = getitem_114 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_3: b8[1, 2048, 2, 2] = torch.ops.aten.le.Scalar(relu_45, 0);  relu_45 = None
        where_3: f32[1, 2048, 2, 2] = torch.ops.aten.where.self(le_3, full_default, add_281);  le_3 = add_281 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_248: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_147, 0);  squeeze_147 = None
        unsqueeze_249: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_248, 2);  unsqueeze_248 = None
        unsqueeze_250: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_249, 3);  unsqueeze_249 = None
        sum_8: f32[2048] = torch.ops.aten.sum.dim_IntList(where_3, [0, 2, 3])
        sub_65: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_49, unsqueeze_250);  convolution_49 = unsqueeze_250 = None
        mul_398: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(where_3, sub_65)
        sum_9: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_398, [0, 2, 3]);  mul_398 = None
        mul_399: f32[2048] = torch.ops.aten.mul.Tensor(sum_8, 0.25)
        unsqueeze_251: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_399, 0);  mul_399 = None
        unsqueeze_252: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_251, 2);  unsqueeze_251 = None
        unsqueeze_253: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_252, 3);  unsqueeze_252 = None
        mul_400: f32[2048] = torch.ops.aten.mul.Tensor(sum_9, 0.25)
        mul_401: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_148, squeeze_148)
        mul_402: f32[2048] = torch.ops.aten.mul.Tensor(mul_400, mul_401);  mul_400 = mul_401 = None
        unsqueeze_254: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_402, 0);  mul_402 = None
        unsqueeze_255: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_254, 2);  unsqueeze_254 = None
        unsqueeze_256: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_255, 3);  unsqueeze_255 = None
        mul_403: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_148, primals_149);  primals_149 = None
        unsqueeze_257: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_403, 0);  mul_403 = None
        unsqueeze_258: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_257, 2);  unsqueeze_257 = None
        unsqueeze_259: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_258, 3);  unsqueeze_258 = None
        mul_404: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_65, unsqueeze_256);  sub_65 = unsqueeze_256 = None
        sub_67: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(where_3, mul_404);  mul_404 = None
        sub_68: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(sub_67, unsqueeze_253);  sub_67 = unsqueeze_253 = None
        mul_405: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_68, unsqueeze_259);  sub_68 = unsqueeze_259 = None
        mul_406: f32[2048] = torch.ops.aten.mul.Tensor(sum_9, squeeze_148);  sum_9 = squeeze_148 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_3 = torch.ops.aten.convolution_backward.default(mul_405, relu_44, primals_148, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_405 = primals_148 = None
        getitem_117: f32[1, 512, 2, 2] = convolution_backward_3[0]
        getitem_118: f32[2048, 512, 1, 1] = convolution_backward_3[1];  convolution_backward_3 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_4: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_44, 0);  relu_44 = None
        where_4: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_4, full_default, getitem_117);  le_4 = getitem_117 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_260: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_144, 0);  squeeze_144 = None
        unsqueeze_261: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_260, 2);  unsqueeze_260 = None
        unsqueeze_262: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_261, 3);  unsqueeze_261 = None
        sum_10: f32[512] = torch.ops.aten.sum.dim_IntList(where_4, [0, 2, 3])
        sub_69: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_48, unsqueeze_262);  convolution_48 = unsqueeze_262 = None
        mul_407: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_4, sub_69)
        sum_11: f32[512] = torch.ops.aten.sum.dim_IntList(mul_407, [0, 2, 3]);  mul_407 = None
        mul_408: f32[512] = torch.ops.aten.mul.Tensor(sum_10, 0.25)
        unsqueeze_263: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_408, 0);  mul_408 = None
        unsqueeze_264: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_263, 2);  unsqueeze_263 = None
        unsqueeze_265: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_264, 3);  unsqueeze_264 = None
        mul_409: f32[512] = torch.ops.aten.mul.Tensor(sum_11, 0.25)
        mul_410: f32[512] = torch.ops.aten.mul.Tensor(squeeze_145, squeeze_145)
        mul_411: f32[512] = torch.ops.aten.mul.Tensor(mul_409, mul_410);  mul_409 = mul_410 = None
        unsqueeze_266: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_411, 0);  mul_411 = None
        unsqueeze_267: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_266, 2);  unsqueeze_266 = None
        unsqueeze_268: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_267, 3);  unsqueeze_267 = None
        mul_412: f32[512] = torch.ops.aten.mul.Tensor(squeeze_145, primals_146);  primals_146 = None
        unsqueeze_269: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_412, 0);  mul_412 = None
        unsqueeze_270: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_269, 2);  unsqueeze_269 = None
        unsqueeze_271: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_270, 3);  unsqueeze_270 = None
        mul_413: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_69, unsqueeze_268);  sub_69 = unsqueeze_268 = None
        sub_71: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_4, mul_413);  where_4 = mul_413 = None
        sub_72: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_71, unsqueeze_265);  sub_71 = unsqueeze_265 = None
        mul_414: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_72, unsqueeze_271);  sub_72 = unsqueeze_271 = None
        mul_415: f32[512] = torch.ops.aten.mul.Tensor(sum_11, squeeze_145);  sum_11 = squeeze_145 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_4 = torch.ops.aten.convolution_backward.default(mul_414, relu_43, primals_145, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_414 = primals_145 = None
        getitem_120: f32[1, 512, 2, 2] = convolution_backward_4[0]
        getitem_121: f32[512, 512, 3, 3] = convolution_backward_4[1];  convolution_backward_4 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_5: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_43, 0);  relu_43 = None
        where_5: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_5, full_default, getitem_120);  le_5 = getitem_120 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        unsqueeze_272: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_141, 0);  squeeze_141 = None
        unsqueeze_273: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_272, 2);  unsqueeze_272 = None
        unsqueeze_274: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_273, 3);  unsqueeze_273 = None
        sum_12: f32[512] = torch.ops.aten.sum.dim_IntList(where_5, [0, 2, 3])
        sub_73: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_47, unsqueeze_274);  convolution_47 = unsqueeze_274 = None
        mul_416: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_5, sub_73)
        sum_13: f32[512] = torch.ops.aten.sum.dim_IntList(mul_416, [0, 2, 3]);  mul_416 = None
        mul_417: f32[512] = torch.ops.aten.mul.Tensor(sum_12, 0.25)
        unsqueeze_275: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_417, 0);  mul_417 = None
        unsqueeze_276: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_275, 2);  unsqueeze_275 = None
        unsqueeze_277: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_276, 3);  unsqueeze_276 = None
        mul_418: f32[512] = torch.ops.aten.mul.Tensor(sum_13, 0.25)
        mul_419: f32[512] = torch.ops.aten.mul.Tensor(squeeze_142, squeeze_142)
        mul_420: f32[512] = torch.ops.aten.mul.Tensor(mul_418, mul_419);  mul_418 = mul_419 = None
        unsqueeze_278: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_420, 0);  mul_420 = None
        unsqueeze_279: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_278, 2);  unsqueeze_278 = None
        unsqueeze_280: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_279, 3);  unsqueeze_279 = None
        mul_421: f32[512] = torch.ops.aten.mul.Tensor(squeeze_142, primals_143);  primals_143 = None
        unsqueeze_281: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_421, 0);  mul_421 = None
        unsqueeze_282: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_281, 2);  unsqueeze_281 = None
        unsqueeze_283: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_282, 3);  unsqueeze_282 = None
        mul_422: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_73, unsqueeze_280);  sub_73 = unsqueeze_280 = None
        sub_75: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_5, mul_422);  where_5 = mul_422 = None
        sub_76: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_75, unsqueeze_277);  sub_75 = unsqueeze_277 = None
        mul_423: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_76, unsqueeze_283);  sub_76 = unsqueeze_283 = None
        mul_424: f32[512] = torch.ops.aten.mul.Tensor(sum_13, squeeze_142);  sum_13 = squeeze_142 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_5 = torch.ops.aten.convolution_backward.default(mul_423, relu_42, primals_142, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_423 = primals_142 = None
        getitem_123: f32[1, 2048, 2, 2] = convolution_backward_5[0]
        getitem_124: f32[512, 2048, 1, 1] = convolution_backward_5[1];  convolution_backward_5 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_282: f32[1, 2048, 2, 2] = torch.ops.aten.add.Tensor(where_3, getitem_123);  where_3 = getitem_123 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_6: b8[1, 2048, 2, 2] = torch.ops.aten.le.Scalar(relu_42, 0);  relu_42 = None
        where_6: f32[1, 2048, 2, 2] = torch.ops.aten.where.self(le_6, full_default, add_282);  le_6 = add_282 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        unsqueeze_284: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_138, 0);  squeeze_138 = None
        unsqueeze_285: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_284, 2);  unsqueeze_284 = None
        unsqueeze_286: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_285, 3);  unsqueeze_285 = None
        sum_14: f32[2048] = torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])
        sub_77: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_46, unsqueeze_286);  convolution_46 = unsqueeze_286 = None
        mul_425: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(where_6, sub_77)
        sum_15: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_425, [0, 2, 3]);  mul_425 = None
        mul_426: f32[2048] = torch.ops.aten.mul.Tensor(sum_14, 0.25)
        unsqueeze_287: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_426, 0);  mul_426 = None
        unsqueeze_288: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_287, 2);  unsqueeze_287 = None
        unsqueeze_289: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_288, 3);  unsqueeze_288 = None
        mul_427: f32[2048] = torch.ops.aten.mul.Tensor(sum_15, 0.25)
        mul_428: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_139, squeeze_139)
        mul_429: f32[2048] = torch.ops.aten.mul.Tensor(mul_427, mul_428);  mul_427 = mul_428 = None
        unsqueeze_290: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_429, 0);  mul_429 = None
        unsqueeze_291: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_290, 2);  unsqueeze_290 = None
        unsqueeze_292: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_291, 3);  unsqueeze_291 = None
        mul_430: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_139, primals_140);  primals_140 = None
        unsqueeze_293: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_430, 0);  mul_430 = None
        unsqueeze_294: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_293, 2);  unsqueeze_293 = None
        unsqueeze_295: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_294, 3);  unsqueeze_294 = None
        mul_431: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_77, unsqueeze_292);  sub_77 = unsqueeze_292 = None
        sub_79: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(where_6, mul_431);  mul_431 = None
        sub_80: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(sub_79, unsqueeze_289);  sub_79 = None
        mul_432: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_80, unsqueeze_295);  sub_80 = unsqueeze_295 = None
        mul_433: f32[2048] = torch.ops.aten.mul.Tensor(sum_15, squeeze_139);  sum_15 = squeeze_139 = None
        convolution_backward_6 = torch.ops.aten.convolution_backward.default(mul_432, relu_39, primals_139, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_432 = primals_139 = None
        getitem_126: f32[1, 1024, 4, 4] = convolution_backward_6[0]
        getitem_127: f32[2048, 1024, 1, 1] = convolution_backward_6[1];  convolution_backward_6 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        unsqueeze_296: f32[1, 2048] = torch.ops.aten.unsqueeze.default(squeeze_135, 0);  squeeze_135 = None
        unsqueeze_297: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_296, 2);  unsqueeze_296 = None
        unsqueeze_298: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_297, 3);  unsqueeze_297 = None
        sub_81: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(convolution_45, unsqueeze_298);  convolution_45 = unsqueeze_298 = None
        mul_434: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(where_6, sub_81)
        sum_17: f32[2048] = torch.ops.aten.sum.dim_IntList(mul_434, [0, 2, 3]);  mul_434 = None
        mul_436: f32[2048] = torch.ops.aten.mul.Tensor(sum_17, 0.25)
        mul_437: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_136, squeeze_136)
        mul_438: f32[2048] = torch.ops.aten.mul.Tensor(mul_436, mul_437);  mul_436 = mul_437 = None
        unsqueeze_302: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_438, 0);  mul_438 = None
        unsqueeze_303: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_302, 2);  unsqueeze_302 = None
        unsqueeze_304: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_303, 3);  unsqueeze_303 = None
        mul_439: f32[2048] = torch.ops.aten.mul.Tensor(squeeze_136, primals_137);  primals_137 = None
        unsqueeze_305: f32[1, 2048] = torch.ops.aten.unsqueeze.default(mul_439, 0);  mul_439 = None
        unsqueeze_306: f32[1, 2048, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_305, 2);  unsqueeze_305 = None
        unsqueeze_307: f32[1, 2048, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_306, 3);  unsqueeze_306 = None
        mul_440: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_81, unsqueeze_304);  sub_81 = unsqueeze_304 = None
        sub_83: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(where_6, mul_440);  where_6 = mul_440 = None
        sub_84: f32[1, 2048, 2, 2] = torch.ops.aten.sub.Tensor(sub_83, unsqueeze_289);  sub_83 = unsqueeze_289 = None
        mul_441: f32[1, 2048, 2, 2] = torch.ops.aten.mul.Tensor(sub_84, unsqueeze_307);  sub_84 = unsqueeze_307 = None
        mul_442: f32[2048] = torch.ops.aten.mul.Tensor(sum_17, squeeze_136);  sum_17 = squeeze_136 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_7 = torch.ops.aten.convolution_backward.default(mul_441, relu_41, primals_136, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_441 = primals_136 = None
        getitem_129: f32[1, 512, 2, 2] = convolution_backward_7[0]
        getitem_130: f32[2048, 512, 1, 1] = convolution_backward_7[1];  convolution_backward_7 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_7: b8[1, 512, 2, 2] = torch.ops.aten.le.Scalar(relu_41, 0);  relu_41 = None
        where_7: f32[1, 512, 2, 2] = torch.ops.aten.where.self(le_7, full_default, getitem_129);  le_7 = getitem_129 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        unsqueeze_308: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_132, 0);  squeeze_132 = None
        unsqueeze_309: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_308, 2);  unsqueeze_308 = None
        unsqueeze_310: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_309, 3);  unsqueeze_309 = None
        sum_18: f32[512] = torch.ops.aten.sum.dim_IntList(where_7, [0, 2, 3])
        sub_85: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(convolution_44, unsqueeze_310);  convolution_44 = unsqueeze_310 = None
        mul_443: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(where_7, sub_85)
        sum_19: f32[512] = torch.ops.aten.sum.dim_IntList(mul_443, [0, 2, 3]);  mul_443 = None
        mul_444: f32[512] = torch.ops.aten.mul.Tensor(sum_18, 0.25)
        unsqueeze_311: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_444, 0);  mul_444 = None
        unsqueeze_312: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_311, 2);  unsqueeze_311 = None
        unsqueeze_313: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_312, 3);  unsqueeze_312 = None
        mul_445: f32[512] = torch.ops.aten.mul.Tensor(sum_19, 0.25)
        mul_446: f32[512] = torch.ops.aten.mul.Tensor(squeeze_133, squeeze_133)
        mul_447: f32[512] = torch.ops.aten.mul.Tensor(mul_445, mul_446);  mul_445 = mul_446 = None
        unsqueeze_314: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_447, 0);  mul_447 = None
        unsqueeze_315: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_314, 2);  unsqueeze_314 = None
        unsqueeze_316: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_315, 3);  unsqueeze_315 = None
        mul_448: f32[512] = torch.ops.aten.mul.Tensor(squeeze_133, primals_134);  primals_134 = None
        unsqueeze_317: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_448, 0);  mul_448 = None
        unsqueeze_318: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_317, 2);  unsqueeze_317 = None
        unsqueeze_319: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_318, 3);  unsqueeze_318 = None
        mul_449: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_85, unsqueeze_316);  sub_85 = unsqueeze_316 = None
        sub_87: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(where_7, mul_449);  where_7 = mul_449 = None
        sub_88: f32[1, 512, 2, 2] = torch.ops.aten.sub.Tensor(sub_87, unsqueeze_313);  sub_87 = unsqueeze_313 = None
        mul_450: f32[1, 512, 2, 2] = torch.ops.aten.mul.Tensor(sub_88, unsqueeze_319);  sub_88 = unsqueeze_319 = None
        mul_451: f32[512] = torch.ops.aten.mul.Tensor(sum_19, squeeze_133);  sum_19 = squeeze_133 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_8 = torch.ops.aten.convolution_backward.default(mul_450, relu_40, primals_133, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_450 = primals_133 = None
        getitem_132: f32[1, 512, 4, 4] = convolution_backward_8[0]
        getitem_133: f32[512, 512, 3, 3] = convolution_backward_8[1];  convolution_backward_8 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_8: b8[1, 512, 4, 4] = torch.ops.aten.le.Scalar(relu_40, 0);  relu_40 = None
        where_8: f32[1, 512, 4, 4] = torch.ops.aten.where.self(le_8, full_default, getitem_132);  le_8 = getitem_132 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_20: f32[512] = torch.ops.aten.sum.dim_IntList(where_8, [0, 2, 3])
        sub_89: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(convolution_43, unsqueeze_322);  convolution_43 = unsqueeze_322 = None
        mul_452: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(where_8, sub_89)
        sum_21: f32[512] = torch.ops.aten.sum.dim_IntList(mul_452, [0, 2, 3]);  mul_452 = None
        mul_453: f32[512] = torch.ops.aten.mul.Tensor(sum_20, 0.0625)
        unsqueeze_323: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_453, 0);  mul_453 = None
        unsqueeze_324: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_323, 2);  unsqueeze_323 = None
        unsqueeze_325: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_324, 3);  unsqueeze_324 = None
        mul_454: f32[512] = torch.ops.aten.mul.Tensor(sum_21, 0.0625)
        mul_455: f32[512] = torch.ops.aten.mul.Tensor(squeeze_130, squeeze_130)
        mul_456: f32[512] = torch.ops.aten.mul.Tensor(mul_454, mul_455);  mul_454 = mul_455 = None
        unsqueeze_326: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_456, 0);  mul_456 = None
        unsqueeze_327: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_326, 2);  unsqueeze_326 = None
        unsqueeze_328: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_327, 3);  unsqueeze_327 = None
        mul_457: f32[512] = torch.ops.aten.mul.Tensor(squeeze_130, primals_131);  primals_131 = None
        unsqueeze_329: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_457, 0);  mul_457 = None
        unsqueeze_330: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_329, 2);  unsqueeze_329 = None
        unsqueeze_331: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_330, 3);  unsqueeze_330 = None
        mul_458: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(sub_89, unsqueeze_328);  sub_89 = unsqueeze_328 = None
        sub_91: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(where_8, mul_458);  where_8 = mul_458 = None
        sub_92: f32[1, 512, 4, 4] = torch.ops.aten.sub.Tensor(sub_91, unsqueeze_325);  sub_91 = unsqueeze_325 = None
        mul_459: f32[1, 512, 4, 4] = torch.ops.aten.mul.Tensor(sub_92, unsqueeze_331);  sub_92 = unsqueeze_331 = None
        mul_460: f32[512] = torch.ops.aten.mul.Tensor(sum_21, squeeze_130);  sum_21 = squeeze_130 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_9 = torch.ops.aten.convolution_backward.default(mul_459, relu_39, primals_130, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_459 = primals_130 = None
        getitem_135: f32[1, 1024, 4, 4] = convolution_backward_9[0]
        getitem_136: f32[512, 1024, 1, 1] = convolution_backward_9[1];  convolution_backward_9 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_283: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(getitem_126, getitem_135);  getitem_126 = getitem_135 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_9: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_39, 0);  relu_39 = None
        where_9: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_9, full_default, add_283);  le_9 = add_283 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_22: f32[1024] = torch.ops.aten.sum.dim_IntList(where_9, [0, 2, 3])
        sub_93: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_42, unsqueeze_334);  convolution_42 = unsqueeze_334 = None
        mul_461: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_9, sub_93)
        sum_23: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_461, [0, 2, 3]);  mul_461 = None
        mul_462: f32[1024] = torch.ops.aten.mul.Tensor(sum_22, 0.0625)
        unsqueeze_335: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_462, 0);  mul_462 = None
        unsqueeze_336: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_335, 2);  unsqueeze_335 = None
        unsqueeze_337: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_336, 3);  unsqueeze_336 = None
        mul_463: f32[1024] = torch.ops.aten.mul.Tensor(sum_23, 0.0625)
        mul_464: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_127, squeeze_127)
        mul_465: f32[1024] = torch.ops.aten.mul.Tensor(mul_463, mul_464);  mul_463 = mul_464 = None
        unsqueeze_338: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_465, 0);  mul_465 = None
        unsqueeze_339: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_338, 2);  unsqueeze_338 = None
        unsqueeze_340: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_339, 3);  unsqueeze_339 = None
        mul_466: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_127, primals_128);  primals_128 = None
        unsqueeze_341: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_466, 0);  mul_466 = None
        unsqueeze_342: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_341, 2);  unsqueeze_341 = None
        unsqueeze_343: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_342, 3);  unsqueeze_342 = None
        mul_467: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_93, unsqueeze_340);  sub_93 = unsqueeze_340 = None
        sub_95: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_9, mul_467);  mul_467 = None
        sub_96: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_95, unsqueeze_337);  sub_95 = unsqueeze_337 = None
        mul_468: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_96, unsqueeze_343);  sub_96 = unsqueeze_343 = None
        mul_469: f32[1024] = torch.ops.aten.mul.Tensor(sum_23, squeeze_127);  sum_23 = squeeze_127 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_10 = torch.ops.aten.convolution_backward.default(mul_468, relu_38, primals_127, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_468 = primals_127 = None
        getitem_138: f32[1, 256, 4, 4] = convolution_backward_10[0]
        getitem_139: f32[1024, 256, 1, 1] = convolution_backward_10[1];  convolution_backward_10 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_10: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_38, 0);  relu_38 = None
        where_10: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_10, full_default, getitem_138);  le_10 = getitem_138 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_24: f32[256] = torch.ops.aten.sum.dim_IntList(where_10, [0, 2, 3])
        sub_97: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_41, unsqueeze_346);  convolution_41 = unsqueeze_346 = None
        mul_470: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_10, sub_97)
        sum_25: f32[256] = torch.ops.aten.sum.dim_IntList(mul_470, [0, 2, 3]);  mul_470 = None
        mul_471: f32[256] = torch.ops.aten.mul.Tensor(sum_24, 0.0625)
        unsqueeze_347: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_471, 0);  mul_471 = None
        unsqueeze_348: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_347, 2);  unsqueeze_347 = None
        unsqueeze_349: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_348, 3);  unsqueeze_348 = None
        mul_472: f32[256] = torch.ops.aten.mul.Tensor(sum_25, 0.0625)
        mul_473: f32[256] = torch.ops.aten.mul.Tensor(squeeze_124, squeeze_124)
        mul_474: f32[256] = torch.ops.aten.mul.Tensor(mul_472, mul_473);  mul_472 = mul_473 = None
        unsqueeze_350: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_474, 0);  mul_474 = None
        unsqueeze_351: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_350, 2);  unsqueeze_350 = None
        unsqueeze_352: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_351, 3);  unsqueeze_351 = None
        mul_475: f32[256] = torch.ops.aten.mul.Tensor(squeeze_124, primals_125);  primals_125 = None
        unsqueeze_353: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_475, 0);  mul_475 = None
        unsqueeze_354: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_353, 2);  unsqueeze_353 = None
        unsqueeze_355: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_354, 3);  unsqueeze_354 = None
        mul_476: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_97, unsqueeze_352);  sub_97 = unsqueeze_352 = None
        sub_99: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_10, mul_476);  where_10 = mul_476 = None
        sub_100: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_99, unsqueeze_349);  sub_99 = unsqueeze_349 = None
        mul_477: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_100, unsqueeze_355);  sub_100 = unsqueeze_355 = None
        mul_478: f32[256] = torch.ops.aten.mul.Tensor(sum_25, squeeze_124);  sum_25 = squeeze_124 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_11 = torch.ops.aten.convolution_backward.default(mul_477, relu_37, primals_124, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_477 = primals_124 = None
        getitem_141: f32[1, 256, 4, 4] = convolution_backward_11[0]
        getitem_142: f32[256, 256, 3, 3] = convolution_backward_11[1];  convolution_backward_11 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_11: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_37, 0);  relu_37 = None
        where_11: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_11, full_default, getitem_141);  le_11 = getitem_141 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_26: f32[256] = torch.ops.aten.sum.dim_IntList(where_11, [0, 2, 3])
        sub_101: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_40, unsqueeze_358);  convolution_40 = unsqueeze_358 = None
        mul_479: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_11, sub_101)
        sum_27: f32[256] = torch.ops.aten.sum.dim_IntList(mul_479, [0, 2, 3]);  mul_479 = None
        mul_480: f32[256] = torch.ops.aten.mul.Tensor(sum_26, 0.0625)
        unsqueeze_359: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_480, 0);  mul_480 = None
        unsqueeze_360: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_359, 2);  unsqueeze_359 = None
        unsqueeze_361: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_360, 3);  unsqueeze_360 = None
        mul_481: f32[256] = torch.ops.aten.mul.Tensor(sum_27, 0.0625)
        mul_482: f32[256] = torch.ops.aten.mul.Tensor(squeeze_121, squeeze_121)
        mul_483: f32[256] = torch.ops.aten.mul.Tensor(mul_481, mul_482);  mul_481 = mul_482 = None
        unsqueeze_362: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_483, 0);  mul_483 = None
        unsqueeze_363: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_362, 2);  unsqueeze_362 = None
        unsqueeze_364: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_363, 3);  unsqueeze_363 = None
        mul_484: f32[256] = torch.ops.aten.mul.Tensor(squeeze_121, primals_122);  primals_122 = None
        unsqueeze_365: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_484, 0);  mul_484 = None
        unsqueeze_366: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_365, 2);  unsqueeze_365 = None
        unsqueeze_367: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_366, 3);  unsqueeze_366 = None
        mul_485: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_101, unsqueeze_364);  sub_101 = unsqueeze_364 = None
        sub_103: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_11, mul_485);  where_11 = mul_485 = None
        sub_104: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_103, unsqueeze_361);  sub_103 = unsqueeze_361 = None
        mul_486: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_104, unsqueeze_367);  sub_104 = unsqueeze_367 = None
        mul_487: f32[256] = torch.ops.aten.mul.Tensor(sum_27, squeeze_121);  sum_27 = squeeze_121 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_12 = torch.ops.aten.convolution_backward.default(mul_486, relu_36, primals_121, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_486 = primals_121 = None
        getitem_144: f32[1, 1024, 4, 4] = convolution_backward_12[0]
        getitem_145: f32[256, 1024, 1, 1] = convolution_backward_12[1];  convolution_backward_12 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_284: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_9, getitem_144);  where_9 = getitem_144 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_12: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_36, 0);  relu_36 = None
        where_12: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_12, full_default, add_284);  le_12 = add_284 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_28: f32[1024] = torch.ops.aten.sum.dim_IntList(where_12, [0, 2, 3])
        sub_105: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_39, unsqueeze_370);  convolution_39 = unsqueeze_370 = None
        mul_488: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_12, sub_105)
        sum_29: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_488, [0, 2, 3]);  mul_488 = None
        mul_489: f32[1024] = torch.ops.aten.mul.Tensor(sum_28, 0.0625)
        unsqueeze_371: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_489, 0);  mul_489 = None
        unsqueeze_372: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_371, 2);  unsqueeze_371 = None
        unsqueeze_373: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_372, 3);  unsqueeze_372 = None
        mul_490: f32[1024] = torch.ops.aten.mul.Tensor(sum_29, 0.0625)
        mul_491: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_118, squeeze_118)
        mul_492: f32[1024] = torch.ops.aten.mul.Tensor(mul_490, mul_491);  mul_490 = mul_491 = None
        unsqueeze_374: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_492, 0);  mul_492 = None
        unsqueeze_375: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_374, 2);  unsqueeze_374 = None
        unsqueeze_376: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_375, 3);  unsqueeze_375 = None
        mul_493: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_118, primals_119);  primals_119 = None
        unsqueeze_377: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_493, 0);  mul_493 = None
        unsqueeze_378: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_377, 2);  unsqueeze_377 = None
        unsqueeze_379: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_378, 3);  unsqueeze_378 = None
        mul_494: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_105, unsqueeze_376);  sub_105 = unsqueeze_376 = None
        sub_107: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_12, mul_494);  mul_494 = None
        sub_108: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_107, unsqueeze_373);  sub_107 = unsqueeze_373 = None
        mul_495: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_108, unsqueeze_379);  sub_108 = unsqueeze_379 = None
        mul_496: f32[1024] = torch.ops.aten.mul.Tensor(sum_29, squeeze_118);  sum_29 = squeeze_118 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_13 = torch.ops.aten.convolution_backward.default(mul_495, relu_35, primals_118, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_495 = primals_118 = None
        getitem_147: f32[1, 256, 4, 4] = convolution_backward_13[0]
        getitem_148: f32[1024, 256, 1, 1] = convolution_backward_13[1];  convolution_backward_13 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_13: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_35, 0);  relu_35 = None
        where_13: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_13, full_default, getitem_147);  le_13 = getitem_147 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_30: f32[256] = torch.ops.aten.sum.dim_IntList(where_13, [0, 2, 3])
        sub_109: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_38, unsqueeze_382);  convolution_38 = unsqueeze_382 = None
        mul_497: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_13, sub_109)
        sum_31: f32[256] = torch.ops.aten.sum.dim_IntList(mul_497, [0, 2, 3]);  mul_497 = None
        mul_498: f32[256] = torch.ops.aten.mul.Tensor(sum_30, 0.0625)
        unsqueeze_383: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_498, 0);  mul_498 = None
        unsqueeze_384: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_383, 2);  unsqueeze_383 = None
        unsqueeze_385: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_384, 3);  unsqueeze_384 = None
        mul_499: f32[256] = torch.ops.aten.mul.Tensor(sum_31, 0.0625)
        mul_500: f32[256] = torch.ops.aten.mul.Tensor(squeeze_115, squeeze_115)
        mul_501: f32[256] = torch.ops.aten.mul.Tensor(mul_499, mul_500);  mul_499 = mul_500 = None
        unsqueeze_386: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_501, 0);  mul_501 = None
        unsqueeze_387: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_386, 2);  unsqueeze_386 = None
        unsqueeze_388: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_387, 3);  unsqueeze_387 = None
        mul_502: f32[256] = torch.ops.aten.mul.Tensor(squeeze_115, primals_116);  primals_116 = None
        unsqueeze_389: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_502, 0);  mul_502 = None
        unsqueeze_390: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_389, 2);  unsqueeze_389 = None
        unsqueeze_391: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_390, 3);  unsqueeze_390 = None
        mul_503: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_109, unsqueeze_388);  sub_109 = unsqueeze_388 = None
        sub_111: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_13, mul_503);  where_13 = mul_503 = None
        sub_112: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_111, unsqueeze_385);  sub_111 = unsqueeze_385 = None
        mul_504: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_112, unsqueeze_391);  sub_112 = unsqueeze_391 = None
        mul_505: f32[256] = torch.ops.aten.mul.Tensor(sum_31, squeeze_115);  sum_31 = squeeze_115 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_14 = torch.ops.aten.convolution_backward.default(mul_504, relu_34, primals_115, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_504 = primals_115 = None
        getitem_150: f32[1, 256, 4, 4] = convolution_backward_14[0]
        getitem_151: f32[256, 256, 3, 3] = convolution_backward_14[1];  convolution_backward_14 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_14: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_34, 0);  relu_34 = None
        where_14: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_14, full_default, getitem_150);  le_14 = getitem_150 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_32: f32[256] = torch.ops.aten.sum.dim_IntList(where_14, [0, 2, 3])
        sub_113: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_37, unsqueeze_394);  convolution_37 = unsqueeze_394 = None
        mul_506: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_14, sub_113)
        sum_33: f32[256] = torch.ops.aten.sum.dim_IntList(mul_506, [0, 2, 3]);  mul_506 = None
        mul_507: f32[256] = torch.ops.aten.mul.Tensor(sum_32, 0.0625)
        unsqueeze_395: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_507, 0);  mul_507 = None
        unsqueeze_396: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_395, 2);  unsqueeze_395 = None
        unsqueeze_397: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_396, 3);  unsqueeze_396 = None
        mul_508: f32[256] = torch.ops.aten.mul.Tensor(sum_33, 0.0625)
        mul_509: f32[256] = torch.ops.aten.mul.Tensor(squeeze_112, squeeze_112)
        mul_510: f32[256] = torch.ops.aten.mul.Tensor(mul_508, mul_509);  mul_508 = mul_509 = None
        unsqueeze_398: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_510, 0);  mul_510 = None
        unsqueeze_399: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_398, 2);  unsqueeze_398 = None
        unsqueeze_400: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_399, 3);  unsqueeze_399 = None
        mul_511: f32[256] = torch.ops.aten.mul.Tensor(squeeze_112, primals_113);  primals_113 = None
        unsqueeze_401: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_511, 0);  mul_511 = None
        unsqueeze_402: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_401, 2);  unsqueeze_401 = None
        unsqueeze_403: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_402, 3);  unsqueeze_402 = None
        mul_512: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_113, unsqueeze_400);  sub_113 = unsqueeze_400 = None
        sub_115: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_14, mul_512);  where_14 = mul_512 = None
        sub_116: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_115, unsqueeze_397);  sub_115 = unsqueeze_397 = None
        mul_513: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_116, unsqueeze_403);  sub_116 = unsqueeze_403 = None
        mul_514: f32[256] = torch.ops.aten.mul.Tensor(sum_33, squeeze_112);  sum_33 = squeeze_112 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_15 = torch.ops.aten.convolution_backward.default(mul_513, relu_33, primals_112, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_513 = primals_112 = None
        getitem_153: f32[1, 1024, 4, 4] = convolution_backward_15[0]
        getitem_154: f32[256, 1024, 1, 1] = convolution_backward_15[1];  convolution_backward_15 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_285: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_12, getitem_153);  where_12 = getitem_153 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_15: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_33, 0);  relu_33 = None
        where_15: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_15, full_default, add_285);  le_15 = add_285 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_34: f32[1024] = torch.ops.aten.sum.dim_IntList(where_15, [0, 2, 3])
        sub_117: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_36, unsqueeze_406);  convolution_36 = unsqueeze_406 = None
        mul_515: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_15, sub_117)
        sum_35: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_515, [0, 2, 3]);  mul_515 = None
        mul_516: f32[1024] = torch.ops.aten.mul.Tensor(sum_34, 0.0625)
        unsqueeze_407: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_516, 0);  mul_516 = None
        unsqueeze_408: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_407, 2);  unsqueeze_407 = None
        unsqueeze_409: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_408, 3);  unsqueeze_408 = None
        mul_517: f32[1024] = torch.ops.aten.mul.Tensor(sum_35, 0.0625)
        mul_518: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_109, squeeze_109)
        mul_519: f32[1024] = torch.ops.aten.mul.Tensor(mul_517, mul_518);  mul_517 = mul_518 = None
        unsqueeze_410: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_519, 0);  mul_519 = None
        unsqueeze_411: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_410, 2);  unsqueeze_410 = None
        unsqueeze_412: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_411, 3);  unsqueeze_411 = None
        mul_520: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_109, primals_110);  primals_110 = None
        unsqueeze_413: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_520, 0);  mul_520 = None
        unsqueeze_414: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_413, 2);  unsqueeze_413 = None
        unsqueeze_415: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_414, 3);  unsqueeze_414 = None
        mul_521: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_117, unsqueeze_412);  sub_117 = unsqueeze_412 = None
        sub_119: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_15, mul_521);  mul_521 = None
        sub_120: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_119, unsqueeze_409);  sub_119 = unsqueeze_409 = None
        mul_522: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_120, unsqueeze_415);  sub_120 = unsqueeze_415 = None
        mul_523: f32[1024] = torch.ops.aten.mul.Tensor(sum_35, squeeze_109);  sum_35 = squeeze_109 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_16 = torch.ops.aten.convolution_backward.default(mul_522, relu_32, primals_109, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_522 = primals_109 = None
        getitem_156: f32[1, 256, 4, 4] = convolution_backward_16[0]
        getitem_157: f32[1024, 256, 1, 1] = convolution_backward_16[1];  convolution_backward_16 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_16: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_32, 0);  relu_32 = None
        where_16: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_16, full_default, getitem_156);  le_16 = getitem_156 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_36: f32[256] = torch.ops.aten.sum.dim_IntList(where_16, [0, 2, 3])
        sub_121: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_35, unsqueeze_418);  convolution_35 = unsqueeze_418 = None
        mul_524: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_16, sub_121)
        sum_37: f32[256] = torch.ops.aten.sum.dim_IntList(mul_524, [0, 2, 3]);  mul_524 = None
        mul_525: f32[256] = torch.ops.aten.mul.Tensor(sum_36, 0.0625)
        unsqueeze_419: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_525, 0);  mul_525 = None
        unsqueeze_420: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_419, 2);  unsqueeze_419 = None
        unsqueeze_421: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_420, 3);  unsqueeze_420 = None
        mul_526: f32[256] = torch.ops.aten.mul.Tensor(sum_37, 0.0625)
        mul_527: f32[256] = torch.ops.aten.mul.Tensor(squeeze_106, squeeze_106)
        mul_528: f32[256] = torch.ops.aten.mul.Tensor(mul_526, mul_527);  mul_526 = mul_527 = None
        unsqueeze_422: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_528, 0);  mul_528 = None
        unsqueeze_423: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_422, 2);  unsqueeze_422 = None
        unsqueeze_424: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_423, 3);  unsqueeze_423 = None
        mul_529: f32[256] = torch.ops.aten.mul.Tensor(squeeze_106, primals_107);  primals_107 = None
        unsqueeze_425: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_529, 0);  mul_529 = None
        unsqueeze_426: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_425, 2);  unsqueeze_425 = None
        unsqueeze_427: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_426, 3);  unsqueeze_426 = None
        mul_530: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_121, unsqueeze_424);  sub_121 = unsqueeze_424 = None
        sub_123: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_16, mul_530);  where_16 = mul_530 = None
        sub_124: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_123, unsqueeze_421);  sub_123 = unsqueeze_421 = None
        mul_531: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_124, unsqueeze_427);  sub_124 = unsqueeze_427 = None
        mul_532: f32[256] = torch.ops.aten.mul.Tensor(sum_37, squeeze_106);  sum_37 = squeeze_106 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_17 = torch.ops.aten.convolution_backward.default(mul_531, relu_31, primals_106, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_531 = primals_106 = None
        getitem_159: f32[1, 256, 4, 4] = convolution_backward_17[0]
        getitem_160: f32[256, 256, 3, 3] = convolution_backward_17[1];  convolution_backward_17 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_17: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_31, 0);  relu_31 = None
        where_17: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_17, full_default, getitem_159);  le_17 = getitem_159 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_38: f32[256] = torch.ops.aten.sum.dim_IntList(where_17, [0, 2, 3])
        sub_125: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_34, unsqueeze_430);  convolution_34 = unsqueeze_430 = None
        mul_533: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_17, sub_125)
        sum_39: f32[256] = torch.ops.aten.sum.dim_IntList(mul_533, [0, 2, 3]);  mul_533 = None
        mul_534: f32[256] = torch.ops.aten.mul.Tensor(sum_38, 0.0625)
        unsqueeze_431: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_534, 0);  mul_534 = None
        unsqueeze_432: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_431, 2);  unsqueeze_431 = None
        unsqueeze_433: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_432, 3);  unsqueeze_432 = None
        mul_535: f32[256] = torch.ops.aten.mul.Tensor(sum_39, 0.0625)
        mul_536: f32[256] = torch.ops.aten.mul.Tensor(squeeze_103, squeeze_103)
        mul_537: f32[256] = torch.ops.aten.mul.Tensor(mul_535, mul_536);  mul_535 = mul_536 = None
        unsqueeze_434: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_537, 0);  mul_537 = None
        unsqueeze_435: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_434, 2);  unsqueeze_434 = None
        unsqueeze_436: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_435, 3);  unsqueeze_435 = None
        mul_538: f32[256] = torch.ops.aten.mul.Tensor(squeeze_103, primals_104);  primals_104 = None
        unsqueeze_437: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_538, 0);  mul_538 = None
        unsqueeze_438: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_437, 2);  unsqueeze_437 = None
        unsqueeze_439: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_438, 3);  unsqueeze_438 = None
        mul_539: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_125, unsqueeze_436);  sub_125 = unsqueeze_436 = None
        sub_127: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_17, mul_539);  where_17 = mul_539 = None
        sub_128: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_127, unsqueeze_433);  sub_127 = unsqueeze_433 = None
        mul_540: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_128, unsqueeze_439);  sub_128 = unsqueeze_439 = None
        mul_541: f32[256] = torch.ops.aten.mul.Tensor(sum_39, squeeze_103);  sum_39 = squeeze_103 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_18 = torch.ops.aten.convolution_backward.default(mul_540, relu_30, primals_103, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_540 = primals_103 = None
        getitem_162: f32[1, 1024, 4, 4] = convolution_backward_18[0]
        getitem_163: f32[256, 1024, 1, 1] = convolution_backward_18[1];  convolution_backward_18 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_286: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_15, getitem_162);  where_15 = getitem_162 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_18: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_30, 0);  relu_30 = None
        where_18: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_18, full_default, add_286);  le_18 = add_286 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_40: f32[1024] = torch.ops.aten.sum.dim_IntList(where_18, [0, 2, 3])
        sub_129: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_33, unsqueeze_442);  convolution_33 = unsqueeze_442 = None
        mul_542: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_18, sub_129)
        sum_41: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_542, [0, 2, 3]);  mul_542 = None
        mul_543: f32[1024] = torch.ops.aten.mul.Tensor(sum_40, 0.0625)
        unsqueeze_443: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_543, 0);  mul_543 = None
        unsqueeze_444: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_443, 2);  unsqueeze_443 = None
        unsqueeze_445: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_444, 3);  unsqueeze_444 = None
        mul_544: f32[1024] = torch.ops.aten.mul.Tensor(sum_41, 0.0625)
        mul_545: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_100, squeeze_100)
        mul_546: f32[1024] = torch.ops.aten.mul.Tensor(mul_544, mul_545);  mul_544 = mul_545 = None
        unsqueeze_446: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_546, 0);  mul_546 = None
        unsqueeze_447: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_446, 2);  unsqueeze_446 = None
        unsqueeze_448: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_447, 3);  unsqueeze_447 = None
        mul_547: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_100, primals_101);  primals_101 = None
        unsqueeze_449: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_547, 0);  mul_547 = None
        unsqueeze_450: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_449, 2);  unsqueeze_449 = None
        unsqueeze_451: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_450, 3);  unsqueeze_450 = None
        mul_548: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_129, unsqueeze_448);  sub_129 = unsqueeze_448 = None
        sub_131: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_18, mul_548);  mul_548 = None
        sub_132: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_131, unsqueeze_445);  sub_131 = unsqueeze_445 = None
        mul_549: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_132, unsqueeze_451);  sub_132 = unsqueeze_451 = None
        mul_550: f32[1024] = torch.ops.aten.mul.Tensor(sum_41, squeeze_100);  sum_41 = squeeze_100 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_19 = torch.ops.aten.convolution_backward.default(mul_549, relu_29, primals_100, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_549 = primals_100 = None
        getitem_165: f32[1, 256, 4, 4] = convolution_backward_19[0]
        getitem_166: f32[1024, 256, 1, 1] = convolution_backward_19[1];  convolution_backward_19 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_19: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_29, 0);  relu_29 = None
        where_19: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_19, full_default, getitem_165);  le_19 = getitem_165 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_42: f32[256] = torch.ops.aten.sum.dim_IntList(where_19, [0, 2, 3])
        sub_133: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_32, unsqueeze_454);  convolution_32 = unsqueeze_454 = None
        mul_551: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_19, sub_133)
        sum_43: f32[256] = torch.ops.aten.sum.dim_IntList(mul_551, [0, 2, 3]);  mul_551 = None
        mul_552: f32[256] = torch.ops.aten.mul.Tensor(sum_42, 0.0625)
        unsqueeze_455: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_552, 0);  mul_552 = None
        unsqueeze_456: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_455, 2);  unsqueeze_455 = None
        unsqueeze_457: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_456, 3);  unsqueeze_456 = None
        mul_553: f32[256] = torch.ops.aten.mul.Tensor(sum_43, 0.0625)
        mul_554: f32[256] = torch.ops.aten.mul.Tensor(squeeze_97, squeeze_97)
        mul_555: f32[256] = torch.ops.aten.mul.Tensor(mul_553, mul_554);  mul_553 = mul_554 = None
        unsqueeze_458: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_555, 0);  mul_555 = None
        unsqueeze_459: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_458, 2);  unsqueeze_458 = None
        unsqueeze_460: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_459, 3);  unsqueeze_459 = None
        mul_556: f32[256] = torch.ops.aten.mul.Tensor(squeeze_97, primals_98);  primals_98 = None
        unsqueeze_461: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_556, 0);  mul_556 = None
        unsqueeze_462: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_461, 2);  unsqueeze_461 = None
        unsqueeze_463: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_462, 3);  unsqueeze_462 = None
        mul_557: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_133, unsqueeze_460);  sub_133 = unsqueeze_460 = None
        sub_135: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_19, mul_557);  where_19 = mul_557 = None
        sub_136: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_135, unsqueeze_457);  sub_135 = unsqueeze_457 = None
        mul_558: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_136, unsqueeze_463);  sub_136 = unsqueeze_463 = None
        mul_559: f32[256] = torch.ops.aten.mul.Tensor(sum_43, squeeze_97);  sum_43 = squeeze_97 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_20 = torch.ops.aten.convolution_backward.default(mul_558, relu_28, primals_97, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_558 = primals_97 = None
        getitem_168: f32[1, 256, 4, 4] = convolution_backward_20[0]
        getitem_169: f32[256, 256, 3, 3] = convolution_backward_20[1];  convolution_backward_20 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_20: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_28, 0);  relu_28 = None
        where_20: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_20, full_default, getitem_168);  le_20 = getitem_168 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_44: f32[256] = torch.ops.aten.sum.dim_IntList(where_20, [0, 2, 3])
        sub_137: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_31, unsqueeze_466);  convolution_31 = unsqueeze_466 = None
        mul_560: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_20, sub_137)
        sum_45: f32[256] = torch.ops.aten.sum.dim_IntList(mul_560, [0, 2, 3]);  mul_560 = None
        mul_561: f32[256] = torch.ops.aten.mul.Tensor(sum_44, 0.0625)
        unsqueeze_467: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_561, 0);  mul_561 = None
        unsqueeze_468: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_467, 2);  unsqueeze_467 = None
        unsqueeze_469: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_468, 3);  unsqueeze_468 = None
        mul_562: f32[256] = torch.ops.aten.mul.Tensor(sum_45, 0.0625)
        mul_563: f32[256] = torch.ops.aten.mul.Tensor(squeeze_94, squeeze_94)
        mul_564: f32[256] = torch.ops.aten.mul.Tensor(mul_562, mul_563);  mul_562 = mul_563 = None
        unsqueeze_470: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_564, 0);  mul_564 = None
        unsqueeze_471: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_470, 2);  unsqueeze_470 = None
        unsqueeze_472: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_471, 3);  unsqueeze_471 = None
        mul_565: f32[256] = torch.ops.aten.mul.Tensor(squeeze_94, primals_95);  primals_95 = None
        unsqueeze_473: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_565, 0);  mul_565 = None
        unsqueeze_474: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_473, 2);  unsqueeze_473 = None
        unsqueeze_475: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_474, 3);  unsqueeze_474 = None
        mul_566: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_137, unsqueeze_472);  sub_137 = unsqueeze_472 = None
        sub_139: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_20, mul_566);  where_20 = mul_566 = None
        sub_140: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_139, unsqueeze_469);  sub_139 = unsqueeze_469 = None
        mul_567: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_140, unsqueeze_475);  sub_140 = unsqueeze_475 = None
        mul_568: f32[256] = torch.ops.aten.mul.Tensor(sum_45, squeeze_94);  sum_45 = squeeze_94 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_21 = torch.ops.aten.convolution_backward.default(mul_567, relu_27, primals_94, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_567 = primals_94 = None
        getitem_171: f32[1, 1024, 4, 4] = convolution_backward_21[0]
        getitem_172: f32[256, 1024, 1, 1] = convolution_backward_21[1];  convolution_backward_21 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_287: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_18, getitem_171);  where_18 = getitem_171 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_21: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_27, 0);  relu_27 = None
        where_21: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_21, full_default, add_287);  le_21 = add_287 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_46: f32[1024] = torch.ops.aten.sum.dim_IntList(where_21, [0, 2, 3])
        sub_141: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_30, unsqueeze_478);  convolution_30 = unsqueeze_478 = None
        mul_569: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_21, sub_141)
        sum_47: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_569, [0, 2, 3]);  mul_569 = None
        mul_570: f32[1024] = torch.ops.aten.mul.Tensor(sum_46, 0.0625)
        unsqueeze_479: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_570, 0);  mul_570 = None
        unsqueeze_480: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_479, 2);  unsqueeze_479 = None
        unsqueeze_481: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_480, 3);  unsqueeze_480 = None
        mul_571: f32[1024] = torch.ops.aten.mul.Tensor(sum_47, 0.0625)
        mul_572: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_91, squeeze_91)
        mul_573: f32[1024] = torch.ops.aten.mul.Tensor(mul_571, mul_572);  mul_571 = mul_572 = None
        unsqueeze_482: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_573, 0);  mul_573 = None
        unsqueeze_483: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_482, 2);  unsqueeze_482 = None
        unsqueeze_484: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_483, 3);  unsqueeze_483 = None
        mul_574: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_91, primals_92);  primals_92 = None
        unsqueeze_485: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_574, 0);  mul_574 = None
        unsqueeze_486: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_485, 2);  unsqueeze_485 = None
        unsqueeze_487: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_486, 3);  unsqueeze_486 = None
        mul_575: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_141, unsqueeze_484);  sub_141 = unsqueeze_484 = None
        sub_143: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_21, mul_575);  mul_575 = None
        sub_144: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_143, unsqueeze_481);  sub_143 = unsqueeze_481 = None
        mul_576: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_144, unsqueeze_487);  sub_144 = unsqueeze_487 = None
        mul_577: f32[1024] = torch.ops.aten.mul.Tensor(sum_47, squeeze_91);  sum_47 = squeeze_91 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_22 = torch.ops.aten.convolution_backward.default(mul_576, relu_26, primals_91, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_576 = primals_91 = None
        getitem_174: f32[1, 256, 4, 4] = convolution_backward_22[0]
        getitem_175: f32[1024, 256, 1, 1] = convolution_backward_22[1];  convolution_backward_22 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_22: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_26, 0);  relu_26 = None
        where_22: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_22, full_default, getitem_174);  le_22 = getitem_174 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_48: f32[256] = torch.ops.aten.sum.dim_IntList(where_22, [0, 2, 3])
        sub_145: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_29, unsqueeze_490);  convolution_29 = unsqueeze_490 = None
        mul_578: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_22, sub_145)
        sum_49: f32[256] = torch.ops.aten.sum.dim_IntList(mul_578, [0, 2, 3]);  mul_578 = None
        mul_579: f32[256] = torch.ops.aten.mul.Tensor(sum_48, 0.0625)
        unsqueeze_491: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_579, 0);  mul_579 = None
        unsqueeze_492: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_491, 2);  unsqueeze_491 = None
        unsqueeze_493: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_492, 3);  unsqueeze_492 = None
        mul_580: f32[256] = torch.ops.aten.mul.Tensor(sum_49, 0.0625)
        mul_581: f32[256] = torch.ops.aten.mul.Tensor(squeeze_88, squeeze_88)
        mul_582: f32[256] = torch.ops.aten.mul.Tensor(mul_580, mul_581);  mul_580 = mul_581 = None
        unsqueeze_494: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_582, 0);  mul_582 = None
        unsqueeze_495: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_494, 2);  unsqueeze_494 = None
        unsqueeze_496: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_495, 3);  unsqueeze_495 = None
        mul_583: f32[256] = torch.ops.aten.mul.Tensor(squeeze_88, primals_89);  primals_89 = None
        unsqueeze_497: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_583, 0);  mul_583 = None
        unsqueeze_498: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_497, 2);  unsqueeze_497 = None
        unsqueeze_499: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_498, 3);  unsqueeze_498 = None
        mul_584: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_145, unsqueeze_496);  sub_145 = unsqueeze_496 = None
        sub_147: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_22, mul_584);  where_22 = mul_584 = None
        sub_148: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_147, unsqueeze_493);  sub_147 = unsqueeze_493 = None
        mul_585: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_148, unsqueeze_499);  sub_148 = unsqueeze_499 = None
        mul_586: f32[256] = torch.ops.aten.mul.Tensor(sum_49, squeeze_88);  sum_49 = squeeze_88 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_23 = torch.ops.aten.convolution_backward.default(mul_585, relu_25, primals_88, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_585 = primals_88 = None
        getitem_177: f32[1, 256, 4, 4] = convolution_backward_23[0]
        getitem_178: f32[256, 256, 3, 3] = convolution_backward_23[1];  convolution_backward_23 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_23: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_25, 0);  relu_25 = None
        where_23: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_23, full_default, getitem_177);  le_23 = getitem_177 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_50: f32[256] = torch.ops.aten.sum.dim_IntList(where_23, [0, 2, 3])
        sub_149: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_28, unsqueeze_502);  convolution_28 = unsqueeze_502 = None
        mul_587: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_23, sub_149)
        sum_51: f32[256] = torch.ops.aten.sum.dim_IntList(mul_587, [0, 2, 3]);  mul_587 = None
        mul_588: f32[256] = torch.ops.aten.mul.Tensor(sum_50, 0.0625)
        unsqueeze_503: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_588, 0);  mul_588 = None
        unsqueeze_504: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_503, 2);  unsqueeze_503 = None
        unsqueeze_505: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_504, 3);  unsqueeze_504 = None
        mul_589: f32[256] = torch.ops.aten.mul.Tensor(sum_51, 0.0625)
        mul_590: f32[256] = torch.ops.aten.mul.Tensor(squeeze_85, squeeze_85)
        mul_591: f32[256] = torch.ops.aten.mul.Tensor(mul_589, mul_590);  mul_589 = mul_590 = None
        unsqueeze_506: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_591, 0);  mul_591 = None
        unsqueeze_507: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_506, 2);  unsqueeze_506 = None
        unsqueeze_508: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_507, 3);  unsqueeze_507 = None
        mul_592: f32[256] = torch.ops.aten.mul.Tensor(squeeze_85, primals_86);  primals_86 = None
        unsqueeze_509: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_592, 0);  mul_592 = None
        unsqueeze_510: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_509, 2);  unsqueeze_509 = None
        unsqueeze_511: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_510, 3);  unsqueeze_510 = None
        mul_593: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_149, unsqueeze_508);  sub_149 = unsqueeze_508 = None
        sub_151: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_23, mul_593);  where_23 = mul_593 = None
        sub_152: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_151, unsqueeze_505);  sub_151 = unsqueeze_505 = None
        mul_594: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_152, unsqueeze_511);  sub_152 = unsqueeze_511 = None
        mul_595: f32[256] = torch.ops.aten.mul.Tensor(sum_51, squeeze_85);  sum_51 = squeeze_85 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_24 = torch.ops.aten.convolution_backward.default(mul_594, relu_24, primals_85, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_594 = primals_85 = None
        getitem_180: f32[1, 1024, 4, 4] = convolution_backward_24[0]
        getitem_181: f32[256, 1024, 1, 1] = convolution_backward_24[1];  convolution_backward_24 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_288: f32[1, 1024, 4, 4] = torch.ops.aten.add.Tensor(where_21, getitem_180);  where_21 = getitem_180 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_24: b8[1, 1024, 4, 4] = torch.ops.aten.le.Scalar(relu_24, 0);  relu_24 = None
        where_24: f32[1, 1024, 4, 4] = torch.ops.aten.where.self(le_24, full_default, add_288);  le_24 = add_288 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        sum_52: f32[1024] = torch.ops.aten.sum.dim_IntList(where_24, [0, 2, 3])
        sub_153: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_27, unsqueeze_514);  convolution_27 = unsqueeze_514 = None
        mul_596: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_24, sub_153)
        sum_53: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_596, [0, 2, 3]);  mul_596 = None
        mul_597: f32[1024] = torch.ops.aten.mul.Tensor(sum_52, 0.0625)
        unsqueeze_515: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_597, 0);  mul_597 = None
        unsqueeze_516: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_515, 2);  unsqueeze_515 = None
        unsqueeze_517: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_516, 3);  unsqueeze_516 = None
        mul_598: f32[1024] = torch.ops.aten.mul.Tensor(sum_53, 0.0625)
        mul_599: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_82, squeeze_82)
        mul_600: f32[1024] = torch.ops.aten.mul.Tensor(mul_598, mul_599);  mul_598 = mul_599 = None
        unsqueeze_518: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_600, 0);  mul_600 = None
        unsqueeze_519: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_518, 2);  unsqueeze_518 = None
        unsqueeze_520: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_519, 3);  unsqueeze_519 = None
        mul_601: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_82, primals_83);  primals_83 = None
        unsqueeze_521: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_601, 0);  mul_601 = None
        unsqueeze_522: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_521, 2);  unsqueeze_521 = None
        unsqueeze_523: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_522, 3);  unsqueeze_522 = None
        mul_602: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_153, unsqueeze_520);  sub_153 = unsqueeze_520 = None
        sub_155: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_24, mul_602);  mul_602 = None
        sub_156: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_155, unsqueeze_517);  sub_155 = None
        mul_603: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_156, unsqueeze_523);  sub_156 = unsqueeze_523 = None
        mul_604: f32[1024] = torch.ops.aten.mul.Tensor(sum_53, squeeze_82);  sum_53 = squeeze_82 = None
        convolution_backward_25 = torch.ops.aten.convolution_backward.default(mul_603, relu_21, primals_82, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_603 = primals_82 = None
        getitem_183: f32[1, 512, 8, 8] = convolution_backward_25[0]
        getitem_184: f32[1024, 512, 1, 1] = convolution_backward_25[1];  convolution_backward_25 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sub_157: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(convolution_26, unsqueeze_526);  convolution_26 = unsqueeze_526 = None
        mul_605: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(where_24, sub_157)
        sum_55: f32[1024] = torch.ops.aten.sum.dim_IntList(mul_605, [0, 2, 3]);  mul_605 = None
        mul_607: f32[1024] = torch.ops.aten.mul.Tensor(sum_55, 0.0625)
        mul_608: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_79, squeeze_79)
        mul_609: f32[1024] = torch.ops.aten.mul.Tensor(mul_607, mul_608);  mul_607 = mul_608 = None
        unsqueeze_530: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_609, 0);  mul_609 = None
        unsqueeze_531: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_530, 2);  unsqueeze_530 = None
        unsqueeze_532: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_531, 3);  unsqueeze_531 = None
        mul_610: f32[1024] = torch.ops.aten.mul.Tensor(squeeze_79, primals_80);  primals_80 = None
        unsqueeze_533: f32[1, 1024] = torch.ops.aten.unsqueeze.default(mul_610, 0);  mul_610 = None
        unsqueeze_534: f32[1, 1024, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_533, 2);  unsqueeze_533 = None
        unsqueeze_535: f32[1, 1024, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_534, 3);  unsqueeze_534 = None
        mul_611: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_157, unsqueeze_532);  sub_157 = unsqueeze_532 = None
        sub_159: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(where_24, mul_611);  where_24 = mul_611 = None
        sub_160: f32[1, 1024, 4, 4] = torch.ops.aten.sub.Tensor(sub_159, unsqueeze_517);  sub_159 = unsqueeze_517 = None
        mul_612: f32[1, 1024, 4, 4] = torch.ops.aten.mul.Tensor(sub_160, unsqueeze_535);  sub_160 = unsqueeze_535 = None
        mul_613: f32[1024] = torch.ops.aten.mul.Tensor(sum_55, squeeze_79);  sum_55 = squeeze_79 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_26 = torch.ops.aten.convolution_backward.default(mul_612, relu_23, primals_79, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_612 = primals_79 = None
        getitem_186: f32[1, 256, 4, 4] = convolution_backward_26[0]
        getitem_187: f32[1024, 256, 1, 1] = convolution_backward_26[1];  convolution_backward_26 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_25: b8[1, 256, 4, 4] = torch.ops.aten.le.Scalar(relu_23, 0);  relu_23 = None
        where_25: f32[1, 256, 4, 4] = torch.ops.aten.where.self(le_25, full_default, getitem_186);  le_25 = getitem_186 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_56: f32[256] = torch.ops.aten.sum.dim_IntList(where_25, [0, 2, 3])
        sub_161: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(convolution_25, unsqueeze_538);  convolution_25 = unsqueeze_538 = None
        mul_614: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(where_25, sub_161)
        sum_57: f32[256] = torch.ops.aten.sum.dim_IntList(mul_614, [0, 2, 3]);  mul_614 = None
        mul_615: f32[256] = torch.ops.aten.mul.Tensor(sum_56, 0.0625)
        unsqueeze_539: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_615, 0);  mul_615 = None
        unsqueeze_540: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_539, 2);  unsqueeze_539 = None
        unsqueeze_541: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_540, 3);  unsqueeze_540 = None
        mul_616: f32[256] = torch.ops.aten.mul.Tensor(sum_57, 0.0625)
        mul_617: f32[256] = torch.ops.aten.mul.Tensor(squeeze_76, squeeze_76)
        mul_618: f32[256] = torch.ops.aten.mul.Tensor(mul_616, mul_617);  mul_616 = mul_617 = None
        unsqueeze_542: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_618, 0);  mul_618 = None
        unsqueeze_543: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_542, 2);  unsqueeze_542 = None
        unsqueeze_544: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_543, 3);  unsqueeze_543 = None
        mul_619: f32[256] = torch.ops.aten.mul.Tensor(squeeze_76, primals_77);  primals_77 = None
        unsqueeze_545: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_619, 0);  mul_619 = None
        unsqueeze_546: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_545, 2);  unsqueeze_545 = None
        unsqueeze_547: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_546, 3);  unsqueeze_546 = None
        mul_620: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_161, unsqueeze_544);  sub_161 = unsqueeze_544 = None
        sub_163: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(where_25, mul_620);  where_25 = mul_620 = None
        sub_164: f32[1, 256, 4, 4] = torch.ops.aten.sub.Tensor(sub_163, unsqueeze_541);  sub_163 = unsqueeze_541 = None
        mul_621: f32[1, 256, 4, 4] = torch.ops.aten.mul.Tensor(sub_164, unsqueeze_547);  sub_164 = unsqueeze_547 = None
        mul_622: f32[256] = torch.ops.aten.mul.Tensor(sum_57, squeeze_76);  sum_57 = squeeze_76 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_27 = torch.ops.aten.convolution_backward.default(mul_621, relu_22, primals_76, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_621 = primals_76 = None
        getitem_189: f32[1, 256, 8, 8] = convolution_backward_27[0]
        getitem_190: f32[256, 256, 3, 3] = convolution_backward_27[1];  convolution_backward_27 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_26: b8[1, 256, 8, 8] = torch.ops.aten.le.Scalar(relu_22, 0);  relu_22 = None
        where_26: f32[1, 256, 8, 8] = torch.ops.aten.where.self(le_26, full_default, getitem_189);  le_26 = getitem_189 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_58: f32[256] = torch.ops.aten.sum.dim_IntList(where_26, [0, 2, 3])
        sub_165: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(convolution_24, unsqueeze_550);  convolution_24 = unsqueeze_550 = None
        mul_623: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(where_26, sub_165)
        sum_59: f32[256] = torch.ops.aten.sum.dim_IntList(mul_623, [0, 2, 3]);  mul_623 = None
        mul_624: f32[256] = torch.ops.aten.mul.Tensor(sum_58, 0.015625)
        unsqueeze_551: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_624, 0);  mul_624 = None
        unsqueeze_552: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_551, 2);  unsqueeze_551 = None
        unsqueeze_553: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_552, 3);  unsqueeze_552 = None
        mul_625: f32[256] = torch.ops.aten.mul.Tensor(sum_59, 0.015625)
        mul_626: f32[256] = torch.ops.aten.mul.Tensor(squeeze_73, squeeze_73)
        mul_627: f32[256] = torch.ops.aten.mul.Tensor(mul_625, mul_626);  mul_625 = mul_626 = None
        unsqueeze_554: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_627, 0);  mul_627 = None
        unsqueeze_555: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_554, 2);  unsqueeze_554 = None
        unsqueeze_556: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_555, 3);  unsqueeze_555 = None
        mul_628: f32[256] = torch.ops.aten.mul.Tensor(squeeze_73, primals_74);  primals_74 = None
        unsqueeze_557: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_628, 0);  mul_628 = None
        unsqueeze_558: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_557, 2);  unsqueeze_557 = None
        unsqueeze_559: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_558, 3);  unsqueeze_558 = None
        mul_629: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(sub_165, unsqueeze_556);  sub_165 = unsqueeze_556 = None
        sub_167: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(where_26, mul_629);  where_26 = mul_629 = None
        sub_168: f32[1, 256, 8, 8] = torch.ops.aten.sub.Tensor(sub_167, unsqueeze_553);  sub_167 = unsqueeze_553 = None
        mul_630: f32[1, 256, 8, 8] = torch.ops.aten.mul.Tensor(sub_168, unsqueeze_559);  sub_168 = unsqueeze_559 = None
        mul_631: f32[256] = torch.ops.aten.mul.Tensor(sum_59, squeeze_73);  sum_59 = squeeze_73 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_28 = torch.ops.aten.convolution_backward.default(mul_630, relu_21, primals_73, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_630 = primals_73 = None
        getitem_192: f32[1, 512, 8, 8] = convolution_backward_28[0]
        getitem_193: f32[256, 512, 1, 1] = convolution_backward_28[1];  convolution_backward_28 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_289: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(getitem_183, getitem_192);  getitem_183 = getitem_192 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_27: b8[1, 512, 8, 8] = torch.ops.aten.le.Scalar(relu_21, 0);  relu_21 = None
        where_27: f32[1, 512, 8, 8] = torch.ops.aten.where.self(le_27, full_default, add_289);  le_27 = add_289 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_60: f32[512] = torch.ops.aten.sum.dim_IntList(where_27, [0, 2, 3])
        sub_169: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_23, unsqueeze_562);  convolution_23 = unsqueeze_562 = None
        mul_632: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_27, sub_169)
        sum_61: f32[512] = torch.ops.aten.sum.dim_IntList(mul_632, [0, 2, 3]);  mul_632 = None
        mul_633: f32[512] = torch.ops.aten.mul.Tensor(sum_60, 0.015625)
        unsqueeze_563: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_633, 0);  mul_633 = None
        unsqueeze_564: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_563, 2);  unsqueeze_563 = None
        unsqueeze_565: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_564, 3);  unsqueeze_564 = None
        mul_634: f32[512] = torch.ops.aten.mul.Tensor(sum_61, 0.015625)
        mul_635: f32[512] = torch.ops.aten.mul.Tensor(squeeze_70, squeeze_70)
        mul_636: f32[512] = torch.ops.aten.mul.Tensor(mul_634, mul_635);  mul_634 = mul_635 = None
        unsqueeze_566: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_636, 0);  mul_636 = None
        unsqueeze_567: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_566, 2);  unsqueeze_566 = None
        unsqueeze_568: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_567, 3);  unsqueeze_567 = None
        mul_637: f32[512] = torch.ops.aten.mul.Tensor(squeeze_70, primals_71);  primals_71 = None
        unsqueeze_569: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_637, 0);  mul_637 = None
        unsqueeze_570: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_569, 2);  unsqueeze_569 = None
        unsqueeze_571: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_570, 3);  unsqueeze_570 = None
        mul_638: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_169, unsqueeze_568);  sub_169 = unsqueeze_568 = None
        sub_171: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_27, mul_638);  mul_638 = None
        sub_172: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_171, unsqueeze_565);  sub_171 = unsqueeze_565 = None
        mul_639: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_172, unsqueeze_571);  sub_172 = unsqueeze_571 = None
        mul_640: f32[512] = torch.ops.aten.mul.Tensor(sum_61, squeeze_70);  sum_61 = squeeze_70 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_29 = torch.ops.aten.convolution_backward.default(mul_639, relu_20, primals_70, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_639 = primals_70 = None
        getitem_195: f32[1, 128, 8, 8] = convolution_backward_29[0]
        getitem_196: f32[512, 128, 1, 1] = convolution_backward_29[1];  convolution_backward_29 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_28: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_20, 0);  relu_20 = None
        where_28: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_28, full_default, getitem_195);  le_28 = getitem_195 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_62: f32[128] = torch.ops.aten.sum.dim_IntList(where_28, [0, 2, 3])
        sub_173: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_22, unsqueeze_574);  convolution_22 = unsqueeze_574 = None
        mul_641: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_28, sub_173)
        sum_63: f32[128] = torch.ops.aten.sum.dim_IntList(mul_641, [0, 2, 3]);  mul_641 = None
        mul_642: f32[128] = torch.ops.aten.mul.Tensor(sum_62, 0.015625)
        unsqueeze_575: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_642, 0);  mul_642 = None
        unsqueeze_576: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_575, 2);  unsqueeze_575 = None
        unsqueeze_577: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_576, 3);  unsqueeze_576 = None
        mul_643: f32[128] = torch.ops.aten.mul.Tensor(sum_63, 0.015625)
        mul_644: f32[128] = torch.ops.aten.mul.Tensor(squeeze_67, squeeze_67)
        mul_645: f32[128] = torch.ops.aten.mul.Tensor(mul_643, mul_644);  mul_643 = mul_644 = None
        unsqueeze_578: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_645, 0);  mul_645 = None
        unsqueeze_579: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_578, 2);  unsqueeze_578 = None
        unsqueeze_580: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_579, 3);  unsqueeze_579 = None
        mul_646: f32[128] = torch.ops.aten.mul.Tensor(squeeze_67, primals_68);  primals_68 = None
        unsqueeze_581: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_646, 0);  mul_646 = None
        unsqueeze_582: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_581, 2);  unsqueeze_581 = None
        unsqueeze_583: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_582, 3);  unsqueeze_582 = None
        mul_647: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_173, unsqueeze_580);  sub_173 = unsqueeze_580 = None
        sub_175: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_28, mul_647);  where_28 = mul_647 = None
        sub_176: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_175, unsqueeze_577);  sub_175 = unsqueeze_577 = None
        mul_648: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_176, unsqueeze_583);  sub_176 = unsqueeze_583 = None
        mul_649: f32[128] = torch.ops.aten.mul.Tensor(sum_63, squeeze_67);  sum_63 = squeeze_67 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_30 = torch.ops.aten.convolution_backward.default(mul_648, relu_19, primals_67, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_648 = primals_67 = None
        getitem_198: f32[1, 128, 8, 8] = convolution_backward_30[0]
        getitem_199: f32[128, 128, 3, 3] = convolution_backward_30[1];  convolution_backward_30 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_29: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_19, 0);  relu_19 = None
        where_29: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_29, full_default, getitem_198);  le_29 = getitem_198 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_64: f32[128] = torch.ops.aten.sum.dim_IntList(where_29, [0, 2, 3])
        sub_177: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_21, unsqueeze_586);  convolution_21 = unsqueeze_586 = None
        mul_650: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_29, sub_177)
        sum_65: f32[128] = torch.ops.aten.sum.dim_IntList(mul_650, [0, 2, 3]);  mul_650 = None
        mul_651: f32[128] = torch.ops.aten.mul.Tensor(sum_64, 0.015625)
        unsqueeze_587: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_651, 0);  mul_651 = None
        unsqueeze_588: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_587, 2);  unsqueeze_587 = None
        unsqueeze_589: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_588, 3);  unsqueeze_588 = None
        mul_652: f32[128] = torch.ops.aten.mul.Tensor(sum_65, 0.015625)
        mul_653: f32[128] = torch.ops.aten.mul.Tensor(squeeze_64, squeeze_64)
        mul_654: f32[128] = torch.ops.aten.mul.Tensor(mul_652, mul_653);  mul_652 = mul_653 = None
        unsqueeze_590: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_654, 0);  mul_654 = None
        unsqueeze_591: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_590, 2);  unsqueeze_590 = None
        unsqueeze_592: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_591, 3);  unsqueeze_591 = None
        mul_655: f32[128] = torch.ops.aten.mul.Tensor(squeeze_64, primals_65);  primals_65 = None
        unsqueeze_593: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_655, 0);  mul_655 = None
        unsqueeze_594: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_593, 2);  unsqueeze_593 = None
        unsqueeze_595: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_594, 3);  unsqueeze_594 = None
        mul_656: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_177, unsqueeze_592);  sub_177 = unsqueeze_592 = None
        sub_179: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_29, mul_656);  where_29 = mul_656 = None
        sub_180: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_179, unsqueeze_589);  sub_179 = unsqueeze_589 = None
        mul_657: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_180, unsqueeze_595);  sub_180 = unsqueeze_595 = None
        mul_658: f32[128] = torch.ops.aten.mul.Tensor(sum_65, squeeze_64);  sum_65 = squeeze_64 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_31 = torch.ops.aten.convolution_backward.default(mul_657, relu_18, primals_64, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_657 = primals_64 = None
        getitem_201: f32[1, 512, 8, 8] = convolution_backward_31[0]
        getitem_202: f32[128, 512, 1, 1] = convolution_backward_31[1];  convolution_backward_31 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_290: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(where_27, getitem_201);  where_27 = getitem_201 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_30: b8[1, 512, 8, 8] = torch.ops.aten.le.Scalar(relu_18, 0);  relu_18 = None
        where_30: f32[1, 512, 8, 8] = torch.ops.aten.where.self(le_30, full_default, add_290);  le_30 = add_290 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_66: f32[512] = torch.ops.aten.sum.dim_IntList(where_30, [0, 2, 3])
        sub_181: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_20, unsqueeze_598);  convolution_20 = unsqueeze_598 = None
        mul_659: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_30, sub_181)
        sum_67: f32[512] = torch.ops.aten.sum.dim_IntList(mul_659, [0, 2, 3]);  mul_659 = None
        mul_660: f32[512] = torch.ops.aten.mul.Tensor(sum_66, 0.015625)
        unsqueeze_599: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_660, 0);  mul_660 = None
        unsqueeze_600: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_599, 2);  unsqueeze_599 = None
        unsqueeze_601: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_600, 3);  unsqueeze_600 = None
        mul_661: f32[512] = torch.ops.aten.mul.Tensor(sum_67, 0.015625)
        mul_662: f32[512] = torch.ops.aten.mul.Tensor(squeeze_61, squeeze_61)
        mul_663: f32[512] = torch.ops.aten.mul.Tensor(mul_661, mul_662);  mul_661 = mul_662 = None
        unsqueeze_602: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_663, 0);  mul_663 = None
        unsqueeze_603: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_602, 2);  unsqueeze_602 = None
        unsqueeze_604: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_603, 3);  unsqueeze_603 = None
        mul_664: f32[512] = torch.ops.aten.mul.Tensor(squeeze_61, primals_62);  primals_62 = None
        unsqueeze_605: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_664, 0);  mul_664 = None
        unsqueeze_606: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_605, 2);  unsqueeze_605 = None
        unsqueeze_607: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_606, 3);  unsqueeze_606 = None
        mul_665: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_181, unsqueeze_604);  sub_181 = unsqueeze_604 = None
        sub_183: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_30, mul_665);  mul_665 = None
        sub_184: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_183, unsqueeze_601);  sub_183 = unsqueeze_601 = None
        mul_666: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_184, unsqueeze_607);  sub_184 = unsqueeze_607 = None
        mul_667: f32[512] = torch.ops.aten.mul.Tensor(sum_67, squeeze_61);  sum_67 = squeeze_61 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_32 = torch.ops.aten.convolution_backward.default(mul_666, relu_17, primals_61, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_666 = primals_61 = None
        getitem_204: f32[1, 128, 8, 8] = convolution_backward_32[0]
        getitem_205: f32[512, 128, 1, 1] = convolution_backward_32[1];  convolution_backward_32 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_31: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_17, 0);  relu_17 = None
        where_31: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_31, full_default, getitem_204);  le_31 = getitem_204 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_68: f32[128] = torch.ops.aten.sum.dim_IntList(where_31, [0, 2, 3])
        sub_185: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_610);  convolution_19 = unsqueeze_610 = None
        mul_668: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_31, sub_185)
        sum_69: f32[128] = torch.ops.aten.sum.dim_IntList(mul_668, [0, 2, 3]);  mul_668 = None
        mul_669: f32[128] = torch.ops.aten.mul.Tensor(sum_68, 0.015625)
        unsqueeze_611: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_669, 0);  mul_669 = None
        unsqueeze_612: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_611, 2);  unsqueeze_611 = None
        unsqueeze_613: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_612, 3);  unsqueeze_612 = None
        mul_670: f32[128] = torch.ops.aten.mul.Tensor(sum_69, 0.015625)
        mul_671: f32[128] = torch.ops.aten.mul.Tensor(squeeze_58, squeeze_58)
        mul_672: f32[128] = torch.ops.aten.mul.Tensor(mul_670, mul_671);  mul_670 = mul_671 = None
        unsqueeze_614: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_672, 0);  mul_672 = None
        unsqueeze_615: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_614, 2);  unsqueeze_614 = None
        unsqueeze_616: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_615, 3);  unsqueeze_615 = None
        mul_673: f32[128] = torch.ops.aten.mul.Tensor(squeeze_58, primals_59);  primals_59 = None
        unsqueeze_617: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_673, 0);  mul_673 = None
        unsqueeze_618: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_617, 2);  unsqueeze_617 = None
        unsqueeze_619: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_618, 3);  unsqueeze_618 = None
        mul_674: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_185, unsqueeze_616);  sub_185 = unsqueeze_616 = None
        sub_187: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_31, mul_674);  where_31 = mul_674 = None
        sub_188: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_187, unsqueeze_613);  sub_187 = unsqueeze_613 = None
        mul_675: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_188, unsqueeze_619);  sub_188 = unsqueeze_619 = None
        mul_676: f32[128] = torch.ops.aten.mul.Tensor(sum_69, squeeze_58);  sum_69 = squeeze_58 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_33 = torch.ops.aten.convolution_backward.default(mul_675, relu_16, primals_58, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_675 = primals_58 = None
        getitem_207: f32[1, 128, 8, 8] = convolution_backward_33[0]
        getitem_208: f32[128, 128, 3, 3] = convolution_backward_33[1];  convolution_backward_33 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_32: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_16, 0);  relu_16 = None
        where_32: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_32, full_default, getitem_207);  le_32 = getitem_207 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_70: f32[128] = torch.ops.aten.sum.dim_IntList(where_32, [0, 2, 3])
        sub_189: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_622);  convolution_18 = unsqueeze_622 = None
        mul_677: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_32, sub_189)
        sum_71: f32[128] = torch.ops.aten.sum.dim_IntList(mul_677, [0, 2, 3]);  mul_677 = None
        mul_678: f32[128] = torch.ops.aten.mul.Tensor(sum_70, 0.015625)
        unsqueeze_623: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_678, 0);  mul_678 = None
        unsqueeze_624: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_623, 2);  unsqueeze_623 = None
        unsqueeze_625: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_624, 3);  unsqueeze_624 = None
        mul_679: f32[128] = torch.ops.aten.mul.Tensor(sum_71, 0.015625)
        mul_680: f32[128] = torch.ops.aten.mul.Tensor(squeeze_55, squeeze_55)
        mul_681: f32[128] = torch.ops.aten.mul.Tensor(mul_679, mul_680);  mul_679 = mul_680 = None
        unsqueeze_626: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_681, 0);  mul_681 = None
        unsqueeze_627: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_626, 2);  unsqueeze_626 = None
        unsqueeze_628: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_627, 3);  unsqueeze_627 = None
        mul_682: f32[128] = torch.ops.aten.mul.Tensor(squeeze_55, primals_56);  primals_56 = None
        unsqueeze_629: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_682, 0);  mul_682 = None
        unsqueeze_630: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_629, 2);  unsqueeze_629 = None
        unsqueeze_631: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_630, 3);  unsqueeze_630 = None
        mul_683: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_189, unsqueeze_628);  sub_189 = unsqueeze_628 = None
        sub_191: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_32, mul_683);  where_32 = mul_683 = None
        sub_192: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_191, unsqueeze_625);  sub_191 = unsqueeze_625 = None
        mul_684: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_192, unsqueeze_631);  sub_192 = unsqueeze_631 = None
        mul_685: f32[128] = torch.ops.aten.mul.Tensor(sum_71, squeeze_55);  sum_71 = squeeze_55 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_34 = torch.ops.aten.convolution_backward.default(mul_684, relu_15, primals_55, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_684 = primals_55 = None
        getitem_210: f32[1, 512, 8, 8] = convolution_backward_34[0]
        getitem_211: f32[128, 512, 1, 1] = convolution_backward_34[1];  convolution_backward_34 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_291: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(where_30, getitem_210);  where_30 = getitem_210 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_33: b8[1, 512, 8, 8] = torch.ops.aten.le.Scalar(relu_15, 0);  relu_15 = None
        where_33: f32[1, 512, 8, 8] = torch.ops.aten.where.self(le_33, full_default, add_291);  le_33 = add_291 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_72: f32[512] = torch.ops.aten.sum.dim_IntList(where_33, [0, 2, 3])
        sub_193: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_634);  convolution_17 = unsqueeze_634 = None
        mul_686: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_33, sub_193)
        sum_73: f32[512] = torch.ops.aten.sum.dim_IntList(mul_686, [0, 2, 3]);  mul_686 = None
        mul_687: f32[512] = torch.ops.aten.mul.Tensor(sum_72, 0.015625)
        unsqueeze_635: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_687, 0);  mul_687 = None
        unsqueeze_636: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_635, 2);  unsqueeze_635 = None
        unsqueeze_637: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_636, 3);  unsqueeze_636 = None
        mul_688: f32[512] = torch.ops.aten.mul.Tensor(sum_73, 0.015625)
        mul_689: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, squeeze_52)
        mul_690: f32[512] = torch.ops.aten.mul.Tensor(mul_688, mul_689);  mul_688 = mul_689 = None
        unsqueeze_638: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_690, 0);  mul_690 = None
        unsqueeze_639: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_638, 2);  unsqueeze_638 = None
        unsqueeze_640: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_639, 3);  unsqueeze_639 = None
        mul_691: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, primals_53);  primals_53 = None
        unsqueeze_641: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_691, 0);  mul_691 = None
        unsqueeze_642: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_641, 2);  unsqueeze_641 = None
        unsqueeze_643: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_642, 3);  unsqueeze_642 = None
        mul_692: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_193, unsqueeze_640);  sub_193 = unsqueeze_640 = None
        sub_195: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_33, mul_692);  mul_692 = None
        sub_196: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_195, unsqueeze_637);  sub_195 = unsqueeze_637 = None
        mul_693: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_196, unsqueeze_643);  sub_196 = unsqueeze_643 = None
        mul_694: f32[512] = torch.ops.aten.mul.Tensor(sum_73, squeeze_52);  sum_73 = squeeze_52 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_35 = torch.ops.aten.convolution_backward.default(mul_693, relu_14, primals_52, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_693 = primals_52 = None
        getitem_213: f32[1, 128, 8, 8] = convolution_backward_35[0]
        getitem_214: f32[512, 128, 1, 1] = convolution_backward_35[1];  convolution_backward_35 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_34: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_14, 0);  relu_14 = None
        where_34: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_34, full_default, getitem_213);  le_34 = getitem_213 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_74: f32[128] = torch.ops.aten.sum.dim_IntList(where_34, [0, 2, 3])
        sub_197: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_646);  convolution_16 = unsqueeze_646 = None
        mul_695: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_34, sub_197)
        sum_75: f32[128] = torch.ops.aten.sum.dim_IntList(mul_695, [0, 2, 3]);  mul_695 = None
        mul_696: f32[128] = torch.ops.aten.mul.Tensor(sum_74, 0.015625)
        unsqueeze_647: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_696, 0);  mul_696 = None
        unsqueeze_648: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_647, 2);  unsqueeze_647 = None
        unsqueeze_649: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_648, 3);  unsqueeze_648 = None
        mul_697: f32[128] = torch.ops.aten.mul.Tensor(sum_75, 0.015625)
        mul_698: f32[128] = torch.ops.aten.mul.Tensor(squeeze_49, squeeze_49)
        mul_699: f32[128] = torch.ops.aten.mul.Tensor(mul_697, mul_698);  mul_697 = mul_698 = None
        unsqueeze_650: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_699, 0);  mul_699 = None
        unsqueeze_651: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_650, 2);  unsqueeze_650 = None
        unsqueeze_652: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_651, 3);  unsqueeze_651 = None
        mul_700: f32[128] = torch.ops.aten.mul.Tensor(squeeze_49, primals_50);  primals_50 = None
        unsqueeze_653: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_700, 0);  mul_700 = None
        unsqueeze_654: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_653, 2);  unsqueeze_653 = None
        unsqueeze_655: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_654, 3);  unsqueeze_654 = None
        mul_701: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_197, unsqueeze_652);  sub_197 = unsqueeze_652 = None
        sub_199: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_34, mul_701);  where_34 = mul_701 = None
        sub_200: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_199, unsqueeze_649);  sub_199 = unsqueeze_649 = None
        mul_702: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_200, unsqueeze_655);  sub_200 = unsqueeze_655 = None
        mul_703: f32[128] = torch.ops.aten.mul.Tensor(sum_75, squeeze_49);  sum_75 = squeeze_49 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_36 = torch.ops.aten.convolution_backward.default(mul_702, relu_13, primals_49, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_702 = primals_49 = None
        getitem_216: f32[1, 128, 8, 8] = convolution_backward_36[0]
        getitem_217: f32[128, 128, 3, 3] = convolution_backward_36[1];  convolution_backward_36 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_35: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_13, 0);  relu_13 = None
        where_35: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_35, full_default, getitem_216);  le_35 = getitem_216 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_76: f32[128] = torch.ops.aten.sum.dim_IntList(where_35, [0, 2, 3])
        sub_201: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_658);  convolution_15 = unsqueeze_658 = None
        mul_704: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_35, sub_201)
        sum_77: f32[128] = torch.ops.aten.sum.dim_IntList(mul_704, [0, 2, 3]);  mul_704 = None
        mul_705: f32[128] = torch.ops.aten.mul.Tensor(sum_76, 0.015625)
        unsqueeze_659: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_705, 0);  mul_705 = None
        unsqueeze_660: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_659, 2);  unsqueeze_659 = None
        unsqueeze_661: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_660, 3);  unsqueeze_660 = None
        mul_706: f32[128] = torch.ops.aten.mul.Tensor(sum_77, 0.015625)
        mul_707: f32[128] = torch.ops.aten.mul.Tensor(squeeze_46, squeeze_46)
        mul_708: f32[128] = torch.ops.aten.mul.Tensor(mul_706, mul_707);  mul_706 = mul_707 = None
        unsqueeze_662: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_708, 0);  mul_708 = None
        unsqueeze_663: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_662, 2);  unsqueeze_662 = None
        unsqueeze_664: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_663, 3);  unsqueeze_663 = None
        mul_709: f32[128] = torch.ops.aten.mul.Tensor(squeeze_46, primals_47);  primals_47 = None
        unsqueeze_665: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_709, 0);  mul_709 = None
        unsqueeze_666: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_665, 2);  unsqueeze_665 = None
        unsqueeze_667: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_666, 3);  unsqueeze_666 = None
        mul_710: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_201, unsqueeze_664);  sub_201 = unsqueeze_664 = None
        sub_203: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_35, mul_710);  where_35 = mul_710 = None
        sub_204: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_203, unsqueeze_661);  sub_203 = unsqueeze_661 = None
        mul_711: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_204, unsqueeze_667);  sub_204 = unsqueeze_667 = None
        mul_712: f32[128] = torch.ops.aten.mul.Tensor(sum_77, squeeze_46);  sum_77 = squeeze_46 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_37 = torch.ops.aten.convolution_backward.default(mul_711, relu_12, primals_46, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_711 = primals_46 = None
        getitem_219: f32[1, 512, 8, 8] = convolution_backward_37[0]
        getitem_220: f32[128, 512, 1, 1] = convolution_backward_37[1];  convolution_backward_37 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_292: f32[1, 512, 8, 8] = torch.ops.aten.add.Tensor(where_33, getitem_219);  where_33 = getitem_219 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_36: b8[1, 512, 8, 8] = torch.ops.aten.le.Scalar(relu_12, 0);  relu_12 = None
        where_36: f32[1, 512, 8, 8] = torch.ops.aten.where.self(le_36, full_default, add_292);  le_36 = add_292 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        sum_78: f32[512] = torch.ops.aten.sum.dim_IntList(where_36, [0, 2, 3])
        sub_205: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_670);  convolution_14 = unsqueeze_670 = None
        mul_713: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_36, sub_205)
        sum_79: f32[512] = torch.ops.aten.sum.dim_IntList(mul_713, [0, 2, 3]);  mul_713 = None
        mul_714: f32[512] = torch.ops.aten.mul.Tensor(sum_78, 0.015625)
        unsqueeze_671: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_714, 0);  mul_714 = None
        unsqueeze_672: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_671, 2);  unsqueeze_671 = None
        unsqueeze_673: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_672, 3);  unsqueeze_672 = None
        mul_715: f32[512] = torch.ops.aten.mul.Tensor(sum_79, 0.015625)
        mul_716: f32[512] = torch.ops.aten.mul.Tensor(squeeze_43, squeeze_43)
        mul_717: f32[512] = torch.ops.aten.mul.Tensor(mul_715, mul_716);  mul_715 = mul_716 = None
        unsqueeze_674: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_717, 0);  mul_717 = None
        unsqueeze_675: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_674, 2);  unsqueeze_674 = None
        unsqueeze_676: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_675, 3);  unsqueeze_675 = None
        mul_718: f32[512] = torch.ops.aten.mul.Tensor(squeeze_43, primals_44);  primals_44 = None
        unsqueeze_677: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_718, 0);  mul_718 = None
        unsqueeze_678: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_677, 2);  unsqueeze_677 = None
        unsqueeze_679: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_678, 3);  unsqueeze_678 = None
        mul_719: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_205, unsqueeze_676);  sub_205 = unsqueeze_676 = None
        sub_207: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_36, mul_719);  mul_719 = None
        sub_208: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_207, unsqueeze_673);  sub_207 = None
        mul_720: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_208, unsqueeze_679);  sub_208 = unsqueeze_679 = None
        mul_721: f32[512] = torch.ops.aten.mul.Tensor(sum_79, squeeze_43);  sum_79 = squeeze_43 = None
        convolution_backward_38 = torch.ops.aten.convolution_backward.default(mul_720, relu_9, primals_43, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_720 = primals_43 = None
        getitem_222: f32[1, 256, 16, 16] = convolution_backward_38[0]
        getitem_223: f32[512, 256, 1, 1] = convolution_backward_38[1];  convolution_backward_38 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sub_209: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_682);  convolution_13 = unsqueeze_682 = None
        mul_722: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(where_36, sub_209)
        sum_81: f32[512] = torch.ops.aten.sum.dim_IntList(mul_722, [0, 2, 3]);  mul_722 = None
        mul_724: f32[512] = torch.ops.aten.mul.Tensor(sum_81, 0.015625)
        mul_725: f32[512] = torch.ops.aten.mul.Tensor(squeeze_40, squeeze_40)
        mul_726: f32[512] = torch.ops.aten.mul.Tensor(mul_724, mul_725);  mul_724 = mul_725 = None
        unsqueeze_686: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_726, 0);  mul_726 = None
        unsqueeze_687: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_686, 2);  unsqueeze_686 = None
        unsqueeze_688: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_687, 3);  unsqueeze_687 = None
        mul_727: f32[512] = torch.ops.aten.mul.Tensor(squeeze_40, primals_41);  primals_41 = None
        unsqueeze_689: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_727, 0);  mul_727 = None
        unsqueeze_690: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_689, 2);  unsqueeze_689 = None
        unsqueeze_691: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_690, 3);  unsqueeze_690 = None
        mul_728: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_209, unsqueeze_688);  sub_209 = unsqueeze_688 = None
        sub_211: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(where_36, mul_728);  where_36 = mul_728 = None
        sub_212: f32[1, 512, 8, 8] = torch.ops.aten.sub.Tensor(sub_211, unsqueeze_673);  sub_211 = unsqueeze_673 = None
        mul_729: f32[1, 512, 8, 8] = torch.ops.aten.mul.Tensor(sub_212, unsqueeze_691);  sub_212 = unsqueeze_691 = None
        mul_730: f32[512] = torch.ops.aten.mul.Tensor(sum_81, squeeze_40);  sum_81 = squeeze_40 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_39 = torch.ops.aten.convolution_backward.default(mul_729, relu_11, primals_40, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_729 = primals_40 = None
        getitem_225: f32[1, 128, 8, 8] = convolution_backward_39[0]
        getitem_226: f32[512, 128, 1, 1] = convolution_backward_39[1];  convolution_backward_39 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_37: b8[1, 128, 8, 8] = torch.ops.aten.le.Scalar(relu_11, 0);  relu_11 = None
        where_37: f32[1, 128, 8, 8] = torch.ops.aten.where.self(le_37, full_default, getitem_225);  le_37 = getitem_225 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_82: f32[128] = torch.ops.aten.sum.dim_IntList(where_37, [0, 2, 3])
        sub_213: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_694);  convolution_12 = unsqueeze_694 = None
        mul_731: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(where_37, sub_213)
        sum_83: f32[128] = torch.ops.aten.sum.dim_IntList(mul_731, [0, 2, 3]);  mul_731 = None
        mul_732: f32[128] = torch.ops.aten.mul.Tensor(sum_82, 0.015625)
        unsqueeze_695: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_732, 0);  mul_732 = None
        unsqueeze_696: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_695, 2);  unsqueeze_695 = None
        unsqueeze_697: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_696, 3);  unsqueeze_696 = None
        mul_733: f32[128] = torch.ops.aten.mul.Tensor(sum_83, 0.015625)
        mul_734: f32[128] = torch.ops.aten.mul.Tensor(squeeze_37, squeeze_37)
        mul_735: f32[128] = torch.ops.aten.mul.Tensor(mul_733, mul_734);  mul_733 = mul_734 = None
        unsqueeze_698: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_735, 0);  mul_735 = None
        unsqueeze_699: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_698, 2);  unsqueeze_698 = None
        unsqueeze_700: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_699, 3);  unsqueeze_699 = None
        mul_736: f32[128] = torch.ops.aten.mul.Tensor(squeeze_37, primals_38);  primals_38 = None
        unsqueeze_701: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_736, 0);  mul_736 = None
        unsqueeze_702: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_701, 2);  unsqueeze_701 = None
        unsqueeze_703: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_702, 3);  unsqueeze_702 = None
        mul_737: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_213, unsqueeze_700);  sub_213 = unsqueeze_700 = None
        sub_215: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(where_37, mul_737);  where_37 = mul_737 = None
        sub_216: f32[1, 128, 8, 8] = torch.ops.aten.sub.Tensor(sub_215, unsqueeze_697);  sub_215 = unsqueeze_697 = None
        mul_738: f32[1, 128, 8, 8] = torch.ops.aten.mul.Tensor(sub_216, unsqueeze_703);  sub_216 = unsqueeze_703 = None
        mul_739: f32[128] = torch.ops.aten.mul.Tensor(sum_83, squeeze_37);  sum_83 = squeeze_37 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_40 = torch.ops.aten.convolution_backward.default(mul_738, relu_10, primals_37, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_738 = primals_37 = None
        getitem_228: f32[1, 128, 16, 16] = convolution_backward_40[0]
        getitem_229: f32[128, 128, 3, 3] = convolution_backward_40[1];  convolution_backward_40 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_38: b8[1, 128, 16, 16] = torch.ops.aten.le.Scalar(relu_10, 0);  relu_10 = None
        where_38: f32[1, 128, 16, 16] = torch.ops.aten.where.self(le_38, full_default, getitem_228);  le_38 = getitem_228 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_84: f32[128] = torch.ops.aten.sum.dim_IntList(where_38, [0, 2, 3])
        sub_217: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_706);  convolution_11 = unsqueeze_706 = None
        mul_740: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(where_38, sub_217)
        sum_85: f32[128] = torch.ops.aten.sum.dim_IntList(mul_740, [0, 2, 3]);  mul_740 = None
        mul_741: f32[128] = torch.ops.aten.mul.Tensor(sum_84, 0.00390625)
        unsqueeze_707: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_741, 0);  mul_741 = None
        unsqueeze_708: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_707, 2);  unsqueeze_707 = None
        unsqueeze_709: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_708, 3);  unsqueeze_708 = None
        mul_742: f32[128] = torch.ops.aten.mul.Tensor(sum_85, 0.00390625)
        mul_743: f32[128] = torch.ops.aten.mul.Tensor(squeeze_34, squeeze_34)
        mul_744: f32[128] = torch.ops.aten.mul.Tensor(mul_742, mul_743);  mul_742 = mul_743 = None
        unsqueeze_710: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_744, 0);  mul_744 = None
        unsqueeze_711: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_710, 2);  unsqueeze_710 = None
        unsqueeze_712: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_711, 3);  unsqueeze_711 = None
        mul_745: f32[128] = torch.ops.aten.mul.Tensor(squeeze_34, primals_35);  primals_35 = None
        unsqueeze_713: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_745, 0);  mul_745 = None
        unsqueeze_714: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_713, 2);  unsqueeze_713 = None
        unsqueeze_715: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_714, 3);  unsqueeze_714 = None
        mul_746: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(sub_217, unsqueeze_712);  sub_217 = unsqueeze_712 = None
        sub_219: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(where_38, mul_746);  where_38 = mul_746 = None
        sub_220: f32[1, 128, 16, 16] = torch.ops.aten.sub.Tensor(sub_219, unsqueeze_709);  sub_219 = unsqueeze_709 = None
        mul_747: f32[1, 128, 16, 16] = torch.ops.aten.mul.Tensor(sub_220, unsqueeze_715);  sub_220 = unsqueeze_715 = None
        mul_748: f32[128] = torch.ops.aten.mul.Tensor(sum_85, squeeze_34);  sum_85 = squeeze_34 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_41 = torch.ops.aten.convolution_backward.default(mul_747, relu_9, primals_34, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_747 = primals_34 = None
        getitem_231: f32[1, 256, 16, 16] = convolution_backward_41[0]
        getitem_232: f32[128, 256, 1, 1] = convolution_backward_41[1];  convolution_backward_41 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_293: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(getitem_222, getitem_231);  getitem_222 = getitem_231 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_39: b8[1, 256, 16, 16] = torch.ops.aten.le.Scalar(relu_9, 0);  relu_9 = None
        where_39: f32[1, 256, 16, 16] = torch.ops.aten.where.self(le_39, full_default, add_293);  le_39 = add_293 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_86: f32[256] = torch.ops.aten.sum.dim_IntList(where_39, [0, 2, 3])
        sub_221: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_718);  convolution_10 = unsqueeze_718 = None
        mul_749: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(where_39, sub_221)
        sum_87: f32[256] = torch.ops.aten.sum.dim_IntList(mul_749, [0, 2, 3]);  mul_749 = None
        mul_750: f32[256] = torch.ops.aten.mul.Tensor(sum_86, 0.00390625)
        unsqueeze_719: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_750, 0);  mul_750 = None
        unsqueeze_720: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_719, 2);  unsqueeze_719 = None
        unsqueeze_721: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_720, 3);  unsqueeze_720 = None
        mul_751: f32[256] = torch.ops.aten.mul.Tensor(sum_87, 0.00390625)
        mul_752: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, squeeze_31)
        mul_753: f32[256] = torch.ops.aten.mul.Tensor(mul_751, mul_752);  mul_751 = mul_752 = None
        unsqueeze_722: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_753, 0);  mul_753 = None
        unsqueeze_723: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_722, 2);  unsqueeze_722 = None
        unsqueeze_724: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_723, 3);  unsqueeze_723 = None
        mul_754: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, primals_32);  primals_32 = None
        unsqueeze_725: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_754, 0);  mul_754 = None
        unsqueeze_726: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_725, 2);  unsqueeze_725 = None
        unsqueeze_727: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_726, 3);  unsqueeze_726 = None
        mul_755: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_221, unsqueeze_724);  sub_221 = unsqueeze_724 = None
        sub_223: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(where_39, mul_755);  mul_755 = None
        sub_224: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(sub_223, unsqueeze_721);  sub_223 = unsqueeze_721 = None
        mul_756: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_224, unsqueeze_727);  sub_224 = unsqueeze_727 = None
        mul_757: f32[256] = torch.ops.aten.mul.Tensor(sum_87, squeeze_31);  sum_87 = squeeze_31 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_42 = torch.ops.aten.convolution_backward.default(mul_756, relu_8, primals_31, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_756 = primals_31 = None
        getitem_234: f32[1, 64, 16, 16] = convolution_backward_42[0]
        getitem_235: f32[256, 64, 1, 1] = convolution_backward_42[1];  convolution_backward_42 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_40: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_8, 0);  relu_8 = None
        where_40: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_40, full_default, getitem_234);  le_40 = getitem_234 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_88: f32[64] = torch.ops.aten.sum.dim_IntList(where_40, [0, 2, 3])
        sub_225: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_730);  convolution_9 = unsqueeze_730 = None
        mul_758: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_40, sub_225)
        sum_89: f32[64] = torch.ops.aten.sum.dim_IntList(mul_758, [0, 2, 3]);  mul_758 = None
        mul_759: f32[64] = torch.ops.aten.mul.Tensor(sum_88, 0.00390625)
        unsqueeze_731: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_759, 0);  mul_759 = None
        unsqueeze_732: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_731, 2);  unsqueeze_731 = None
        unsqueeze_733: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_732, 3);  unsqueeze_732 = None
        mul_760: f32[64] = torch.ops.aten.mul.Tensor(sum_89, 0.00390625)
        mul_761: f32[64] = torch.ops.aten.mul.Tensor(squeeze_28, squeeze_28)
        mul_762: f32[64] = torch.ops.aten.mul.Tensor(mul_760, mul_761);  mul_760 = mul_761 = None
        unsqueeze_734: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_762, 0);  mul_762 = None
        unsqueeze_735: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_734, 2);  unsqueeze_734 = None
        unsqueeze_736: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_735, 3);  unsqueeze_735 = None
        mul_763: f32[64] = torch.ops.aten.mul.Tensor(squeeze_28, primals_29);  primals_29 = None
        unsqueeze_737: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_763, 0);  mul_763 = None
        unsqueeze_738: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_737, 2);  unsqueeze_737 = None
        unsqueeze_739: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_738, 3);  unsqueeze_738 = None
        mul_764: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_225, unsqueeze_736);  sub_225 = unsqueeze_736 = None
        sub_227: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_40, mul_764);  where_40 = mul_764 = None
        sub_228: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_227, unsqueeze_733);  sub_227 = unsqueeze_733 = None
        mul_765: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_228, unsqueeze_739);  sub_228 = unsqueeze_739 = None
        mul_766: f32[64] = torch.ops.aten.mul.Tensor(sum_89, squeeze_28);  sum_89 = squeeze_28 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_43 = torch.ops.aten.convolution_backward.default(mul_765, relu_7, primals_28, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_765 = primals_28 = None
        getitem_237: f32[1, 64, 16, 16] = convolution_backward_43[0]
        getitem_238: f32[64, 64, 3, 3] = convolution_backward_43[1];  convolution_backward_43 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_41: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_7, 0);  relu_7 = None
        where_41: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_41, full_default, getitem_237);  le_41 = getitem_237 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_90: f32[64] = torch.ops.aten.sum.dim_IntList(where_41, [0, 2, 3])
        sub_229: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_742);  convolution_8 = unsqueeze_742 = None
        mul_767: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_41, sub_229)
        sum_91: f32[64] = torch.ops.aten.sum.dim_IntList(mul_767, [0, 2, 3]);  mul_767 = None
        mul_768: f32[64] = torch.ops.aten.mul.Tensor(sum_90, 0.00390625)
        unsqueeze_743: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_768, 0);  mul_768 = None
        unsqueeze_744: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_743, 2);  unsqueeze_743 = None
        unsqueeze_745: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_744, 3);  unsqueeze_744 = None
        mul_769: f32[64] = torch.ops.aten.mul.Tensor(sum_91, 0.00390625)
        mul_770: f32[64] = torch.ops.aten.mul.Tensor(squeeze_25, squeeze_25)
        mul_771: f32[64] = torch.ops.aten.mul.Tensor(mul_769, mul_770);  mul_769 = mul_770 = None
        unsqueeze_746: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_771, 0);  mul_771 = None
        unsqueeze_747: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_746, 2);  unsqueeze_746 = None
        unsqueeze_748: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_747, 3);  unsqueeze_747 = None
        mul_772: f32[64] = torch.ops.aten.mul.Tensor(squeeze_25, primals_26);  primals_26 = None
        unsqueeze_749: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_772, 0);  mul_772 = None
        unsqueeze_750: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_749, 2);  unsqueeze_749 = None
        unsqueeze_751: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_750, 3);  unsqueeze_750 = None
        mul_773: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_229, unsqueeze_748);  sub_229 = unsqueeze_748 = None
        sub_231: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_41, mul_773);  where_41 = mul_773 = None
        sub_232: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_231, unsqueeze_745);  sub_231 = unsqueeze_745 = None
        mul_774: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_232, unsqueeze_751);  sub_232 = unsqueeze_751 = None
        mul_775: f32[64] = torch.ops.aten.mul.Tensor(sum_91, squeeze_25);  sum_91 = squeeze_25 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_44 = torch.ops.aten.convolution_backward.default(mul_774, relu_6, primals_25, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_774 = primals_25 = None
        getitem_240: f32[1, 256, 16, 16] = convolution_backward_44[0]
        getitem_241: f32[64, 256, 1, 1] = convolution_backward_44[1];  convolution_backward_44 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_294: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(where_39, getitem_240);  where_39 = getitem_240 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_42: b8[1, 256, 16, 16] = torch.ops.aten.le.Scalar(relu_6, 0);  relu_6 = None
        where_42: f32[1, 256, 16, 16] = torch.ops.aten.where.self(le_42, full_default, add_294);  le_42 = add_294 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sum_92: f32[256] = torch.ops.aten.sum.dim_IntList(where_42, [0, 2, 3])
        sub_233: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_754);  convolution_7 = unsqueeze_754 = None
        mul_776: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(where_42, sub_233)
        sum_93: f32[256] = torch.ops.aten.sum.dim_IntList(mul_776, [0, 2, 3]);  mul_776 = None
        mul_777: f32[256] = torch.ops.aten.mul.Tensor(sum_92, 0.00390625)
        unsqueeze_755: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_777, 0);  mul_777 = None
        unsqueeze_756: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_755, 2);  unsqueeze_755 = None
        unsqueeze_757: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_756, 3);  unsqueeze_756 = None
        mul_778: f32[256] = torch.ops.aten.mul.Tensor(sum_93, 0.00390625)
        mul_779: f32[256] = torch.ops.aten.mul.Tensor(squeeze_22, squeeze_22)
        mul_780: f32[256] = torch.ops.aten.mul.Tensor(mul_778, mul_779);  mul_778 = mul_779 = None
        unsqueeze_758: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_780, 0);  mul_780 = None
        unsqueeze_759: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_758, 2);  unsqueeze_758 = None
        unsqueeze_760: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_759, 3);  unsqueeze_759 = None
        mul_781: f32[256] = torch.ops.aten.mul.Tensor(squeeze_22, primals_23);  primals_23 = None
        unsqueeze_761: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_781, 0);  mul_781 = None
        unsqueeze_762: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_761, 2);  unsqueeze_761 = None
        unsqueeze_763: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_762, 3);  unsqueeze_762 = None
        mul_782: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_233, unsqueeze_760);  sub_233 = unsqueeze_760 = None
        sub_235: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(where_42, mul_782);  mul_782 = None
        sub_236: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(sub_235, unsqueeze_757);  sub_235 = unsqueeze_757 = None
        mul_783: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_236, unsqueeze_763);  sub_236 = unsqueeze_763 = None
        mul_784: f32[256] = torch.ops.aten.mul.Tensor(sum_93, squeeze_22);  sum_93 = squeeze_22 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_45 = torch.ops.aten.convolution_backward.default(mul_783, relu_5, primals_22, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_783 = primals_22 = None
        getitem_243: f32[1, 64, 16, 16] = convolution_backward_45[0]
        getitem_244: f32[256, 64, 1, 1] = convolution_backward_45[1];  convolution_backward_45 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_43: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_5, 0);  relu_5 = None
        where_43: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_43, full_default, getitem_243);  le_43 = getitem_243 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_94: f32[64] = torch.ops.aten.sum.dim_IntList(where_43, [0, 2, 3])
        sub_237: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_766);  convolution_6 = unsqueeze_766 = None
        mul_785: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_43, sub_237)
        sum_95: f32[64] = torch.ops.aten.sum.dim_IntList(mul_785, [0, 2, 3]);  mul_785 = None
        mul_786: f32[64] = torch.ops.aten.mul.Tensor(sum_94, 0.00390625)
        unsqueeze_767: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_786, 0);  mul_786 = None
        unsqueeze_768: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_767, 2);  unsqueeze_767 = None
        unsqueeze_769: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_768, 3);  unsqueeze_768 = None
        mul_787: f32[64] = torch.ops.aten.mul.Tensor(sum_95, 0.00390625)
        mul_788: f32[64] = torch.ops.aten.mul.Tensor(squeeze_19, squeeze_19)
        mul_789: f32[64] = torch.ops.aten.mul.Tensor(mul_787, mul_788);  mul_787 = mul_788 = None
        unsqueeze_770: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_789, 0);  mul_789 = None
        unsqueeze_771: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_770, 2);  unsqueeze_770 = None
        unsqueeze_772: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_771, 3);  unsqueeze_771 = None
        mul_790: f32[64] = torch.ops.aten.mul.Tensor(squeeze_19, primals_20);  primals_20 = None
        unsqueeze_773: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_790, 0);  mul_790 = None
        unsqueeze_774: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_773, 2);  unsqueeze_773 = None
        unsqueeze_775: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_774, 3);  unsqueeze_774 = None
        mul_791: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_237, unsqueeze_772);  sub_237 = unsqueeze_772 = None
        sub_239: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_43, mul_791);  where_43 = mul_791 = None
        sub_240: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_239, unsqueeze_769);  sub_239 = unsqueeze_769 = None
        mul_792: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_240, unsqueeze_775);  sub_240 = unsqueeze_775 = None
        mul_793: f32[64] = torch.ops.aten.mul.Tensor(sum_95, squeeze_19);  sum_95 = squeeze_19 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_46 = torch.ops.aten.convolution_backward.default(mul_792, relu_4, primals_19, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_792 = primals_19 = None
        getitem_246: f32[1, 64, 16, 16] = convolution_backward_46[0]
        getitem_247: f32[64, 64, 3, 3] = convolution_backward_46[1];  convolution_backward_46 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_44: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_4, 0);  relu_4 = None
        where_44: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_44, full_default, getitem_246);  le_44 = getitem_246 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_96: f32[64] = torch.ops.aten.sum.dim_IntList(where_44, [0, 2, 3])
        sub_241: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_778);  convolution_5 = unsqueeze_778 = None
        mul_794: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_44, sub_241)
        sum_97: f32[64] = torch.ops.aten.sum.dim_IntList(mul_794, [0, 2, 3]);  mul_794 = None
        mul_795: f32[64] = torch.ops.aten.mul.Tensor(sum_96, 0.00390625)
        unsqueeze_779: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_795, 0);  mul_795 = None
        unsqueeze_780: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_779, 2);  unsqueeze_779 = None
        unsqueeze_781: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_780, 3);  unsqueeze_780 = None
        mul_796: f32[64] = torch.ops.aten.mul.Tensor(sum_97, 0.00390625)
        mul_797: f32[64] = torch.ops.aten.mul.Tensor(squeeze_16, squeeze_16)
        mul_798: f32[64] = torch.ops.aten.mul.Tensor(mul_796, mul_797);  mul_796 = mul_797 = None
        unsqueeze_782: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_798, 0);  mul_798 = None
        unsqueeze_783: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_782, 2);  unsqueeze_782 = None
        unsqueeze_784: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_783, 3);  unsqueeze_783 = None
        mul_799: f32[64] = torch.ops.aten.mul.Tensor(squeeze_16, primals_17);  primals_17 = None
        unsqueeze_785: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_799, 0);  mul_799 = None
        unsqueeze_786: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_785, 2);  unsqueeze_785 = None
        unsqueeze_787: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_786, 3);  unsqueeze_786 = None
        mul_800: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_241, unsqueeze_784);  sub_241 = unsqueeze_784 = None
        sub_243: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_44, mul_800);  where_44 = mul_800 = None
        sub_244: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_243, unsqueeze_781);  sub_243 = unsqueeze_781 = None
        mul_801: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_244, unsqueeze_787);  sub_244 = unsqueeze_787 = None
        mul_802: f32[64] = torch.ops.aten.mul.Tensor(sum_97, squeeze_16);  sum_97 = squeeze_16 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_47 = torch.ops.aten.convolution_backward.default(mul_801, relu_3, primals_16, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_801 = primals_16 = None
        getitem_249: f32[1, 256, 16, 16] = convolution_backward_47[0]
        getitem_250: f32[64, 256, 1, 1] = convolution_backward_47[1];  convolution_backward_47 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_295: f32[1, 256, 16, 16] = torch.ops.aten.add.Tensor(where_42, getitem_249);  where_42 = getitem_249 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:139, code: out = self.relu(out)
        le_45: b8[1, 256, 16, 16] = torch.ops.aten.le.Scalar(relu_3, 0);  relu_3 = None
        where_45: f32[1, 256, 16, 16] = torch.ops.aten.where.self(le_45, full_default, add_295);  le_45 = add_295 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:136, code: identity = self.downsample(x)
        sum_98: f32[256] = torch.ops.aten.sum.dim_IntList(where_45, [0, 2, 3])
        sub_245: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_790);  convolution_4 = unsqueeze_790 = None
        mul_803: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(where_45, sub_245)
        sum_99: f32[256] = torch.ops.aten.sum.dim_IntList(mul_803, [0, 2, 3]);  mul_803 = None
        mul_804: f32[256] = torch.ops.aten.mul.Tensor(sum_98, 0.00390625)
        unsqueeze_791: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_804, 0);  mul_804 = None
        unsqueeze_792: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_791, 2);  unsqueeze_791 = None
        unsqueeze_793: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_792, 3);  unsqueeze_792 = None
        mul_805: f32[256] = torch.ops.aten.mul.Tensor(sum_99, 0.00390625)
        mul_806: f32[256] = torch.ops.aten.mul.Tensor(squeeze_13, squeeze_13)
        mul_807: f32[256] = torch.ops.aten.mul.Tensor(mul_805, mul_806);  mul_805 = mul_806 = None
        unsqueeze_794: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_807, 0);  mul_807 = None
        unsqueeze_795: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_794, 2);  unsqueeze_794 = None
        unsqueeze_796: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_795, 3);  unsqueeze_795 = None
        mul_808: f32[256] = torch.ops.aten.mul.Tensor(squeeze_13, primals_14);  primals_14 = None
        unsqueeze_797: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_808, 0);  mul_808 = None
        unsqueeze_798: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_797, 2);  unsqueeze_797 = None
        unsqueeze_799: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_798, 3);  unsqueeze_798 = None
        mul_809: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_245, unsqueeze_796);  sub_245 = unsqueeze_796 = None
        sub_247: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(where_45, mul_809);  mul_809 = None
        sub_248: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(sub_247, unsqueeze_793);  sub_247 = None
        mul_810: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_248, unsqueeze_799);  sub_248 = unsqueeze_799 = None
        mul_811: f32[256] = torch.ops.aten.mul.Tensor(sum_99, squeeze_13);  sum_99 = squeeze_13 = None
        convolution_backward_48 = torch.ops.aten.convolution_backward.default(mul_810, getitem_2, primals_13, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_810 = primals_13 = None
        getitem_252: f32[1, 64, 16, 16] = convolution_backward_48[0]
        getitem_253: f32[256, 64, 1, 1] = convolution_backward_48[1];  convolution_backward_48 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:133, code: out = self.bn3(out)
        sub_249: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_802);  convolution_3 = unsqueeze_802 = None
        mul_812: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(where_45, sub_249)
        sum_101: f32[256] = torch.ops.aten.sum.dim_IntList(mul_812, [0, 2, 3]);  mul_812 = None
        mul_814: f32[256] = torch.ops.aten.mul.Tensor(sum_101, 0.00390625)
        mul_815: f32[256] = torch.ops.aten.mul.Tensor(squeeze_10, squeeze_10)
        mul_816: f32[256] = torch.ops.aten.mul.Tensor(mul_814, mul_815);  mul_814 = mul_815 = None
        unsqueeze_806: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_816, 0);  mul_816 = None
        unsqueeze_807: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_806, 2);  unsqueeze_806 = None
        unsqueeze_808: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_807, 3);  unsqueeze_807 = None
        mul_817: f32[256] = torch.ops.aten.mul.Tensor(squeeze_10, primals_11);  primals_11 = None
        unsqueeze_809: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_817, 0);  mul_817 = None
        unsqueeze_810: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_809, 2);  unsqueeze_809 = None
        unsqueeze_811: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_810, 3);  unsqueeze_810 = None
        mul_818: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_249, unsqueeze_808);  sub_249 = unsqueeze_808 = None
        sub_251: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(where_45, mul_818);  where_45 = mul_818 = None
        sub_252: f32[1, 256, 16, 16] = torch.ops.aten.sub.Tensor(sub_251, unsqueeze_793);  sub_251 = unsqueeze_793 = None
        mul_819: f32[1, 256, 16, 16] = torch.ops.aten.mul.Tensor(sub_252, unsqueeze_811);  sub_252 = unsqueeze_811 = None
        mul_820: f32[256] = torch.ops.aten.mul.Tensor(sum_101, squeeze_10);  sum_101 = squeeze_10 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:132, code: out = self.conv3(out)
        convolution_backward_49 = torch.ops.aten.convolution_backward.default(mul_819, relu_2, primals_10, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_819 = primals_10 = None
        getitem_255: f32[1, 64, 16, 16] = convolution_backward_49[0]
        getitem_256: f32[256, 64, 1, 1] = convolution_backward_49[1];  convolution_backward_49 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:130, code: out = self.relu(out)
        le_46: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_2, 0);  relu_2 = None
        where_46: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_46, full_default, getitem_255);  le_46 = getitem_255 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:129, code: out = self.bn2(out)
        sum_102: f32[64] = torch.ops.aten.sum.dim_IntList(where_46, [0, 2, 3])
        sub_253: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_814);  convolution_2 = unsqueeze_814 = None
        mul_821: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_46, sub_253)
        sum_103: f32[64] = torch.ops.aten.sum.dim_IntList(mul_821, [0, 2, 3]);  mul_821 = None
        mul_822: f32[64] = torch.ops.aten.mul.Tensor(sum_102, 0.00390625)
        unsqueeze_815: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_822, 0);  mul_822 = None
        unsqueeze_816: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_815, 2);  unsqueeze_815 = None
        unsqueeze_817: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_816, 3);  unsqueeze_816 = None
        mul_823: f32[64] = torch.ops.aten.mul.Tensor(sum_103, 0.00390625)
        mul_824: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, squeeze_7)
        mul_825: f32[64] = torch.ops.aten.mul.Tensor(mul_823, mul_824);  mul_823 = mul_824 = None
        unsqueeze_818: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_825, 0);  mul_825 = None
        unsqueeze_819: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_818, 2);  unsqueeze_818 = None
        unsqueeze_820: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_819, 3);  unsqueeze_819 = None
        mul_826: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, primals_8);  primals_8 = None
        unsqueeze_821: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_826, 0);  mul_826 = None
        unsqueeze_822: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_821, 2);  unsqueeze_821 = None
        unsqueeze_823: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_822, 3);  unsqueeze_822 = None
        mul_827: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_253, unsqueeze_820);  sub_253 = unsqueeze_820 = None
        sub_255: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_46, mul_827);  where_46 = mul_827 = None
        sub_256: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_255, unsqueeze_817);  sub_255 = unsqueeze_817 = None
        mul_828: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_256, unsqueeze_823);  sub_256 = unsqueeze_823 = None
        mul_829: f32[64] = torch.ops.aten.mul.Tensor(sum_103, squeeze_7);  sum_103 = squeeze_7 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:128, code: out = self.conv2(out)
        convolution_backward_50 = torch.ops.aten.convolution_backward.default(mul_828, relu_1, primals_7, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_828 = primals_7 = None
        getitem_258: f32[1, 64, 16, 16] = convolution_backward_50[0]
        getitem_259: f32[64, 64, 3, 3] = convolution_backward_50[1];  convolution_backward_50 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:126, code: out = self.relu(out)
        le_47: b8[1, 64, 16, 16] = torch.ops.aten.le.Scalar(relu_1, 0);  relu_1 = None
        where_47: f32[1, 64, 16, 16] = torch.ops.aten.where.self(le_47, full_default, getitem_258);  le_47 = getitem_258 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:125, code: out = self.bn1(out)
        sum_104: f32[64] = torch.ops.aten.sum.dim_IntList(where_47, [0, 2, 3])
        sub_257: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_826);  convolution_1 = unsqueeze_826 = None
        mul_830: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(where_47, sub_257)
        sum_105: f32[64] = torch.ops.aten.sum.dim_IntList(mul_830, [0, 2, 3]);  mul_830 = None
        mul_831: f32[64] = torch.ops.aten.mul.Tensor(sum_104, 0.00390625)
        unsqueeze_827: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_831, 0);  mul_831 = None
        unsqueeze_828: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_827, 2);  unsqueeze_827 = None
        unsqueeze_829: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_828, 3);  unsqueeze_828 = None
        mul_832: f32[64] = torch.ops.aten.mul.Tensor(sum_105, 0.00390625)
        mul_833: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, squeeze_4)
        mul_834: f32[64] = torch.ops.aten.mul.Tensor(mul_832, mul_833);  mul_832 = mul_833 = None
        unsqueeze_830: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_834, 0);  mul_834 = None
        unsqueeze_831: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_830, 2);  unsqueeze_830 = None
        unsqueeze_832: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_831, 3);  unsqueeze_831 = None
        mul_835: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, primals_5);  primals_5 = None
        unsqueeze_833: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_835, 0);  mul_835 = None
        unsqueeze_834: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_833, 2);  unsqueeze_833 = None
        unsqueeze_835: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_834, 3);  unsqueeze_834 = None
        mul_836: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_257, unsqueeze_832);  sub_257 = unsqueeze_832 = None
        sub_259: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(where_47, mul_836);  where_47 = mul_836 = None
        sub_260: f32[1, 64, 16, 16] = torch.ops.aten.sub.Tensor(sub_259, unsqueeze_829);  sub_259 = unsqueeze_829 = None
        mul_837: f32[1, 64, 16, 16] = torch.ops.aten.mul.Tensor(sub_260, unsqueeze_835);  sub_260 = unsqueeze_835 = None
        mul_838: f32[64] = torch.ops.aten.mul.Tensor(sum_105, squeeze_4);  sum_105 = squeeze_4 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        convolution_backward_51 = torch.ops.aten.convolution_backward.default(mul_837, getitem_2, primals_4, [0], [1, 1], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_837 = getitem_2 = primals_4 = None
        getitem_261: f32[1, 64, 16, 16] = convolution_backward_51[0]
        getitem_262: f32[64, 64, 1, 1] = convolution_backward_51[1];  convolution_backward_51 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:124, code: out = self.conv1(x)
        add_296: f32[1, 64, 16, 16] = torch.ops.aten.add.Tensor(getitem_252, getitem_261);  getitem_252 = getitem_261 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:235, code: x = self.maxpool(x)
        max_pool2d_with_indices_backward: f32[1, 64, 32, 32] = torch.ops.aten.max_pool2d_with_indices_backward.default(add_296, relu, [3, 3], [2, 2], [1, 1], [1, 1], False, getitem_3);  add_296 = getitem_3 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:234, code: x = self.relu(x)
        le_48: b8[1, 64, 32, 32] = torch.ops.aten.le.Scalar(relu, 0);  relu = None
        where_48: f32[1, 64, 32, 32] = torch.ops.aten.where.self(le_48, full_default, max_pool2d_with_indices_backward);  le_48 = full_default = max_pool2d_with_indices_backward = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:233, code: x = self.bn1(x)
        sum_106: f32[64] = torch.ops.aten.sum.dim_IntList(where_48, [0, 2, 3])
        sub_261: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(convolution, unsqueeze_838);  convolution = unsqueeze_838 = None
        mul_839: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(where_48, sub_261)
        sum_107: f32[64] = torch.ops.aten.sum.dim_IntList(mul_839, [0, 2, 3]);  mul_839 = None
        mul_840: f32[64] = torch.ops.aten.mul.Tensor(sum_106, 0.0009765625)
        unsqueeze_839: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_840, 0);  mul_840 = None
        unsqueeze_840: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_839, 2);  unsqueeze_839 = None
        unsqueeze_841: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_840, 3);  unsqueeze_840 = None
        mul_841: f32[64] = torch.ops.aten.mul.Tensor(sum_107, 0.0009765625)
        mul_842: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, squeeze_1)
        mul_843: f32[64] = torch.ops.aten.mul.Tensor(mul_841, mul_842);  mul_841 = mul_842 = None
        unsqueeze_842: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_843, 0);  mul_843 = None
        unsqueeze_843: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_842, 2);  unsqueeze_842 = None
        unsqueeze_844: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_843, 3);  unsqueeze_843 = None
        mul_844: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, primals_2);  primals_2 = None
        unsqueeze_845: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_844, 0);  mul_844 = None
        unsqueeze_846: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_845, 2);  unsqueeze_845 = None
        unsqueeze_847: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_846, 3);  unsqueeze_846 = None
        mul_845: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(sub_261, unsqueeze_844);  sub_261 = unsqueeze_844 = None
        sub_263: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(where_48, mul_845);  where_48 = mul_845 = None
        sub_264: f32[1, 64, 32, 32] = torch.ops.aten.sub.Tensor(sub_263, unsqueeze_841);  sub_263 = unsqueeze_841 = None
        mul_846: f32[1, 64, 32, 32] = torch.ops.aten.mul.Tensor(sub_264, unsqueeze_847);  sub_264 = unsqueeze_847 = None
        mul_847: f32[64] = torch.ops.aten.mul.Tensor(sum_107, squeeze_1);  sum_107 = squeeze_1 = None
        
        # File: /root/.cache/torch/hub/pytorch_vision_v0.10.0/torchvision/models/resnet.py:232, code: x = self.conv1(x)
        convolution_backward_52 = torch.ops.aten.convolution_backward.default(mul_846, primals_321, primals_1, [0], [2, 2], [3, 3], [1, 1], False, [0, 0], 1, [False, True, False]);  mul_846 = primals_321 = primals_1 = None
        getitem_265: f32[64, 3, 7, 7] = convolution_backward_52[1];  convolution_backward_52 = None
        return [getitem_265, mul_847, sum_106, getitem_262, mul_838, sum_104, getitem_259, mul_829, sum_102, getitem_256, mul_820, sum_98, getitem_253, mul_811, sum_98, getitem_250, mul_802, sum_96, getitem_247, mul_793, sum_94, getitem_244, mul_784, sum_92, getitem_241, mul_775, sum_90, getitem_238, mul_766, sum_88, getitem_235, mul_757, sum_86, getitem_232, mul_748, sum_84, getitem_229, mul_739, sum_82, getitem_226, mul_730, sum_78, getitem_223, mul_721, sum_78, getitem_220, mul_712, sum_76, getitem_217, mul_703, sum_74, getitem_214, mul_694, sum_72, getitem_211, mul_685, sum_70, getitem_208, mul_676, sum_68, getitem_205, mul_667, sum_66, getitem_202, mul_658, sum_64, getitem_199, mul_649, sum_62, getitem_196, mul_640, sum_60, getitem_193, mul_631, sum_58, getitem_190, mul_622, sum_56, getitem_187, mul_613, sum_52, getitem_184, mul_604, sum_52, getitem_181, mul_595, sum_50, getitem_178, mul_586, sum_48, getitem_175, mul_577, sum_46, getitem_172, mul_568, sum_44, getitem_169, mul_559, sum_42, getitem_166, mul_550, sum_40, getitem_163, mul_541, sum_38, getitem_160, mul_532, sum_36, getitem_157, mul_523, sum_34, getitem_154, mul_514, sum_32, getitem_151, mul_505, sum_30, getitem_148, mul_496, sum_28, getitem_145, mul_487, sum_26, getitem_142, mul_478, sum_24, getitem_139, mul_469, sum_22, getitem_136, mul_460, sum_20, getitem_133, mul_451, sum_18, getitem_130, mul_442, sum_14, getitem_127, mul_433, sum_14, getitem_124, mul_424, sum_12, getitem_121, mul_415, sum_10, getitem_118, mul_406, sum_8, getitem_115, mul_397, sum_6, getitem_112, mul_388, sum_4, getitem_109, mul_379, sum_2, permute_4, view_1, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]
        

